{
  "status": "success",
  "functions_generated": 6,
  "output_file": "automatedderivedmetricsagent_functions.py",
  "module_size": 14312,
  "function_code_content": "\"\"\"\nAutomated Derived Metrics Functions\n===================================\n\nGenerated by AutomatedDerivedMetricsAgent for experiment: Test Experiment\nDescription: Test experiment for derived metrics\nGenerated: 2025-08-27T16:22:14.083464+00:00\n\nThis module contains automatically generated calculation functions for derived metrics\nas specified in the framework's natural language descriptions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom typing import Optional, Dict, Any\n\n\ndef calculate_identity_tension(data, **kwargs):\n    \"\"\"\n    Calculate identity_tension: Conflict between tribal dominance and individual dignity dimensions\n\n    Formula: tribal_dominance * individual_dignity\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        **kwargs: Additional parameters\n        \n    Returns:\n        float: Calculated result or None if insufficient data\n    \"\"\"\n    import pandas as pd\n    \n    try:\n        # This calculation requires 'tribal_dominance' and 'individual_dignity' scores,\n        # as specified by the calculation's description. The function assumes these\n        # columns will be present in the provided data.\n        tribal_dominance = data['tribal_dominance']\n        individual_dignity = data['individual_dignity']\n\n        # Handle missing data gracefully by returning None if either value is null.\n        if pd.isna(tribal_dominance) or pd.isna(individual_dignity):\n            return None\n\n        # The tension is calculated as the product of the two dimension scores.\n        # Values are cast to float to ensure proper arithmetic.\n        return float(tribal_dominance) * float(individual_dignity)\n        \n    except Exception:\n        # A broad exception handler ensures production-level robustness. It will\n        # catch KeyErrors if the required columns are missing, TypeErrors if data\n        # is non-numeric, or any other unexpected issues, returning None.\n        return None\n\ndef calculate_emotional_balance(data, **kwargs):\n    \"\"\"\n    Calculate emotional_balance: Difference between hope and fear scores\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        **kwargs: Additional parameters\n        \n    Returns:\n        float: Calculated result or None if insufficient data\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # This calculation requires 'hope' and 'fear' scores, which are assumed\n        # to exist in the input data object despite not being listed in the\n        # provided metadata structure. The function is designed to be robust\n        # against their absence.\n        hope_score = data['hope']\n        fear_score = data['fear']\n\n        # Handle missing data gracefully as per requirements.\n        if pd.isna(hope_score) or pd.isna(fear_score):\n            return None\n\n        # Convert to float for calculation and handle non-numeric types.\n        result = float(hope_score) - float(fear_score)\n\n        # Ensure the final result is a finite number (i.e., not NaN or infinity).\n        if not np.isfinite(result):\n            return None\n            \n        return result\n        \n    except (KeyError, TypeError, ValueError):\n        # This block handles several failure modes:\n        # KeyError: If the required 'hope' or 'fear' columns are missing.\n        # TypeError/ValueError: If score values are not valid numbers.\n        return None\n    except Exception:\n        # A general fallback for any other unexpected errors.\n        return None\n\ndef calculate_success_climate(data, **kwargs):\n    \"\"\"\n    Calculate success_climate: Difference between compersion and envy scores.\n\n    Formula: success_climate = compersion - envy\n\n    Args:\n        data (pd.Series): A row of data containing the necessary scores.\n        **kwargs: Additional parameters (unused).\n\n    Returns:\n        float: The calculated score, or None if 'compersion' or 'envy' scores\n               are missing or invalid in the input data.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # The calculation requires 'compersion' and 'envy' scores.\n        # We use .get() to safely access these from the input data object,\n        # which returns None if a key is not found. This handles cases\n        # where the data row does not contain the necessary columns.\n        compersion_score = data.get('compersion')\n        envy_score = data.get('envy')\n\n        # Check if the required scores are missing (either not found by .get()\n        # which returns None, or present as a NaN value).\n        # pd.isna() robustly checks for both None and np.nan.\n        if pd.isna(compersion_score) or pd.isna(envy_score):\n            return None\n\n        # Convert scores to float to ensure correct arithmetic and handle\n        # cases where scores might be strings or integers.\n        # This will raise a ValueError if conversion is not possible,\n        # which is caught by the except block below.\n        compersion_val = float(compersion_score)\n        envy_val = float(envy_score)\n\n        # Perform the specified calculation.\n        result = compersion_val - envy_val\n        \n        # Ensure the final result is a finite number (i.e., not infinity).\n        if not np.isfinite(result):\n            return None\n\n        return result\n\n    except (ValueError, TypeError, AttributeError):\n        # This block handles several potential errors:\n        # - ValueError: If a score cannot be converted to a float.\n        # - TypeError: If the input data has an unexpected type.\n        # - AttributeError: If 'data' does not support the .get() method.\n        # In all these cases, the data is invalid for this calculation.\n        return None\n    except Exception:\n        # A general catch-all for any other unexpected errors, ensuring the\n        # function is robust and does not crash in production.\n        return None\n\ndef calculate_relational_climate(data, **kwargs):\n    \"\"\"\n    Calculate relational_climate: Difference between amity and enmity scores.\n\n    Formula: relational_climate = amity - enmity\n\n    Args:\n        data (pd.Series): A single row of data as a pandas Series, expected\n                          to contain 'amity' and 'enmity' scores.\n        **kwargs: Additional keyword arguments (not used).\n\n    Returns:\n        float: The calculated relational climate score. Returns None if\n               'amity' or 'enmity' columns are missing, or if their\n               values are non-numeric or NaN.\n    \"\"\"\n    import pandas as pd\n\n    try:\n        # The calculation is defined as the difference between amity and enmity.\n        # Therefore, the function must assume these columns exist, despite the\n        # provided data structure not listing them. The try/except block\n        # gracefully handles cases where these columns are missing.\n        amity_score = data['amity']\n        enmity_score = data['enmity']\n\n        # Check for missing data (NaN, None, etc.)\n        if pd.isna(amity_score) or pd.isna(enmity_score):\n            return None\n\n        # Ensure values are numeric before calculation\n        if not isinstance(amity_score, (int, float)) or not isinstance(enmity_score, (int, float)):\n            return None\n\n        # Calculate the difference and ensure the result is a float\n        relational_climate = float(amity_score - enmity_score)\n\n        return relational_climate\n\n    except (KeyError, TypeError, Exception):\n        # KeyError: Catches cases where 'amity' or 'enmity' columns do not exist.\n        # TypeError: Catches non-numeric data that cannot be subtracted.\n        # Exception: Catches any other unexpected errors for production robustness.\n        return None\n\ndef calculate_goal_orientation(data, **kwargs):\n    \"\"\"\n    Calculate goal_orientation: Difference between cohesive goals and fragmentative goals.\n\n    Formula: goal_orientation = cohesive_goals - fragmentative_goals\n\n    Args:\n        data (pd.Series): \n            A row of data containing the dimension scores.\n            It is expected to contain 'cohesive_goals' and 'fragmentative_goals'.\n        **kwargs: \n            Additional keyword arguments (unused).\n\n    Returns:\n        float: \n            The calculated score.\n        None: \n            If required columns are missing, or if data is non-numeric,\n            null, or results in a non-finite number (e.g., infinity).\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # Safely access data and convert to numeric, coercing errors to NaN\n        cohesive_val = pd.to_numeric(data.get('cohesive_goals'), errors='coerce')\n        fragmentative_val = pd.to_numeric(data.get('fragmentative_goals'), errors='coerce')\n\n        # Perform the calculation. The result will be NaN if either input was NaN.\n        result = cohesive_val - fragmentative_val\n\n        # Check if the result is a finite number (i.e., not NaN or infinity).\n        # This single check handles missing columns, non-numeric data, and infinities.\n        if np.isfinite(result):\n            return float(result)\n        else:\n            return None\n\n    except Exception:\n        # A broad exception handler for any other unexpected errors.\n        return None\n\ndef calculate_overall_cohesion_index(data, **kwargs):\n    \"\"\"\n    Calculate overall_cohesion_index: Comprehensive measure combining all dimensions.\n\n    This index measures the degree of uniformity across the six emotional\n    dimensions of the framework. A high value (approaching 1) indicates that the\n    emotional dimensions are at similar levels, suggesting a cohesive emotional\n    climate. A low value (approaching 0) indicates high variance between\n    dimensions, suggesting a fragmented or conflicted emotional climate.\n\n    The framework's six dimension scores are required for this calculation.\n    As specific column names were not provided in the data structure, this function\n    assumes they are named 'dimension_score_1' through 'dimension_score_6'.\n\n    Formula: OCI = 1 / (1 + \u03c3)\n    where \u03c3 is the sample standard deviation of the six emotional dimension scores.\n\n    Args:\n        data (pd.Series or pd.DataFrame): A single row of analysis data containing\n            the necessary dimension scores.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        float: Calculated Overall Cohesion Index, or None if data is insufficient\n               or contains non-numeric values.\n    \"\"\"\n    import pandas as pd\n\n    try:\n        # The framework is described as having six dimensions. As column names are\n        # not specified, placeholder names are used to define the function's\n        # requirements. The function will return None if these columns are not found.\n        dimension_columns = [\n            'dimension_score_1', 'dimension_score_2', 'dimension_score_3',\n            'dimension_score_4', 'dimension_score_5', 'dimension_score_6'\n        ]\n\n        # Ensure data is a single pandas Series for processing\n        if isinstance(data, pd.DataFrame):\n            if data.shape[0] != 1:\n                return None  # This function processes one row at a time\n            data = data.iloc[0]\n\n        if not isinstance(data, pd.Series):\n            return None\n\n        # Verify that all required dimension columns are present in the data\n        if not all(col in data.index for col in dimension_columns):\n            return None\n\n        # Extract scores, convert to numeric, and handle any conversion errors\n        scores = pd.to_numeric(data[dimension_columns], errors='coerce')\n\n        # If any score is missing (NaN) after conversion, calculation is not possible\n        if scores.isnull().any():\n            return None\n\n        # Calculate the sample standard deviation (ddof=1 is default for Series.std)\n        # This measures the dispersion of the emotional scores.\n        std_dev = scores.std()\n\n        # The result of std() could be NaN if there's only one data point,\n        # though our column check ensures we have more than one.\n        if pd.isna(std_dev):\n            return None\n\n        # The cohesion index is the inverse of 1 + standard deviation.\n        # This maps a std_dev of 0 (perfect cohesion) to an index of 1.\n        # As std_dev increases, the index approaches 0.\n        return 1.0 / (1.0 + std_dev)\n\n    except Exception:\n        # Broad exception catch for any unexpected errors during processing\n        return None\n\ndef calculate_all_derived_metrics(data: pd.DataFrame) -> Dict[str, Optional[float]]:\n    \"\"\"\n    Calculate all derived metrics for the given dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        Dictionary mapping metric names to calculated values\n    \"\"\"\n    results = {}\n    \n    # Get all calculation functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith('calculate_') and \n            name not in ['calculate_all_derived_metrics', 'calculate_derived_metrics']):\n            try:\n                results[name.replace('calculate_', '')] = obj(data)\n            except Exception as e:\n                results[name.replace('calculate_', '')] = None\n                \n    return results\n\n\ndef calculate_derived_metrics(data: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Template-compatible wrapper function for derived metrics calculation.\n    \n    This function is called by the universal notebook template and returns\n    the original data with additional derived metric columns.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        DataFrame with original data plus derived metric columns\n    \"\"\"\n    # Calculate all derived metrics\n    derived_metrics = calculate_all_derived_metrics(data)\n    \n    # Create a copy of the original data\n    result = data.copy()\n    \n    # Add derived metrics as new columns\n    for metric_name, metric_value in derived_metrics.items():\n        if metric_value is not None:\n            # For scalar metrics, broadcast to all rows\n            result[metric_name] = metric_value\n        else:\n            # For failed calculations, use NaN\n            result[metric_name] = np.nan\n    \n    return result\n",
  "cached_with_code": true
}