{
  "run_metadata": {
    "experiment_name": "speaker_character_pattern_analysis",
    "run_timestamp": "20250808T023910Z",
    "framework_version": "../../frameworks/reference/core/caf_v7.3.md",
    "model_used": "vertex_ai/gemini-2.5-pro",
    "total_artifacts": 31,
    "organized_artifacts": 12
  },
  "directory_structure": {
    "data/": "CSV files for external statistical analysis",
    "artifacts/analysis_plans/": "What the LLM planned to analyze",
    "artifacts/analysis_results/": "Raw analysis outputs from LLM",
    "artifacts/statistical_results/": "Mathematical computations and metrics",
    "artifacts/evidence/": "Curated quotes and supporting data",
    "artifacts/reports/": "Final synthesis outputs and reports",
    "artifacts/inputs/": "Framework, corpus, and experiment configuration",
    "technical/": "System logs and model interaction records"
  },
  "pipeline_stages": {
    "inputs_and_system": {
      "artifacts": 20,
      "total_size_mb": 0.2419729232788086
    },
    "analysis": {
      "artifacts": 9,
      "total_size_mb": 0.05303382873535156
    },
    "statistical_computation": {
      "artifacts": 1,
      "total_size_mb": 0.04106616973876953
    },
    "synthesis": {
      "artifacts": 1,
      "total_size_mb": 0.010816574096679688
    }
  },
  "artifact_descriptions": {
    "raw_analysis_response_v6_0be57ec3": "Raw analysis response from LLM with scores and reasoning",
    "raw_analysis_response_v6_1ddd1faf": "Raw analysis response from LLM with scores and reasoning",
    "raw_analysis_response_v6_321574d9": "Raw analysis response from LLM with scores and reasoning",
    "raw_analysis_response_v6_3257ebba": "Raw analysis response from LLM with scores and reasoning",
    "raw_analysis_response_v6_5f7d1d64": "Raw analysis response from LLM with scores and reasoning",
    "raw_analysis_response_v6_65bf7bed": "Raw analysis response from LLM with scores and reasoning",
    "raw_analysis_response_v6_67eeec09": "Raw analysis response from LLM with scores and reasoning",
    "raw_analysis_response_v6_ee0370bd": "Raw analysis response from LLM with scores and reasoning",
    "analysis_response_7f80c7b2.json": "Artifact of type analysis_json_v6",
    "analysis_plan_8805f0b5.md": "Analysis plan generated by LLM for systematic evaluation",
    "statistical_results_98c734eb.json": "Statistical computations and significance tests",
    "final_report_2025-08-08_d533898d.md": "Final research report with findings and implications"
  },
  "navigation_guide": {
    "primary_researcher": [
      "FINAL_REPORT.md",
      "data/scores.csv",
      "data/evidence.csv"
    ],
    "internal_reviewer": [
      "METHODOLOGY_SUMMARY.md",
      "STATISTICAL_SUMMARY.md"
    ],
    "replication_researcher": [
      "artifacts/",
      "technical/manifest.json",
      "README.md"
    ],
    "fraud_auditor": [
      "technical/manifest.json",
      "technical/logs/",
      "provenance.json"
    ],
    "llm_skeptic": [
      "technical/model_interactions/",
      "data/reliability_metrics.csv"
    ]
  }
}