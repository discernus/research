test_name,test_type,statistic_name,statistic_value,p_value,effect_size,degrees_of_freedom,sample_size,dependent_variable,grouping_variable,significance_level,interpretation,notes
descriptives,descriptive_stats,result_value,"{'type': 'descriptive_stats', 'columns_analyzed': ['dignity_score', 'tribalism_score', 'dignity_salience', 'tribalism_salience', 'dignity_confidence', 'tribalism_confidence', 'truth_score', 'manipulation_score', 'truth_salience', 'manipulation_salience', 'truth_confidence', 'manipulation_confidence', 'justice_score', 'resentment_score', 'justice_salience', 'resentment_salience', 'justice_confidence', 'resentment_confidence', 'hope_score', 'fear_score', 'hope_salience', 'fear_salience', 'hope_confidence', 'fear_confidence', 'pragmatism_score', 'fantasy_score', 'pragmatism_salience', 'fantasy_salience', 'pragmatism_confidence', 'fantasy_confidence'], 'results': {'dignity_score': {'count': 8, 'mean': 0.59375, 'std': 0.36098822695484134, 'min': 0.1, 'max': 0.9, 'median': 0.7749999999999999, 'q25': 0.2, 'q75': 0.9, 'skewness': -0.5598711282767638, 'kurtosis': -2.1069716888359826, 'data_type': 'numerical'}, 'tribalism_score': {'count': 8, 'mean': 0.5, 'std': 0.40970372570571395, 'min': 0.05, 'max': 0.9, 'median': 0.55, 'q25': 0.08750000000000001, 'q75': 0.9, 'skewness': -0.09763152612561686, 'kurtosis': -2.5379610683567226, 'data_type': 'numerical'}, 'dignity_salience': {'count': 8, 'mean': 0.6125, 'std': 0.2936835031117683, 'min': 0.1, 'max': 0.9, 'median': 0.7, 'q25': 0.45, 'q75': 0.85, 'skewness': -0.8227050694786424, 'kurtosis': -0.6083715906022125, 'data_type': 'numerical'}, 'tribalism_salience': {'count': 8, 'mean': 0.54375, 'std': 0.3940970692608612, 'min': 0.05, 'max': 0.9, 'median': 0.65, 'q25': 0.17500000000000002, 'q75': 0.9, 'skewness': -0.21935523428391665, 'kurtosis': -2.383834481450359, 'data_type': 'numerical'}, 'dignity_confidence': {'count': 8, 'mean': 0.8812500000000001, 'std': 0.0703942976586679, 'min': 0.8, 'max': 0.95, 'median': 0.9, 'q25': 0.8, 'q75': 0.95, 'skewness': -0.3391449970796682, 'kurtosis': -2.135281227173117, 'data_type': 'numerical'}, 'tribalism_confidence': {'count': 8, 'mean': 0.9125000000000001, 'std': 0.05175491695067653, 'min': 0.8, 'max': 0.95, 'median': 0.925, 'q25': 0.9, 'q75': 0.95, 'skewness': -1.674559090670789, 'kurtosis': 3.1360000000000294, 'data_type': 'numerical'}, 'truth_score': {'count': 8, 'mean': 0.6375, 'std': 0.2183542338233253, 'min': 0.3, 'max': 0.85, 'median': 0.7, 'q25': 0.475, 'q75': 0.8125, 'skewness': -0.4888459049531157, 'kurtosis': -1.5836384294912271, 'data_type': 'numerical'}, 'manipulation_score': {'count': 8, 'mean': 0.4375, 'std': 0.377728171346236, 'min': 0.05, 'max': 0.85, 'median': 0.425, 'q25': 0.08750000000000001, 'q75': 0.8, 'skewness': 0.017561019054726314, 'kurtosis': -2.6576975913258285, 'data_type': 'numerical'}, 'truth_salience': {'count': 8, 'mean': 0.625, 'std': 0.14638501094227999, 'min': 0.4, 'max': 0.8, 'median': 0.6499999999999999, 'q25': 0.5, 'q75': 0.75, 'skewness': -0.3415650255319862, 'kurtosis': -1.5330000000000004, 'data_type': 'numerical'}, 'manipulation_salience': {'count': 8, 'mean': 0.48125000000000007, 'std': 0.3769591679289871, 'min': 0.05, 'max': 0.9, 'median': 0.55, 'q25': 0.125, 'q75': 0.8, 'skewness': -0.11422156099745659, 'kurtosis': -2.4547112472806316, 'data_type': 'numerical'}, 'truth_confidence': {'count': 8, 'mean': 0.85, 'std': 0.08017837257372731, 'min': 0.7, 'max': 0.95, 'median': 0.875, 'q25': 0.8, 'q75': 0.9, 'skewness': -0.831479419283098, 'kurtosis': 0.38888888888889017, 'data_type': 'numerical'}, 'manipulation_confidence': {'count': 8, 'mean': 0.8999999999999999, 'std': 0.05345224838248485, 'min': 0.8, 'max': 0.95, 'median': 0.9, 'q25': 0.8875, 'q75': 0.95, 'skewness': -0.93541434669348, 'kurtosis': 0.349999999999989, 'data_type': 'numerical'}, 'justice_score': {'count': 8, 'mean': 0.7374999999999999, 'std': 0.2117107190754133, 'min': 0.3, 'max': 0.95, 'median': 0.775, 'q25': 0.6749999999999999, 'q75': 0.9, 'skewness': -1.3643363112429598, 'kurtosis': 2.0024571038554893, 'data_type': 'numerical'}, 'resentment_score': {'count': 8, 'mean': 0.6062500000000001, 'std': 0.3931897942288359, 'min': 0.1, 'max': 0.9, 'median': 0.875, 'q25': 0.17500000000000002, 'q75': 0.9, 'skewness': -0.6601345974722763, 'kurtosis': -2.146894179123407, 'data_type': 'numerical'}, 'justice_salience': {'count': 8, 'mean': 0.7250000000000001, 'std': 0.20528725518857022, 'min': 0.3, 'max': 0.9, 'median': 0.75, 'q25': 0.6749999999999999, 'q75': 0.9, 'skewness': -1.3705474893945353, 'kurtosis': 1.9948290721057225, 'data_type': 'numerical'}, 'resentment_salience': {'count': 8, 'mean': 0.61875, 'std': 0.379790825887845, 'min': 0.1, 'max': 0.9, 'median': 0.875, 'q25': 0.25, 'q75': 0.9, 'skewness': -0.7309485456700177, 'kurtosis': -1.8836173593383725, 'data_type': 'numerical'}, 'justice_confidence': {'count': 8, 'mean': 0.89375, 'std': 0.062321172737911205, 'min': 0.8, 'max': 0.95, 'median': 0.9, 'q25': 0.875, 'q75': 0.95, 'skewness': -0.876069861185597, 'kurtosis': -0.7058263971462493, 'data_type': 'numerical'}, 'resentment_confidence': {'count': 8, 'mean': 0.8999999999999999, 'std': 0.026726124191242432, 'min': 0.85, 'max': 0.95, 'median': 0.9, 'q25': 0.9, 'q75': 0.9, 'skewness': 0.0, 'kurtosis': 3.5000000000000018, 'data_type': 'numerical'}, 'hope_score': {'count': 8, 'mean': 0.6812499999999999, 'std': 0.22825033249858429, 'min': 0.2, 'max': 0.95, 'median': 0.725, 'q25': 0.6, 'q75': 0.8125, 'skewness': -1.3824851678178771, 'kurtosis': 2.6760066349019613, 'data_type': 'numerical'}, 'fear_score': {'count': 8, 'mean': 0.54375, 'std': 0.26109316892087175, 'min': 0.1, 'max': 0.8, 'median': 0.575, 'q25': 0.375, 'q75': 0.8, 'skewness': -0.5797748221648958, 'kurtosis': -0.7921846835545665, 'data_type': 'numerical'}, 'hope_salience': {'count': 8, 'mean': 0.65625, 'std': 0.22270656543019623, 'min': 0.2, 'max': 0.9, 'median': 0.725, 'q25': 0.575, 'q75': 0.8, 'skewness': -1.3387787419091597, 'kurtosis': 1.8461492593903852, 'data_type': 'numerical'}, 'fear_salience': {'count': 8, 'mean': 0.56, 'std': 0.2719243592303881, 'min': 0.08, 'max': 0.9, 'median': 0.55, 'q25': 0.4, 'q75': 0.8, 'skewness': -0.49245443058452487, 'kurtosis': -0.233966541569818, 'data_type': 'numerical'}, 'hope_confidence': {'count': 8, 'mean': 0.8625, 'std': 0.07905694150420949, 'min': 0.7, 'max': 0.95, 'median': 0.9, 'q25': 0.8375, 'q75': 0.9, 'skewness': -1.4094723285321948, 'kurtosis': 1.9382857142857217, 'data_type': 'numerical'}, 'fear_confidence': {'count': 8, 'mean': 0.86875, 'std': 0.03720119045714225, 'min': 0.8, 'max': 0.9, 'median': 0.875, 'q25': 0.85, 'q75': 0.9, 'skewness': -0.8237682964911408, 'kurtosis': -0.15150884495317918, 'data_type': 'numerical'}, 'pragmatism_score': {'count': 8, 'mean': 0.64375, 'std': 0.22109710213258918, 'min': 0.35, 'max': 0.85, 'median': 0.75, 'q25': 0.4, 'q75': 0.8125, 'skewness': -0.5103235146005998, 'kurtosis': -2.1270121974103953, 'data_type': 'numerical'}, 'fantasy_score': {'count': 8, 'mean': 0.33125, 'std': 0.3022977482076712, 'min': 0.05, 'max': 0.7, 'median': 0.25, 'q25': 0.05, 'q75': 0.625, 'skewness': 0.282076624739276, 'kurtosis': -2.2786265792470024, 'data_type': 'numerical'}, 'pragmatism_salience': {'count': 8, 'mean': 0.6062500000000001, 'std': 0.17410485346480148, 'min': 0.4, 'max': 0.8, 'median': 0.7, 'q25': 0.4, 'q75': 0.7124999999999999, 'skewness': -0.4910453149662421, 'kurtosis': -2.102716244325341, 'data_type': 'numerical'}, 'fantasy_salience': {'count': 8, 'mean': 0.3125, 'std': 0.2924648941081891, 'min': 0.05, 'max': 0.7, 'median': 0.2, 'q25': 0.05, 'q75': 0.6125, 'skewness': 0.4304354733567815, 'kurtosis': -2.1521733256044033, 'data_type': 'numerical'}, 'pragmatism_confidence': {'count': 8, 'mean': 0.8375, 'std': 0.0744023809142845, 'min': 0.7, 'max': 0.9, 'median': 0.8500000000000001, 'q25': 0.8, 'q75': 0.9, 'skewness': -0.8237682964911427, 'kurtosis': -0.15150884495316852, 'data_type': 'numerical'}, 'fantasy_confidence': {'count': 8, 'mean': 0.8374999999999999, 'std': 0.1246423454758225, 'min': 0.6, 'max': 0.95, 'median': 0.875, 'q25': 0.8125, 'q75': 0.9125, 'skewness': -1.2449413816847887, 'kurtosis': 0.6259215219976157, 'data_type': 'numerical'}}, 'provenance': {'input_columns': ['dignity_score', 'tribalism_score', 'dignity_salience', 'tribalism_salience', 'dignity_confidence', 'tribalism_confidence', 'truth_score', 'manipulation_score', 'truth_salience', 'manipulation_salience', 'truth_confidence', 'manipulation_confidence', 'justice_score', 'resentment_score', 'justice_salience', 'resentment_salience', 'justice_confidence', 'resentment_confidence', 'hope_score', 'fear_score', 'hope_salience', 'fear_salience', 'hope_confidence', 'fear_confidence', 'pragmatism_score', 'fantasy_score', 'pragmatism_salience', 'fantasy_salience', 'pragmatism_confidence', 'fantasy_confidence'], 'input_document_ids': ['alexandria_ocasio_cortez_2025_fighting_oligarchy.txt', 'bernie_sanders_2025_fighting_oligarchy.txt', 'cory_booker_2018_first_step_act.txt', 'jd_vance_2022_natcon_conference.txt', 'john_lewis_1963_march_on_washington.txt', 'john_mccain_2008_concession.txt', 'mitt_romney_2020_impeachment.txt', 'steve_king_2017_house_floor.txt'], 'filter_conditions': 'None'}}",,,,,,,,Generic descriptive_stats result,
