test_name,test_type,statistic_name,statistic_value,p_value,effect_size,degrees_of_freedom,sample_size,dependent_variable,grouping_variable,significance_level,interpretation,notes
task_01_calculate_derived_metrics,derived_metrics_calculation,result_value,"{'type': 'derived_metrics_calculation', 'success': True, 'calculated_metrics': {'dignity_tribalism_tension': [0.575, 0.625, 0.725, 0.6, 0.6499999999999999, 0.85, 0.6000000000000001, 0.55], 'truth_manipulation_tension': [0.4, 0.575, 0.725, 0.6499999999999999, 0.55, 0.75, 0.55, 0.25], 'justice_resentment_tension': [0.65, 0.575, 0.825, 0.55, 0.65, 0.75, 0.7250000000000001, 0.45], 'hope_fear_tension': [0.65, 0.55, 0.825, 0.7749999999999999, 0.6, 0.8500000000000001, 0.675, 0.35], 'pragmatism_fantasy_tension': [0.525, 0.775, 0.825, 0.65, 0.55, 0.825, 0.675, 0.5], 'virtue_index': [0.55, 0.7, 0.7699999999999999, 0.5199999999999999, 0.6, 0.74, 0.5, 0.34], 'pathology_index': [0.43, 0.45999999999999996, 0.2, 0.23000000000000004, 0.4, 0.12999999999999998, 0.21000000000000002, 0.4999999999999999], 'civic_character_index': [0.5599999999999999, 0.62, 0.7849999999999999, 0.645, 0.6, 0.805, 0.6450000000000001, 0.42000000000000004], 'salience_weighted_civic_character_index': [0.5672131147540985, 0.6249999999999999, 0.7861764705882353, 0.6608333333333333, 0.6100000000000001, 0.808, 0.6472222222222223, 0.4178571428571428]}, 'successful_calculations': ['dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension', 'virtue_index', 'pathology_index', 'civic_character_index', 'salience_weighted_civic_character_index'], 'failed_calculations': [], 'skipped_due_to_missing_inputs': [], 'formulas_used': ['dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension', 'civic_character_index', 'salience_weighted_civic_character_index', 'virtue_index', 'pathology_index'], 'input_columns': ['dignity_score', 'tribalism_score', 'truth_score', 'manipulation_score', 'justice_score', 'resentment_score', 'hope_score', 'fear_score', 'pragmatism_score', 'fantasy_score', 'dignity_salience', 'truth_salience', 'justice_salience', 'hope_salience', 'pragmatism_salience'], 'total_metrics': 9, 'success_rate': 1.0, 'calculation_source': 'framework_calculation_spec', 'provenance': {'input_columns': ['dignity_score', 'tribalism_score', 'truth_score', 'manipulation_score', 'justice_score', 'resentment_score', 'hope_score', 'fear_score', 'pragmatism_score', 'fantasy_score', 'dignity_salience', 'truth_salience', 'justice_salience', 'hope_salience', 'pragmatism_salience'], 'input_document_ids': ['alexandria_ocasio_cortez_2025_fighting_oligarchy.txt', 'bernie_sanders_2025_fighting_oligarchy.txt', 'cory_booker_2018_first_step_act.txt', 'jd_vance_2022_natcon_conference.txt', 'john_lewis_1963_march_on_washington.txt', 'john_mccain_2008_concession.txt', 'mitt_romney_2020_impeachment.txt', 'steve_king_2017_house_floor.txt'], 'filter_conditions': 'None'}}",,,,,,,,Generic derived_metrics_calculation result,
task_02_validate_calculated_metrics,metric_validation,result_value,"{'type': 'metric_validation', 'validation_rules': ['missing_data_check', 'range_check', 'consistency_check'], 'results': {'missing_data_check': {'status': 'completed', 'missing_data_by_column': {'aid': 0, 'expert_categorization': 0, 'political_party': 0, 'speaker': 0, 'leadership_type': 0, 'date': 0, 'era': 0, 'ideology': 0, 'context': 0, 'dignity_score': 0, 'tribalism_score': 0, 'dignity_salience': 0, 'tribalism_salience': 0, 'dignity_confidence': 0, 'tribalism_confidence': 0, 'truth_score': 0, 'manipulation_score': 0, 'truth_salience': 0, 'manipulation_salience': 0, 'truth_confidence': 0, 'manipulation_confidence': 0, 'justice_score': 0, 'resentment_score': 0, 'justice_salience': 0, 'resentment_salience': 0, 'justice_confidence': 0, 'resentment_confidence': 0, 'hope_score': 0, 'fear_score': 0, 'hope_salience': 0, 'fear_salience': 0, 'hope_confidence': 0, 'fear_confidence': 0, 'pragmatism_score': 0, 'fantasy_score': 0, 'pragmatism_salience': 0, 'fantasy_salience': 0, 'pragmatism_confidence': 0, 'fantasy_confidence': 0, 'gasket_version': 0, 'extraction_time_seconds': 0, 'dignity_tribalism_tension': 0, 'truth_manipulation_tension': 0, 'justice_resentment_tension': 0, 'hope_fear_tension': 0, 'pragmatism_fantasy_tension': 0, 'virtue_index': 0, 'pathology_index': 0, 'civic_character_index': 0, 'salience_weighted_civic_character_index': 0}, 'total_missing': 0}, 'range_check': {'status': 'completed', 'ranges': {'dignity_score': {'min': 0.4, 'max': 0.85, 'mean': 0.7062499999999999}, 'tribalism_score': {'min': 0.15, 'max': 0.65, 'mean': 0.4125}, 'dignity_salience': {'min': 0.6, 'max': 0.9, 'mean': 0.7625}, 'tribalism_salience': {'min': 0.3, 'max': 0.85, 'mean': 0.6}, 'dignity_confidence': {'min': 0.7, 'max': 0.95, 'mean': 0.825}, 'tribalism_confidence': {'min': 0.6, 'max': 0.9, 'mean': 0.7625}, 'truth_score': {'min': 0.2, 'max': 0.7, 'mean': 0.53125}, 'manipulation_score': {'min': 0.2, 'max': 0.7, 'mean': 0.41874999999999996}, 'truth_salience': {'min': 0.6, 'max': 0.8, 'mean': 0.7250000000000001}, 'manipulation_salience': {'min': 0.35, 'max': 0.9, 'mean': 0.58125}, 'truth_confidence': {'min': 0.3, 'max': 0.9, 'mean': 0.7125}, 'manipulation_confidence': {'min': 0.6, 'max': 0.9, 'mean': 0.73125}, 'justice_score': {'min': 0.2, 'max': 0.85, 'mean': 0.6312500000000001}, 'resentment_score': {'min': 0.1, 'max': 0.65, 'mean': 0.3375}, 'justice_salience': {'min': 0.3, 'max': 0.95, 'mean': 0.7562500000000001}, 'resentment_salience': {'min': 0.15, 'max': 0.8, 'mean': 0.4875}, 'justice_confidence': {'min': 0.5, 'max': 0.95, 'mean': 0.80625}, 'resentment_confidence': {'min': 0.4, 'max': 0.9, 'mean': 0.6625}, 'hope_score': {'min': 0.1, 'max': 0.8, 'mean': 0.575}, 'fear_score': {'min': 0.1, 'max': 0.5, 'mean': 0.25625}, 'hope_salience': {'min': 0.2, 'max': 0.85, 'mean': 0.65625}, 'fear_salience': {'min': 0.15, 'max': 0.6, 'mean': 0.35}, 'hope_confidence': {'min': 0.5, 'max': 0.95, 'mean': 0.75625}, 'fear_confidence': {'min': 0.45, 'max': 0.9, 'mean': 0.59375}, 'pragmatism_score': {'min': 0.3, 'max': 0.75, 'mean': 0.5062500000000001}, 'fantasy_score': {'min': 0.1, 'max': 0.3, 'mean': 0.175}, 'pragmatism_salience': {'min': 0.4, 'max': 0.8, 'mean': 0.575}, 'fantasy_salience': {'min': 0.1, 'max': 0.4, 'mean': 0.26875}, 'pragmatism_confidence': {'min': 0.4, 'max': 0.95, 'mean': 0.6875}, 'fantasy_confidence': {'min': 0.4, 'max': 0.9, 'mean': 0.51875}, 'extraction_time_seconds': {'min': 1.074596881866455, 'max': 1.405405044555664, 'mean': 1.1880815625190735}, 'dignity_tribalism_tension': {'min': 0.55, 'max': 0.85, 'mean': 0.6468750000000001}, 'truth_manipulation_tension': {'min': 0.25, 'max': 0.75, 'mean': 0.55625}, 'justice_resentment_tension': {'min': 0.45, 'max': 0.825, 'mean': 0.6468750000000001}, 'hope_fear_tension': {'min': 0.35, 'max': 0.8500000000000001, 'mean': 0.659375}, 'pragmatism_fantasy_tension': {'min': 0.5, 'max': 0.825, 'mean': 0.665625}, 'virtue_index': {'min': 0.34, 'max': 0.7699999999999999, 'mean': 0.59}, 'pathology_index': {'min': 0.12999999999999998, 'max': 0.4999999999999999, 'mean': 0.31999999999999995}, 'civic_character_index': {'min': 0.42000000000000004, 'max': 0.805, 'mean': 0.635}, 'salience_weighted_civic_character_index': {'min': 0.4178571428571428, 'max': 0.808, 'mean': 0.6402877854693789}}}, 'consistency_check': {'status': 'completed', 'notes': 'Basic consistency check completed'}}, 'quality_thresholds': {'completeness_threshold': 0.95, 'range_min': 0.0, 'range_max': 1.0}, 'provenance': {'input_columns': ['missing_data_check', 'range_check', 'consistency_check'], 'input_document_ids': ['alexandria_ocasio_cortez_2025_fighting_oligarchy.txt', 'bernie_sanders_2025_fighting_oligarchy.txt', 'cory_booker_2018_first_step_act.txt', 'jd_vance_2022_natcon_conference.txt', 'john_lewis_1963_march_on_washington.txt', 'john_mccain_2008_concession.txt', 'mitt_romney_2020_impeachment.txt', 'steve_king_2017_house_floor.txt'], 'filter_conditions': 'Validation rules applied as specified'}}",,,,,,,,Generic metric_validation result,
task_03_descriptive_statistics_overview,descriptive_stats,result_value,"{'type': 'descriptive_stats', 'columns_analyzed': ['dignity_score', 'tribalism_score', 'truth_score', 'manipulation_score', 'justice_score', 'resentment_score', 'hope_score', 'fear_score', 'pragmatism_score', 'fantasy_score', 'virtue_index', 'pathology_index', 'civic_character_index', 'salience_weighted_civic_character_index'], 'results': {'dignity_score': {'count': 8, 'mean': 0.7062499999999999, 'std': 0.14985111658862318, 'min': 0.4, 'max': 0.85, 'median': 0.725, 'q25': 0.6749999999999999, 'q75': 0.8125, 'skewness': -1.3061340521110256, 'kurtosis': 1.8034014600271098, 'data_type': 'numerical'}, 'tribalism_score': {'count': 8, 'mean': 0.4125, 'std': 0.18273712579237186, 'min': 0.15, 'max': 0.65, 'median': 0.45, 'q25': 0.275, 'q75': 0.525, 'skewness': -0.2428900342254404, 'kurtosis': -1.3695330149561045, 'data_type': 'numerical'}, 'truth_score': {'count': 8, 'mean': 0.53125, 'std': 0.17915974515977154, 'min': 0.2, 'max': 0.7, 'median': 0.55, 'q25': 0.4375, 'q75': 0.7, 'skewness': -0.8092947763895122, 'kurtosis': 0.03715560748296287, 'data_type': 'numerical'}, 'manipulation_score': {'count': 8, 'mean': 0.41874999999999996, 'std': 0.17915974515977154, 'min': 0.2, 'max': 0.7, 'median': 0.375, 'q25': 0.2875, 'q75': 0.5625, 'skewness': 0.43666984337563663, 'kurtosis': -1.254429637825678, 'data_type': 'numerical'}, 'justice_score': {'count': 8, 'mean': 0.6312500000000001, 'std': 0.21702123003456203, 'min': 0.2, 'max': 0.85, 'median': 0.675, 'q25': 0.5375000000000001, 'q75': 0.8, 'skewness': -1.1419154945062446, 'kurtosis': 1.1339720132072504, 'data_type': 'numerical'}, 'resentment_score': {'count': 8, 'mean': 0.3375, 'std': 0.23717082451262844, 'min': 0.1, 'max': 0.65, 'median': 0.325, 'q25': 0.1, 'q75': 0.525, 'skewness': 0.16463921786273442, 'kurtosis': -2.18615873015873, 'data_type': 'numerical'}, 'hope_score': {'count': 8, 'mean': 0.575, 'std': 0.23754698783308414, 'min': 0.1, 'max': 0.8, 'median': 0.6499999999999999, 'q25': 0.475, 'q75': 0.725, 'skewness': -1.2256069553317261, 'kurtosis': 1.2903060406986055, 'data_type': 'numerical'}, 'fear_score': {'count': 8, 'mean': 0.25625, 'std': 0.13741880719693564, 'min': 0.1, 'max': 0.5, 'median': 0.225, 'q25': 0.15, 'q75': 0.325, 'skewness': 0.8180201080965087, 'kurtosis': -0.264212061767517, 'data_type': 'numerical'}, 'pragmatism_score': {'count': 8, 'mean': 0.5062500000000001, 'std': 0.21286732957408, 'min': 0.3, 'max': 0.75, 'median': 0.45, 'q25': 0.3, 'q75': 0.75, 'skewness': 0.31449547914107484, 'kurtosis': -2.2038199422456275, 'data_type': 'numerical'}, 'fantasy_score': {'count': 8, 'mean': 0.175, 'std': 0.07559289460184544, 'min': 0.1, 'max': 0.3, 'median': 0.175, 'q25': 0.1, 'q75': 0.21250000000000002, 'skewness': 0.4960783708246114, 'kurtosis': -0.9953124999999989, 'data_type': 'numerical'}, 'virtue_index': {'count': 8, 'mean': 0.59, 'std': 0.1435270009440732, 'min': 0.34, 'max': 0.7699999999999999, 'median': 0.575, 'q25': 0.5149999999999999, 'q75': 0.71, 'skewness': -0.40083891030258395, 'kurtosis': -0.2940508732477811, 'data_type': 'numerical'}, 'pathology_index': {'count': 8, 'mean': 0.31999999999999995, 'std': 0.1420261545329893, 'min': 0.12999999999999998, 'max': 0.4999999999999999, 'median': 0.31500000000000006, 'q25': 0.20750000000000002, 'q75': 0.4375, 'skewness': -0.01515900019491929, 'kurtosis': -2.0823271192289483, 'data_type': 'numerical'}, 'civic_character_index': {'count': 8, 'mean': 0.635, 'std': 0.12241615206219433, 'min': 0.42000000000000004, 'max': 0.805, 'median': 0.6325000000000001, 'q25': 0.59, 'q75': 0.68, 'skewness': -0.21975704019140183, 'kurtosis': 0.4609455098641302, 'data_type': 'numerical'}, 'salience_weighted_civic_character_index': {'count': 8, 'mean': 0.6402877854693789, 'std': 0.12296774600614294, 'min': 0.4178571428571428, 'max': 0.808, 'median': 0.6361111111111111, 'q25': 0.5993032786885247, 'q75': 0.6921691176470588, 'skewness': -0.36827754979545796, 'kurtosis': 0.6804781777926747, 'data_type': 'numerical'}}, 'provenance': {'input_columns': ['dignity_score', 'tribalism_score', 'truth_score', 'manipulation_score', 'justice_score', 'resentment_score', 'hope_score', 'fear_score', 'pragmatism_score', 'fantasy_score', 'virtue_index', 'pathology_index', 'civic_character_index', 'salience_weighted_civic_character_index'], 'input_document_ids': ['alexandria_ocasio_cortez_2025_fighting_oligarchy.txt', 'bernie_sanders_2025_fighting_oligarchy.txt', 'cory_booker_2018_first_step_act.txt', 'jd_vance_2022_natcon_conference.txt', 'john_lewis_1963_march_on_washington.txt', 'john_mccain_2008_concession.txt', 'mitt_romney_2020_impeachment.txt', 'steve_king_2017_house_floor.txt'], 'filter_conditions': 'None'}}",,,,,,,,Generic descriptive_stats result,
task_05_hypothesis_testing_speaker_differentiation_skipped,one_way_anova,F_statistic,nan,nan,,,,civic_character_index,speaker,p >= 0.05,,
task_06_final_reporting_summary,summary_statistics,result_value,"{'type': 'summary_statistics', 'metrics': ['civic_character_index', 'salience_weighted_civic_character_index', 'virtue_index', 'pathology_index'], 'summary_types': ['mean', 'std', 'min', 'max', 'count'], 'results': {'civic_character_index': {'mean': 0.635, 'std': 0.12241615206219433, 'min': 0.42000000000000004, 'max': 0.805, 'count': 8}, 'salience_weighted_civic_character_index': {'mean': 0.6402877854693789, 'std': 0.12296774600614294, 'min': 0.4178571428571428, 'max': 0.808, 'count': 8}, 'virtue_index': {'mean': 0.59, 'std': 0.1435270009440732, 'min': 0.34, 'max': 0.7699999999999999, 'count': 8}, 'pathology_index': {'mean': 0.31999999999999995, 'std': 0.1420261545329893, 'min': 0.12999999999999998, 'max': 0.4999999999999999, 'count': 8}}, 'missing_metrics': [], 'provenance': {'input_columns': ['civic_character_index', 'salience_weighted_civic_character_index', 'virtue_index', 'pathology_index'], 'input_document_ids': ['alexandria_ocasio_cortez_2025_fighting_oligarchy.txt', 'bernie_sanders_2025_fighting_oligarchy.txt', 'cory_booker_2018_first_step_act.txt', 'jd_vance_2022_natcon_conference.txt', 'john_lewis_1963_march_on_washington.txt', 'john_mccain_2008_concession.txt', 'mitt_romney_2020_impeachment.txt', 'steve_king_2017_house_floor.txt'], 'filter_conditions': 'None'}}",,,,,,,,Generic summary_statistics result,
