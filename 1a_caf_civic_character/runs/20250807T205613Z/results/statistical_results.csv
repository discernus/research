test_name,test_type,statistic_name,statistic_value,p_value,effect_size,degrees_of_freedom,sample_size,dependent_variable,grouping_variable,significance_level,interpretation,notes
calculate_civic_character_index,derived_metrics_calculation,result_value,"{'type': 'derived_metrics_calculation', 'success': True, 'calculated_metrics': {'dignity_tribalism_tension': [0.575, 0.7, 0.7749999999999999, 0.3, 0.725, 0.875, 0.75, 0.45], 'truth_manipulation_tension': [0.47500000000000003, 0.55, 0.75, 0.4, 0.625, 0.825, 0.6499999999999999, 0.45], 'justice_resentment_tension': [0.625, 0.6000000000000001, 0.75, 0.47500000000000003, 0.575, 0.675, 0.8500000000000001, 0.6499999999999999], 'hope_fear_tension': [0.7250000000000001, 0.6, 0.7250000000000001, 0.525, 0.6499999999999999, 0.85, 0.65, 0.44999999999999996], 'pragmatism_fantasy_tension': [0.625, 0.75, 0.7749999999999999, 0.625, 0.7, 0.7749999999999999, 0.75, 0.55], 'virtue_index': [0.5700000000000001, 0.68, 0.8, 0.20999999999999996, 0.68, 0.6799999999999999, 0.6399999999999999, 0.42000000000000004], 'pathology_index': [0.36, 0.4, 0.29, 0.28, 0.36999999999999994, 0.08, 0.18, 0.4], 'civic_character_index': [0.6050000000000001, 0.64, 0.755, 0.465, 0.655, 0.8, 0.73, 0.51], 'salience_weighted_civic_character_index': [0.6113636363636363, 0.645, 0.754494382022472, 0.4964285714285714, 0.6513333333333333, 0.8203125, 0.7369565217391306, 0.5166666666666667]}, 'successful_calculations': ['dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension', 'virtue_index', 'pathology_index', 'civic_character_index', 'salience_weighted_civic_character_index'], 'failed_calculations': [], 'formulas_used': ['dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension', 'civic_character_index', 'salience_weighted_civic_character_index', 'virtue_index', 'pathology_index'], 'input_columns': ['dignity_score', 'tribalism_score', 'truth_score', 'manipulation_score', 'justice_score', 'resentment_score', 'hope_score', 'fear_score', 'pragmatism_score', 'fantasy_score', 'dignity_salience', 'tribalism_salience', 'truth_salience', 'manipulation_salience', 'justice_salience', 'resentment_salience', 'hope_salience', 'fear_salience', 'pragmatism_salience', 'fantasy_salience'], 'total_metrics': 9, 'success_rate': 1.0, 'calculation_source': 'framework_calculation_spec', 'provenance': {'input_columns': ['dignity_score', 'tribalism_score', 'truth_score', 'manipulation_score', 'justice_score', 'resentment_score', 'hope_score', 'fear_score', 'pragmatism_score', 'fantasy_score', 'dignity_salience', 'tribalism_salience', 'truth_salience', 'manipulation_salience', 'justice_salience', 'resentment_salience', 'hope_salience', 'fear_salience', 'pragmatism_salience', 'fantasy_salience'], 'input_document_ids': ['alexandria_ocasio_cortez_2025_fighting_oligarchy.txt', 'bernie_sanders_2025_fighting_oligarchy.txt', 'cory_booker_2018_first_step_act.txt', 'jd_vance_2022_natcon_conference.txt', 'john_lewis_1963_march_on_washington.txt', 'john_mccain_2008_concession.txt', 'mitt_romney_2020_impeachment.txt', 'steve_king_2017_house_floor.txt'], 'filter_conditions': 'None'}}",,,,,,,,Generic derived_metrics_calculation result,
calculate_virtue_pathology_indices,derived_metrics_calculation,result_value,"{'type': 'derived_metrics_calculation', 'success': True, 'calculated_metrics': {'dignity_tribalism_tension': [0.575, 0.7, 0.7749999999999999, 0.3, 0.725, 0.875, 0.75, 0.45], 'truth_manipulation_tension': [0.47500000000000003, 0.55, 0.75, 0.4, 0.625, 0.825, 0.6499999999999999, 0.45], 'justice_resentment_tension': [0.625, 0.6000000000000001, 0.75, 0.47500000000000003, 0.575, 0.675, 0.8500000000000001, 0.6499999999999999], 'hope_fear_tension': [0.7250000000000001, 0.6, 0.7250000000000001, 0.525, 0.6499999999999999, 0.85, 0.65, 0.44999999999999996], 'pragmatism_fantasy_tension': [0.625, 0.75, 0.7749999999999999, 0.625, 0.7, 0.7749999999999999, 0.75, 0.55], 'virtue_index': [0.5700000000000001, 0.68, 0.8, 0.20999999999999996, 0.68, 0.6799999999999999, 0.6399999999999999, 0.42000000000000004], 'pathology_index': [0.36, 0.4, 0.29, 0.28, 0.36999999999999994, 0.08, 0.18, 0.4], 'civic_character_index': [0.6050000000000001, 0.64, 0.755, 0.465, 0.655, 0.8, 0.73, 0.51]}, 'successful_calculations': ['dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension', 'virtue_index', 'pathology_index', 'civic_character_index'], 'failed_calculations': [{'metric': 'salience_weighted_civic_character_index', 'formula': '(dignity_tribalism_tension * dignity_salience + truth_manipulation_tension * truth_salience + justice_resentment_tension * justice_salience + hope_fear_tension * hope_salience + pragmatism_fantasy_tension * pragmatism_salience) / (dignity_salience + truth_salience + justice_salience + hope_salience + pragmatism_salience)', 'error': ""name 'dignity_salience' is not defined""}], 'formulas_used': ['dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension', 'civic_character_index', 'salience_weighted_civic_character_index', 'virtue_index', 'pathology_index'], 'input_columns': ['dignity_score', 'tribalism_score', 'truth_score', 'manipulation_score', 'justice_score', 'resentment_score', 'hope_score', 'fear_score', 'pragmatism_score', 'fantasy_score'], 'total_metrics': 9, 'success_rate': 0.8888888888888888, 'calculation_source': 'framework_calculation_spec', 'provenance': {'input_columns': ['dignity_score', 'tribalism_score', 'truth_score', 'manipulation_score', 'justice_score', 'resentment_score', 'hope_score', 'fear_score', 'pragmatism_score', 'fantasy_score'], 'input_document_ids': ['alexandria_ocasio_cortez_2025_fighting_oligarchy.txt', 'bernie_sanders_2025_fighting_oligarchy.txt', 'cory_booker_2018_first_step_act.txt', 'jd_vance_2022_natcon_conference.txt', 'john_lewis_1963_march_on_washington.txt', 'john_mccain_2008_concession.txt', 'mitt_romney_2020_impeachment.txt', 'steve_king_2017_house_floor.txt'], 'filter_conditions': 'None'}}",,,,,,,,Generic derived_metrics_calculation result,
calculate_tension_scores,derived_metrics_calculation,result_value,"{'type': 'derived_metrics_calculation', 'success': True, 'calculated_metrics': {'dignity_tribalism_tension': [0.575, 0.7, 0.7749999999999999, 0.3, 0.725, 0.875, 0.75, 0.45], 'truth_manipulation_tension': [0.47500000000000003, 0.55, 0.75, 0.4, 0.625, 0.825, 0.6499999999999999, 0.45], 'justice_resentment_tension': [0.625, 0.6000000000000001, 0.75, 0.47500000000000003, 0.575, 0.675, 0.8500000000000001, 0.6499999999999999], 'hope_fear_tension': [0.7250000000000001, 0.6, 0.7250000000000001, 0.525, 0.6499999999999999, 0.85, 0.65, 0.44999999999999996], 'pragmatism_fantasy_tension': [0.625, 0.75, 0.7749999999999999, 0.625, 0.7, 0.7749999999999999, 0.75, 0.55], 'virtue_index': [0.5700000000000001, 0.68, 0.8, 0.20999999999999996, 0.68, 0.6799999999999999, 0.6399999999999999, 0.42000000000000004], 'pathology_index': [0.36, 0.4, 0.29, 0.28, 0.36999999999999994, 0.08, 0.18, 0.4], 'civic_character_index': [0.6050000000000001, 0.64, 0.755, 0.465, 0.655, 0.8, 0.73, 0.51]}, 'successful_calculations': ['dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension', 'virtue_index', 'pathology_index', 'civic_character_index'], 'failed_calculations': [{'metric': 'salience_weighted_civic_character_index', 'formula': '(dignity_tribalism_tension * dignity_salience + truth_manipulation_tension * truth_salience + justice_resentment_tension * justice_salience + hope_fear_tension * hope_salience + pragmatism_fantasy_tension * pragmatism_salience) / (dignity_salience + truth_salience + justice_salience + hope_salience + pragmatism_salience)', 'error': ""name 'dignity_salience' is not defined""}], 'formulas_used': ['dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension', 'civic_character_index', 'salience_weighted_civic_character_index', 'virtue_index', 'pathology_index'], 'input_columns': ['dignity_score', 'tribalism_score', 'truth_score', 'manipulation_score', 'justice_score', 'resentment_score', 'hope_score', 'fear_score', 'pragmatism_score', 'fantasy_score'], 'total_metrics': 9, 'success_rate': 0.8888888888888888, 'calculation_source': 'framework_calculation_spec', 'provenance': {'input_columns': ['dignity_score', 'tribalism_score', 'truth_score', 'manipulation_score', 'justice_score', 'resentment_score', 'hope_score', 'fear_score', 'pragmatism_score', 'fantasy_score'], 'input_document_ids': ['alexandria_ocasio_cortez_2025_fighting_oligarchy.txt', 'bernie_sanders_2025_fighting_oligarchy.txt', 'cory_booker_2018_first_step_act.txt', 'jd_vance_2022_natcon_conference.txt', 'john_lewis_1963_march_on_washington.txt', 'john_mccain_2008_concession.txt', 'mitt_romney_2020_impeachment.txt', 'steve_king_2017_house_floor.txt'], 'filter_conditions': 'None'}}",,,,,,,,Generic derived_metrics_calculation result,
validate_derived_metrics,metric_validation,result_value,"{'type': 'metric_validation', 'validation_rules': ['missing_data_check', 'range_check', 'consistency_check'], 'results': {'missing_data_check': {'status': 'completed', 'missing_data_by_column': {'aid': 0, 'expert_categorization': 0, 'political_party': 0, 'speaker': 0, 'leadership_type': 0, 'date': 0, 'era': 0, 'ideology': 0, 'context': 0, 'dignity_score': 0, 'tribalism_score': 0, 'dignity_salience': 0, 'tribalism_salience': 0, 'dignity_confidence': 0, 'tribalism_confidence': 0, 'truth_score': 0, 'manipulation_score': 0, 'truth_salience': 0, 'manipulation_salience': 0, 'truth_confidence': 0, 'manipulation_confidence': 0, 'justice_score': 0, 'resentment_score': 0, 'justice_salience': 0, 'resentment_salience': 0, 'justice_confidence': 0, 'resentment_confidence': 0, 'hope_score': 0, 'fear_score': 0, 'hope_salience': 0, 'fear_salience': 0, 'hope_confidence': 0, 'fear_confidence': 0, 'pragmatism_score': 0, 'fantasy_score': 0, 'pragmatism_salience': 0, 'fantasy_salience': 0, 'pragmatism_confidence': 0, 'fantasy_confidence': 0, 'gasket_version': 0, 'extraction_time_seconds': 0, 'dignity_tribalism_tension': 0, 'truth_manipulation_tension': 0, 'justice_resentment_tension': 0, 'hope_fear_tension': 0, 'pragmatism_fantasy_tension': 0, 'virtue_index': 0, 'pathology_index': 0, 'civic_character_index': 0, 'salience_weighted_civic_character_index': 0}, 'total_missing': 0}, 'range_check': {'status': 'completed', 'ranges': {'dignity_score': {'min': 0.15, 'max': 0.85, 'mean': 0.65}, 'tribalism_score': {'min': 0.1, 'max': 0.55, 'mean': 0.36250000000000004}, 'dignity_salience': {'min': 0.3, 'max': 0.95, 'mean': 0.7250000000000001}, 'tribalism_salience': {'min': 0.2, 'max': 0.85, 'mean': 0.58125}, 'dignity_confidence': {'min': 0.6, 'max': 0.9, 'mean': 0.81875}, 'tribalism_confidence': {'min': 0.6, 'max': 0.95, 'mean': 0.76875}, 'truth_score': {'min': 0.2, 'max': 0.75, 'mean': 0.53125}, 'manipulation_score': {'min': 0.05, 'max': 0.5, 'mean': 0.35}, 'truth_salience': {'min': 0.4, 'max': 0.85, 'mean': 0.58125}, 'manipulation_salience': {'min': 0.1, 'max': 0.75, 'mean': 0.55}, 'truth_confidence': {'min': 0.6, 'max': 0.85, 'mean': 0.75}, 'manipulation_confidence': {'min': 0.6, 'max': 0.9, 'mean': 0.73125}, 'justice_score': {'min': 0.05, 'max': 0.9, 'mean': 0.65}, 'resentment_score': {'min': 0.1, 'max': 0.65, 'mean': 0.35000000000000003}, 'justice_salience': {'min': 0.15, 'max': 1.0, 'mean': 0.6812499999999999}, 'resentment_salience': {'min': 0.2, 'max': 0.7, 'mean': 0.49375}, 'justice_confidence': {'min': 0.4, 'max': 0.95, 'mean': 0.8125}, 'resentment_confidence': {'min': 0.55, 'max': 0.8, 'mean': 0.6875}, 'hope_score': {'min': 0.3, 'max': 0.8, 'mean': 0.5625}, 'fear_score': {'min': 0.05, 'max': 0.4, 'mean': 0.26875000000000004}, 'hope_salience': {'min': 0.3, 'max': 0.9, 'mean': 0.625}, 'fear_salience': {'min': 0.1, 'max': 0.65, 'mean': 0.38125}, 'hope_confidence': {'min': 0.5, 'max': 0.95, 'mean': 0.76875}, 'fear_confidence': {'min': 0.4, 'max': 0.75, 'mean': 0.60625}, 'pragmatism_score': {'min': 0.35, 'max': 0.7, 'mean': 0.53125}, 'fantasy_score': {'min': 0.05, 'max': 0.3, 'mean': 0.14375000000000002}, 'pragmatism_salience': {'min': 0.4, 'max': 0.75, 'mean': 0.59375}, 'fantasy_salience': {'min': 0.1, 'max': 0.3, 'mean': 0.225}, 'pragmatism_confidence': {'min': 0.5, 'max': 0.85, 'mean': 0.74375}, 'fantasy_confidence': {'min': 0.3, 'max': 0.65, 'mean': 0.49375}, 'extraction_time_seconds': {'min': 1.027845859527588, 'max': 1.2694668769836426, 'mean': 1.1716606318950653}, 'dignity_tribalism_tension': {'min': 0.3, 'max': 0.875, 'mean': 0.6437499999999999}, 'truth_manipulation_tension': {'min': 0.4, 'max': 0.825, 'mean': 0.590625}, 'justice_resentment_tension': {'min': 0.47500000000000003, 'max': 0.8500000000000001, 'mean': 0.65}, 'hope_fear_tension': {'min': 0.44999999999999996, 'max': 0.85, 'mean': 0.6468750000000001}, 'pragmatism_fantasy_tension': {'min': 0.55, 'max': 0.7749999999999999, 'mean': 0.69375}, 'virtue_index': {'min': 0.20999999999999996, 'max': 0.8, 'mean': 0.585}, 'pathology_index': {'min': 0.08, 'max': 0.4, 'mean': 0.29500000000000004}, 'civic_character_index': {'min': 0.465, 'max': 0.8, 'mean': 0.645}, 'salience_weighted_civic_character_index': {'min': 0.4964285714285714, 'max': 0.8203125, 'mean': 0.6540694514442262}}}, 'consistency_check': {'status': 'completed', 'notes': 'Basic consistency check completed'}}, 'quality_thresholds': {'missing_data_check': {'max_allowed_missing_percentage': 0.05}, 'range_check': {'min_value': 0.0, 'max_value': 1.0}, 'consistency_check': {'logic': 'Ensure tension scores are consistent with individual dimension scores'}}, 'provenance': {'input_columns': ['missing_data_check', 'range_check', 'consistency_check'], 'input_document_ids': ['alexandria_ocasio_cortez_2025_fighting_oligarchy.txt', 'bernie_sanders_2025_fighting_oligarchy.txt', 'cory_booker_2018_first_step_act.txt', 'jd_vance_2022_natcon_conference.txt', 'john_lewis_1963_march_on_washington.txt', 'john_mccain_2008_concession.txt', 'mitt_romney_2020_impeachment.txt', 'steve_king_2017_house_floor.txt'], 'filter_conditions': 'Validation rules applied as specified'}}",,,,,,,,Generic metric_validation result,
describe_all_dimensions_and_metrics,summary_statistics,result_value,"{'type': 'summary_statistics', 'metrics': ['dignity_score', 'tribalism_score', 'truth_score', 'manipulation_score', 'justice_score', 'resentment_score', 'hope_score', 'fear_score', 'pragmatism_score', 'fantasy_score', 'dignity_salience', 'tribalism_salience', 'truth_salience', 'manipulation_salience', 'justice_salience', 'resentment_salience', 'hope_salience', 'fear_salience', 'pragmatism_salience', 'fantasy_salience', 'dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension', 'civic_character_index', 'salience_weighted_civic_character_index', 'virtue_index', 'pathology_index'], 'summary_types': ['mean', 'std', 'min', 'max', 'count'], 'results': {'dignity_score': {'mean': 0.65, 'std': 0.247847879612821, 'min': 0.15, 'max': 0.85, 'count': 8}, 'tribalism_score': {'mean': 0.36250000000000004, 'std': 0.1663687814121731, 'min': 0.1, 'max': 0.55, 'count': 8}, 'truth_score': {'mean': 0.53125, 'std': 0.18310321055155127, 'min': 0.2, 'max': 0.75, 'count': 8}, 'manipulation_score': {'mean': 0.35, 'std': 0.1511857892036909, 'min': 0.05, 'max': 0.5, 'count': 8}, 'justice_score': {'mean': 0.65, 'std': 0.27386127875258304, 'min': 0.05, 'max': 0.9, 'count': 8}, 'resentment_score': {'mean': 0.35000000000000003, 'std': 0.22200386097028646, 'min': 0.1, 'max': 0.65, 'count': 8}, 'hope_score': {'mean': 0.5625, 'std': 0.1941096891671599, 'min': 0.3, 'max': 0.8, 'count': 8}, 'fear_score': {'mean': 0.26875000000000004, 'std': 0.11933596033288302, 'min': 0.05, 'max': 0.4, 'count': 8}, 'pragmatism_score': {'mean': 0.53125, 'std': 0.14623244705409455, 'min': 0.35, 'max': 0.7, 'count': 8}, 'fantasy_score': {'mean': 0.14375000000000002, 'std': 0.07763237542601485, 'min': 0.05, 'max': 0.3, 'count': 8}, 'dignity_salience': {'mean': 0.7250000000000001, 'std': 0.20354009783964297, 'min': 0.3, 'max': 0.95, 'count': 8}, 'tribalism_salience': {'mean': 0.58125, 'std': 0.22668023418778394, 'min': 0.2, 'max': 0.85, 'count': 8}, 'truth_salience': {'mean': 0.58125, 'std': 0.15103807466993213, 'min': 0.4, 'max': 0.85, 'count': 8}, 'manipulation_salience': {'mean': 0.55, 'std': 0.20177781274036477, 'min': 0.1, 'max': 0.75, 'count': 8}, 'justice_salience': {'mean': 0.6812499999999999, 'std': 0.306987086745634, 'min': 0.15, 'max': 1.0, 'count': 8}, 'resentment_salience': {'mean': 0.49375, 'std': 0.20777305613852545, 'min': 0.2, 'max': 0.7, 'count': 8}, 'hope_salience': {'mean': 0.625, 'std': 0.20354009783964297, 'min': 0.3, 'max': 0.9, 'count': 8}, 'fear_salience': {'mean': 0.38125, 'std': 0.1771550975033701, 'min': 0.1, 'max': 0.65, 'count': 8}, 'pragmatism_salience': {'mean': 0.59375, 'std': 0.1293872923766914, 'min': 0.4, 'max': 0.75, 'count': 8}, 'fantasy_salience': {'mean': 0.225, 'std': 0.08864052604279182, 'min': 0.1, 'max': 0.3, 'count': 8}, 'dignity_tribalism_tension': {'mean': 0.6437499999999999, 'std': 0.18980723303996008, 'min': 0.3, 'max': 0.875, 'count': 8}, 'truth_manipulation_tension': {'mean': 0.590625, 'std': 0.14936622060272814, 'min': 0.4, 'max': 0.825, 'count': 8}, 'justice_resentment_tension': {'mean': 0.65, 'std': 0.11338934190276818, 'min': 0.47500000000000003, 'max': 0.8500000000000001, 'count': 8}, 'hope_fear_tension': {'mean': 0.6468750000000001, 'std': 0.12495534916807, 'min': 0.44999999999999996, 'max': 0.85, 'count': 8}, 'pragmatism_fantasy_tension': {'mean': 0.69375, 'std': 0.0842509008006103, 'min': 0.55, 'max': 0.7749999999999999, 'count': 8}, 'civic_character_index': {'mean': 0.645, 'std': 0.11692488431223086, 'min': 0.465, 'max': 0.8, 'count': 8}, 'salience_weighted_civic_character_index': {'mean': 0.6540694514442262, 'std': 0.11353783796419535, 'min': 0.4964285714285714, 'max': 0.8203125, 'count': 8}, 'virtue_index': {'mean': 0.585, 'std': 0.1868536478484852, 'min': 0.20999999999999996, 'max': 0.8, 'count': 8}, 'pathology_index': {'mean': 0.29500000000000004, 'std': 0.114392806966672, 'min': 0.08, 'max': 0.4, 'count': 8}}, 'missing_metrics': [], 'provenance': {'input_columns': ['dignity_score', 'tribalism_score', 'truth_score', 'manipulation_score', 'justice_score', 'resentment_score', 'hope_score', 'fear_score', 'pragmatism_score', 'fantasy_score', 'dignity_salience', 'tribalism_salience', 'truth_salience', 'manipulation_salience', 'justice_salience', 'resentment_salience', 'hope_salience', 'fear_salience', 'pragmatism_salience', 'fantasy_salience', 'dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension', 'civic_character_index', 'salience_weighted_civic_character_index', 'virtue_index', 'pathology_index'], 'input_document_ids': ['alexandria_ocasio_cortez_2025_fighting_oligarchy.txt', 'bernie_sanders_2025_fighting_oligarchy.txt', 'cory_booker_2018_first_step_act.txt', 'jd_vance_2022_natcon_conference.txt', 'john_lewis_1963_march_on_washington.txt', 'john_mccain_2008_concession.txt', 'mitt_romney_2020_impeachment.txt', 'steve_king_2017_house_floor.txt'], 'filter_conditions': 'None'}}",,,,,,,,Generic summary_statistics result,
anova_speaker_differentiation_dimensions,one_way_anova,F_statistic,nan,nan,,,,dignity_score,speaker,p >= 0.05,,
anova_speaker_differentiation_truth,one_way_anova,F_statistic,nan,nan,,,,truth_score,speaker,p >= 0.05,,
anova_speaker_differentiation_justice,one_way_anova,F_statistic,nan,nan,,,,justice_score,speaker,p >= 0.05,,
anova_speaker_differentiation_hope,one_way_anova,F_statistic,nan,nan,,,,hope_score,speaker,p >= 0.05,,
anova_speaker_differentiation_pragmatism,one_way_anova,F_statistic,nan,nan,,,,pragmatism_score,speaker,p >= 0.05,,
anova_speaker_differentiation_civic_index,one_way_anova,F_statistic,nan,nan,,,,civic_character_index,speaker,p >= 0.05,,
anova_mc_sci_coherence_patterns,one_way_anova,F_statistic,nan,nan,,,,salience_weighted_civic_character_index,speaker,p >= 0.05,,
describe_speaker_differences,descriptive_stats_grouped,result_value,"{'type': 'descriptive_stats_grouped', 'grouping_variable': 'speaker', 'groups': {'Alexandria Ocasio-Cortez': {'dignity_score': {'count': 1, 'mean': 0.7, 'std': nan, 'min': 0.7, 'max': 0.7, 'data_type': 'numerical'}, 'tribalism_score': {'count': 1, 'mean': 0.55, 'std': nan, 'min': 0.55, 'max': 0.55, 'data_type': 'numerical'}, 'truth_score': {'count': 1, 'mean': 0.4, 'std': nan, 'min': 0.4, 'max': 0.4, 'data_type': 'numerical'}, 'manipulation_score': {'count': 1, 'mean': 0.45, 'std': nan, 'min': 0.45, 'max': 0.45, 'data_type': 'numerical'}, 'justice_score': {'count': 1, 'mean': 0.75, 'std': nan, 'min': 0.75, 'max': 0.75, 'data_type': 'numerical'}, 'resentment_score': {'count': 1, 'mean': 0.5, 'std': nan, 'min': 0.5, 'max': 0.5, 'data_type': 'numerical'}, 'hope_score': {'count': 1, 'mean': 0.65, 'std': nan, 'min': 0.65, 'max': 0.65, 'data_type': 'numerical'}, 'fear_score': {'count': 1, 'mean': 0.2, 'std': nan, 'min': 0.2, 'max': 0.2, 'data_type': 'numerical'}, 'pragmatism_score': {'count': 1, 'mean': 0.35, 'std': nan, 'min': 0.35, 'max': 0.35, 'data_type': 'numerical'}, 'fantasy_score': {'count': 1, 'mean': 0.1, 'std': nan, 'min': 0.1, 'max': 0.1, 'data_type': 'numerical'}, 'civic_character_index': {'count': 1, 'mean': 0.6050000000000001, 'std': nan, 'min': 0.6050000000000001, 'max': 0.6050000000000001, 'data_type': 'numerical'}, 'salience_weighted_civic_character_index': {'count': 1, 'mean': 0.6113636363636363, 'std': nan, 'min': 0.6113636363636363, 'max': 0.6113636363636363, 'data_type': 'numerical'}, 'virtue_index': {'count': 1, 'mean': 0.5700000000000001, 'std': nan, 'min': 0.5700000000000001, 'max': 0.5700000000000001, 'data_type': 'numerical'}, 'pathology_index': {'count': 1, 'mean': 0.36, 'std': nan, 'min': 0.36, 'max': 0.36, 'data_type': 'numerical'}}, 'Bernie Sanders': {'dignity_score': {'count': 1, 'mean': 0.8, 'std': nan, 'min': 0.8, 'max': 0.8, 'data_type': 'numerical'}, 'tribalism_score': {'count': 1, 'mean': 0.4, 'std': nan, 'min': 0.4, 'max': 0.4, 'data_type': 'numerical'}, 'truth_score': {'count': 1, 'mean': 0.6, 'std': nan, 'min': 0.6, 'max': 0.6, 'data_type': 'numerical'}, 'manipulation_score': {'count': 1, 'mean': 0.5, 'std': nan, 'min': 0.5, 'max': 0.5, 'data_type': 'numerical'}, 'justice_score': {'count': 1, 'mean': 0.8, 'std': nan, 'min': 0.8, 'max': 0.8, 'data_type': 'numerical'}, 'resentment_score': {'count': 1, 'mean': 0.6, 'std': nan, 'min': 0.6, 'max': 0.6, 'data_type': 'numerical'}, 'hope_score': {'count': 1, 'mean': 0.5, 'std': nan, 'min': 0.5, 'max': 0.5, 'data_type': 'numerical'}, 'fear_score': {'count': 1, 'mean': 0.3, 'std': nan, 'min': 0.3, 'max': 0.3, 'data_type': 'numerical'}, 'pragmatism_score': {'count': 1, 'mean': 0.7, 'std': nan, 'min': 0.7, 'max': 0.7, 'data_type': 'numerical'}, 'fantasy_score': {'count': 1, 'mean': 0.2, 'std': nan, 'min': 0.2, 'max': 0.2, 'data_type': 'numerical'}, 'civic_character_index': {'count': 1, 'mean': 0.64, 'std': nan, 'min': 0.64, 'max': 0.64, 'data_type': 'numerical'}, 'salience_weighted_civic_character_index': {'count': 1, 'mean': 0.645, 'std': nan, 'min': 0.645, 'max': 0.645, 'data_type': 'numerical'}, 'virtue_index': {'count': 1, 'mean': 0.68, 'std': nan, 'min': 0.68, 'max': 0.68, 'data_type': 'numerical'}, 'pathology_index': {'count': 1, 'mean': 0.4, 'std': nan, 'min': 0.4, 'max': 0.4, 'data_type': 'numerical'}}, 'Cory Booker': {'dignity_score': {'count': 1, 'mean': 0.85, 'std': nan, 'min': 0.85, 'max': 0.85, 'data_type': 'numerical'}, 'tribalism_score': {'count': 1, 'mean': 0.3, 'std': nan, 'min': 0.3, 'max': 0.3, 'data_type': 'numerical'}, 'truth_score': {'count': 1, 'mean': 0.75, 'std': nan, 'min': 0.75, 'max': 0.75, 'data_type': 'numerical'}, 'manipulation_score': {'count': 1, 'mean': 0.25, 'std': nan, 'min': 0.25, 'max': 0.25, 'data_type': 'numerical'}, 'justice_score': {'count': 1, 'mean': 0.9, 'std': nan, 'min': 0.9, 'max': 0.9, 'data_type': 'numerical'}, 'resentment_score': {'count': 1, 'mean': 0.4, 'std': nan, 'min': 0.4, 'max': 0.4, 'data_type': 'numerical'}, 'hope_score': {'count': 1, 'mean': 0.8, 'std': nan, 'min': 0.8, 'max': 0.8, 'data_type': 'numerical'}, 'fear_score': {'count': 1, 'mean': 0.35, 'std': nan, 'min': 0.35, 'max': 0.35, 'data_type': 'numerical'}, 'pragmatism_score': {'count': 1, 'mean': 0.7, 'std': nan, 'min': 0.7, 'max': 0.7, 'data_type': 'numerical'}, 'fantasy_score': {'count': 1, 'mean': 0.15, 'std': nan, 'min': 0.15, 'max': 0.15, 'data_type': 'numerical'}, 'civic_character_index': {'count': 1, 'mean': 0.755, 'std': nan, 'min': 0.755, 'max': 0.755, 'data_type': 'numerical'}, 'salience_weighted_civic_character_index': {'count': 1, 'mean': 0.754494382022472, 'std': nan, 'min': 0.754494382022472, 'max': 0.754494382022472, 'data_type': 'numerical'}, 'virtue_index': {'count': 1, 'mean': 0.8, 'std': nan, 'min': 0.8, 'max': 0.8, 'data_type': 'numerical'}, 'pathology_index': {'count': 1, 'mean': 0.29, 'std': nan, 'min': 0.29, 'max': 0.29, 'data_type': 'numerical'}}, 'J.D. Vance': {'dignity_score': {'count': 1, 'mean': 0.15, 'std': nan, 'min': 0.15, 'max': 0.15, 'data_type': 'numerical'}, 'tribalism_score': {'count': 1, 'mean': 0.55, 'std': nan, 'min': 0.55, 'max': 0.55, 'data_type': 'numerical'}, 'truth_score': {'count': 1, 'mean': 0.2, 'std': nan, 'min': 0.2, 'max': 0.2, 'data_type': 'numerical'}, 'manipulation_score': {'count': 1, 'mean': 0.4, 'std': nan, 'min': 0.4, 'max': 0.4, 'data_type': 'numerical'}, 'justice_score': {'count': 1, 'mean': 0.05, 'std': nan, 'min': 0.05, 'max': 0.05, 'data_type': 'numerical'}, 'resentment_score': {'count': 1, 'mean': 0.1, 'std': nan, 'min': 0.1, 'max': 0.1, 'data_type': 'numerical'}, 'hope_score': {'count': 1, 'mean': 0.3, 'std': nan, 'min': 0.3, 'max': 0.3, 'data_type': 'numerical'}, 'fear_score': {'count': 1, 'mean': 0.25, 'std': nan, 'min': 0.25, 'max': 0.25, 'data_type': 'numerical'}, 'pragmatism_score': {'count': 1, 'mean': 0.35, 'std': nan, 'min': 0.35, 'max': 0.35, 'data_type': 'numerical'}, 'fantasy_score': {'count': 1, 'mean': 0.1, 'std': nan, 'min': 0.1, 'max': 0.1, 'data_type': 'numerical'}, 'civic_character_index': {'count': 1, 'mean': 0.465, 'std': nan, 'min': 0.465, 'max': 0.465, 'data_type': 'numerical'}, 'salience_weighted_civic_character_index': {'count': 1, 'mean': 0.4964285714285714, 'std': nan, 'min': 0.4964285714285714, 'max': 0.4964285714285714, 'data_type': 'numerical'}, 'virtue_index': {'count': 1, 'mean': 0.20999999999999996, 'std': nan, 'min': 0.20999999999999996, 'max': 0.20999999999999996, 'data_type': 'numerical'}, 'pathology_index': {'count': 1, 'mean': 0.28, 'std': nan, 'min': 0.28, 'max': 0.28, 'data_type': 'numerical'}}, 'John Lewis': {'dignity_score': {'count': 1, 'mean': 0.75, 'std': nan, 'min': 0.75, 'max': 0.75, 'data_type': 'numerical'}, 'tribalism_score': {'count': 1, 'mean': 0.3, 'std': nan, 'min': 0.3, 'max': 0.3, 'data_type': 'numerical'}, 'truth_score': {'count': 1, 'mean': 0.6, 'std': nan, 'min': 0.6, 'max': 0.6, 'data_type': 'numerical'}, 'manipulation_score': {'count': 1, 'mean': 0.35, 'std': nan, 'min': 0.35, 'max': 0.35, 'data_type': 'numerical'}, 'justice_score': {'count': 1, 'mean': 0.8, 'std': nan, 'min': 0.8, 'max': 0.8, 'data_type': 'numerical'}, 'resentment_score': {'count': 1, 'mean': 0.65, 'std': nan, 'min': 0.65, 'max': 0.65, 'data_type': 'numerical'}, 'hope_score': {'count': 1, 'mean': 0.7, 'std': nan, 'min': 0.7, 'max': 0.7, 'data_type': 'numerical'}, 'fear_score': {'count': 1, 'mean': 0.4, 'std': nan, 'min': 0.4, 'max': 0.4, 'data_type': 'numerical'}, 'pragmatism_score': {'count': 1, 'mean': 0.55, 'std': nan, 'min': 0.55, 'max': 0.55, 'data_type': 'numerical'}, 'fantasy_score': {'count': 1, 'mean': 0.15, 'std': nan, 'min': 0.15, 'max': 0.15, 'data_type': 'numerical'}, 'civic_character_index': {'count': 1, 'mean': 0.655, 'std': nan, 'min': 0.655, 'max': 0.655, 'data_type': 'numerical'}, 'salience_weighted_civic_character_index': {'count': 1, 'mean': 0.6513333333333333, 'std': nan, 'min': 0.6513333333333333, 'max': 0.6513333333333333, 'data_type': 'numerical'}, 'virtue_index': {'count': 1, 'mean': 0.68, 'std': nan, 'min': 0.68, 'max': 0.68, 'data_type': 'numerical'}, 'pathology_index': {'count': 1, 'mean': 0.36999999999999994, 'std': nan, 'min': 0.36999999999999994, 'max': 0.36999999999999994, 'data_type': 'numerical'}}, 'John McCain': {'dignity_score': {'count': 1, 'mean': 0.85, 'std': nan, 'min': 0.85, 'max': 0.85, 'data_type': 'numerical'}, 'tribalism_score': {'count': 1, 'mean': 0.1, 'std': nan, 'min': 0.1, 'max': 0.1, 'data_type': 'numerical'}, 'truth_score': {'count': 1, 'mean': 0.7, 'std': nan, 'min': 0.7, 'max': 0.7, 'data_type': 'numerical'}, 'manipulation_score': {'count': 1, 'mean': 0.05, 'std': nan, 'min': 0.05, 'max': 0.05, 'data_type': 'numerical'}, 'justice_score': {'count': 1, 'mean': 0.5, 'std': nan, 'min': 0.5, 'max': 0.5, 'data_type': 'numerical'}, 'resentment_score': {'count': 1, 'mean': 0.15, 'std': nan, 'min': 0.15, 'max': 0.15, 'data_type': 'numerical'}, 'hope_score': {'count': 1, 'mean': 0.75, 'std': nan, 'min': 0.75, 'max': 0.75, 'data_type': 'numerical'}, 'fear_score': {'count': 1, 'mean': 0.05, 'std': nan, 'min': 0.05, 'max': 0.05, 'data_type': 'numerical'}, 'pragmatism_score': {'count': 1, 'mean': 0.6, 'std': nan, 'min': 0.6, 'max': 0.6, 'data_type': 'numerical'}, 'fantasy_score': {'count': 1, 'mean': 0.05, 'std': nan, 'min': 0.05, 'max': 0.05, 'data_type': 'numerical'}, 'civic_character_index': {'count': 1, 'mean': 0.8, 'std': nan, 'min': 0.8, 'max': 0.8, 'data_type': 'numerical'}, 'salience_weighted_civic_character_index': {'count': 1, 'mean': 0.8203125, 'std': nan, 'min': 0.8203125, 'max': 0.8203125, 'data_type': 'numerical'}, 'virtue_index': {'count': 1, 'mean': 0.6799999999999999, 'std': nan, 'min': 0.6799999999999999, 'max': 0.6799999999999999, 'data_type': 'numerical'}, 'pathology_index': {'count': 1, 'mean': 0.08, 'std': nan, 'min': 0.08, 'max': 0.08, 'data_type': 'numerical'}}, 'Mitt Romney': {'dignity_score': {'count': 1, 'mean': 0.7, 'std': nan, 'min': 0.7, 'max': 0.7, 'data_type': 'numerical'}, 'tribalism_score': {'count': 1, 'mean': 0.2, 'std': nan, 'min': 0.2, 'max': 0.2, 'data_type': 'numerical'}, 'truth_score': {'count': 1, 'mean': 0.6, 'std': nan, 'min': 0.6, 'max': 0.6, 'data_type': 'numerical'}, 'manipulation_score': {'count': 1, 'mean': 0.3, 'std': nan, 'min': 0.3, 'max': 0.3, 'data_type': 'numerical'}, 'justice_score': {'count': 1, 'mean': 0.8, 'std': nan, 'min': 0.8, 'max': 0.8, 'data_type': 'numerical'}, 'resentment_score': {'count': 1, 'mean': 0.1, 'std': nan, 'min': 0.1, 'max': 0.1, 'data_type': 'numerical'}, 'hope_score': {'count': 1, 'mean': 0.5, 'std': nan, 'min': 0.5, 'max': 0.5, 'data_type': 'numerical'}, 'fear_score': {'count': 1, 'mean': 0.2, 'std': nan, 'min': 0.2, 'max': 0.2, 'data_type': 'numerical'}, 'pragmatism_score': {'count': 1, 'mean': 0.6, 'std': nan, 'min': 0.6, 'max': 0.6, 'data_type': 'numerical'}, 'fantasy_score': {'count': 1, 'mean': 0.1, 'std': nan, 'min': 0.1, 'max': 0.1, 'data_type': 'numerical'}, 'civic_character_index': {'count': 1, 'mean': 0.73, 'std': nan, 'min': 0.73, 'max': 0.73, 'data_type': 'numerical'}, 'salience_weighted_civic_character_index': {'count': 1, 'mean': 0.7369565217391306, 'std': nan, 'min': 0.7369565217391306, 'max': 0.7369565217391306, 'data_type': 'numerical'}, 'virtue_index': {'count': 1, 'mean': 0.6399999999999999, 'std': nan, 'min': 0.6399999999999999, 'max': 0.6399999999999999, 'data_type': 'numerical'}, 'pathology_index': {'count': 1, 'mean': 0.18, 'std': nan, 'min': 0.18, 'max': 0.18, 'data_type': 'numerical'}}, 'Steve King': {'dignity_score': {'count': 1, 'mean': 0.4, 'std': nan, 'min': 0.4, 'max': 0.4, 'data_type': 'numerical'}, 'tribalism_score': {'count': 1, 'mean': 0.5, 'std': nan, 'min': 0.5, 'max': 0.5, 'data_type': 'numerical'}, 'truth_score': {'count': 1, 'mean': 0.4, 'std': nan, 'min': 0.4, 'max': 0.4, 'data_type': 'numerical'}, 'manipulation_score': {'count': 1, 'mean': 0.5, 'std': nan, 'min': 0.5, 'max': 0.5, 'data_type': 'numerical'}, 'justice_score': {'count': 1, 'mean': 0.6, 'std': nan, 'min': 0.6, 'max': 0.6, 'data_type': 'numerical'}, 'resentment_score': {'count': 1, 'mean': 0.3, 'std': nan, 'min': 0.3, 'max': 0.3, 'data_type': 'numerical'}, 'hope_score': {'count': 1, 'mean': 0.3, 'std': nan, 'min': 0.3, 'max': 0.3, 'data_type': 'numerical'}, 'fear_score': {'count': 1, 'mean': 0.4, 'std': nan, 'min': 0.4, 'max': 0.4, 'data_type': 'numerical'}, 'pragmatism_score': {'count': 1, 'mean': 0.4, 'std': nan, 'min': 0.4, 'max': 0.4, 'data_type': 'numerical'}, 'fantasy_score': {'count': 1, 'mean': 0.3, 'std': nan, 'min': 0.3, 'max': 0.3, 'data_type': 'numerical'}, 'civic_character_index': {'count': 1, 'mean': 0.51, 'std': nan, 'min': 0.51, 'max': 0.51, 'data_type': 'numerical'}, 'salience_weighted_civic_character_index': {'count': 1, 'mean': 0.5166666666666667, 'std': nan, 'min': 0.5166666666666667, 'max': 0.5166666666666667, 'data_type': 'numerical'}, 'virtue_index': {'count': 1, 'mean': 0.42000000000000004, 'std': nan, 'min': 0.42000000000000004, 'max': 0.42000000000000004, 'data_type': 'numerical'}, 'pathology_index': {'count': 1, 'mean': 0.4, 'std': nan, 'min': 0.4, 'max': 0.4, 'data_type': 'numerical'}}}, 'provenance': {'input_columns': ['dignity_score', 'tribalism_score', 'truth_score', 'manipulation_score', 'justice_score', 'resentment_score', 'hope_score', 'fear_score', 'pragmatism_score', 'fantasy_score', 'civic_character_index', 'salience_weighted_civic_character_index', 'virtue_index', 'pathology_index', 'speaker'], 'input_document_ids': ['alexandria_ocasio_cortez_2025_fighting_oligarchy.txt', 'bernie_sanders_2025_fighting_oligarchy.txt', 'cory_booker_2018_first_step_act.txt', 'jd_vance_2022_natcon_conference.txt', 'john_lewis_1963_march_on_washington.txt', 'john_mccain_2008_concession.txt', 'mitt_romney_2020_impeachment.txt', 'steve_king_2017_house_floor.txt'], 'filter_conditions': 'Grouped by speaker'}}",,,,,,,,Generic descriptive_stats_grouped result,
