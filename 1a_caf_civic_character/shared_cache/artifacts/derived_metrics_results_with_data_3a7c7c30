{
  "generation_metadata": {
    "status": "success",
    "functions_generated": 6,
    "output_file": "automatedderivedmetricsagent_functions.py",
    "module_size": 14420,
    "function_code_content": "\"\"\"\nAutomated Derived Metrics Functions\n===================================\n\nGenerated by AutomatedDerivedMetricsAgent for experiment: Test Experiment\nDescription: Test experiment for derived metrics\nGenerated: 2025-08-23T16:52:29.799909+00:00\n\nThis module contains automatically generated calculation functions for derived metrics\nas specified in the framework's natural language descriptions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom typing import Optional, Dict, Any\n\n\ndef calculate_identity_tension(data, **kwargs):\n    \"\"\"\n    Calculate identity_tension: Conflict between tribal dominance and individual dignity dimensions.\n\n    Formula: |dim_tribal_dominance - dim_individual_dignity|\n\n    Args:\n        data: pandas DataFrame (expected as a single row or pandas Series representing a single row)\n              containing the required dimension scores.\n              Must contain 'dim_tribal_dominance' and 'dim_individual_dignity' columns/indices.\n        **kwargs: Additional parameters (not used in this calculation).\n\n    Returns:\n        float: The calculated identity tension, or None if required data is missing or invalid.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    # Define the generic column names based on the problem description:\n    # \"No analysis data available - use generic column names\"\n    TRIBAL_DOMINANCE_COL = 'dim_tribal_dominance'\n    INDIVIDUAL_DIGNITY_COL = 'dim_individual_dignity'\n\n    try:\n        tribal_dominance_score = None\n        individual_dignity_score = None\n\n        # Determine if 'data' is a pandas Series (single row) or a single-row DataFrame\n        if isinstance(data, pd.Series):\n            if TRIBAL_DOMINANCE_COL in data and INDIVIDUAL_DIGNITY_COL in data:\n                tribal_dominance_score = data[TRIBAL_DOMINANCE_COL]\n                individual_dignity_score = data[INDIVIDUAL_DIGNITY_COL]\n            else:\n                # Required columns/indices not found in Series\n                return None\n        elif isinstance(data, pd.DataFrame) and len(data) == 1:\n            if TRIBAL_DOMINANCE_COL in data.columns and INDIVIDUAL_DIGNITY_COL in data.columns:\n                # Extract scalar values from the single-row DataFrame\n                tribal_dominance_score = data[TRIBAL_DOMINANCE_COL].iloc[0]\n                individual_dignity_score = data[INDIVIDUAL_DIGNITY_COL].iloc[0]\n            else:\n                # Required columns not found in DataFrame\n                return None\n        else:\n            # 'data' is not in the expected single row/Series format\n            return None\n\n        # Handle missing (NaN) values gracefully for the extracted scores\n        if pd.isna(tribal_dominance_score) or pd.isna(individual_dignity_score):\n            return None\n\n        # Ensure values are numeric. Attempt conversion to float.\n        try:\n            tribal_dominance_score = float(tribal_dominance_score)\n            individual_dignity_score = float(individual_dignity_score)\n        except (ValueError, TypeError):\n            # If conversion fails, it means the data contains non-numeric values that weren't NaN\n            return None\n\n        # Calculate the tension using the specified formula: absolute difference\n        # This formula quantifies the magnitude of conflict or disparity between the two dimensions.\n        identity_tension_value = abs(tribal_dominance_score - individual_dignity_score)\n\n        return float(identity_tension_value)\n\n    except Exception:\n        # Catch any unexpected errors during processing and return None\n        return None\n\ndef calculate_emotional_balance(data, **kwargs):\n    \"\"\"\n    Calculate emotional_balance: Difference between hope and fear scores\n\n    Formula: emotional_balance = hope - fear\n\n    Args:\n        data (pd.Series): A single row of data containing the necessary columns.\n        **kwargs: Additional parameters (not used in this calculation).\n\n    Returns:\n        float: The calculated emotional balance score, or None if input data is missing or invalid.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # Based on the description \"Difference between hope and fear scores\",\n        # the required columns are inferred to be 'hope' and 'fear'.\n        hope_col = 'hope'\n        fear_col = 'fear'\n\n        # Ensure the input is a pandas Series\n        if not isinstance(data, pd.Series):\n            # Attempt to convert if it's a single-row DataFrame\n            if isinstance(data, pd.DataFrame) and len(data) == 1:\n                data = data.iloc[0]\n            else:\n                return None\n\n        # Check for the presence of required columns\n        if hope_col not in data.index or fear_col not in data.index:\n            return None\n\n        hope_score = data[hope_col]\n        fear_score = data[fear_col]\n\n        # Check for missing or non-numeric values\n        if pd.isna(hope_score) or pd.isna(fear_score):\n            return None\n        \n        # Ensure values are numeric before calculation\n        if not all(isinstance(score, (int, float, np.number)) for score in [hope_score, fear_score]):\n             return None\n\n        # Calculate the difference\n        emotional_balance = float(hope_score) - float(fear_score)\n\n        return emotional_balance\n\n    except (AttributeError, KeyError, TypeError, ValueError):\n        # Catch potential errors from invalid data types or structures\n        return None\n\ndef calculate_success_climate(data, **kwargs):\n    \"\"\"\n    Calculate success_climate: Difference between compersion and envy scores\n\n    Formula: success_climate = compersion - envy\n    \n    Args:\n        data (pd.Series): A row of data containing compersion and envy scores.\n        **kwargs: Additional parameters (unused).\n        \n    Returns:\n        float: Calculated result or None if insufficient data.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # The calculation requires 'compersion' and 'envy' columns.\n        compersion_score = data['compersion']\n        envy_score = data['envy']\n        \n        # The subtraction will result in NaN if either input is missing or non-numeric.\n        result = compersion_score - envy_score\n        \n        # Return None if the result is NaN, otherwise return the float value.\n        # This gracefully handles missing data (NaNs) in the input columns.\n        if pd.isna(result):\n            return None\n        else:\n            return float(result)\n            \n    except (KeyError, TypeError):\n        # A KeyError occurs if required columns are missing.\n        # A TypeError occurs if data is not of a numeric type.\n        return None\n    except Exception:\n        # Catch any other unexpected errors during execution.\n        return None\n\ndef calculate_relational_climate(data, **kwargs):\n    \"\"\"\n    Calculate relational_climate: Difference between amity and enmity scores\n\n    Formula: relational_climate = amity_score - enmity_score\n\n    Args:\n        data (pd.Series): A single row of analysis data containing the necessary columns.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        float: The calculated relational climate score, or None if input data is missing or invalid.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # The calculation requires 'amity_score' and 'enmity_score'.\n        # These are inferred from the function's description as no explicit column names were provided.\n        amity_score = data['amity_score']\n        enmity_score = data['enmity_score']\n\n        # Check for missing values (NaN, None)\n        if pd.isna(amity_score) or pd.isna(enmity_score):\n            return None\n\n        # Ensure values are numeric before calculation\n        relational_climate = float(amity_score) - float(enmity_score)\n\n        return relational_climate\n\n    except (KeyError, TypeError, ValueError):\n        # KeyError: If 'amity_score' or 'enmity_score' columns are not in the data.\n        # TypeError: If the data in the columns is not numeric.\n        # ValueError: If conversion to float fails for another reason.\n        return None\n    except Exception:\n        # Catch any other unexpected errors.\n        return None\n\ndef calculate_goal_orientation(data, **kwargs):\n    \"\"\"\n    Calculate goal_orientation: Difference between cohesive goals and fragmentative goals\n\n    Formula: cohesive_goals - fragmentative_goals\n    \n    Args:\n        data: pandas DataFrame with dimension scores (expected as a single row or Series)\n        **kwargs: Additional parameters\n        \n    Returns:\n        float: Calculated result or None if insufficient data\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    # As per instructions, generic column names are inferred from the calculation \n    # description because no specific column names were provided in the data structure.\n    COHESIVE_COL = 'cohesive_goals'\n    FRAGMENTATIVE_COL = 'fragmentative_goals'\n    \n    try:\n        # Retrieve values from the data Series/row\n        cohesive_value = data[COHESIVE_COL]\n        fragmentative_value = data[FRAGMENTATIVE_COL]\n\n        # Check for any missing values (NaN, None, etc.)\n        if pd.isna(cohesive_value) or pd.isna(fragmentative_value):\n            return None\n\n        # Ensure values are numeric and calculate the difference\n        # The float conversion will raise an error for non-numeric types,\n        # which is caught by the except block.\n        result = float(cohesive_value) - float(fragmentative_value)\n        \n        return result\n\n    except Exception:\n        # Catches KeyError for missing columns, TypeError/ValueError for\n        # non-numeric data, and any other unexpected errors.\n        return None\n\ndef calculate_overall_cohesion_index(data, **kwargs):\n    \"\"\"\n    Calculate overall_cohesion_index: Comprehensive measure combining all dimensions.\n\n    This function assesses the internal consistency or 'cohesion' of the various\n    civic dimension scores provided for a single entity (e.g., a document or speaker).\n    A high cohesion index indicates that the dimension scores are closely clustered,\n    suggesting a consistent civic character profile. A low index indicates high\n    variance among scores, suggesting a more complex or contradictory profile.\n\n    Formula:\n    Cohesion Index = 1 / (1 + \u03c3)\n    where \u03c3 is the population standard deviation of all available numeric\n    dimension scores in the input data.\n\n    Args:\n        data (pd.Series or pd.DataFrame): A single row of data containing the\n            dimension scores to be analyzed. The function will attempt to use\n            all numeric values present.\n        **kwargs: Not used.\n\n    Returns:\n        float: The calculated overall cohesion index, ranging from 0 to 1.\n               Returns None if there are fewer than two valid numeric scores\n               or if an error occurs.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # Ensure the input is a pandas Series\n        if isinstance(data, pd.DataFrame):\n            if len(data) == 1:\n                data = data.iloc[0]\n            else:\n                # Cannot process a multi-row DataFrame\n                return None\n        \n        if not isinstance(data, pd.Series):\n            return None\n\n        # Coerce all values to numeric, dropping non-numeric columns/indices.\n        # Then, drop any rows with missing values (NaN).\n        numeric_scores = pd.to_numeric(data, errors='coerce').dropna()\n\n        # Cohesion requires at least two data points to measure dispersion.\n        # If fewer than 2, the concept is undefined.\n        if len(numeric_scores) < 2:\n            return None\n\n        # Calculate the population standard deviation of the scores.\n        # np.std is used for population std (ddof=0), which is appropriate\n        # as we are considering the complete set of dimensions for one observation.\n        std_dev = np.std(numeric_scores.values)\n\n        # Handle the unlikely case of a non-finite or negative std dev\n        if not np.isfinite(std_dev) or std_dev < 0:\n            return None\n\n        # The formula maps std dev to a 0-1 scale.\n        # std_dev = 0 -> cohesion = 1 (perfect cohesion)\n        # std_dev -> inf -> cohesion -> 0 (no cohesion)\n        cohesion_index = 1.0 / (1.0 + std_dev)\n\n        return float(cohesion_index)\n\n    except (TypeError, ValueError, AttributeError, Exception):\n        # Gracefully handle any errors during processing\n        return None\n\ndef calculate_all_derived_metrics(data: pd.DataFrame) -> Dict[str, Optional[float]]:\n    \"\"\"\n    Calculate all derived metrics for the given dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        Dictionary mapping metric names to calculated values\n    \"\"\"\n    results = {}\n    \n    # Get all calculation functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith('calculate_') and \n            name not in ['calculate_all_derived_metrics', 'calculate_derived_metrics']):\n            try:\n                results[name.replace('calculate_', '')] = obj(data)\n            except Exception as e:\n                results[name.replace('calculate_', '')] = None\n                \n    return results\n\n\ndef calculate_derived_metrics(data: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Template-compatible wrapper function for derived metrics calculation.\n    \n    This function is called by the universal notebook template and returns\n    the original data with additional derived metric columns.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        DataFrame with original data plus derived metric columns\n    \"\"\"\n    # Calculate all derived metrics\n    derived_metrics = calculate_all_derived_metrics(data)\n    \n    # Create a copy of the original data\n    result = data.copy()\n    \n    # Add derived metrics as new columns\n    for metric_name, metric_value in derived_metrics.items():\n        if metric_value is not None:\n            # For scalar metrics, broadcast to all rows\n            result[metric_name] = metric_value\n        else:\n            # For failed calculations, use NaN\n            result[metric_name] = np.nan\n    \n    return result\n",
    "cached_with_code": true
  },
  "derived_metrics_data": {
    "status": "success",
    "original_count": 8,
    "derived_count": 8,
    "derived_metrics": [
      {
        "analysis_id": "analysis_5ffab56a2309",
        "result_hash": "a4d156e65045f0aa2a5a7c88dc21efec974408de325f56c4a275372c2aa16708",
        "duration_seconds": 21.622371
      },
      {
        "analysis_id": "analysis_242657b0aeb8",
        "result_hash": "df7fa516f6a809dd2fb546d1ead8e1159d192376cb4d9893584875d4637f20b7",
        "duration_seconds": 22.690722
      },
      {
        "analysis_id": "analysis_3ce57d72a628",
        "result_hash": "2966236a3515afed2c06752a0d35ed2d3fd23ffbe3a6b329f8821d05e9fecb5f",
        "duration_seconds": 34.206964
      },
      {
        "analysis_id": "analysis_c8027b9643c9",
        "result_hash": "00cde5ba3d13a309d07ae68783f2e80aae6b74e253aa0eb8d6a31a03d94b77e1",
        "duration_seconds": 22.622521
      },
      {
        "analysis_id": "analysis_709d24a3a014",
        "result_hash": "1fd404c7f7c9dcace982909082d854ec22cad9f4e028b559e2a4bf73850e123f",
        "duration_seconds": 24.481267
      },
      {
        "analysis_id": "analysis_2bf1d7723910",
        "result_hash": "09da45002c7a311227daa9e12882b9d0f8c5734f9d5ee9328449885187e2fb31",
        "duration_seconds": 31.323243
      },
      {
        "analysis_id": "analysis_c5e329c9edc3",
        "result_hash": "bda8a494dd98d84b2f06172e3a8be8c4698bcb9af2cb5f1e3557c9cc3325528b",
        "duration_seconds": 21.809571
      },
      {
        "analysis_id": "analysis_15dc7328772f",
        "result_hash": "9d80a71fad025a572fdc17e92eb3d7c5c21de3437e7a3f5036a7ed7cff5db3b7",
        "duration_seconds": 36.358737
      }
    ],
    "columns_added": []
  },
  "status": "success_with_data",
  "validation_passed": true
}