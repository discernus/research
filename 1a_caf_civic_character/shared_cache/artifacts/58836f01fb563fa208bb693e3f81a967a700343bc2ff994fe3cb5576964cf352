{"stage_1_raw_data": {"analysis_plan": {"stage": "raw_data_collection", "experiment_summary": "This plan outlines the collection and initial validation of raw data from the LLM analysis phase for the speaker_character_pattern_analysis experiment. It focuses on capturing the 10 core dimensional scores, along with their corresponding salience and confidence values, as specified by the Character Assessment Framework v6.1. The plan includes validation steps to ensure data integrity, completeness, and adherence to the framework's 0.0-1.0 scale before any derived metrics are calculated in Stage 2.", "tasks": {"dimensional_scores_and_salience_validation": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["dignity_score", "dignity_salience", "truth_score", "truth_salience", "justice_score", "justice_salience", "hope_score", "hope_salience", "pragmatism_score", "pragmatism_salience", "tribalism_score", "tribalism_salience", "manipulation_score", "manipulation_salience", "resentment_score", "resentment_salience", "fear_score", "fear_salience", "fantasy_score", "fantasy_salience"]}, "purpose": "To validate that all raw dimensional and salience scores generated by the LLM are within the expected 0.0-1.0 range and to identify any missing values or initial outliers. This ensures the foundational data for Stage 2 calculations is clean and reliable, as required by the CAF v6.1 calculation specification."}, "confidence_scores_validation": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["dignity_confidence", "truth_confidence", "justice_confidence", "hope_confidence", "pragmatism_confidence", "tribalism_confidence", "manipulation_confidence", "resentment_confidence", "fear_confidence", "fantasy_confidence"]}, "purpose": "To assess the LLM's confidence for each dimensional rating. This provides a critical metadata layer to evaluate the quality and reliability of the raw scores before they are used in subsequent analysis, as specified in the framework's output contract."}, "raw_data_completeness_check": {"tool": "create_summary_statistics", "parameters": {"metrics": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score"], "summary_types": ["count", "mean", "std"]}, "purpose": "To generate an aggregate overview of the collected raw data, confirming the count of records for each dimension and providing initial descriptive statistics. This serves as a final check for data completeness and distribution across all 8 documents before proceeding to Stage 2 analysis."}}}, "results": {"dimensional_scores_and_salience_validation": {"type": "descriptive_stats", "columns_analyzed": ["dignity_score", "dignity_salience", "truth_score", "truth_salience", "justice_score", "justice_salience", "hope_score", "hope_salience", "pragmatism_score", "pragmatism_salience", "tribalism_score", "tribalism_salience", "manipulation_score", "manipulation_salience", "resentment_score", "resentment_salience", "fear_score", "fear_salience", "fantasy_score", "fantasy_salience"], "results": {"dignity_score": {"count": 7, "mean": 0.7071428571428572, "std": 0.11700630833624397, "min": 0.6, "max": 0.9, "median": 0.7, "q25": 0.6, "q75": 0.775, "skewness": 0.6354172449685459, "kurtosis": -0.7777542533081299}, "dignity_salience": {"count": 7, "mean": 0.7571428571428572, "std": 0.09322272357358044, "min": 0.7, "max": 0.95, "median": 0.7, "q25": 0.7, "q75": 0.775, "skewness": 1.8735510780128417, "kurtosis": 3.432351285419381}, "truth_score": {"count": 8, "mean": 0.6125, "std": 0.15294723646688466, "min": 0.4, "max": 0.85, "median": 0.625, "q25": 0.55, "q75": 0.7, "skewness": -0.23457673001622417, "kurtosis": -0.27672047083503326}, "truth_salience": {"count": 8, "mean": 0.675, "std": 0.13887301496588275, "min": 0.4, "max": 0.8, "median": 0.7, "q25": 0.6, "q75": 0.8, "skewness": -1.1201280219470378, "kurtosis": 1.1061728395061703}, "justice_score": {"count": 8, "mean": 0.73125, "std": 0.15797264681854625, "min": 0.5, "max": 0.9, "median": 0.775, "q25": 0.6499999999999999, "q75": 0.8250000000000001, "skewness": -0.70039978049317, "kurtosis": -0.8331514556085038}, "justice_salience": {"count": 8, "mean": 0.7875, "std": 0.18850918886280923, "min": 0.5, "max": 0.95, "median": 0.875, "q25": 0.6875, "q75": 0.9125, "skewness": -1.0209704509304138, "kurtosis": -0.719779803540316}, "hope_score": {"count": 8, "mean": 0.6475, "std": 0.23614462880676687, "min": 0.2, "max": 0.9, "median": 0.7, "q25": 0.5, "q75": 0.8200000000000001, "skewness": -0.9189397658129868, "kurtosis": 0.45756744270958816}, "hope_salience": {"count": 8, "mean": 0.6625, "std": 0.24892626561752318, "min": 0.2, "max": 0.9, "median": 0.75, "q25": 0.55, "q75": 0.85, "skewness": -1.0870897317668808, "kurtosis": 0.14808195400676105}, "pragmatism_score": {"count": 8, "mean": 0.5249999999999999, "std": 0.12817398889233114, "min": 0.3, "max": 0.7, "median": 0.55, "q25": 0.475, "q75": 0.6, "skewness": -0.6105830850825585, "kurtosis": -0.021172022684313063}, "pragmatism_salience": {"count": 8, "mean": 0.51875, "std": 0.14623244705409455, "min": 0.3, "max": 0.75, "median": 0.55, "q25": 0.4, "q75": 0.6, "skewness": 0.009279703405700527, "kurtosis": -0.6426401558570607}, "tribalism_score": {"count": 8, "mean": 0.4125, "std": 0.18850918886280923, "min": 0.1, "max": 0.7, "median": 0.4, "q25": 0.3, "q75": 0.525, "skewness": -0.06664297982574521, "kurtosis": -0.01725208959369784}, "tribalism_salience": {"count": 8, "mean": 0.42500000000000004, "std": 0.17525491637693283, "min": 0.1, "max": 0.7, "median": 0.45, "q25": 0.375, "q75": 0.5, "skewness": -0.5042488670228694, "kurtosis": 1.3568415359653878}, "manipulation_score": {"count": 8, "mean": 0.40625, "std": 0.2111828929760038, "min": 0.15, "max": 0.7, "median": 0.4, "q25": 0.2, "q75": 0.6, "skewness": 0.1116263407578763, "kurtosis": -1.763594224855487}, "manipulation_salience": {"count": 8, "mean": 0.4749999999999999, "std": 0.21380899352993948, "min": 0.15, "max": 0.7, "median": 0.55, "q25": 0.2875, "q75": 0.625, "skewness": -0.4750150979302847, "kurtosis": -1.5741455078125002}, "resentment_score": {"count": 8, "mean": 0.39375000000000004, "std": 0.2043063176423368, "min": 0.05, "max": 0.7, "median": 0.35, "q25": 0.3, "q75": 0.525, "skewness": -0.09815396884072479, "kurtosis": 0.005367954473961767}, "resentment_salience": {"count": 8, "mean": 0.41875, "std": 0.19628241315585487, "min": 0.05, "max": 0.7, "median": 0.4, "q25": 0.375, "q75": 0.525, "skewness": -0.5817875780138718, "kurtosis": 1.121535402252242}, "fear_score": {"count": 8, "mean": 0.25625000000000003, "std": 0.1347948176197544, "min": 0.1, "max": 0.5, "median": 0.2, "q25": 0.1875, "q75": 0.325, "skewness": 0.9323479781707691, "kurtosis": -0.004124383485562433}, "fear_salience": {"count": 8, "mean": 0.28125, "std": 0.09977653603356425, "min": 0.1, "max": 0.4, "median": 0.3, "q25": 0.2375, "q75": 0.325, "skewness": -0.6044898304046372, "kurtosis": 0.3646323071045048}, "fantasy_score": {"count": 8, "mean": 0.175, "std": 0.10350983390135313, "min": 0.0, "max": 0.3, "median": 0.2, "q25": 0.1, "q75": 0.225, "skewness": -0.3864367132317181, "kurtosis": -0.4479999999999986}, "fantasy_salience": {"count": 8, "mean": 0.20625, "std": 0.126596941962615, "min": 0.0, "max": 0.4, "median": 0.2, "q25": 0.1375, "q75": 0.3, "skewness": -0.1155158663790897, "kurtosis": -0.21386550383687286}}}, "confidence_scores_validation": {"type": "descriptive_stats", "columns_analyzed": ["dignity_confidence", "truth_confidence", "justice_confidence", "hope_confidence", "pragmatism_confidence", "tribalism_confidence", "manipulation_confidence", "resentment_confidence", "fear_confidence", "fantasy_confidence"], "results": {"dignity_confidence": {"count": 7, "mean": 0.7928571428571428, "std": 0.10177004891982151, "min": 0.7, "max": 0.9, "median": 0.75, "q25": 0.7, "q75": 0.9, "skewness": 0.267675800488283, "kurtosis": -2.6951248513674186}, "truth_confidence": {"count": 8, "mean": 0.7687499999999999, "std": 0.11933596033288303, "min": 0.6, "max": 0.95, "median": 0.8, "q25": 0.7125, "q75": 0.8125, "skewness": -0.34017919805586205, "kurtosis": -0.2550132172443309}, "justice_confidence": {"count": 8, "mean": 0.8187499999999999, "std": 0.14126343172547218, "min": 0.5, "max": 0.95, "median": 0.85, "q25": 0.8, "q75": 0.875, "skewness": -1.8774322889140391, "kurtosis": 4.501490923832252}, "hope_confidence": {"count": 8, "mean": 0.765, "std": 0.1461897006338975, "min": 0.6, "max": 0.95, "median": 0.75, "q25": 0.6375, "q75": 0.905, "skewness": 0.10845917943952225, "kurtosis": -2.079485580085219}, "pragmatism_confidence": {"count": 8, "mean": 0.65625, "std": 0.11783008347374015, "min": 0.5, "max": 0.85, "median": 0.7, "q25": 0.575, "q75": 0.7, "skewness": -0.023195425908955142, "kurtosis": -0.22939382347163573}, "tribalism_confidence": {"count": 8, "mean": 0.6499999999999999, "std": 0.13093073414159542, "min": 0.4, "max": 0.8, "median": 0.6499999999999999, "q25": 0.6, "q75": 0.725, "skewness": -0.7637626158259697, "kurtosis": 0.8749999999999947}, "manipulation_confidence": {"count": 8, "mean": 0.6499999999999999, "std": 0.13627702877384937, "min": 0.5, "max": 0.85, "median": 0.675, "q25": 0.5, "q75": 0.75, "skewness": 0.0, "kurtosis": -1.5946745562130182}, "resentment_confidence": {"count": 8, "mean": 0.64375, "std": 0.14252192813739223, "min": 0.4, "max": 0.8, "median": 0.7, "q25": 0.5375000000000001, "q75": 0.75, "skewness": -0.7702689769562403, "kurtosis": -0.823885038038882}, "fear_confidence": {"count": 8, "mean": 0.5187499999999999, "std": 0.16889874396894047, "min": 0.3, "max": 0.7, "median": 0.55, "q25": 0.375, "q75": 0.6625, "skewness": -0.3127134054837214, "kurtosis": -1.8339571072758938}, "fantasy_confidence": {"count": 8, "mean": 0.5062500000000001, "std": 0.20430631764233684, "min": 0.3, "max": 0.9, "median": 0.45, "q25": 0.375, "q75": 0.6125, "skewness": 1.0027409456768288, "kurtosis": 0.6916462009208111}}}, "raw_data_completeness_check": {"type": "summary_statistics", "metrics": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score"], "summary_types": ["count", "mean", "std"], "results": {"dignity_score": {"mean": 0.7071428571428572, "std": 0.11700630833624397, "count": 7}, "truth_score": {"mean": 0.6125, "std": 0.15294723646688466, "count": 8}, "justice_score": {"mean": 0.73125, "std": 0.15797264681854625, "count": 8}, "hope_score": {"mean": 0.6475, "std": 0.23614462880676687, "count": 8}, "pragmatism_score": {"mean": 0.5249999999999999, "std": 0.12817398889233114, "count": 8}, "tribalism_score": {"mean": 0.4125, "std": 0.18850918886280923, "count": 8}, "manipulation_score": {"mean": 0.40625, "std": 0.2111828929760038, "count": 8}, "resentment_score": {"mean": 0.39375000000000004, "std": 0.2043063176423368, "count": 8}, "fear_score": {"mean": 0.25625000000000003, "std": 0.1347948176197544, "count": 8}, "fantasy_score": {"mean": 0.175, "std": 0.10350983390135313, "count": 8}}, "missing_metrics": []}}, "errors": []}, "stage_2_derived_metrics": {"analysis_plan": {"stage": "derived_metrics_analysis", "experiment_summary": "This plan outlines Stage 2 of the analysis, focusing on calculating derived metrics from the Character Assessment Framework v6.1, including character tensions and the MC-SCI. It then details the statistical tests (ANOVA, correlation, descriptive statistics) required to evaluate the research hypotheses regarding speaker differentiation, character signatures, and character coherence patterns.", "tasks": {"task_01_calculate_derived_metrics": {"tool": "calculate_derived_metrics", "parameters": {"metric_formulas": {"dignity_tribalism_tension": "np.minimum(dignity_score, tribalism_score) * abs(dignity_salience - tribalism_salience)", "truth_manipulation_tension": "np.minimum(truth_score, manipulation_score) * abs(truth_salience - manipulation_salience)", "justice_resentment_tension": "np.minimum(justice_score, resentment_score) * abs(justice_salience - resentment_salience)", "hope_fear_tension": "np.minimum(hope_score, fear_score) * abs(hope_salience - fear_salience)", "pragmatism_fantasy_tension": "np.minimum(pragmatism_score, fantasy_score) * abs(pragmatism_salience - fantasy_salience)", "mc_sci": "(dignity_tribalism_tension + truth_manipulation_tension + justice_resentment_tension + hope_fear_tension + pragmatism_fantasy_tension) / 5.0"}, "input_columns": ["dignity_score", "dignity_salience", "tribalism_score", "tribalism_salience", "truth_score", "truth_salience", "manipulation_score", "manipulation_salience", "justice_score", "justice_salience", "resentment_score", "resentment_salience", "hope_score", "hope_salience", "fear_score", "fear_salience", "pragmatism_score", "pragmatism_salience", "fantasy_score", "fantasy_salience"]}, "purpose": "To compute the five character tension scores and the overall Moral Character Strategic Contradiction Index (MC-SCI) as defined in the CAF v6.1 specification. These derived metrics are fundamental for subsequent hypothesis testing."}, "task_02_validate_calculated_metrics": {"tool": "validate_calculated_metrics", "parameters": {"validation_rules": ["missing_data_check", "range_check"], "quality_thresholds": {"range_check": {"min": 0.0, "max": 1.0}}}, "purpose": "To ensure the integrity of the newly calculated tension and MC-SCI metrics by checking for null values and verifying that all values fall within the expected theoretical range of [0.0, 1.0] before they are used in statistical analyses."}, "task_03_test_speaker_differentiation_h1": {"tool": "perform_one_way_anova", "parameters": {"grouping_variable": "tribalism_score", "dependent_variable": "dignity_score"}, "purpose": "To test hypothesis H1 (Speaker Differentiation) by proxy. This analysis determines if a core virtue (Dignity) shows statistically significant differences based on the level of its opposing vice (Tribalism), which is a key indicator of character differentiation."}, "task_04_analyze_character_signatures_h2": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score"], "grouping_variable": "aid"}, "purpose": "To address hypothesis H2 (Character Signatures) by calculating the mean scores for all 10 dimensions for each document (identified by 'aid'). This creates a quantitative profile for each speaker, forming their unique character signature."}, "task_05_test_mc_sci_patterns_h3": {"tool": "perform_one_way_anova", "parameters": {"grouping_variable": "hope_score", "dependent_variable": "mc_sci"}, "purpose": "To test hypothesis H3 (MC-SCI Patterns) by examining if the MC-SCI score, representing character coherence, varies significantly across different levels of a key dimension like Hope. This helps identify drivers of character (in)coherence."}, "task_06_explore_dimensional_relationships": {"tool": "generate_correlation_matrix", "parameters": {"dimensions": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score"], "correlation_method": "pearson"}, "purpose": "To understand the underlying structure of the character framework by identifying significant positive and negative correlations between the 10 core dimensions, revealing which virtues and vices tend to co-occur."}, "task_07_summarize_corpus_metrics": {"tool": "create_summary_statistics", "parameters": {"metrics": ["dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "hope_fear_tension", "pragmatism_fantasy_tension", "mc_sci"], "summary_types": ["mean", "std", "min", "max", "median"]}, "purpose": "To generate a final summary of all derived metrics, providing a high-level overview of the central tendency and dispersion for character tensions and the MC-SCI across the entire corpus for the final report."}}}, "results": {"task_01_calculate_derived_metrics": {"type": "derived_metrics_calculation", "success": true, "calculated_metrics": {"hope_fear_tension": [0.11999999999999998, 0.06, 0.09749999999999999, 0.1, 0.22499999999999998, 0.08000000000000002, 0.030000000000000006, 0.04000000000000001], "dignity_tribalism_tension": [0.15, 0.08999999999999998, 0.12000000000000002, 0.0, 0.16, 0.085, 0.08999999999999998, NaN], "truth_manipulation_tension": [0.059999999999999984, 0.08000000000000003, 0.08, 0.039999999999999994, 0.11000000000000001, 0.08249999999999999, 0.06000000000000005, 0.07999999999999999], "justice_resentment_tension": [0.175, 0.12000000000000004, 0.16499999999999998, 0.029999999999999992, 0.24499999999999997, 0.034999999999999996, 0.18000000000000002, 0.039999999999999994], "pragmatism_fantasy_tension": [0.04000000000000001, 0.04000000000000001, 0.06, 0.059999999999999984, 0.030000000000000006, 0.0, 0.08, 0.0], "mc_sci": [0.10899999999999999, 0.078, 0.1045, 0.046, 0.154, 0.056499999999999995, 0.08800000000000002, NaN]}, "successful_calculations": ["hope_fear_tension", "dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "pragmatism_fantasy_tension", "mc_sci"], "failed_calculations": [], "formulas_used": ["dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "hope_fear_tension", "pragmatism_fantasy_tension", "mc_sci"], "input_columns": ["dignity_score", "dignity_salience", "tribalism_score", "tribalism_salience", "truth_score", "truth_salience", "manipulation_score", "manipulation_salience", "justice_score", "justice_salience", "resentment_score", "resentment_salience", "hope_score", "hope_salience", "fear_score", "fear_salience", "pragmatism_score", "pragmatism_salience", "fantasy_score", "fantasy_salience"], "total_metrics": 6, "success_rate": 1.0}, "task_02_validate_calculated_metrics": {"type": "metric_validation", "validation_rules": ["missing_data_check", "range_check"], "results": {"missing_data_check": {"status": "completed", "missing_data_by_column": {"aid": 0, "expert_categorization": 0, "political_party": 0, "speaker": 0, "leadership_type": 0, "date": 0, "era": 0, "ideology": 0, "context": 0, "dignity_score": 1, "dignity_raw_score": 1, "dignity_salience": 1, "dignity_confidence": 1, "truth_score": 0, "truth_raw_score": 0, "truth_salience": 0, "truth_confidence": 0, "justice_score": 0, "justice_raw_score": 0, "justice_salience": 0, "justice_confidence": 0, "hope_score": 0, "hope_raw_score": 0, "hope_salience": 0, "hope_confidence": 0, "pragmatism_score": 0, "pragmatism_raw_score": 0, "pragmatism_salience": 0, "pragmatism_confidence": 0, "tribalism_score": 0, "tribalism_raw_score": 0, "tribalism_salience": 0, "tribalism_confidence": 0, "manipulation_score": 0, "manipulation_raw_score": 0, "manipulation_salience": 0, "manipulation_confidence": 0, "resentment_score": 0, "resentment_raw_score": 0, "resentment_salience": 0, "resentment_confidence": 0, "fear_score": 0, "fear_raw_score": 0, "fear_salience": 0, "fear_confidence": 0, "fantasy_score": 0, "fantasy_raw_score": 0, "fantasy_salience": 0, "fantasy_confidence": 0, "diginity_score": 7, "diginity_raw_score": 7, "diginity_salience": 7, "diginity_confidence": 7, "hope_fear_tension": 0, "dignity_tribalism_tension": 1, "truth_manipulation_tension": 0, "justice_resentment_tension": 0, "pragmatism_fantasy_tension": 0, "mc_sci": 1}, "total_missing": 34}, "range_check": {"status": "completed", "ranges": {"dignity_score": {"min": 0.6, "max": 0.9, "mean": 0.7071428571428572}, "dignity_raw_score": {"min": 0.6, "max": 0.9, "mean": 0.7071428571428572}, "dignity_salience": {"min": 0.7, "max": 0.95, "mean": 0.7571428571428571}, "dignity_confidence": {"min": 0.7, "max": 0.9, "mean": 0.7928571428571428}, "truth_score": {"min": 0.4, "max": 0.85, "mean": 0.6125}, "truth_raw_score": {"min": 0.4, "max": 0.85, "mean": 0.6125}, "truth_salience": {"min": 0.4, "max": 0.8, "mean": 0.675}, "truth_confidence": {"min": 0.6, "max": 0.95, "mean": 0.7687499999999999}, "justice_score": {"min": 0.5, "max": 0.9, "mean": 0.73125}, "justice_raw_score": {"min": 0.5, "max": 0.9, "mean": 0.73125}, "justice_salience": {"min": 0.5, "max": 0.95, "mean": 0.7875}, "justice_confidence": {"min": 0.5, "max": 0.95, "mean": 0.8187499999999999}, "hope_score": {"min": 0.2, "max": 0.9, "mean": 0.6475}, "hope_raw_score": {"min": 0.2, "max": 0.9, "mean": 0.6475}, "hope_salience": {"min": 0.2, "max": 0.9, "mean": 0.6625}, "hope_confidence": {"min": 0.6, "max": 0.95, "mean": 0.765}, "pragmatism_score": {"min": 0.3, "max": 0.7, "mean": 0.5249999999999999}, "pragmatism_raw_score": {"min": 0.3, "max": 0.7, "mean": 0.5249999999999999}, "pragmatism_salience": {"min": 0.3, "max": 0.75, "mean": 0.51875}, "pragmatism_confidence": {"min": 0.5, "max": 0.85, "mean": 0.65625}, "tribalism_score": {"min": 0.1, "max": 0.7, "mean": 0.4125}, "tribalism_raw_score": {"min": 0.1, "max": 0.7, "mean": 0.4125}, "tribalism_salience": {"min": 0.1, "max": 0.7, "mean": 0.42500000000000004}, "tribalism_confidence": {"min": 0.4, "max": 0.8, "mean": 0.6499999999999999}, "manipulation_score": {"min": 0.15, "max": 0.7, "mean": 0.40625}, "manipulation_raw_score": {"min": 0.15, "max": 0.7, "mean": 0.40625}, "manipulation_salience": {"min": 0.15, "max": 0.7, "mean": 0.4749999999999999}, "manipulation_confidence": {"min": 0.5, "max": 0.85, "mean": 0.6499999999999999}, "resentment_score": {"min": 0.05, "max": 0.7, "mean": 0.39375000000000004}, "resentment_raw_score": {"min": 0.05, "max": 0.7, "mean": 0.39375000000000004}, "resentment_salience": {"min": 0.05, "max": 0.7, "mean": 0.41875}, "resentment_confidence": {"min": 0.4, "max": 0.8, "mean": 0.64375}, "fear_score": {"min": 0.1, "max": 0.5, "mean": 0.25625000000000003}, "fear_raw_score": {"min": 0.1, "max": 0.5, "mean": 0.25625000000000003}, "fear_salience": {"min": 0.1, "max": 0.4, "mean": 0.28125}, "fear_confidence": {"min": 0.3, "max": 0.7, "mean": 0.5187499999999999}, "fantasy_score": {"min": 0.0, "max": 0.3, "mean": 0.175}, "fantasy_raw_score": {"min": 0.0, "max": 0.3, "mean": 0.175}, "fantasy_salience": {"min": 0.0, "max": 0.4, "mean": 0.20625}, "fantasy_confidence": {"min": 0.3, "max": 0.9, "mean": 0.5062500000000001}, "diginity_score": {"min": 0.3, "max": 0.3, "mean": 0.3}, "diginity_raw_score": {"min": 0.3, "max": 0.3, "mean": 0.3}, "diginity_salience": {"min": 0.3, "max": 0.3, "mean": 0.3}, "diginity_confidence": {"min": 0.7, "max": 0.7, "mean": 0.7}, "hope_fear_tension": {"min": 0.030000000000000006, "max": 0.22499999999999998, "mean": 0.0940625}, "dignity_tribalism_tension": {"min": 0.0, "max": 0.16, "mean": 0.09928571428571428}, "truth_manipulation_tension": {"min": 0.039999999999999994, "max": 0.11000000000000001, "mean": 0.0740625}, "justice_resentment_tension": {"min": 0.029999999999999992, "max": 0.24499999999999997, "mean": 0.12375}, "pragmatism_fantasy_tension": {"min": 0.0, "max": 0.08, "mean": 0.03875000000000001}, "mc_sci": {"min": 0.046, "max": 0.154, "mean": 0.09085714285714286}}}}, "quality_thresholds": {"range_check": {"min": 0.0, "max": 1.0}}}, "task_03_test_speaker_differentiation_h1": {"type": "one_way_anova", "grouping_variable": "tribalism_score", "dependent_variable": "dignity_score", "groups": {"0.1": {"n": 1, "mean": 0.9, "std": 0.0}, "0.3": {"n": 2, "mean": 0.6, "std": 0.0}, "0.4": {"n": 2, "mean": 0.775, "std": 0.025000000000000022}, "0.6": {"n": 1, "mean": 0.7, "std": 0.0}, "0.7": {"n": 1, "mean": 0.6, "std": 0.0}}, "f_statistic": 32.35714285714284, "p_value": 0.030203213610586026, "significant": "True"}, "task_04_analyze_character_signatures_h2": {"type": "descriptive_stats_grouped", "grouping_variable": "aid", "groups": {"{artifact_id}": {"dignity_score": {"count": 7, "mean": 0.7071428571428572, "std": 0.11700630833624397, "min": 0.6, "max": 0.9}, "truth_score": {"count": 8, "mean": 0.6125, "std": 0.15294723646688466, "min": 0.4, "max": 0.85}, "justice_score": {"count": 8, "mean": 0.73125, "std": 0.15797264681854625, "min": 0.5, "max": 0.9}, "hope_score": {"count": 8, "mean": 0.6475, "std": 0.23614462880676687, "min": 0.2, "max": 0.9}, "pragmatism_score": {"count": 8, "mean": 0.5249999999999999, "std": 0.12817398889233114, "min": 0.3, "max": 0.7}, "tribalism_score": {"count": 8, "mean": 0.4125, "std": 0.18850918886280923, "min": 0.1, "max": 0.7}, "manipulation_score": {"count": 8, "mean": 0.40625, "std": 0.2111828929760038, "min": 0.15, "max": 0.7}, "resentment_score": {"count": 8, "mean": 0.39375000000000004, "std": 0.2043063176423368, "min": 0.05, "max": 0.7}, "fear_score": {"count": 8, "mean": 0.25625000000000003, "std": 0.1347948176197544, "min": 0.1, "max": 0.5}, "fantasy_score": {"count": 8, "mean": 0.175, "std": 0.10350983390135313, "min": 0.0, "max": 0.3}}}}, "task_05_test_mc_sci_patterns_h3": {"type": "one_way_anova", "grouping_variable": "hope_score", "dependent_variable": "mc_sci", "groups": {"0.5": {"n": 2, "mean": 0.08300000000000002, "std": 0.005000000000000011}, "0.7": {"n": 2, "mean": 0.07749999999999999, "std": 0.03149999999999999}, "0.8": {"n": 1, "mean": 0.1045, "std": 0.0}, "0.88": {"n": 1, "mean": 0.154, "std": 0.0}, "0.9": {"n": 1, "mean": 0.056499999999999995, "std": 0.0}}, "f_statistic": 1.43373240178352, "p_value": 0.45027757740367536, "significant": "False"}, "task_06_explore_dimensional_relationships": {"type": "correlation_matrix", "dimensions": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score"], "method": "pearson", "matrix": {"dignity_score": {"dignity_score": 1.0, "truth_score": 0.576770389298682, "justice_score": 0.4843884930464273, "hope_score": 0.8893427293057098, "pragmatism_score": 0.5421374765483945, "tribalism_score": -0.49854861812834383, "manipulation_score": -0.6651662082893139, "resentment_score": -0.2881837200291647, "fear_score": 0.061952247412989436, "fantasy_score": -0.9174634218511292}, "truth_score": {"dignity_score": 0.576770389298682, "truth_score": 1.0, "justice_score": 0.897975984067584, "hope_score": 0.6140643187067323, "pragmatism_score": 0.6740655909056726, "tribalism_score": -0.6007718129713515, "manipulation_score": -0.4671628644330198, "resentment_score": 0.20858419942357415, "fear_score": 0.11693133599279322, "fantasy_score": -0.7895629608911476}, "justice_score": {"dignity_score": 0.4843884930464273, "truth_score": 0.897975984067584, "justice_score": 1.0, "hope_score": 0.6093690745575551, "pragmatism_score": 0.7672721428435879, "tribalism_score": -0.42275297305978327, "manipulation_score": -0.35996778188527995, "resentment_score": 0.19503268660627737, "fear_score": 0.0062895293220607915, "fantasy_score": -0.7316835130490091}, "hope_score": {"dignity_score": 0.8893427293057098, "truth_score": 0.6140643187067323, "justice_score": 0.6093690745575551, "hope_score": 1.0, "pragmatism_score": 0.7952870179044798, "tribalism_score": -0.20779310668060388, "manipulation_score": -0.6971738961522156, "resentment_score": -0.14397984649651582, "fear_score": -0.2126179447022601, "fantasy_score": -0.7510094540244864}, "pragmatism_score": {"dignity_score": 0.5421374765483945, "truth_score": 0.6740655909056726, "justice_score": 0.7672721428435879, "hope_score": 0.7952870179044798, "pragmatism_score": 1.0, "tribalism_score": -0.31040509310661096, "manipulation_score": -0.5607538494404394, "resentment_score": -0.2932234722018026, "fear_score": -0.3410773006656662, "fantasy_score": -0.6998964726756151}, "tribalism_score": {"dignity_score": -0.49854861812834383, "truth_score": -0.6007718129713515, "justice_score": -0.42275297305978327, "hope_score": -0.20779310668060388, "pragmatism_score": -0.31040509310661096, "tribalism_score": 1.0, "manipulation_score": 0.48220218903683554, "resentment_score": 0.31760565283189346, "fear_score": 0.3619207488858103, "fantasy_score": 0.7504325943927066}, "manipulation_score": {"dignity_score": -0.6651662082893139, "truth_score": -0.4671628644330198, "justice_score": -0.35996778188527995, "hope_score": -0.6971738961522156, "pragmatism_score": -0.5607538494404394, "tribalism_score": 0.48220218903683554, "manipulation_score": 1.0, "resentment_score": 0.191418178326564, "fear_score": 0.21171606805422713, "fantasy_score": 0.72704557073721}, "resentment_score": {"dignity_score": -0.2881837200291647, "truth_score": 0.20858419942357415, "justice_score": 0.19503268660627737, "hope_score": -0.14397984649651582, "pragmatism_score": -0.2932234722018026, "tribalism_score": 0.31760565283189346, "manipulation_score": 0.191418178326564, "resentment_score": 1.0, "fear_score": 0.7408208383886864, "fantasy_score": 0.2617642051708646}, "fear_score": {"dignity_score": 0.061952247412989436, "truth_score": 0.11693133599279322, "justice_score": 0.0062895293220607915, "hope_score": -0.2126179447022601, "pragmatism_score": -0.3410773006656662, "tribalism_score": 0.3619207488858103, "manipulation_score": 0.21171606805422713, "resentment_score": 0.7408208383886864, "fear_score": 1.0, "fantasy_score": 0.268767319880733}, "fantasy_score": {"dignity_score": -0.9174634218511292, "truth_score": -0.7895629608911476, "justice_score": -0.7316835130490091, "hope_score": -0.7510094540244864, "pragmatism_score": -0.6998964726756151, "tribalism_score": 0.7504325943927066, "manipulation_score": 0.72704557073721, "resentment_score": 0.2617642051708646, "fear_score": 0.268767319880733, "fantasy_score": 1.0}}, "missing_dimensions": []}, "task_07_summarize_corpus_metrics": {"type": "summary_statistics", "metrics": ["dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "hope_fear_tension", "pragmatism_fantasy_tension", "mc_sci"], "summary_types": ["mean", "std", "min", "max", "median"], "results": {"dignity_tribalism_tension": {"mean": 0.09928571428571428, "std": 0.05310591393845036, "min": 0.0, "max": 0.16, "median": 0.08999999999999998}, "truth_manipulation_tension": {"mean": 0.0740625, "std": 0.020785361435394865, "min": 0.039999999999999994, "max": 0.11000000000000001, "median": 0.07999999999999999}, "justice_resentment_tension": {"mean": 0.12375, "std": 0.08096516005577424, "min": 0.029999999999999992, "max": 0.24499999999999997, "median": 0.14250000000000002}, "hope_fear_tension": {"mean": 0.0940625, "std": 0.06123633229429357, "min": 0.030000000000000006, "max": 0.22499999999999998, "median": 0.08875}, "pragmatism_fantasy_tension": {"mean": 0.03875000000000001, "std": 0.028504385627478448, "min": 0.0, "max": 0.08, "median": 0.04000000000000001}, "mc_sci": {"mean": 0.09085714285714284, "std": 0.03621315861869629, "min": 0.046, "max": 0.154, "median": 0.08800000000000002}}, "missing_metrics": []}}, "errors": []}, "combined_summary": "Two-stage execution: 3 raw data results + 7 derived metrics results"}