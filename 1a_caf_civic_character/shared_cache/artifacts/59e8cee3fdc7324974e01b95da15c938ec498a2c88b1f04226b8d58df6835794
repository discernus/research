{"stage_1_raw_data": {"stage": "raw_data_collection", "experiment_summary": "This plan outlines the collection of raw dimensional scores (score, salience, confidence) and supporting textual evidence for 10 character dimensions across 8 documents, as specified by the CAF v6.1 framework. It focuses solely on Stage 1 data acquisition without any derived calculations.", "tasks": {"collect_dimensional_scores": {"tool": "collect_raw_scores", "parameters": {"dimensions": ["dignity", "truth", "justice", "hope", "pragmatism", "tribalism", "manipulation", "resentment", "fear", "fantasy"], "scoring_scale": "0.0-1.0"}, "purpose": "To capture the fundamental intensity score for each of the 10 character dimensions as assessed by the LLM. This is the primary raw data required by the CAF v6.1 output contract."}, "collect_score_metadata": {"tool": "collect_metadata", "parameters": {"metadata_types": ["salience", "confidence"], "collection_method": "per_dimension_assessment"}, "purpose": "To gather the 'salience' and 'confidence' values for each dimension, which are critical for understanding the prominence of each trait and the reliability of the LLM's assessment, as specified in the framework's scoring protocol."}, "collect_supporting_evidence": {"tool": "collect_evidence", "parameters": {"evidence_types": ["supporting_quotes"], "max_quotes_per_dimension": 2}, "purpose": "To collect direct textual evidence (quotations) supporting each dimensional score, ensuring auditability and enabling qualitative analysis as specified in the framework's evidence structure requirements."}, "validate_initial_output": {"tool": "validate_raw_data", "parameters": {"validation_rules": ["score_range_check", "completeness_check", "evidence_presence_check"], "quality_thresholds": {"numeric_range": [0.0, 1.0], "required_dimensions": 10, "min_quotes_per_dimension": 1}}, "purpose": "To perform initial quality control on the LLM output, verifying that all collected raw scores and metadata adhere to the framework's structural and range requirements (e.g., scores are between 0.0 and 1.0) before any further processing."}}}, "stage_2_derived_metrics": {"stage": "derived_metrics_analysis", "experiment_summary": "This plan outlines Stage 2 of the speaker_character_pattern_analysis experiment. It focuses on calculating derived metrics from raw Stage 1 data, including Character Tensions and the Moral Character Strategic Contradiction Index (MC-SCI), as specified by the CAF v6.1 framework. Subsequently, it details the statistical analyses, primarily ANOVA, required to test the research hypotheses regarding speaker differentiation, character signatures, and MC-SCI patterns.", "tasks": {"calculate_derived_character_metrics": {"tool": "calculate_derived_metrics", "parameters": {"metric_formulas": {"dignity_tribalism_tension": "min(dignity_score, tribalism_score) * abs(dignity_salience - tribalism_salience)", "truth_manipulation_tension": "min(truth_score, manipulation_score) * abs(truth_salience - manipulation_salience)", "justice_resentment_tension": "min(justice_score, resentment_score) * abs(justice_salience - resentment_salience)", "hope_fear_tension": "min(hope_score, fear_score) * abs(hope_salience - fear_salience)", "pragmatism_fantasy_tension": "min(pragmatism_score, fantasy_score) * abs(pragmatism_salience - fantasy_salience)", "mc_sci": "(dignity_tribalism_tension + truth_manipulation_tension + justice_resentment_tension + hope_fear_tension + pragmatism_fantasy_tension) / 5"}, "input_columns": ["dignity_score", "dignity_salience", "tribalism_score", "tribalism_salience", "truth_score", "truth_salience", "manipulation_score", "manipulation_salience", "justice_score", "justice_salience", "resentment_score", "resentment_salience", "hope_score", "hope_salience", "fear_score", "fear_salience", "pragmatism_score", "pragmatism_salience", "fantasy_score", "fantasy_salience"]}, "purpose": "To compute the core derived metrics (Character Tensions and MC-SCI) from raw dimensional scores and salience values, as defined by the CAF v6.1 framework specification."}, "validate_calculated_metrics": {"tool": "validate_calculated_metrics", "parameters": {"validation_rules": [{"metric": "dignity_tribalism_tension", "range": [0.0, 1.0]}, {"metric": "truth_manipulation_tension", "range": [0.0, 1.0]}, {"metric": "justice_resentment_tension", "range": [0.0, 1.0]}, {"metric": "hope_fear_tension", "range": [0.0, 1.0]}, {"metric": "pragmatism_fantasy_tension", "range": [0.0, 1.0]}, {"metric": "mc_sci", "range": [0.0, 1.0]}], "quality_thresholds": {}}, "purpose": "To ensure the calculated derived metrics are mathematically sound and fall within their expected theoretical ranges (0.0 to 1.0), confirming the integrity of the calculation process."}, "generate_descriptive_statistics": {"tool": "create_summary_statistics", "parameters": {"metrics": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score", "dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "hope_fear_tension", "pragmatism_fantasy_tension", "mc_sci"], "grouping_variables": ["speaker", "era", "ideology"], "summary_types": ["mean", "std", "min", "max", "count"]}, "purpose": "To generate descriptive statistics for all raw and derived metrics, providing a foundational overview for reporting and supporting the qualitative assessment of character signatures (H2)."}, "test_speaker_differentiation_h1": {"tool": "perform_statistical_tests", "parameters": {"test_types": ["speaker_differentiation_anova"], "grouping_variables": ["speaker"], "dependent_variables": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score"]}, "purpose": "To statistically test hypothesis H1 (Speaker Differentiation) by performing an ANOVA to determine if there are significant differences between individual speakers across the 10 core CAF dimensions."}, "test_mc_sci_variation_h3": {"tool": "perform_statistical_tests", "parameters": {"test_types": ["mc_sci_coherence_patterns"], "grouping_variables": ["speaker", "era", "ideology"], "dependent_variables": ["mc_sci"]}, "purpose": "To statistically test hypothesis H3 (MC-SCI Patterns) by performing an ANOVA to determine if MC-SCI scores, representing character coherence, vary meaningfully across speakers and experimental groups (era, ideology)."}, "analyze_character_signatures_h2": {"tool": "generate_correlation_matrix", "parameters": {"dimensions": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score"], "correlation_method": "pearson"}, "purpose": "To provide quantitative support for hypothesis H2 (Character Signatures) by revealing the interrelationships between character dimensions. This, combined with descriptive statistics, helps to define and visualize the unique character patterns for each speaker."}}}, "combined_summary": "Two-stage analysis plan: This plan outlines the collection of raw dimensional scores (score, salience, confidence) and supporting textual evidence for 10 character dimensions across 8 documents, as specified by the CAF v6.1 framework. It focuses solely on Stage 1 data acquisition without any derived calculations. + This plan outlines Stage 2 of the speaker_character_pattern_analysis experiment. It focuses on calculating derived metrics from raw Stage 1 data, including Character Tensions and the Moral Character Strategic Contradiction Index (MC-SCI), as specified by the CAF v6.1 framework. Subsequently, it details the statistical analyses, primarily ANOVA, required to test the research hypotheses regarding speaker differentiation, character signatures, and MC-SCI patterns."}