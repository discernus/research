{
  "status": "success",
  "functions_generated": 6,
  "output_file": "automatedderivedmetricsagent_functions.py",
  "module_size": 14529,
  "function_code_content": "\"\"\"\nAutomated Derived Metrics Functions\n===================================\n\nGenerated by AutomatedDerivedMetricsAgent for experiment: Test Experiment\nDescription: Test experiment for derived metrics\nGenerated: 2025-08-25T12:52:15.608153+00:00\n\nThis module contains automatically generated calculation functions for derived metrics\nas specified in the framework's natural language descriptions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom typing import Optional, Dict, Any\n\n\ndef calculate_identity_tension(data, **kwargs):\n    \"\"\"\n    Calculate identity_tension: Conflict between tribal dominance and individual dignity dimensions.\n\n    This tension is highest when both tribal dominance and individual dignity are\n    strongly and simultaneously invoked. The calculation measures the degree of\n    this co-occurrence.\n\n    Formula: (A + B) - abs(A - B)\n    which is equivalent to: 2 * min(A, B)\n    where:\n    A = Value from the 'tribal_dominance_col'\n    B = Value from the 'individual_dignity_col'\n\n    Args:\n        data (pd.Series): A single row of data from a pandas DataFrame.\n        **kwargs: Keyword arguments containing the column names.\n            - tribal_dominance_col (str): The name of the column for the tribal dominance score.\n            - individual_dignity_col (str): The name of the column for the individual dignity score.\n\n    Returns:\n        float: The calculated identity tension score, or None if input data is\n               missing, invalid, or required column names are not provided.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # Retrieve column names from kwargs, which is necessary because no\n        # column names are specified in the problem description.\n        tribal_col = kwargs.get('tribal_dominance_col')\n        dignity_col = kwargs.get('individual_dignity_col')\n\n        # Ensure that the necessary column names have been provided.\n        if not tribal_col or not dignity_col:\n            return None\n\n        # Extract scores from the data Series using the provided column names.\n        # A KeyError will be caught by the general exception handler if columns don't exist.\n        tribal_dominance = data[tribal_col]\n        individual_dignity = data[dignity_col]\n\n        # Handle cases where data is missing (NaN) in either column.\n        if pd.isna(tribal_dominance) or pd.isna(individual_dignity):\n            return None\n\n        # Ensure values are numeric types (int or float) before calculation\n        if not all(isinstance(v, (int, float, np.number)) for v in [tribal_dominance, individual_dignity]):\n            return None\n        \n        # Calculate the tension. The formula (A + B) - abs(A - B) measures the\n        # extent to which both values are high, capturing simultaneous appeal.\n        # This is arithmetically equivalent to 2 * min(A, B).\n        tension = (tribal_dominance + individual_dignity) - np.abs(tribal_dominance - individual_dignity)\n\n        return float(tension)\n\n    except (KeyError, TypeError, AttributeError, Exception):\n        # Broad exception handling for production readiness.\n        # Catches:\n        # - KeyError: if column names in kwargs are not in the DataFrame.\n        # - TypeError: if data in columns is not numeric.\n        # - AttributeError: if `data` is not a pandas Series/DataFrame.\n        # - Other unexpected errors.\n        return None\n\ndef calculate_emotional_balance(data, **kwargs):\n    \"\"\"\n    Calculate emotional_balance: Difference between hope and fear scores.\n\n    Formula: emotional_balance = hope_score - fear_score\n\n    Args:\n        data (pd.Series):\n            A single row of data from a DataFrame, expected to contain\n            'hope_score' and 'fear_score' columns.\n        **kwargs:\n            Additional keyword arguments (not used).\n\n    Returns:\n        float:\n            The calculated emotional balance. Returns None if 'hope_score'\n            or 'fear_score' is missing, not a number, or NaN.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # Since no column names were provided, generic names are inferred from the description.\n        # .get() safely handles missing columns, returning None.\n        # pd.to_numeric converts None or non-numeric values to NaN.\n        hope_score = pd.to_numeric(data.get('hope_score'))\n        fear_score = pd.to_numeric(data.get('fear_score'))\n\n        # Check if either value is NaN after conversion. This handles missing keys,\n        # non-numeric data, and existing NaN values in one step.\n        if np.isnan(hope_score) or np.isnan(fear_score):\n            return None\n\n        return float(hope_score - fear_score)\n    except Exception:\n        # A broad exception handler for any other unforeseen errors.\n        return None\n\ndef calculate_success_climate(data, **kwargs):\n    \"\"\"\n    Calculate success_climate: Difference between compersion and envy scores\n\n    Formula: success_climate = compersion - envy\n    \n    Args:\n        data (pd.Series): A single row of data representing dimension scores.\n        **kwargs: Additional parameters (not used).\n        \n    Returns:\n        float: The calculated result, or None if essential data is missing or invalid.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # Column names are inferred from the calculation description\n        compersion_col = 'compersion'\n        envy_col = 'envy'\n\n        compersion_score = data[compersion_col]\n        envy_score = data[envy_col]\n\n        # Ensure both values are non-null before calculation\n        if pd.isna(compersion_score) or pd.isna(envy_score):\n            return None\n            \n        # Perform the calculation, ensuring values are numeric\n        result = float(compersion_score) - float(envy_score)\n        \n        # An additional check in case the subtraction results in NaN for other reasons\n        if np.isnan(result):\n            return None\n            \n        return result\n        \n    except (KeyError, TypeError, ValueError):\n        # Handles missing columns (KeyError) or non-numeric data (TypeError, ValueError)\n        return None\n    except Exception:\n        # A final catch-all for any other unexpected errors\n        return None\n\ndef calculate_relational_climate(data, **kwargs):\n    \"\"\"\n    Calculate relational_climate: Difference between amity and enmity scores.\n\n    Formula: amity - enmity\n\n    Args:\n        data (pd.Series): A single row of data containing the necessary columns.\n        **kwargs: Additional parameters (unused).\n\n    Returns:\n        float: Calculated result or None if insufficient data.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # The calculation is the difference between amity and enmity scores.\n        # As per the framework description, we infer the necessary columns are 'amity' and 'enmity'.\n        amity_score = data['amity']\n        enmity_score = data['enmity']\n\n        # Check for missing data before calculation\n        if pd.isna(amity_score) or pd.isna(enmity_score):\n            return None\n\n        # Ensure values are numeric and perform the calculation\n        result = float(amity_score) - float(enmity_score)\n        return result\n\n    except (KeyError, TypeError, ValueError):\n        # Handles missing columns ('amity', 'enmity') or non-numeric data.\n        return None\n    except Exception:\n        # A general catch-all for any other unexpected errors.\n        return None\n\ndef calculate_goal_orientation(data, **kwargs):\n    \"\"\"\n    Calculate goal_orientation: Difference between cohesive goals and fragmentative goals\n    \n    Formula: cohesive_goals - fragmentative_goals\n    \n    Args:\n        data (pd.Series): A single row of data from a pandas DataFrame.\n        **kwargs: Additional parameters (not used in this calculation).\n        \n    Returns:\n        float: Calculated result or None if essential data is missing or invalid.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        cohesive_col = 'cohesive_goals'\n        fragmentative_col = 'fragmentative_goals'\n        \n        # Ensure the input is a pandas Series for consistent access\n        if isinstance(data, pd.DataFrame):\n            if data.shape[0] == 1:\n                data = data.iloc[0]\n            else:\n                # Cannot determine a single row to process\n                return None\n\n        # Check for the existence of required columns\n        if cohesive_col not in data.index or fragmentative_col not in data.index:\n            return None\n            \n        # Extract values\n        cohesive_score = data[cohesive_col]\n        fragmentative_score = data[fragmentative_col]\n        \n        # Check for missing values (None, np.nan)\n        if pd.isna(cohesive_score) or pd.isna(fragmentative_score):\n            return None\n            \n        # Ensure values are numeric\n        cohesive_score = float(cohesive_score)\n        fragmentative_score = float(fragmentative_score)\n        \n        # Perform the calculation\n        result = cohesive_score - fragmentative_score\n        \n        return result\n\n    except (KeyError, TypeError, ValueError):\n        # KeyError: Column not found (already handled, but as a safeguard)\n        # TypeError: Data is not of a type that can be cast to float\n        # ValueError: Data cannot be cast to float\n        return None\n    except Exception:\n        # Catch any other unexpected errors during execution\n        return None\n\ndef calculate_overall_cohesion_index(data, **kwargs):\n    \"\"\"\n    Calculate overall_cohesion_index: Comprehensive measure combining all dimensions.\n\n    This index measures the internal consistency or 'cohesion' among a set of\n    related dimension scores. A higher index (closer to 1.0) indicates that the\n    scores are tightly clustered, suggesting a high degree of cohesion. A lower\n    index (closer to 0.0) indicates the scores are widely dispersed.\n\n    The function expects a list of column names, representing the dimensions to be\n    included in the calculation, to be passed via the `dimension_columns` keyword\n    argument.\n\n    Formula:\n    Index = 1 / (1 + \u03c3)\n    where \u03c3 is the population standard deviation of the dimension scores.\n\n    Args:\n        data (pd.DataFrame or pd.Series): A pandas DataFrame or Series containing\n            the data for calculation. If a DataFrame, the first row is used.\n        **kwargs: Arbitrary keyword arguments.\n            Expected: `dimension_columns` (list of str): A list of column names\n            that represent the dimensions for the cohesion calculation.\n\n    Returns:\n        float: The calculated overall cohesion index, ranging from (0, 1].\n               Returns None if there are fewer than two valid numeric scores,\n               if required columns are missing, or if an error occurs.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        dimension_columns = kwargs.get('dimension_columns')\n        if not dimension_columns or not isinstance(dimension_columns, list):\n            # Cannot proceed without a list of columns to analyze\n            return None\n\n        # Ensure we are working with a single Series of data\n        if isinstance(data, pd.DataFrame):\n            if data.empty:\n                return None\n            s = data.iloc[0]\n        elif isinstance(data, pd.Series):\n            s = data\n        else:\n            # Input data is not in a recognized format\n            return None\n\n        # Check if all required dimension columns are present in the data\n        if not all(col in s.index for col in dimension_columns):\n            return None\n\n        # Extract the scores, coercing non-numeric values to NaN, and drop them\n        scores = pd.to_numeric(s[dimension_columns], errors='coerce').dropna()\n\n        # Standard deviation requires at least two data points for a meaningful result\n        if len(scores) < 2:\n            return None\n\n        # Calculate the population standard deviation of the valid scores\n        std_dev = np.std(scores.values)\n\n        # The cohesion index is inversely related to the standard deviation.\n        # Adding 1 to the denominator prevents division by zero for perfect cohesion.\n        # This maps std_dev=[0, inf) to an index of (0, 1].\n        cohesion_index = 1.0 / (1.0 + std_dev)\n\n        return float(cohesion_index)\n\n    except (AttributeError, KeyError, IndexError, TypeError):\n        # Handle specific, predictable errors related to data structure\n        return None\n    except Exception:\n        # A general catch-all for any other unexpected errors\n        return None\n\ndef calculate_all_derived_metrics(data: pd.DataFrame) -> Dict[str, Optional[float]]:\n    \"\"\"\n    Calculate all derived metrics for the given dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        Dictionary mapping metric names to calculated values\n    \"\"\"\n    results = {}\n    \n    # Get all calculation functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith('calculate_') and \n            name not in ['calculate_all_derived_metrics', 'calculate_derived_metrics']):\n            try:\n                results[name.replace('calculate_', '')] = obj(data)\n            except Exception as e:\n                results[name.replace('calculate_', '')] = None\n                \n    return results\n\n\ndef calculate_derived_metrics(data: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Template-compatible wrapper function for derived metrics calculation.\n    \n    This function is called by the universal notebook template and returns\n    the original data with additional derived metric columns.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        DataFrame with original data plus derived metric columns\n    \"\"\"\n    # Calculate all derived metrics\n    derived_metrics = calculate_all_derived_metrics(data)\n    \n    # Create a copy of the original data\n    result = data.copy()\n    \n    # Add derived metrics as new columns\n    for metric_name, metric_value in derived_metrics.items():\n        if metric_value is not None:\n            # For scalar metrics, broadcast to all rows\n            result[metric_name] = metric_value\n        else:\n            # For failed calculations, use NaN\n            result[metric_name] = np.nan\n    \n    return result\n",
  "cached_with_code": true
}