{
  "status": "success",
  "functions_generated": 6,
  "output_file": "automatedderivedmetricsagent_functions.py",
  "module_size": 13976,
  "function_code_content": "\"\"\"\nAutomated Derived Metrics Functions\n===================================\n\nGenerated by AutomatedDerivedMetricsAgent for experiment: Test Experiment\nDescription: Test experiment for derived metrics\nGenerated: 2025-08-25T04:10:57.312932+00:00\n\nThis module contains automatically generated calculation functions for derived metrics\nas specified in the framework's natural language descriptions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom typing import Optional, Dict, Any\n\n\ndef calculate_identity_tension(data, **kwargs):\n    \"\"\"\n    Calculate identity_tension: Conflict between tribal dominance and individual dignity dimensions\n\n    Formula: tribal_dominance * individual_dignity\n    \n    Args:\n        data: pandas DataFrame or Series with dimension scores.\n        **kwargs: Additional parameters (not used).\n        \n    Returns:\n        float: Calculated result or None if insufficient data.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # The description implies the existence of these two dimensions.\n        # Tension is modeled as the interaction (product) between them.\n        tribal_dominance = data['tribal_dominance']\n        individual_dignity = data['individual_dignity']\n\n        # Handle missing data gracefully by checking for NaN values.\n        if pd.isna(tribal_dominance) or pd.isna(individual_dignity):\n            return None\n        \n        # Perform the calculation\n        tension = float(tribal_dominance * individual_dignity)\n\n        # Ensure the result is a finite number (e.g., not infinity)\n        if not np.isfinite(tension):\n            return None\n            \n        return tension\n\n    except (KeyError, TypeError):\n        # A required column was not found (KeyError) or data was non-numeric (TypeError).\n        return None\n\ndef calculate_emotional_balance(data, **kwargs):\n    \"\"\"\n    Calculate emotional_balance: Difference between hope and fear scores\n\n    Formula: hope_score - fear_score\n\n    Args:\n        data (pd.Series): A single row of data from a DataFrame, treated as a Series.\n        **kwargs: Additional keyword arguments (not used).\n\n    Returns:\n        float: The calculated emotional balance score, or None if input data\n               is missing, invalid, or cannot be computed.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # The prompt provides no column names, so they are inferred from the\n        # calculation description as 'hope_score' and 'fear_score'.\n        hope_score = data['hope_score']\n        fear_score = data['fear_score']\n\n        # Check for missing data (NaN) in the required columns\n        if pd.isna(hope_score) or pd.isna(fear_score):\n            return None\n\n        # Perform the calculation\n        balance = float(hope_score - fear_score)\n\n        # Ensure the result is a finite number (e.g., not infinity)\n        if not np.isfinite(balance):\n            return None\n\n        return balance\n\n    except (KeyError, TypeError, ValueError):\n        # KeyError: If 'hope_score' or 'fear_score' columns do not exist.\n        # TypeError/ValueError: If the data in the columns is not numeric.\n        return None\n\ndef calculate_success_climate(data, **kwargs):\n    \"\"\"\n    Calculate success_climate: Difference between compersion and envy scores\n\n    Formula: success_climate = compersion - envy\n\n    Args:\n        data (pd.Series): A single row of data as a pandas Series.\n        **kwargs: Additional parameters (unused).\n\n    Returns:\n        float: Calculated result or None if data is missing or invalid.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # The calculation description implies 'compersion' and 'envy' columns.\n        # Since no explicit column names were provided, these are used as generic names.\n        compersion_score = data['compersion']\n        envy_score = data['envy']\n\n        # Check for missing data before calculation\n        if pd.isna(compersion_score) or pd.isna(envy_score):\n            return None\n\n        # Ensure values are numeric before subtraction\n        result = float(compersion_score) - float(envy_score)\n\n        # Check for non-finite results like infinity\n        if not np.isfinite(result):\n            return None\n\n        return result\n    except (KeyError, TypeError, ValueError):\n        # KeyError: A required column is not found.\n        # TypeError/ValueError: Data in columns is not numeric.\n        return None\n    except Exception:\n        # A general catch-all for any other unexpected errors.\n        return None\n\ndef calculate_relational_climate(data, **kwargs):\n    \"\"\"\n    Calculate relational_climate: Difference between amity and enmity scores.\n\n    Formula:\n    relational_climate = amity - enmity\n\n    Args:\n        data (pd.Series): A single row of data as a pandas Series.\n        **kwargs: Additional parameters (not used in this calculation).\n\n    Returns:\n        float: The calculated relational climate score, or None if input data is\n               missing or invalid.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    # Since the data structure is generic, we infer column names from the description.\n    amity_col = 'amity'\n    enmity_col = 'enmity'\n\n    try:\n        # Ensure the data is a pandas Series for consistent access\n        if not isinstance(data, pd.Series):\n            # If data is a DataFrame with one row, convert it\n            if isinstance(data, pd.DataFrame) and len(data) == 1:\n                data = data.iloc[0]\n            else:\n                # Cannot determine the row to process\n                return None\n\n        # Check for the existence of required columns\n        if amity_col not in data.index or enmity_col not in data.index:\n            return None\n\n        amity_score = data[amity_col]\n        enmity_score = data[enmity_col]\n\n        # Check if the values are missing (None, NaN)\n        if pd.isna(amity_score) or pd.isna(enmity_score):\n            return None\n\n        # Ensure values are numeric\n        if not all(isinstance(i, (int, float, np.number)) for i in [amity_score, enmity_score]):\n            return None\n\n        # Calculate the difference\n        relational_climate = float(amity_score) - float(enmity_score)\n\n        return relational_climate\n\n    except (KeyError, TypeError, IndexError):\n        # KeyError: if columns are not found (redundant but safe)\n        # TypeError: if data is not subscriptable or values are not numeric\n        # IndexError: if iloc[0] fails on an empty DataFrame\n        return None\n    except Exception:\n        # Catch any other unexpected errors\n        return None\n\ndef calculate_goal_orientation(data, **kwargs):\n    \"\"\"\n    Calculate goal_orientation: Difference between cohesive goals and fragmentative goals.\n    \n    Formula: goal_orientation = cohesive_goals - fragmentative_goals\n\n    Args:\n        data (pd.Series): A single row of data represented as a pandas Series.\n        **kwargs: Additional keyword arguments (not used in this calculation).\n        \n    Returns:\n        float: The calculated difference, or None if the necessary data is missing or invalid.\n    \"\"\"\n    import pandas as pd\n\n    try:\n        # Since no explicit column names are provided, generic names are derived\n        # from the calculation description as per the instructions.\n        cohesive_col = 'cohesive_goals'\n        fragmentative_col = 'fragmentative_goals'\n        \n        # Retrieve values from the data Series\n        cohesive_value = data[cohesive_col]\n        fragmentative_value = data[fragmentative_col]\n        \n        # Check for missing values (None, NaN, etc.)\n        if pd.isna(cohesive_value) or pd.isna(fragmentative_value):\n            return None\n        \n        # Perform the calculation, ensuring values are numeric.\n        # This will raise a TypeError/ValueError for non-numeric types,\n        # which is caught by the except block.\n        result = float(cohesive_value) - float(fragmentative_value)\n        \n        return result\n\n    except (KeyError, TypeError, ValueError):\n        # KeyError: A required column is not in the data.\n        # TypeError/ValueError: A value is not a number.\n        # In any error case, return None for graceful failure.\n        return None\n\ndef calculate_overall_cohesion_index(data, **kwargs):\n    \"\"\"\n    Calculate overall_cohesion_index: Comprehensive measure combining all dimensions.\n\n    This index measures both the average intensity and the internal consistency\n    of populist rhetoric across its core dimensions. A high score indicates that\n    populist themes are both strongly present and consistently used together.\n    The index is calculated by taking the mean of the dimension scores and\n    penalizing it by the standard deviation of those scores, where a higher\n    standard deviation signifies lower cohesion.\n\n    Formula:\n        mean(scores) * max(0, 1 - stddev_p(scores))\n    \n    where 'scores' are the values from the dimension columns and `stddev_p` is the\n    population standard deviation (ddof=0).\n\n    Note:\n        As the framework did not specify column names, this function assumes the\n        presence of the following generic dimension columns, which are standard in\n        populist discourse analysis. All scores are expected to be normalized\n        between 0 and 1.\n        - 'anti_elitism_score'\n        - 'people_centrism_score'\n        - 'manichean_outlook_score'\n\n    Args:\n        data (pd.Series or pd.DataFrame): A single row of data containing the\n            necessary dimension scores.\n        **kwargs: Additional parameters (not used in this calculation).\n\n    Returns:\n        float: The calculated Overall Cohesion Index, or None if any of the\n               required dimension scores are missing, non-numeric, or outside\n               the expected [0, 1] range.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    # As per the note in the docstring, we assume these generic column names.\n    dimension_columns = [\n        'anti_elitism_score',\n        'people_centrism_score',\n        'manichean_outlook_score'\n    ]\n\n    try:\n        # This function is designed for a single observation (a Series or a single-row DataFrame).\n        if isinstance(data, pd.DataFrame):\n            if data.shape[0] != 1:\n                return None  # Or raise error for batch processing misuse\n            source = data.iloc[0]\n        else:\n            source = data\n\n        # Check for the presence of all required columns\n        if not all(col in source.index for col in dimension_columns):\n            return None\n\n        # Extract scores, coercing errors to NaN\n        scores = pd.to_numeric(source[dimension_columns], errors='coerce')\n\n        # If any score is missing (NaN) after conversion, we cannot calculate.\n        if scores.isnull().any():\n            return None\n        \n        # The formula assumes scores are normalized [0, 1].\n        # Values outside this range make the cohesion factor unreliable.\n        if not ((scores >= 0) & (scores <= 1)).all():\n            return None\n\n        # We need at least two dimensions to calculate a meaningful standard deviation.\n        if len(scores) < 2:\n            return None\n\n        # Calculate the mean and population standard deviation. Using population\n        # std dev (ddof=0) as we are analyzing the full set of defined dimensions.\n        mean_score = scores.mean()\n        std_dev = scores.std(ddof=0)\n\n        # The cohesion factor penalizes inconsistency (high standard deviation).\n        # It's clamped at 0 to prevent negative results if std_dev > 1 (which\n        # is theoretically impossible for scores in [0, 1] but is a safeguard).\n        cohesion_factor = max(0.0, 1.0 - std_dev)\n\n        # The final index is the average intensity modulated by the cohesion factor.\n        result = mean_score * cohesion_factor\n        \n        return float(result)\n\n    except (AttributeError, KeyError, TypeError, ValueError):\n        # A broad catch for unexpected data structures or types.\n        return None\n\ndef calculate_all_derived_metrics(data: pd.DataFrame) -> Dict[str, Optional[float]]:\n    \"\"\"\n    Calculate all derived metrics for the given dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        Dictionary mapping metric names to calculated values\n    \"\"\"\n    results = {}\n    \n    # Get all calculation functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith('calculate_') and \n            name not in ['calculate_all_derived_metrics', 'calculate_derived_metrics']):\n            try:\n                results[name.replace('calculate_', '')] = obj(data)\n            except Exception as e:\n                results[name.replace('calculate_', '')] = None\n                \n    return results\n\n\ndef calculate_derived_metrics(data: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Template-compatible wrapper function for derived metrics calculation.\n    \n    This function is called by the universal notebook template and returns\n    the original data with additional derived metric columns.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        DataFrame with original data plus derived metric columns\n    \"\"\"\n    # Calculate all derived metrics\n    derived_metrics = calculate_all_derived_metrics(data)\n    \n    # Create a copy of the original data\n    result = data.copy()\n    \n    # Add derived metrics as new columns\n    for metric_name, metric_value in derived_metrics.items():\n        if metric_value is not None:\n            # For scalar metrics, broadcast to all rows\n            result[metric_name] = metric_value\n        else:\n            # For failed calculations, use NaN\n            result[metric_name] = np.nan\n    \n    return result\n",
  "cached_with_code": true
}