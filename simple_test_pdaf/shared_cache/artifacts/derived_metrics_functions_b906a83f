{
  "status": "success",
  "functions_generated": 6,
  "output_file": "automatedderivedmetricsagent_functions.py",
  "module_size": 14052,
  "function_code_content": "\"\"\"\nAutomated Derived Metrics Functions\n===================================\n\nGenerated by AutomatedDerivedMetricsAgent for experiment: Test Experiment\nDescription: Test experiment for derived metrics\nGenerated: 2025-08-27T13:58:24.695003+00:00\n\nThis module contains automatically generated calculation functions for derived metrics\nas specified in the framework's natural language descriptions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom typing import Optional, Dict, Any\n\n\ndef calculate_identity_tension(data, **kwargs):\n    \"\"\"\n    Calculate identity_tension: Conflict between tribal dominance and individual dignity dimensions.\n\n    This tension is modeled as the interaction between the two opposing dimensions.\n    The tension is highest when both tribal dominance and individual dignity are salient,\n    representing a direct clash of values in the discourse. A simple product captures this\n    interaction effect effectively.\n\n    Formula:\n    identity_tension = tribal_dominance_score * individual_dignity_score\n\n    Args:\n        data (pd.Series or pd.DataFrame): A single row of data containing the necessary columns.\n        **kwargs: Additional parameters (not used in this calculation).\n\n    Returns:\n        float: The calculated identity tension score, or None if essential data is missing or invalid.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    # As per the prompt, using generic but descriptive column names\n    # since no explicit names were provided in the data structure.\n    tribal_dominance_col = 'tribal_dominance_score'\n    individual_dignity_col = 'individual_dignity_score'\n\n    required_columns = [tribal_dominance_col, individual_dignity_col]\n\n    try:\n        # Ensure data is a pandas Series for consistent access\n        if isinstance(data, pd.DataFrame):\n            if data.shape[0] != 1:\n                # This function is designed to operate on a single row at a time.\n                return None\n            data = data.iloc[0]\n\n        # Check for the existence of required columns\n        if not all(col in data.index for col in required_columns):\n            return None\n\n        # Extract values\n        tribal_score = data[tribal_dominance_col]\n        dignity_score = data[individual_dignity_col]\n\n        # Check for missing or non-numeric values\n        if pd.isna(tribal_score) or pd.isna(dignity_score):\n            return None\n\n        # Convert to numeric types to ensure calculation is possible\n        tribal_score = pd.to_numeric(tribal_score, errors='coerce')\n        dignity_score = pd.to_numeric(dignity_score, errors='coerce')\n        \n        # Check again after coercion in case of non-numeric strings\n        if pd.isna(tribal_score) or pd.isna(dignity_score):\n            return None\n\n        # Calculate the tension as the product of the two scores\n        tension = float(tribal_score) * float(dignity_score)\n\n        return tension\n\n    except (AttributeError, KeyError, TypeError, ValueError):\n        # AttributeError: data is not a pandas object with .index or .iloc\n        # KeyError: A column name does not exist\n        # TypeError: Data is of an unsupported type for an operation\n        # ValueError: pd.to_numeric fails on an object it can't handle\n        return None\n\ndef calculate_emotional_balance(data, **kwargs):\n    \"\"\"\n    Calculate emotional_balance: Difference between hope and fear scores.\n\n    Formula:\n        emotional_balance = hope - fear\n\n    Args:\n        data (pd.Series): A row of data containing score columns.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        float: The calculated emotional balance, or None if input data is\n               missing or invalid.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # Per instructions, generic column names 'hope' and 'fear' are inferred\n        # from the calculation description as no specific data structure was provided.\n        hope_score = data['hope']\n        fear_score = data['fear']\n\n        # Coerce values to numeric, turning non-numeric into Not-a-Number (NaN).\n        # This robustly handles missing data or incorrect data types.\n        numeric_hope = pd.to_numeric(hope_score, errors='coerce')\n        numeric_fear = pd.to_numeric(fear_score, errors='coerce')\n\n        # If either value is NaN, the calculation will result in NaN.\n        result = numeric_hope - numeric_fear\n\n        # Return None if the result is NaN or infinite.\n        if not np.isfinite(result):\n            return None\n\n        return float(result)\n\n    except (KeyError, TypeError, ValueError):\n        # KeyError: A required column ('hope' or 'fear') is missing.\n        # TypeError/ValueError: Data is in an unexpected format.\n        return None\n\ndef calculate_success_climate(data, **kwargs):\n    \"\"\"\n    Calculate success_climate: Difference between compersion and envy scores\n\n    Formula: success_climate = compersion - envy\n    \n    Args:\n        data (pd.Series): A row of data containing the necessary columns.\n        **kwargs: Additional parameters (not used).\n        \n    Returns:\n        float: Calculated result or None if insufficient data.\n    \"\"\"\n    import pandas as pd\n\n    try:\n        # As per the calculation description, we require 'compersion' and 'envy' columns.\n        # These are inferred as generic column names since none were explicitly provided.\n        compersion_score = data['compersion']\n        envy_score = data['envy']\n\n        # Check for non-numeric or missing data (NaN)\n        if pd.isna(compersion_score) or pd.isna(envy_score):\n            return None\n\n        # Calculate the difference and ensure the result is a float\n        result = float(compersion_score - envy_score)\n        \n        return result\n\n    except (KeyError, TypeError):\n        # KeyError: A required column is missing from the data.\n        # TypeError: A column contains non-numeric data.\n        return None\n\ndef calculate_relational_climate(data, **kwargs):\n    \"\"\"\n    Calculate relational_climate: Difference between amity and enmity scores\n\n    Formula: relational_climate = amity - enmity\n    \n    Args:\n        data (pd.Series): A single row of data from a DataFrame.\n        **kwargs: Additional keyword arguments (not used).\n        \n    Returns:\n        float: The calculated relational climate score, or None if data is missing or invalid.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # Per the prompt, using generic column names as none were provided in the data structure.\n        # 'amity' and 'enmity' are assumed based on the calculation description.\n        amity_score = data['amity']\n        enmity_score = data['enmity']\n        \n        # Gracefully handle missing data by checking for null values (NaN, None, etc.)\n        if pd.isna(amity_score) or pd.isna(enmity_score):\n            return None\n        \n        # Ensure values are numeric and perform the calculation.\n        # A TypeError will be raised if values are not convertible to float,\n        # which is caught by the exception handling below.\n        return float(amity_score) - float(enmity_score)\n        \n    except (KeyError, TypeError, ValueError):\n        # Handles cases where:\n        # - KeyError: 'amity' or 'enmity' columns are missing.\n        # - TypeError/ValueError: Values in columns are not numeric or cannot be converted.\n        return None\n\ndef calculate_goal_orientation(data, **kwargs):\n    \"\"\"\n    Calculate goal_orientation: Difference between cohesive goals and fragmentative goals.\n\n    Formula:\n    goal_orientation = cohesive_goals - fragmentative_goals\n    \n    Args:\n        data (pd.Series): A row of data from a DataFrame. This function assumes\n                          the presence of 'cohesive_goals' and 'fragmentative_goals'\n                          columns, inferred from the calculation description as no\n                          explicit column names were provided in the framework.\n        **kwargs: Additional keyword arguments (not used).\n        \n    Returns:\n        float: The calculated score, or None if the necessary data is missing or invalid.\n    \"\"\"\n    import pandas as pd\n\n    try:\n        cohesive_goals_score = data['cohesive_goals']\n        fragmentative_goals_score = data['fragmentative_goals']\n\n        # Check for missing values (e.g., NaN, None)\n        if pd.isna(cohesive_goals_score) or pd.isna(fragmentative_goals_score):\n            return None\n\n        # Ensure values are numeric and perform the calculation\n        result = float(cohesive_goals_score) - float(fragmentative_goals_score)\n        return result\n\n    except Exception:\n        # Handles errors like missing columns (KeyError), non-numeric data\n        # (TypeError, ValueError), or other unexpected issues.\n        return None\n\ndef calculate_overall_cohesion_index(data, **kwargs):\n    \"\"\"\n    Calculate overall_cohesion_index: A comprehensive measure combining the\n    magnitude and consistency of various populist discourse dimensions.\n\n    This function operationalizes the \"overall_cohesion_index\" from the\n    Populist Discourse Analysis Framework (PDAF). Since no explicit dimension\n    columns are provided in the framework specification, this function\n    requires them to be passed as a keyword argument.\n\n    The index is calculated as a function of both the average score across\n    dimensions (magnitude) and the standard deviation of those scores\n    (a proxy for consistency or 'cohesion'). A higher index indicates that\n    the discourse dimensions are both strong (high mean) and consistently\n    expressed (low standard deviation).\n\n    Formula:\n        OCI = Mean(S) / (1 + StdDev(S))\n        Where S is the set of valid, non-null dimension scores.\n\n    A standard deviation is used to measure the dispersion of scores, representing\n    the \"strategic tension\" mentioned in the PDAF. Dividing by (1 + StdDev)\n    normalizes the mean score by its consistency.\n\n    Args:\n        data (pd.Series or pd.DataFrame): A single row of data as a pandas\n            Series or a one-row DataFrame containing the dimension scores.\n        **kwargs: Keyword arguments. Must include:\n            'dimension_cols' (list of str): A list of the exact column names\n            representing the dimension scores to be included in the calculation.\n\n    Returns:\n        float: The calculated Overall Cohesion Index, or None if the calculation\n               is not possible due to missing columns, insufficient data\n               (fewer than two valid scores), or other errors.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        dimension_cols = kwargs.get('dimension_cols')\n\n        # Validate that dimension_cols argument is provided and is a list\n        if not dimension_cols or not isinstance(dimension_cols, list):\n            return None\n\n        # Ensure the input is a pandas Series for consistent handling\n        if isinstance(data, pd.DataFrame):\n            if len(data) != 1:\n                # Function is designed for a single observation\n                return None\n            data = data.iloc[0]\n        elif not isinstance(data, pd.Series):\n            return None\n\n        # Check for the presence of all required columns\n        if not all(col in data.index for col in dimension_cols):\n            return None\n\n        # Extract scores, convert to numeric, and drop any missing values\n        scores = pd.to_numeric(data[dimension_cols], errors='coerce').dropna()\n\n        # Cohesion requires at least two dimensions to compare.\n        # Standard deviation is not defined for a single point.\n        if len(scores) < 2:\n            return None\n\n        mean_score = scores.mean()\n        std_dev = scores.std()\n\n        # The core calculation: mean score penalized by its standard deviation.\n        # Adding 1 to the denominator prevents division by zero if std_dev is 0.\n        cohesion_index = mean_score / (1 + std_dev)\n\n        return float(cohesion_index)\n\n    except (AttributeError, KeyError, TypeError, ValueError):\n        # Catch a wide range of potential pandas/numpy/python errors\n        return None\n\ndef calculate_all_derived_metrics(data: pd.DataFrame) -> Dict[str, Optional[float]]:\n    \"\"\"\n    Calculate all derived metrics for the given dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        Dictionary mapping metric names to calculated values\n    \"\"\"\n    results = {}\n    \n    # Get all calculation functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith('calculate_') and \n            name not in ['calculate_all_derived_metrics', 'calculate_derived_metrics']):\n            try:\n                results[name.replace('calculate_', '')] = obj(data)\n            except Exception as e:\n                results[name.replace('calculate_', '')] = None\n                \n    return results\n\n\ndef calculate_derived_metrics(data: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Template-compatible wrapper function for derived metrics calculation.\n    \n    This function is called by the universal notebook template and returns\n    the original data with additional derived metric columns.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        DataFrame with original data plus derived metric columns\n    \"\"\"\n    # Calculate all derived metrics\n    derived_metrics = calculate_all_derived_metrics(data)\n    \n    # Create a copy of the original data\n    result = data.copy()\n    \n    # Add derived metrics as new columns\n    for metric_name, metric_value in derived_metrics.items():\n        if metric_value is not None:\n            # For scalar metrics, broadcast to all rows\n            result[metric_name] = metric_value\n        else:\n            # For failed calculations, use NaN\n            result[metric_name] = np.nan\n    \n    return result\n",
  "cached_with_code": true
}