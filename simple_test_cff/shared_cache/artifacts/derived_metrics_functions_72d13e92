{
  "status": "success",
  "functions_generated": 6,
  "output_file": "automatedderivedmetricsagent_functions.py",
  "module_size": 13712,
  "function_code_content": "\"\"\"\nAutomated Derived Metrics Functions\n===================================\n\nGenerated by AutomatedDerivedMetricsAgent for experiment: Test Experiment\nDescription: Test experiment for derived metrics\nGenerated: 2025-08-23T17:56:35.615786+00:00\n\nThis module contains automatically generated calculation functions for derived metrics\nas specified in the framework's natural language descriptions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom typing import Optional, Dict, Any\n\n\ndef calculate_identity_tension(data, **kwargs):\n    \"\"\"\n    Calculate identity_tension: Conflict between tribal dominance and individual dignity dimensions.\n\n    This tension is highest when both tribal dominance and individual dignity are strongly present,\n    reflecting a communication strategy that appeals to both in-group superiority and universal human worth simultaneously.\n    The calculation uses a formula related to the harmonic mean to capture this interaction, ensuring the\n    tension is low if either dimension is absent.\n\n    Formula: (2 * tribal_dominance * individual_dignity) / (tribal_dominance + individual_dignity)\n    If (tribal_dominance + individual_dignity) is 0, the result is 0.\n\n    Args:\n        data (pd.Series): A single row of data containing the necessary columns.\n        **kwargs: Additional parameters (unused in this calculation).\n\n    Returns:\n        float: The calculated identity tension score, or None if input data is missing or invalid.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # Based on the description \"Conflict between tribal dominance and individual dignity dimensions\",\n        # the logical column names are 'tribal_dominance' and 'individual_dignity'.\n        tribal_dominance = data.get('tribal_dominance')\n        individual_dignity = data.get('individual_dignity')\n\n        # Gracefully handle missing data: if columns are missing or values are NaN\n        if pd.isna(tribal_dominance) or pd.isna(individual_dignity):\n            return None\n\n        # The calculation requires both scores to be numeric\n        if not all(isinstance(i, (int, float)) for i in [tribal_dominance, individual_dignity]):\n             return None\n\n        numerator = 2 * tribal_dominance * individual_dignity\n        denominator = tribal_dominance + individual_dignity\n\n        # Avoid division by zero. If both scores are 0, there is no tension.\n        if denominator == 0:\n            return 0.0\n        else:\n            return numerator / denominator\n\n    except (TypeError, AttributeError, KeyError):\n        # Handle cases where data is not in the expected format (e.g., not a Series)\n        return None\n    except Exception:\n        # A final catch-all for any other unexpected errors\n        return None\n\ndef calculate_emotional_balance(data, **kwargs):\n    \"\"\"\n    Calculate emotional_balance: Difference between hope and fear scores\n\n    Formula: emotional_balance = hope_score - fear_score\n\n    Args:\n        data (pd.Series): A row of data with dimension scores.\n        **kwargs: Additional keyword arguments (unused).\n\n    Returns:\n        float: The calculated emotional balance, or None if required data is missing or invalid.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # Per instructions to use generic column names as none were specified in the data structure.\n        hope_score_col = 'hope_score'\n        fear_score_col = 'fear_score'\n\n        # Extract scores from the data object (e.g., a pandas Series).\n        hope_score = data[hope_score_col]\n        fear_score = data[fear_score_col]\n\n        # Gracefully handle missing data by checking for null values.\n        if pd.isna(hope_score) or pd.isna(fear_score):\n            return None\n\n        # Calculate the difference and ensure the result is a standard float.\n        result = float(hope_score) - float(fear_score)\n\n        return result\n\n    except Exception:\n        # Catch all exceptions (e.g., KeyError for missing columns, TypeError for non-numeric data)\n        # and return None for production-level robustness.\n        return None\n\ndef calculate_success_climate(data, **kwargs):\n    \"\"\"\n    Calculate success_climate: Difference between compersion and envy scores\n\n    Formula: success_climate = compersion - envy\n    \n    Args:\n        data: pandas DataFrame or Series with dimension scores.\n              This function expects columns 'compersion' and 'envy'.\n        **kwargs: Additional parameters (unused).\n        \n    Returns:\n        float: Calculated result or None if insufficient data.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # Retrieve scores from the data object (which is a single row as a Series)\n        compersion_score = data['compersion']\n        envy_score = data['envy']\n        \n        # Check for missing data (NaN, None, etc.)\n        if pd.isna(compersion_score) or pd.isna(envy_score):\n            return None\n            \n        # Perform the calculation and ensure the result is a float\n        result = float(compersion_score) - float(envy_score)\n        \n        return result\n        \n    except (KeyError, TypeError, ValueError):\n        # KeyError: If 'compersion' or 'envy' columns are missing.\n        # TypeError: If data in columns is not numeric.\n        # ValueError: If casting to float fails for an unexpected reason.\n        return None\n    except Exception:\n        # A general catch-all for any other unexpected errors.\n        return None\n\ndef calculate_relational_climate(data, **kwargs):\n    \"\"\"\n    Calculate relational_climate: Difference between amity and enmity scores\n\n    Formula: relational_climate = amity - enmity\n\n    Args:\n        data (pd.Series): A single row of data containing the necessary columns.\n        **kwargs: Additional parameters (unused).\n\n    Returns:\n        float: Calculated result or None if insufficient data.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # The calculation is the difference between 'amity' and 'enmity' scores.\n        # These are the required columns, derived from the calculation description.\n        amity_col = 'amity'\n        enmity_col = 'enmity'\n\n        # Use pd.to_numeric to handle non-numeric data and convert to NaN if invalid.\n        # .get() is used for safety, returning None if a column is missing.\n        amity_score = pd.to_numeric(data.get(amity_col), errors='coerce')\n        enmity_score = pd.to_numeric(data.get(enmity_col), errors='coerce')\n\n        # If either score is NaN (due to missing columns, None values, or non-numeric data),\n        # the calculation is not possible.\n        if pd.isna(amity_score) or pd.isna(enmity_score):\n            return None\n\n        # Perform the calculation and ensure the result is a standard Python float.\n        result = amity_score - enmity_score\n        return float(result)\n\n    except Exception:\n        # Catches any other unexpected errors, such as 'data' not being a\n        # pandas Series or other data access issues.\n        return None\n\ndef calculate_goal_orientation(data, **kwargs):\n    \"\"\"\n    Calculate goal_orientation: Difference between cohesive goals and fragmentative goals\n\n    Formula: goal_orientation = cohesive_goals - fragmentative_goals\n\n    Args:\n        data (pd.Series): A single row of data as a pandas Series.\n        **kwargs: Additional keyword arguments (not used).\n\n    Returns:\n        float: Calculated result or None if insufficient data.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # Based on the description, we infer the necessary column names.\n        cohesive_col = 'cohesive_goals'\n        fragmentative_col = 'fragmentative_goals'\n\n        # Extract values from the data Series\n        cohesive_value = data[cohesive_col]\n        fragmentative_value = data[fragmentative_col]\n\n        # Check for missing data. If either value is null or NaN, return None.\n        if pd.isna(cohesive_value) or pd.isna(fragmentative_value):\n            return None\n\n        # Perform the calculation and ensure the result is a float\n        result = float(cohesive_value - fragmentative_value)\n\n        return result\n\n    except (KeyError, TypeError, ValueError):\n        # KeyError: A required column is missing.\n        # TypeError: Data in columns is not numeric.\n        # ValueError: Data cannot be converted to float.\n        return None\n    except Exception:\n        # Catch any other unexpected errors for production-readiness.\n        return None\n\ndef calculate_overall_cohesion_index(data, **kwargs):\n    \"\"\"\n    Calculate overall_cohesion_index: Comprehensive measure combining all dimensions.\n\n    This index provides a holistic score of a discourse's contribution to social cohesion\n    by averaging scores from key underlying dimensions.\n\n    Formula:\n        mean(social_solidarity_score, institutional_trust_score, civic_engagement_score, constructive_discourse_score)\n\n    Note: The specific dimension column names used in this formula are assumed based\n    on the Cohesive Flourishing Framework's description of its analytical goals\n    (measuring social solidarity, trust, civic engagement), as explicit column names\n    were not provided. These names should be verified and adjusted if necessary.\n\n    Args:\n        data (pd.Series or pd.DataFrame): A row (Series) or table (DataFrame)\n            containing the necessary dimension scores for calculation.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        float or pd.Series or None:\n            - If data is a pd.Series, returns a single float score or None if\n              any required data is missing.\n            - If data is a pd.DataFrame, returns a pd.Series of scores, with None\n              for rows where data is missing.\n            - Returns None if essential columns are missing or an error occurs.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # These column names are inferred from the framework description.\n        # They represent the core dimensions that contribute to the overall index.\n        dimension_columns = [\n            'social_solidarity_score',\n            'institutional_trust_score',\n            'civic_engagement_score',\n            'constructive_discourse_score'\n        ]\n\n        # Check for presence of all required columns to avoid partial calculations.\n        # This check works for both Series (checking index) and DataFrame (checking columns).\n        required_set = set(dimension_columns)\n        available_set = set(data.index if isinstance(data, pd.Series) else data.columns)\n        if not required_set.issubset(available_set):\n            return None\n\n        relevant_data = data[dimension_columns]\n\n        # Handle a single row of data (pd.Series)\n        if isinstance(data, pd.Series):\n            # If any component score is null, the overall index is invalid.\n            if relevant_data.isnull().any():\n                return None\n            return relevant_data.mean()\n\n        # Handle multiple rows of data (pd.DataFrame)\n        elif isinstance(data, pd.DataFrame):\n            # Calculate the mean for each row.\n            # Using skipna=False ensures that if any value in a row is NaN,\n            # the resulting mean for that row will also be NaN.\n            result_series = relevant_data.mean(axis=1, skipna=False)\n            \n            # Replace NaN values with None as per the requirement for graceful handling.\n            return result_series.where(pd.notna(result_series), None)\n            \n        # Return None if the data is not a recognized pandas type\n        return None\n\n    except Exception:\n        # Catch any other errors during processing (e.g., non-numeric data)\n        # and return None for safety.\n        return None\n\ndef calculate_all_derived_metrics(data: pd.DataFrame) -> Dict[str, Optional[float]]:\n    \"\"\"\n    Calculate all derived metrics for the given dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        Dictionary mapping metric names to calculated values\n    \"\"\"\n    results = {}\n    \n    # Get all calculation functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith('calculate_') and \n            name not in ['calculate_all_derived_metrics', 'calculate_derived_metrics']):\n            try:\n                results[name.replace('calculate_', '')] = obj(data)\n            except Exception as e:\n                results[name.replace('calculate_', '')] = None\n                \n    return results\n\n\ndef calculate_derived_metrics(data: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Template-compatible wrapper function for derived metrics calculation.\n    \n    This function is called by the universal notebook template and returns\n    the original data with additional derived metric columns.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        DataFrame with original data plus derived metric columns\n    \"\"\"\n    # Calculate all derived metrics\n    derived_metrics = calculate_all_derived_metrics(data)\n    \n    # Create a copy of the original data\n    result = data.copy()\n    \n    # Add derived metrics as new columns\n    for metric_name, metric_value in derived_metrics.items():\n        if metric_value is not None:\n            # For scalar metrics, broadcast to all rows\n            result[metric_name] = metric_value\n        else:\n            # For failed calculations, use NaN\n            result[metric_name] = np.nan\n    \n    return result\n",
  "cached_with_code": true
}