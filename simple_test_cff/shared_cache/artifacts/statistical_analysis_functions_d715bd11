{
  "status": "success",
  "functions_generated": 4,
  "output_file": "automatedstatisticalanalysisagent_functions.py",
  "module_size": 20556,
  "function_code_content": "\"\"\"\nAutomated Statistical Analysis Functions\n========================================\n\nGenerated by AutomatedStatisticalAnalysisAgent for experiment: simple_test\nDescription: Statistical analysis experiment\nGenerated: 2025-08-24T01:07:33.593135+00:00\n\nThis module contains automatically generated statistical analysis functions\nfor comprehensive data analysis including ANOVA, correlations, reliability,\nand hypothesis testing as appropriate for the research questions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport scipy.stats as stats\nfrom typing import Dict, Any, Optional, List, Tuple\nimport warnings\n\n# Suppress common statistical warnings for cleaner output\nwarnings.filterwarnings('ignore', category=RuntimeWarning)\n\n\ndef calculate_descriptive_statistics(data, **kwargs):\n    \"\"\"\n    Calculates descriptive statistics for all raw score, salience, and confidence dimensions.\n\n    This function provides a baseline understanding of the data distribution across the corpus.\n    It computes the mean, standard deviation, count, min, and max for each primary\n    numeric column provided by the CFF analysis. This helps identify central tendencies,\n    variance, and the range of scores for each rhetorical dimension.\n\n    Args:\n        data (pd.DataFrame): A pandas DataFrame containing the analysis data with columns\n                             matching the CFF specification (e.g., 'tribal_dominance_raw',\n                             'tribal_dominance_salience').\n        **kwargs: Additional parameters (not used in this function).\n\n    Returns:\n        dict: A nested dictionary where each key is a column name and the value is a\n              dictionary of its descriptive statistics (mean, std, count, min, max).\n              Returns None if the input data is invalid or an error occurs.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    import json\n    import glob\n    from pathlib import Path\n\n    try:\n        if data is None or data.empty:\n            return None\n\n        results = {}\n        numeric_columns = data.select_dtypes(include=[np.number]).columns\n\n        for col in numeric_columns:\n            # Ensure we only process the expected CFF columns\n            if col.endswith(('_raw', '_salience', '_confidence')):\n                # Drop NaN values for calculation to avoid errors and get accurate counts\n                col_data = data[col].dropna()\n                if not col_data.empty:\n                    results[col] = {\n                        'mean': float(col_data.mean()),\n                        'std': float(col_data.std()),\n                        'count': int(col_data.count()),\n                        'min': float(col_data.min()),\n                        'max': float(col_data.max())\n                    }\n                else:\n                    results[col] = {\n                        'mean': None, 'std': None, 'count': 0, 'min': None, 'max': None\n                    }\n        \n        return results if results else None\n\n    except Exception as e:\n        # In a real environment, you might log the error e\n        return None\n\ndef calculate_tension_indices(data, **kwargs):\n    \"\"\"\n    Calculates the five Rhetorical Tension Indices and the Strategic Contradiction Index.\n\n    This function implements the CFF's methodology for measuring rhetorical incoherence.\n    Each tension index quantifies the strategic contradiction between opposing conceptual\n    anchors (e.g., Hope vs. Fear). A high tension score indicates that a text strongly\n    appeals to both opposing concepts but emphasizes one over the other, a sophisticated\n    rhetorical strategy. The Strategic Contradiction Index provides an overall measure\n    of the text's rhetorical coherence.\n\n    Methodology:\n    - Tension = min(Score_A, Score_B) * |Salience_A - Salience_B|\n    - Strategic Contradiction Index = Average of the five tension indices.\n\n    Args:\n        data (pd.DataFrame): A pandas DataFrame with CFF scores.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary containing descriptive statistics (mean, std, etc.) for each\n              calculated tension index and the overall strategic contradiction index.\n              Returns None on error or if essential columns are missing.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    import json\n    import glob\n    from pathlib import Path\n\n    try:\n        if data is None or data.empty:\n            return None\n\n        df = data.copy()\n\n        # Define required columns to check for their existence\n        required_cols = [\n            'tribal_dominance_raw', 'individual_dignity_raw', 'tribal_dominance_salience', 'individual_dignity_salience',\n            'fear_raw', 'hope_raw', 'fear_salience', 'hope_salience',\n            'envy_raw', 'compersion_raw', 'envy_salience', 'compersion_salience',\n            'enmity_raw', 'amity_raw', 'enmity_salience', 'amity_salience',\n            'fragmentative_goals_raw', 'cohesive_goals_raw', 'fragmentative_goals_salience', 'cohesive_goals_salience'\n        ]\n        if not all(col in df.columns for col in required_cols):\n            return None # Or raise an error indicating missing columns\n\n        # Calculate Tension Indices\n        df['identity_tension'] = np.minimum(df['tribal_dominance_raw'], df['individual_dignity_raw']) * \\\n                                 abs(df['tribal_dominance_salience'] - df['individual_dignity_salience'])\n\n        df['emotional_tension'] = np.minimum(df['fear_raw'], df['hope_raw']) * \\\n                                  abs(df['fear_salience'] - df['hope_salience'])\n\n        df['success_tension'] = np.minimum(df['envy_raw'], df['compersion_raw']) * \\\n                                abs(df['envy_salience'] - df['compersion_salience'])\n\n        df['relational_tension'] = np.minimum(df['enmity_raw'], df['amity_raw']) * \\\n                                   abs(df['enmity_salience'] - df['amity_salience'])\n\n        df['goal_tension'] = np.minimum(df['fragmentative_goals_raw'], df['cohesive_goals_raw']) * \\\n                             abs(df['fragmentative_goals_salience'] - df['cohesive_goals_salience'])\n\n        # Calculate Strategic Contradiction Index\n        tension_cols = ['identity_tension', 'emotional_tension', 'success_tension', 'relational_tension', 'goal_tension']\n        df['strategic_contradiction_index'] = df[tension_cols].mean(axis=1)\n\n        # Prepare results\n        results = {}\n        index_cols = tension_cols + ['strategic_contradiction_index']\n        for col in index_cols:\n            col_data = df[col].dropna()\n            if not col_data.empty:\n                results[col] = {\n                    'mean': float(col_data.mean()),\n                    'std': float(col_data.std()),\n                    'count': int(col_data.count()),\n                    'min': float(col_data.min()),\n                    'max': float(col_data.max())\n                }\n        \n        return results if results else None\n\n    except Exception as e:\n        return None\n\ndef calculate_cohesion_indices(data, **kwargs):\n    \"\"\"\n    Calculates the three Salience-Weighted Cohesion Indices from the CFF.\n\n    This function computes the core composite metrics of the CFF, which evaluate the\n    overall cohesive or fragmentative thrust of a text. The indices are normalized\n    by the total salience of their constituent dimensions, ensuring that the final\n    score reflects the rhetorical emphasis of the discourse. Scores range from\n    -1.0 (highly fragmentative) to +1.0 (highly cohesive).\n\n    Indices Calculated:\n    - Descriptive Cohesion Index: Focuses on immediate emotional and relational climate.\n    - Motivational Cohesion Index: Adds goal orientation to assess behavioral implications.\n    - Full Cohesion Index: The most comprehensive measure, including all 5 axes to evaluate\n      the overall impact on democratic health and social solidarity.\n\n    Args:\n        data (pd.DataFrame): A pandas DataFrame with CFF scores.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary containing descriptive statistics (mean, std, etc.) for each\n              of the three calculated cohesion indices. Returns None on error or if\n              essential columns are missing.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    import json\n    import glob\n    from pathlib import Path\n\n    try:\n        if data is None or data.empty:\n            return None\n\n        df = data.copy()\n        epsilon = 0.001\n\n        # Define required columns\n        required_cols = [\n            'tribal_dominance_raw', 'individual_dignity_raw', 'tribal_dominance_salience', 'individual_dignity_salience',\n            'fear_raw', 'hope_raw', 'fear_salience', 'hope_salience',\n            'envy_raw', 'compersion_raw', 'envy_salience', 'compersion_salience',\n            'enmity_raw', 'amity_raw', 'enmity_salience', 'amity_salience',\n            'fragmentative_goals_raw', 'cohesive_goals_raw', 'fragmentative_goals_salience', 'cohesive_goals_salience'\n        ]\n        if not all(col in df.columns for col in required_cols):\n            return None\n\n        # Calculate Cohesion Components (Numerators)\n        identity_comp = (df['individual_dignity_raw'] * df['individual_dignity_salience']) - (df['tribal_dominance_raw'] * df['tribal_dominance_salience'])\n        emotional_comp = (df['hope_raw'] * df['hope_salience']) - (df['fear_raw'] * df['fear_salience'])\n        success_comp = (df['compersion_raw'] * df['compersion_salience']) - (df['envy_raw'] * df['envy_salience'])\n        relational_comp = (df['amity_raw'] * df['amity_salience']) - (df['enmity_raw'] * df['enmity_salience'])\n        goal_comp = (df['cohesive_goals_raw'] * df['cohesive_goals_salience']) - (df['fragmentative_goals_raw'] * df['fragmentative_goals_salience'])\n\n        # Calculate Salience Totals (Denominators)\n        descriptive_salience = df['hope_salience'] + df['fear_salience'] + df['compersion_salience'] + df['envy_salience'] + df['amity_salience'] + df['enmity_salience']\n        motivational_salience = descriptive_salience + df['cohesive_goals_salience'] + df['fragmentative_goals_salience']\n        full_salience = motivational_salience + df['individual_dignity_salience'] + df['tribal_dominance_salience']\n\n        # Calculate Final Indices\n        df['descriptive_cohesion_index'] = (emotional_comp + success_comp + relational_comp) / (descriptive_salience + epsilon)\n        df['motivational_cohesion_index'] = (emotional_comp + success_comp + relational_comp + goal_comp) / (motivational_salience + epsilon)\n        df['full_cohesion_index'] = (identity_comp + emotional_comp + success_comp + relational_comp + goal_comp) / (full_salience + epsilon)\n        \n        # Clip values to be strictly within [-1.0, 1.0] as per spec\n        index_cols = ['descriptive_cohesion_index', 'motivational_cohesion_index', 'full_cohesion_index']\n        for col in index_cols:\n            df[col] = df[col].clip(-1.0, 1.0)\n\n        # Prepare results\n        results = {}\n        for col in index_cols:\n            col_data = df[col].dropna()\n            if not col_data.empty:\n                results[col] = {\n                    'mean': float(col_data.mean()),\n                    'std': float(col_data.std()),\n                    'count': int(col_data.count()),\n                    'min': float(col_data.min()),\n                    'max': float(col_data.max())\n                }\n        \n        return results if results else None\n\n    except Exception as e:\n        return None\n\ndef calculate_full_correlation_matrix(data, **kwargs):\n    \"\"\"\n    Calculates and returns a full correlation matrix including raw scores and derived indices.\n\n    This function provides a comprehensive view of the relationships between all primary\n    and derived metrics in the CFF. It first calculates all tension and cohesion indices,\n    adds them to the dataset, and then computes a Pearson correlation matrix. This can\n    reveal important patterns, such as which rhetorical dimensions are commonly used\n    together and how individual dimensions relate to the overall cohesion or tension scores.\n\n    Args:\n        data (pd.DataFrame): A pandas DataFrame with CFF scores.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A JSON-serializable nested dictionary representing the correlation matrix.\n              Returns None on error or if data is insufficient.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    import json\n    import glob\n    from pathlib import Path\n\n    try:\n        if data is None or data.empty or len(data) < 2:\n            return None\n\n        df = data.copy()\n        epsilon = 0.001\n\n        # --- Calculate Tension Indices ---\n        df['identity_tension'] = np.minimum(df['tribal_dominance_raw'], df['individual_dignity_raw']) * abs(df['tribal_dominance_salience'] - df['individual_dignity_salience'])\n        df['emotional_tension'] = np.minimum(df['fear_raw'], df['hope_raw']) * abs(df['fear_salience'] - df['hope_salience'])\n        df['success_tension'] = np.minimum(df['envy_raw'], df['compersion_raw']) * abs(df['envy_salience'] - df['compersion_salience'])\n        df['relational_tension'] = np.minimum(df['enmity_raw'], df['amity_raw']) * abs(df['enmity_salience'] - df['amity_salience'])\n        df['goal_tension'] = np.minimum(df['fragmentative_goals_raw'], df['cohesive_goals_raw']) * abs(df['fragmentative_goals_salience'] - df['cohesive_goals_salience'])\n        tension_cols = ['identity_tension', 'emotional_tension', 'success_tension', 'relational_tension', 'goal_tension']\n        df['strategic_contradiction_index'] = df[tension_cols].mean(axis=1)\n\n        # --- Calculate Cohesion Indices ---\n        identity_comp = (df['individual_dignity_raw'] * df['individual_dignity_salience']) - (df['tribal_dominance_raw'] * df['tribal_dominance_salience'])\n        emotional_comp = (df['hope_raw'] * df['hope_salience']) - (df['fear_raw'] * df['fear_salience'])\n        success_comp = (df['compersion_raw'] * df['compersion_salience']) - (df['envy_raw'] * df['envy_salience'])\n        relational_comp = (df['amity_raw'] * df['amity_salience']) - (df['enmity_raw'] * df['enmity_salience'])\n        goal_comp = (df['cohesive_goals_raw'] * df['cohesive_goals_salience']) - (df['fragmentative_goals_raw'] * df['fragmentative_goals_salience'])\n        \n        descriptive_salience = df['hope_salience'] + df['fear_salience'] + df['compersion_salience'] + df['envy_salience'] + df['amity_salience'] + df['enmity_salience']\n        motivational_salience = descriptive_salience + df['cohesive_goals_salience'] + df['fragmentative_goals_salience']\n        full_salience = motivational_salience + df['individual_dignity_salience'] + df['tribal_dominance_salience']\n\n        df['descriptive_cohesion_index'] = ((emotional_comp + success_comp + relational_comp) / (descriptive_salience + epsilon)).clip(-1, 1)\n        df['motivational_cohesion_index'] = ((emotional_comp + success_comp + relational_comp + goal_comp) / (motivational_salience + epsilon)).clip(-1, 1)\n        df['full_cohesion_index'] = ((identity_comp + emotional_comp + success_comp + relational_comp + goal_comp) / (full_salience + epsilon)).clip(-1, 1)\n\n        # --- Generate Correlation Matrix ---\n        raw_score_cols = [col for col in df.columns if col.endswith('_raw')]\n        derived_cols = tension_cols + ['strategic_contradiction_index', 'descriptive_cohesion_index', 'motivational_cohesion_index', 'full_cohesion_index']\n        \n        cols_for_corr = raw_score_cols + derived_cols\n        \n        # Ensure all columns exist before trying to create correlation matrix\n        final_cols = [col for col in cols_for_corr if col in df.columns]\n        \n        corr_matrix = df[final_cols].corr(method='pearson')\n        \n        # Convert to dictionary and handle NaNs for JSON serialization\n        corr_dict = corr_matrix.where(pd.notnull(corr_matrix), None).to_dict()\n\n        return corr_dict\n\n    except Exception as e:\n        return None\n\ndef run_complete_statistical_analysis(data: pd.DataFrame, alpha: float = 0.05) -> Dict[str, Any]:\n    \"\"\"\n    Run complete statistical analysis suite on the dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        alpha: Significance level for hypothesis tests (default: 0.05)\n        \n    Returns:\n        Dictionary with all statistical analysis results\n    \"\"\"\n    results = {\n        'analysis_metadata': {\n            'timestamp': pd.Timestamp.now().isoformat(),\n            'sample_size': len(data),\n            'alpha_level': alpha,\n            'variables_analyzed': list(data.select_dtypes(include=[np.number]).columns)\n        }\n    }\n    \n    # Get all analysis functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith(('calculate_', 'perform_', 'test_')) and \n            name != 'run_complete_statistical_analysis'):\n            try:\n                # Pass alpha parameter to functions that might need it\n                if 'alpha' in inspect.signature(obj).parameters:\n                    results[name] = obj(data, alpha=alpha)\n                else:\n                    results[name] = obj(data)\n            except Exception as e:\n                results[name] = {'error': f'Analysis failed: {str(e)}'}\n                \n    return results\n\n\ndef perform_statistical_analysis(data: pd.DataFrame) -> Dict[str, Any]:\n    \"\"\"\n    Template-compatible wrapper function for statistical analysis.\n    \n    This function is called by the universal notebook template and performs\n    comprehensive statistical analysis on the provided dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores and derived metrics\n        \n    Returns:\n        Dictionary containing all statistical analysis results\n    \"\"\"\n    return run_complete_statistical_analysis(data)\n\n\ndef generate_statistical_summary_report(analysis_results: Dict[str, Any]) -> str:\n    \"\"\"\n    Generate a human-readable summary report from statistical analysis results.\n    \n    Args:\n        analysis_results: Results from run_complete_statistical_analysis()\n        \n    Returns:\n        String containing formatted statistical report\n    \"\"\"\n    report_lines = []\n    report_lines.append(\"STATISTICAL ANALYSIS SUMMARY REPORT\")\n    report_lines.append(\"=\" * 50)\n    \n    metadata = analysis_results.get('analysis_metadata', {})\n    report_lines.append(f\"Analysis Timestamp: {metadata.get('timestamp', 'Unknown')}\")\n    report_lines.append(f\"Sample Size: {metadata.get('sample_size', 'Unknown')}\")\n    report_lines.append(f\"Alpha Level: {metadata.get('alpha_level', 'Unknown')}\")\n    report_lines.append(f\"Variables: {len(metadata.get('variables_analyzed', []))}\")\n    report_lines.append(\"\")\n    \n    # Summarize key findings\n    for analysis_name, result in analysis_results.items():\n        if analysis_name != 'analysis_metadata' and isinstance(result, dict):\n            if 'error' not in result:\n                report_lines.append(f\"{analysis_name.replace('_', ' ').title()}:\")\n                \n                # Extract key statistics based on analysis type\n                if 'p_value' in result:\n                    p_val = result['p_value']\n                    significance = \"significant\" if p_val < metadata.get('alpha_level', 0.05) else \"not significant\"\n                    report_lines.append(f\"  - p-value: {p_val:.4f} ({significance})\")\n                \n                if 'effect_size' in result:\n                    report_lines.append(f\"  - Effect size: {result['effect_size']:.4f}\")\n                \n                if 'correlation_matrix' in result:\n                    report_lines.append(f\"  - Correlation matrix generated with {len(result['correlation_matrix'])} variables\")\n                \n                if 'cronbach_alpha' in result:\n                    alpha_val = result['cronbach_alpha']\n                    reliability = \"excellent\" if alpha_val > 0.9 else \"good\" if alpha_val > 0.8 else \"acceptable\" if alpha_val > 0.7 else \"questionable\"\n                    report_lines.append(f\"  - Cronbach's \u03b1: {alpha_val:.3f} ({reliability})\")\n                \n                report_lines.append(\"\")\n            else:\n                report_lines.append(f\"{analysis_name}: ERROR - {result['error']}\")\n                report_lines.append(\"\")\n    \n    return \"\\n\".join(report_lines)\n",
  "cached_with_code": true
}