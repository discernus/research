{
  "status": "success",
  "functions_generated": 6,
  "output_file": "automatedderivedmetricsagent_functions.py",
  "module_size": 18369,
  "function_code_content": "\"\"\"\nAutomated Derived Metrics Functions\n===================================\n\nGenerated by AutomatedDerivedMetricsAgent for experiment: Test Experiment\nDescription: Test experiment for derived metrics\nGenerated: 2025-08-28T16:19:45.247080+00:00\n\nThis module contains automatically generated calculation functions for derived metrics\nas specified in the framework's natural language descriptions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom typing import Optional, Dict, Any\n\n\ndef calculate_identity_tension(data, **kwargs):\n    \"\"\"\n    Calculate identity_tension: Conflict between tribal dominance and individual dignity dimensions\n    Formula: abs(Tribal Dominance Score - Individual Dignity Score)\n    \n    Args:\n        data: pandas DataFrame (single row) or Series expected to contain 'tribal_dominance' and 'individual_dignity' scores.\n              While the general data structure might include other columns (e.g., analysis_result, scores_hash),\n              this specific calculation requires columns for 'tribal_dominance' and 'individual_dignity'.\n        **kwargs: Additional parameters (not used in this specific calculation).\n        \n    Returns:\n        float: The calculated tension score, or None if required data is missing or invalid.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # Determine if data is a DataFrame (single row) or a Series\n        if isinstance(data, pd.DataFrame):\n            if data.empty:\n                return None\n            # Access the first (and presumably only) row as a Series\n            row_data = data.iloc[0]\n        elif isinstance(data, pd.Series):\n            row_data = data\n        else:\n            # Data is not a pandas DataFrame or Series, return None\n            return None\n\n        # Define the required dimension column names for this specific calculation\n        # These are inferred from the calculation's description.\n        dimension_columns = ['tribal_dominance', 'individual_dignity']\n\n        # Check if all required dimension columns exist in the row_data\n        for col in dimension_columns:\n            if col not in row_data.index:\n                # Required dimension column is missing, return None\n                return None\n        \n        # Retrieve the scores for tribal dominance and individual dignity\n        score_tribal_dominance = row_data['tribal_dominance']\n        score_individual_dignity = row_data['individual_dignity']\n\n        # Check if retrieved scores are numeric and not NaN\n        if not pd.is_numeric(score_tribal_dominance) or pd.isna(score_tribal_dominance):\n            return None\n        if not pd.is_numeric(score_individual_dignity) or pd.isna(score_individual_dignity):\n            return None\n        \n        # Calculate the absolute difference, representing tension or conflict\n        tension_score = float(np.abs(score_tribal_dominance - score_individual_dignity))\n        \n        return tension_score\n    except Exception:\n        # Catch any unexpected errors during processing and return None\n        return None\n\ndef calculate_emotional_balance(data, **kwargs):\n    \"\"\"\n    Calculate emotional_balance: Difference between hope and fear scores\n    \n    Formula: emotional_balance = hope_score - fear_score\n    \n    Args:\n        data: pandas DataFrame or Series expected to contain 'hope' and 'fear' scores.\n              This will typically be a single row DataFrame or a pandas Series representing one row.\n        **kwargs: Additional parameters (not used in this calculation).\n        \n    Returns:\n        float: Calculated emotional balance score.\n        None: If required 'hope' or 'fear' scores are missing (columns not found or values are NaN/non-numeric).\n    \"\"\"\n    import pandas as pd\n    import numpy as np # numpy is imported as per the template example, although pd.isna is primarily used\n    \n    try:\n        hope_score = None\n        fear_score = None\n\n        # Determine if data is a DataFrame (single-row) or a Series\n        if isinstance(data, pd.DataFrame):\n            # Check for column existence in a DataFrame\n            if 'hope' not in data.columns or 'fear' not in data.columns:\n                return None\n            # Extract scores from the single-row DataFrame\n            hope_score = data['hope'].iloc[0]\n            fear_score = data['fear'].iloc[0]\n        elif isinstance(data, pd.Series):\n            # Check for index existence in a Series\n            if 'hope' not in data.index or 'fear' not in data.index:\n                return None\n            # Extract scores directly from the Series\n            hope_score = data['hope']\n            fear_score = data['fear']\n        else:\n            # Input data is neither a DataFrame nor a Series\n            return None\n        \n        # Handle NaN values and non-numeric types gracefully\n        # pd.isna handles both np.nan and Python's None\n        if pd.isna(hope_score) or pd.isna(fear_score):\n            return None\n        \n        # Explicitly check if values are numeric after NaN check\n        if not isinstance(hope_score, (int, float)) or not isinstance(fear_score, (int, float)):\n            return None\n\n        # Perform the calculation\n        emotional_balance = float(hope_score - fear_score)\n        \n        return emotional_balance\n            \n    except Exception:\n        # Catch any unexpected errors during data access or calculation,\n        # ensuring graceful handling as per requirements.\n        return None\n\ndef calculate_success_climate(data, **kwargs):\n    \"\"\"\n    Calculate success_climate: Difference between compersion and envy scores.\n\n    Formula: success_climate = compersion_score - envy_score\n\n    Args:\n        data: pandas DataFrame with dimension scores. Expected to be a single row\n              (e.g., a Series or a DataFrame with one row) containing 'compersion'\n              and 'envy' scores.\n        **kwargs: Additional parameters (not used in this calculation but part of the\n                  framework's API).\n\n    Returns:\n        float: Calculated success_climate score.\n        None: If 'compersion' or 'envy' columns are missing, or if their values are\n              non-numeric or NaN.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # Check if required columns exist in the DataFrame\n        required_columns = ['compersion', 'envy']\n        if not all(col in data.columns for col in required_columns):\n            # If any required column is missing, return None\n            return None\n\n        # Extract scores. Assuming 'data' could be a single-row DataFrame or a Series.\n        # If it's a single-row DataFrame, .iloc[0] accesses the row.\n        # If it's a Series (effectively a single row), direct access is fine.\n        # Use .item() for robust scalar extraction, which works for both Series and single-element DataFrame slices.\n        compersion_score = pd.to_numeric(data['compersion'].iloc[0] if isinstance(data, pd.DataFrame) else data['compersion'], errors='coerce')\n        envy_score = pd.to_numeric(data['envy'].iloc[0] if isinstance(data, pd.DataFrame) else data['envy'], errors='coerce')\n\n        # Check if the extracted scores are valid numbers (not NaN after conversion)\n        if pd.isna(compersion_score) or pd.isna(envy_score):\n            return None\n\n        # Perform the calculation\n        result = compersion_score - envy_score\n\n        return float(result)\n\n    except Exception:\n        # Catch any other unexpected errors during processing and return None\n        return None\n\ndef calculate_relational_climate(data, **kwargs):\n    \"\"\"\n    Calculate relational_climate: Difference between amity and enmity scores\n    Formula: relational_climate = amity_score - enmity_score\n    \n    Args:\n        data: pandas DataFrame or Series containing the necessary dimension scores.\n              Expected to be a single row/Series for calculation.\n        **kwargs: Additional parameters (not used in this calculation).\n        \n    Returns:\n        float: The calculated relational climate score.\n               Returns None if 'amity' or 'enmity' scores are missing,\n               not numeric, or if the input data format is incorrect.\n    \"\"\"\n    import pandas as pd\n    import numpy as np # Included as per template, used by pandas internally\n    \n    try:\n        # Ensure data is treated as a Series (a single row) for consistent access\n        if isinstance(data, pd.DataFrame):\n            if len(data) != 1:\n                # This function is designed for a single row/Series input\n                return None\n            data_row = data.iloc[0]\n        elif isinstance(data, pd.Series):\n            data_row = data\n        else:\n            # Invalid data type for input (not DataFrame or Series)\n            return None\n\n        # Retrieve 'amity' and 'enmity' scores.\n        # Using .get() to avoid KeyError if columns are missing, returning None by default.\n        amity_score = data_row.get('amity')\n        enmity_score = data_row.get('enmity')\n\n        # Handle missing or NaN values for required scores\n        if pd.isna(amity_score) or pd.isna(enmity_score):\n            return None\n\n        # Ensure retrieved scores are numeric types\n        # pd.api.types.is_numeric_dtype handles various numeric types including numpy integers/floats\n        if not pd.api.types.is_numeric_dtype(type(amity_score)) or \\\n           not pd.api.types.is_numeric_dtype(type(enmity_score)):\n            return None\n            \n        # Perform the calculation\n        # Explicitly convert to float to ensure consistent return type\n        return float(amity_score) - float(enmity_score)\n\n    except Exception:\n        # Catch any unexpected errors during processing (e.g., if type conversion fails unexpectedly)\n        # and return None as per graceful handling requirement.\n        return None\n\ndef calculate_goal_orientation(data, **kwargs):\n    \"\"\"\n    Calculate goal_orientation: Difference between cohesive goals and fragmentative goals\n    \n    Args:\n        data: pandas DataFrame (or Series representing a single row) containing 'cohesive_goals' and 'fragmentative_goals' scores.\n              This function expects the 'cohesive_goals' and 'fragmentative_goals' as the exact column names for the dimension scores.\n        **kwargs: Additional parameters (not used in this calculation).\n        \n    Returns:\n        float: Calculated result (cohesive_goals - fragmentative_goals) or None if insufficient or invalid data.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        cohesive_goals_score = None\n        fragmentative_goals_score = None\n\n        # Determine if data is a Series or a DataFrame and extract relevant scores\n        if isinstance(data, pd.Series):\n            cohesive_goals_score = data.get('cohesive_goals')\n            fragmentative_goals_score = data.get('fragmentative_goals')\n        elif isinstance(data, pd.DataFrame) and not data.empty:\n            # If it's a DataFrame, assume it's a single row context and extract the first row as a Series\n            row_series = data.iloc[0].squeeze() # .squeeze() handles single-element Series or scalar\n            if isinstance(row_series, pd.Series): # Ensure it's still a Series after squeeze\n                cohesive_goals_score = row_series.get('cohesive_goals')\n                fragmentative_goals_score = row_series.get('fragmentative_goals')\n            # If squeeze resulted in a scalar (e.g., df with one cell), it's not the expected structure\n            else:\n                return None\n        else:\n            # Data is neither a Series nor a non-empty DataFrame\n            return None\n\n        # Check if both scores are available and not NaN\n        if (cohesive_goals_score is not None and not pd.isna(cohesive_goals_score)) and \\\n           (fragmentative_goals_score is not None and not pd.isna(fragmentative_goals_score)):\n            \n            # Attempt to convert scores to float to ensure numeric operation and catch non-numeric types\n            try:\n                cohesive_goals_score = float(cohesive_goals_score)\n                fragmentative_goals_score = float(fragmentative_goals_score)\n            except (ValueError, TypeError):\n                # If conversion to float fails, it means data is not valid for calculation\n                return None\n            \n            return cohesive_goals_score - fragmentative_goals_score\n        else:\n            # One or both scores are missing or NaN, return None as per graceful handling\n            return None\n            \n    except Exception:\n        # Catch any unexpected errors during execution (e.g., column not found if not using .get(), or other runtime issues)\n        return None\n\ndef calculate_overall_cohesion_index(data, **kwargs):\n    \"\"\"\n    Calculate overall_cohesion_index: Comprehensive measure combining all dimensions\n\n    Formula:\n        The Overall Cohesion Index is calculated as the arithmetic mean of all numeric dimension scores\n        present in the input `data` DataFrame, excluding specific metadata columns.\n\n        Let `D_1, D_2, ..., D_n` be the numeric dimension scores found in the `data` DataFrame\n        after excluding the following metadata columns:\n        'analysis_result', 'raw_analysis_response', 'scores_hash', 'evidence_hash', 'document_id', 'filename'.\n\n        If `n > 0` (i.e., at least one valid numeric dimension score is present):\n            Overall Cohesion Index = (D_1 + D_2 + ... + D_n) / n\n        If `n = 0` (i.e., no valid numeric dimension scores are found or all are NaN):\n            Returns None.\n\n    Args:\n        data: pandas DataFrame representing a single row of analysis, expected to contain\n              numeric dimension scores for calculation.\n        **kwargs: Additional parameters (not used in this calculation but required by framework).\n\n    Returns:\n        float: The calculated Overall Cohesion Index, or None if insufficient or invalid data\n               is provided (e.g., no calculable numeric dimension columns or all are NaN).\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        if not isinstance(data, (pd.DataFrame, pd.Series)):\n            return None\n\n        # Define columns that are explicitly metadata and should be ignored for calculation\n        # as per the 'ACTUAL DATA STRUCTURE' description \"float - mostly NaN, ignore\".\n        ignored_metadata_columns = [\n            'analysis_result',\n            'raw_analysis_response',\n            'scores_hash',\n            'evidence_hash',\n            'document_id',\n            'filename'\n        ]\n\n        # Convert Series to DataFrame if necessary for consistent processing (e.g., .select_dtypes)\n        if isinstance(data, pd.Series):\n            # If data is a Series, it represents a single row, so convert to 1-row DataFrame\n            data = pd.DataFrame([data])\n\n        # Identify all numeric columns present in the DataFrame that are not in the ignored list.\n        # These are assumed to be the \"dimension\" scores for the calculation.\n        numeric_dimension_columns = [\n            col for col in data.select_dtypes(include=np.number).columns\n            if col not in ignored_metadata_columns\n        ]\n\n        if not numeric_dimension_columns:\n            # If no calculable numeric dimension columns are found (after excluding metadata),\n            # return None as there's insufficient data for calculation.\n            return None\n\n        # Extract values for these dimension columns for the single row.\n        # .iloc[0] is used to get the Series of values from the single-row DataFrame.\n        dimension_values = data[numeric_dimension_columns].iloc[0]\n\n        # Drop any NaN values from the collected dimension scores.\n        # An empty Series after dropping NaNs means no valid dimension scores are present.\n        dimension_values = dimension_values.dropna()\n\n        if dimension_values.empty:\n            # If all numeric dimensions are NaN or were removed, return None\n            return None\n\n        # Calculate the overall cohesion index as the arithmetic mean of the found dimension values.\n        overall_index = dimension_values.mean()\n\n        # Ensure the result is a float as per the return type requirement.\n        return float(overall_index)\n\n    except Exception:\n        # Catch any unexpected errors during processing and return None gracefully.\n        return None\n\ndef calculate_all_derived_metrics(data: pd.DataFrame) -> Dict[str, Optional[float]]:\n    \"\"\"\n    Calculate all derived metrics for the given dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        Dictionary mapping metric names to calculated values\n    \"\"\"\n    results = {}\n    \n    # Get all calculation functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith('calculate_') and \n            name not in ['calculate_all_derived_metrics', 'calculate_derived_metrics']):\n            try:\n                results[name.replace('calculate_', '')] = obj(data)\n            except Exception as e:\n                results[name.replace('calculate_', '')] = None\n                \n    return results\n\n\ndef calculate_derived_metrics(data: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Template-compatible wrapper function for derived metrics calculation.\n    \n    This function is called by the universal notebook template and returns\n    the original data with additional derived metric columns.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        DataFrame with original data plus derived metric columns\n    \"\"\"\n    # Calculate all derived metrics\n    derived_metrics = calculate_all_derived_metrics(data)\n    \n    # Create a copy of the original data\n    result = data.copy()\n    \n    # Add derived metrics as new columns\n    for metric_name, metric_value in derived_metrics.items():\n        if metric_value is not None:\n            # For scalar metrics, broadcast to all rows\n            result[metric_name] = metric_value\n        else:\n            # For failed calculations, use NaN\n            result[metric_name] = np.nan\n    \n    return result\n",
  "cached_with_code": true
}