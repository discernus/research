{
  "status": "success",
  "functions_generated": 6,
  "output_file": "automatedderivedmetricsagent_functions.py",
  "module_size": 18397,
  "function_code_content": "\"\"\"\nAutomated Derived Metrics Functions\n===================================\n\nGenerated by AutomatedDerivedMetricsAgent for experiment: Test Experiment\nDescription: Test experiment for derived metrics\nGenerated: 2025-08-23T20:36:37.030230+00:00\n\nThis module contains automatically generated calculation functions for derived metrics\nas specified in the framework's natural language descriptions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom typing import Optional, Dict, Any\n\n\ndef calculate_identity_tension(data, **kwargs):\n    \"\"\"\n    Calculate identity_tension: Conflict between tribal dominance and individual dignity dimensions\n\n    Formula: abs(tribal_dominance_score - individual_dignity_score)\n\n    Args:\n        data: pandas DataFrame (expected to be a single row/Series) with dimension scores.\n              This function is designed to handle `data` as either a pandas Series\n              (e.g., when applied row-wise using `df.apply(..., axis=1)`) or a\n              single-row pandas DataFrame.\n        **kwargs: Additional parameters (currently unused)\n\n    Returns:\n        float: Calculated result or None if insufficient data (e.g., missing columns or NaN values).\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    # Define the expected column names based on the description and \"generic column names\" directive.\n    # As no specific column names were provided in \"ACTUAL DATA STRUCTURE\", generic names\n    # representing the concepts of \"tribal dominance\" and \"individual dignity\" are used.\n    TRIBAL_DOMINANCE_COL = 'tribal_dominance_score'\n    INDIVIDUAL_DIGNITY_COL = 'individual_dignity_score'\n\n    try:\n        # Standardize data access: convert single-row DataFrame to Series if necessary.\n        # This ensures consistent access via `data_series[column_name]`.\n        if isinstance(data, pd.DataFrame):\n            if not data.empty:\n                data_series = data.iloc[0]\n            else:\n                return None  # Empty DataFrame implies no data to process\n        elif isinstance(data, pd.Series):\n            data_series = data\n        else:\n            return None  # Input 'data' is not a pandas Series or DataFrame\n\n        # Check for the existence of required columns in the data_series (row)\n        if TRIBAL_DOMINANCE_COL not in data_series.index or \\\n           INDIVIDUAL_DIGNITY_COL not in data_series.index:\n            return None  # One or both required columns are missing\n\n        tribal_dominance_score = data_series[TRIBAL_DOMINANCE_COL]\n        individual_dignity_score = data_series[INDIVIDUAL_DIGNITY_COL]\n\n        # Check if the retrieved scores are valid numbers (not NaN)\n        # pd.isna handles both np.nan and Python None, and returns False for valid numbers.\n        if pd.isna(tribal_dominance_score) or pd.isna(individual_dignity_score):\n            return None  # Missing or NaN score for one of the dimensions\n\n        # Attempt to convert to float to ensure numeric operation and catch non-numeric types\n        try:\n            tribal_dominance = float(tribal_dominance_score)\n            individual_dignity = float(individual_dignity_score)\n        except (ValueError, TypeError):\n            return None  # Scores are not convertible to numeric types\n\n        # Calculate identity tension using the absolute difference\n        identity_tension = abs(tribal_dominance - individual_dignity)\n\n        return identity_tension\n\n    except Exception:\n        # Catch any unexpected errors during the process (e.g., data corruption)\n        # and return None to indicate failure to calculate.\n        return None\n\ndef calculate_emotional_balance(data, **kwargs):\n    \"\"\"\n    Calculate emotional_balance: Difference between hope and fear scores\n    \n    Args:\n        data: pandas DataFrame or Series with dimension scores.\n              Expected to represent a single row/data point.\n        **kwargs: Additional parameters (not used in this calculation).\n        \n    Returns:\n        float: Calculated result (hope_score - fear_score) or None if\n               insufficient or invalid data (e.g., missing columns, non-numeric values, NaN).\n    \"\"\"\n    import pandas as pd\n    import numpy as np # Included as per template, though pd.isna is primarily used.\n    \n    try:\n        hope_score = None\n        fear_score = None\n\n        # Determine if data is a DataFrame or a Series and extract scores\n        if isinstance(data, pd.DataFrame):\n            # Check for column existence and if the DataFrame is empty\n            if 'hope' not in data.columns or 'fear' not in data.columns or data.empty:\n                return None\n            # Extract scalar values from the first row of the DataFrame\n            hope_score = data['hope'].iloc[0]\n            fear_score = data['fear'].iloc[0]\n        elif isinstance(data, pd.Series):\n            # Check for index (key) existence in the Series\n            if 'hope' not in data.index or 'fear' not in data.index:\n                return None\n            # Directly access scalar values from the Series\n            hope_score = data['hope']\n            fear_score = data['fear']\n        else:\n            # Data is neither a DataFrame nor a Series, return None\n            return None\n\n        # Check for NaN or None values in the extracted scores\n        if pd.isna(hope_score) or pd.isna(fear_score):\n            return None\n        \n        # Attempt to convert scores to float and perform the calculation.\n        # This will raise ValueError or TypeError if values are not numeric,\n        # which will be caught by the outer Exception block.\n        result = float(hope_score) - float(fear_score)\n        \n        return float(result) # Ensure the result is a float\n    \n    except Exception:\n        # Catch any errors (e.g., KeyError, ValueError, TypeError) and return None\n        return None\n\ndef calculate_success_climate(data, **kwargs):\n    \"\"\"\n    Calculate success_climate: Difference between compersion and envy scores\n    Formula: compersion - envy\n    \n    Args:\n        data: pandas DataFrame or Series with 'compersion' and 'envy' scores.\n              Expected to represent a single observation (row).\n        **kwargs: Additional parameters (not used in this calculation).\n        \n    Returns:\n        float: Calculated result (compersion - envy) if sufficient and valid data is present.\n               Returns None if 'compersion' or 'envy' columns are missing,\n               or if their values are NaN or non-numeric.\n    \"\"\"\n    import pandas as pd\n    import numpy as np \n    \n    try:\n        compersion_score = None\n        envy_score = None\n\n        if isinstance(data, pd.Series):\n            compersion_score = data.get('compersion')\n            envy_score = data.get('envy')\n        elif isinstance(data, pd.DataFrame):\n            # Check if DataFrame is not empty before attempting to access values\n            if not data.empty:\n                if 'compersion' in data.columns:\n                    # .iloc[0] safely retrieves the scalar value from a single-row DataFrame column\n                    compersion_score = data['compersion'].iloc[0]\n                if 'envy' in data.columns:\n                    envy_score = data['envy'].iloc[0]\n            # If data is an empty DataFrame, compersion_score and envy_score remain None,\n            # which will correctly lead to returning None.\n        else:\n            # If data is neither a pandas Series nor a DataFrame, it cannot be processed.\n            return None\n\n        # Check if either score is missing (None from .get() or missing column) or is NaN\n        if pd.isna(compersion_score) or pd.isna(envy_score):\n            return None\n\n        # Attempt to convert scores to float. This handles cases where data might be\n        # of integer type, or numeric strings. It will raise a TypeError or ValueError\n        # if the data is genuinely non-numeric (e.g., a string like 'abc').\n        compersion_score = float(compersion_score)\n        envy_score = float(envy_score)\n\n        # Perform the calculation\n        result = compersion_score - envy_score\n        return result\n    except (TypeError, ValueError, IndexError) as e:\n        # Catch specific errors:\n        # - TypeError/ValueError: if float() conversion fails (non-numeric data)\n        # - IndexError: if .iloc[0] is called on an empty Series (though prior checks minimize this)\n        return None\n    except Exception:\n        # Catch any other unexpected errors during processing\n        return None\n\ndef calculate_relational_climate(data, **kwargs):\n    \"\"\"\n    Calculate relational_climate: Difference between amity and enmity scores\n    \n    Formula: relational_climate = amity - enmity\n    \n    Args:\n        data: pandas Series (representing a single row of a DataFrame) containing\n              'amity' and 'enmity' scores.\n        **kwargs: Additional parameters (not used in this calculation).\n        \n    Returns:\n        float: Calculated relational_climate score.\n        None: If 'amity' or 'enmity' scores are missing or not numeric,\n              or if a general error occurs.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # Ensure 'data' is a Series, although the framework usually passes it as such.\n        if not isinstance(data, pd.Series):\n            return None\n\n        # Check for presence of required columns\n        if 'amity' not in data or 'enmity' not in data:\n            return None\n\n        amity_score = data['amity']\n        enmity_score = data['enmity']\n\n        # Handle missing or non-numeric values gracefully\n        if pd.isna(amity_score) or pd.isna(enmity_score):\n            return None\n        \n        # Attempt conversion to numeric types, coercing errors to NaN\n        amity_score_numeric = pd.to_numeric(amity_score, errors='coerce')\n        enmity_score_numeric = pd.to_numeric(enmity_score, errors='coerce')\n\n        if pd.isna(amity_score_numeric) or pd.isna(enmity_score_numeric):\n            return None\n\n        # Perform the calculation\n        result = amity_score_numeric - enmity_score_numeric\n        \n        return float(result) # Ensure float return type\n    except Exception:\n        # Catch any other unexpected errors and return None\n        return None\n\ndef calculate_goal_orientation(data, **kwargs):\n    \"\"\"\n    Calculate goal_orientation: Difference between cohesive goals and fragmentative goals.\n\n    Formula: cohesive_goals_score - fragmentative_goals_score\n\n    Args:\n        data: pandas Series (representing a single row of data) expected to contain\n              'cohesive_goals_score' and 'fragmentative_goals_score'.\n        **kwargs: Additional parameters (not used in this calculation).\n\n    Returns:\n        float: The calculated goal orientation score.\n        None: If required scores ('cohesive_goals_score', 'fragmentative_goals_score')\n              are missing or are NaN, or if any other error occurs during calculation.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    # Define the generic column names as per instructions\n    COHESIVE_GOALS_COL = 'cohesive_goals_score'\n    FRAGMENTATIVE_GOALS_COL = 'fragmentative_goals_score'\n\n    try:\n        # Ensure data is treated as a Series for consistent access\n        if not isinstance(data, pd.Series):\n            # This handles cases where a DataFrame with one row might be passed,\n            # though the expectation is a Series for a single calculation.\n            # If it's a DataFrame, try to get the first row.\n            if isinstance(data, pd.DataFrame) and not data.empty:\n                data = data.iloc[0]\n            else:\n                return None\n\n        # Check for presence of required columns and handle potential KeyError if missing\n        if COHESIVE_GOALS_COL not in data or FRAGMENTATIVE_GOALS_COL not in data:\n            return None\n\n        cohesive_goals = data[COHESIVE_GOALS_COL]\n        fragmentative_goals = data[FRAGMENTATIVE_GOALS_COL]\n\n        # Handle missing or invalid numerical data (e.g., NaN, None)\n        if pd.isna(cohesive_goals) or pd.isna(fragmentative_goals):\n            return None\n\n        # Ensure scores are numeric before calculation\n        if not (isinstance(cohesive_goals, (int, float)) and isinstance(fragmentative_goals, (int, float))):\n            return None\n\n        # Perform the calculation\n        result = cohesive_goals - fragmentative_goals\n        return float(result)\n\n    except Exception:\n        # Catch any other unexpected errors and return None\n        return None\n\ndef calculate_overall_cohesion_index(data, **kwargs):\n    \"\"\"\n    Calculate overall_cohesion_index: Comprehensive measure combining all dimensions.\n\n    This index quantifies overall discourse cohesion based on a set of core dimensions.\n    It assumes input scores are normalized between 0 and 1, where 1 represents the\n    highest presence of the positive dimension (Hope, Trust, Solidarity, Engagement)\n    or the lowest presence of the negative dimension (Fear).\n\n    Formula:\n    `overall_cohesion_index = ((hope_score + trust_score + solidarity_score + engagement_score - fear_score) + 1) / 5`\n\n    Args:\n        data: A pandas Series representing a single row of dimension scores,\n              or a pandas DataFrame containing a single row of scores.\n              Expected columns (generic names based on framework description):\n              - `hope_score` (float): Score indicating the presence of hope.\n              - `fear_score` (float): Score indicating the presence of fear.\n              - `trust_score` (float): Score indicating the presence of trust.\n              - `solidarity_score` (float): Score indicating the presence of social solidarity.\n              - `engagement_score` (float): Score indicating the presence of constructive civic engagement.\n        **kwargs: Additional parameters (not used in this specific calculation but\n                  included for framework compatibility).\n\n    Returns:\n        float: The calculated overall cohesion index (ranging from 0 to 1),\n               or None if any required score is missing or is NaN, or if the\n               input data format is invalid/empty.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # Ensure data is treated as a pandas Series for consistent access\n        if isinstance(data, pd.DataFrame):\n            if data.empty:\n                return None  # No data rows in DataFrame\n            # Extract the first (and presumably only) row as a Series\n            data = data.iloc[0]\n        elif not isinstance(data, pd.Series):\n            return None  # Input is not a DataFrame or Series\n\n        # Define the exact generic column names required for the calculation\n        # These names are derived from the framework description's implied dimensions.\n        required_cols = [\n            'hope_score',\n            'fear_score',\n            'trust_score',\n            'solidarity_score',\n            'engagement_score'\n        ]\n\n        # Retrieve scores, handling missing columns or NaN values gracefully\n        scores = {}\n        for col_name in required_cols:\n            if col_name not in data.index or pd.isna(data.get(col_name)):\n                # If column is missing or its value is NaN, return None\n                return None\n            scores[col_name] = data[col_name]\n\n        # Extract individual scores for clarity in the calculation\n        hope = scores['hope_score']\n        fear = scores['fear_score']\n        trust = scores['trust_score']\n        solidarity = scores['solidarity_score']\n        engagement = scores['engagement_score']\n\n        # Calculate the raw combined score\n        # Positive contributions: hope, trust, solidarity, engagement\n        # Negative contribution: fear\n        raw_cohesion = (hope + trust + solidarity + engagement) - fear\n\n        # Normalize the raw score to a range between 0 and 1.\n        # Assuming individual input scores (hope, fear, etc.) are already between 0 and 1:\n        # - Minimum possible raw_cohesion: (0 + 0 + 0 + 0) - 1 = -1\n        # - Maximum possible raw_cohesion: (1 + 1 + 1 + 1) - 0 = 4\n        # The range of raw_cohesion is 4 - (-1) = 5.\n        # To normalize to [0, 1]: (raw_score - min_raw_score) / (max_raw_score - min_raw_score)\n        overall_cohesion = (raw_cohesion - (-1)) / 5.0\n\n        return overall_cohesion\n\n    except Exception:\n        # Catch any unexpected errors that might occur during processing\n        return None\n\ndef calculate_all_derived_metrics(data: pd.DataFrame) -> Dict[str, Optional[float]]:\n    \"\"\"\n    Calculate all derived metrics for the given dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        Dictionary mapping metric names to calculated values\n    \"\"\"\n    results = {}\n    \n    # Get all calculation functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith('calculate_') and \n            name not in ['calculate_all_derived_metrics', 'calculate_derived_metrics']):\n            try:\n                results[name.replace('calculate_', '')] = obj(data)\n            except Exception as e:\n                results[name.replace('calculate_', '')] = None\n                \n    return results\n\n\ndef calculate_derived_metrics(data: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Template-compatible wrapper function for derived metrics calculation.\n    \n    This function is called by the universal notebook template and returns\n    the original data with additional derived metric columns.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        DataFrame with original data plus derived metric columns\n    \"\"\"\n    # Calculate all derived metrics\n    derived_metrics = calculate_all_derived_metrics(data)\n    \n    # Create a copy of the original data\n    result = data.copy()\n    \n    # Add derived metrics as new columns\n    for metric_name, metric_value in derived_metrics.items():\n        if metric_value is not None:\n            # For scalar metrics, broadcast to all rows\n            result[metric_name] = metric_value\n        else:\n            # For failed calculations, use NaN\n            result[metric_name] = np.nan\n    \n    return result\n",
  "cached_with_code": true
}