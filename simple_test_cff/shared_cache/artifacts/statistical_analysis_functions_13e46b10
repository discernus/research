{
  "status": "success",
  "functions_generated": 3,
  "output_file": "automatedstatisticalanalysisagent_functions.py",
  "module_size": 19971,
  "function_code_content": "\"\"\"\nAutomated Statistical Analysis Functions\n========================================\n\nGenerated by AutomatedStatisticalAnalysisAgent for experiment: simple_test\nDescription: Statistical analysis experiment\nGenerated: 2025-08-28T16:05:55.586370+00:00\n\nThis module contains automatically generated statistical analysis functions\nfor comprehensive data analysis including ANOVA, correlations, reliability,\nand hypothesis testing as appropriate for the research questions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport scipy.stats as stats\nfrom typing import Dict, Any, Optional, List, Tuple\nimport warnings\n\n# Suppress common statistical warnings for cleaner output\nwarnings.filterwarnings('ignore', category=RuntimeWarning)\n\n\ndef calculate_baseline_statistics(data, **kwargs):\n    \"\"\"\n    Calculates and provides descriptive statistics for the derived CFF v10 metrics.\n\n    This function first computes all derived tension and cohesion indices based on the\n    raw and salience scores for each document, as specified in the Cohesive Flourishing\n    Framework v10. It then calculates baseline descriptive statistics (mean, std, min, \n    25%, 50%, 75%, max) for these derived metrics across the entire corpus. This\n    addresses the research question regarding baseline scores.\n\n    Methodology:\n    1.  Calculates five tension indices (Identity, Emotional, Success, Relational, Goal).\n    2.  Calculates the Strategic Contradiction Index as the average of the tension indices.\n    3.  Calculates three salience-weighted cohesion indices (Descriptive, Motivational, Full).\n    4.  Uses pandas.DataFrame.describe() to generate summary statistics for all derived metrics.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the analysis data with columns for raw scores\n                             and salience for each of the 10 CFF dimensions.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary containing the descriptive statistics for each derived metric.\n              Returns None if the input data is invalid or missing required columns.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # Make a copy to avoid modifying the original DataFrame\n        df = data.copy()\n\n        # --- Calculate Derived Metrics ---\n        # Tension Indices\n        df['identity_tension'] = np.minimum(df['tribal_dominance_raw'], df['individual_dignity_raw']) * \\\n                                 abs(df['tribal_dominance_salience'] - df['individual_dignity_salience'])\n        df['emotional_tension'] = np.minimum(df['fear_raw'], df['hope_raw']) * \\\n                                  abs(df['fear_salience'] - df['hope_salience'])\n        df['success_tension'] = np.minimum(df['envy_raw'], df['compersion_raw']) * \\\n                                abs(df['envy_salience'] - df['compersion_salience'])\n        df['relational_tension'] = np.minimum(df['enmity_raw'], df['amity_raw']) * \\\n                                   abs(df['enmity_salience'] - df['amity_salience'])\n        df['goal_tension'] = np.minimum(df['fragmentative_goals_raw'], df['cohesive_goals_raw']) * \\\n                             abs(df['fragmentative_goals_salience'] - df['cohesive_goals_salience'])\n\n        # Strategic Contradiction Index\n        tension_cols = ['identity_tension', 'emotional_tension', 'success_tension', 'relational_tension', 'goal_tension']\n        df['strategic_contradiction_index'] = df[tension_cols].mean(axis=1)\n\n        # Salience-Weighted Cohesion Indices\n        epsilon = 0.001\n        \n        # Descriptive Cohesion Index\n        descriptive_numerator = (df['hope_raw'] * df['hope_salience'] - df['fear_raw'] * df['fear_salience']) + \\\n                                (df['compersion_raw'] * df['compersion_salience'] - df['envy_raw'] * df['envy_salience']) + \\\n                                (df['amity_raw'] * df['amity_salience'] - df['enmity_raw'] * df['enmity_salience'])\n        descriptive_denominator = df['hope_salience'] + df['fear_salience'] + df['compersion_salience'] + \\\n                                  df['envy_salience'] + df['amity_salience'] + df['enmity_salience']\n        df['descriptive_cohesion_index'] = descriptive_numerator / (descriptive_denominator + epsilon)\n\n        # Motivational Cohesion Index\n        motivational_numerator = descriptive_numerator + \\\n                                 (df['cohesive_goals_raw'] * df['cohesive_goals_salience'] - df['fragmentative_goals_raw'] * df['fragmentative_goals_salience'])\n        motivational_denominator = descriptive_denominator + \\\n                                   df['cohesive_goals_salience'] + df['fragmentative_goals_salience']\n        df['motivational_cohesion_index'] = motivational_numerator / (motivational_denominator + epsilon)\n\n        # Full Cohesion Index\n        full_numerator = motivational_numerator + \\\n                         (df['individual_dignity_raw'] * df['individual_dignity_salience'] - df['tribal_dominance_raw'] * df['tribal_dominance_salience'])\n        full_denominator = motivational_denominator + \\\n                           df['individual_dignity_salience'] + df['tribal_dominance_salience']\n        df['full_cohesion_index'] = full_numerator / (full_denominator + epsilon)\n\n        # --- Generate Descriptive Statistics ---\n        derived_metrics_cols = tension_cols + ['strategic_contradiction_index', 'descriptive_cohesion_index', 'motivational_cohesion_index', 'full_cohesion_index']\n        \n        if df[derived_metrics_cols].empty:\n            return None\n            \n        stats = df[derived_metrics_cols].describe().to_dict()\n        \n        return stats\n\n    except (KeyError, AttributeError, Exception):\n        return None\n\ndef compare_discourse_styles(data, **kwargs):\n    \"\"\"\n    Compares cohesion scores between 'Institutional' and 'Populist' discourse styles.\n\n    This function addresses the research question: \"Will McCain's institutional discourse \n    show higher cohesion than populist styles?\". It first calculates the derived cohesion \n    indices, then categorizes each document into 'Institutional' or 'Populist' style based \n    on the speaker identified in the document name. Finally, it performs an independent \n    samples t-test to compare the mean scores of the key cohesion indices between the two groups.\n\n    Methodology:\n    1.  Calculates derived cohesion indices (Descriptive, Motivational, Full).\n    2.  Assigns a 'style' label ('Institutional', 'Populist') to each document based on a\n        pre-defined mapping of speaker names to styles. This follows the \"thin architecture\"\n        principle, directly mapping document identifiers to metadata.\n    3.  Performs an independent samples t-test (scipy.stats.ttest_ind) for each cohesion\n        index to test for significant differences between the two style groups.\n    4.  Assumes unequal variances (Welch's t-test) for robustness with small and\n        potentially unequal sample sizes.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the analysis data. Must include a\n                             'document_name' column and all raw/salience score columns.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary containing the t-statistic and p-value for each cohesion index\n              comparison. Returns None if there are not at least two groups to compare or\n              if data is insufficient.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    from scipy.stats import ttest_ind\n\n    try:\n        df = data.copy()\n\n        # --- Define Grouping Variable based on document_name ---\n        def get_style(doc_name):\n            doc_name_lower = doc_name.lower()\n            if 'mccain' in doc_name_lower:\n                return 'Institutional'\n            # Grouping other speakers as 'Populist' based on RQ\n            elif 'sanders' in doc_name_lower or 'ocasio_cortez' in doc_name_lower or 'king' in doc_name_lower:\n                return 'Populist'\n            return 'Unknown'\n\n        df['style'] = df['document_name'].apply(get_style)\n        \n        # Filter for only the groups we want to compare\n        df_filtered = df[df['style'].isin(['Institutional', 'Populist'])]\n\n        if df_filtered['style'].nunique() < 2:\n            return {\"error\": \"Insufficient groups for comparison. Found fewer than two of: 'Institutional', 'Populist'.\"}\n\n        # --- Calculate Derived Metrics ---\n        epsilon = 0.001\n        \n        # Descriptive Cohesion Index\n        descriptive_numerator = (df_filtered['hope_raw'] * df_filtered['hope_salience'] - df_filtered['fear_raw'] * df_filtered['fear_salience']) + \\\n                                (df_filtered['compersion_raw'] * df_filtered['compersion_salience'] - df_filtered['envy_raw'] * df_filtered['envy_salience']) + \\\n                                (df_filtered['amity_raw'] * df_filtered['amity_salience'] - df_filtered['enmity_raw'] * df_filtered['enmity_salience'])\n        descriptive_denominator = df_filtered['hope_salience'] + df_filtered['fear_salience'] + df_filtered['compersion_salience'] + \\\n                                  df_filtered['envy_salience'] + df_filtered['amity_salience'] + df_filtered['enmity_salience']\n        df_filtered['descriptive_cohesion_index'] = descriptive_numerator / (descriptive_denominator + epsilon)\n\n        # Motivational Cohesion Index\n        motivational_numerator = descriptive_numerator + \\\n                                 (df_filtered['cohesive_goals_raw'] * df_filtered['cohesive_goals_salience'] - df_filtered['fragmentative_goals_raw'] * df_filtered['fragmentative_goals_salience'])\n        motivational_denominator = descriptive_denominator + \\\n                                   df_filtered['cohesive_goals_salience'] + df_filtered['fragmentative_goals_salience']\n        df_filtered['motivational_cohesion_index'] = motivational_numerator / (motivational_denominator + epsilon)\n\n        # Full Cohesion Index\n        full_numerator = motivational_numerator + \\\n                         (df_filtered['individual_dignity_raw'] * df_filtered['individual_dignity_salience'] - df_filtered['tribal_dominance_raw'] * df_filtered['tribal_dominance_salience'])\n        full_denominator = motivational_denominator + \\\n                           df_filtered['individual_dignity_salience'] + df_filtered['tribal_dominance_salience']\n        df_filtered['full_cohesion_index'] = full_numerator / (full_denominator + epsilon)\n\n        # --- Perform T-Tests ---\n        group1 = df_filtered[df_filtered['style'] == 'Institutional']\n        group2 = df_filtered[df_filtered['style'] == 'Populist']\n\n        if len(group1) < 1 or len(group2) < 1:\n             return {\"error\": \"One or both comparison groups have zero members.\"}\n\n        results = {}\n        cohesion_indices = ['descriptive_cohesion_index', 'motivational_cohesion_index', 'full_cohesion_index']\n\n        for index in cohesion_indices:\n            stat, p_value = ttest_ind(group1[index], group2[index], equal_var=False, nan_policy='omit') # Welch's t-test\n            results[index] = {\n                't_statistic': stat,\n                'p_value': p_value,\n                'group_means': {\n                    'Institutional': group1[index].mean(),\n                    'Populist': group2[index].mean()\n                }\n            }\n        \n        return results\n\n    except (KeyError, AttributeError, Exception):\n        return None\n\ndef analyze_metric_correlations(data, **kwargs):\n    \"\"\"\n    Calculates the correlation matrix for key CFF v10 raw scores and derived indices.\n\n    This function provides an exploratory analysis of the relationships between different\n    rhetorical dimensions and the overall cohesion scores. It helps to understand which\n    rhetorical strategies are most strongly associated with cohesive or fragmentative\n    outcomes within the corpus.\n\n    Methodology:\n    1.  Calculates the three primary derived cohesion indices (Descriptive, Motivational, Full).\n    2.  Selects a set of key variables: the 10 raw dimensional scores and the 3 derived\n        cohesion indices.\n    3.  Computes a Pearson correlation matrix for these selected variables using\n        pandas.DataFrame.corr().\n    4.  The resulting matrix shows the correlation coefficient (from -1 to +1) for each\n        pair of variables.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the analysis data with columns for raw scores\n                             and salience for each of the 10 CFF dimensions.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary representation of the correlation matrix. Returns None if the\n              input data is invalid or missing required columns.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        df = data.copy()\n\n        # --- Calculate Derived Metrics ---\n        epsilon = 0.001\n        \n        # Descriptive Cohesion Index\n        descriptive_numerator = (df['hope_raw'] * df['hope_salience'] - df['fear_raw'] * df['fear_salience']) + \\\n                                (df['compersion_raw'] * df['compersion_salience'] - df['envy_raw'] * df['envy_salience']) + \\\n                                (df['amity_raw'] * df['amity_salience'] - df['enmity_raw'] * df['enmity_salience'])\n        descriptive_denominator = df['hope_salience'] + df['fear_salience'] + df['compersion_salience'] + \\\n                                  df['envy_salience'] + df['amity_salience'] + df['enmity_salience']\n        df['descriptive_cohesion_index'] = descriptive_numerator / (descriptive_denominator + epsilon)\n\n        # Motivational Cohesion Index\n        motivational_numerator = descriptive_numerator + \\\n                                 (df['cohesive_goals_raw'] * df['cohesive_goals_salience'] - df['fragmentative_goals_raw'] * df['fragmentative_goals_salience'])\n        motivational_denominator = descriptive_denominator + \\\n                                   df['cohesive_goals_salience'] + df['fragmentative_goals_salience']\n        df['motivational_cohesion_index'] = motivational_numerator / (motivational_denominator + epsilon)\n\n        # Full Cohesion Index\n        full_numerator = motivational_numerator + \\\n                         (df['individual_dignity_raw'] * df['individual_dignity_salience'] - df['tribal_dominance_raw'] * df['tribal_dominance_salience'])\n        full_denominator = motivational_denominator + \\\n                           df['individual_dignity_salience'] + df['tribal_dominance_salience']\n        df['full_cohesion_index'] = full_numerator / (full_denominator + epsilon)\n\n        # --- Calculate Correlation Matrix ---\n        raw_score_cols = [\n            'tribal_dominance_raw', 'individual_dignity_raw', 'fear_raw', 'hope_raw',\n            'envy_raw', 'compersion_raw', 'enmity_raw', 'amity_raw',\n            'fragmentative_goals_raw', 'cohesive_goals_raw'\n        ]\n        derived_index_cols = ['descriptive_cohesion_index', 'motivational_cohesion_index', 'full_cohesion_index']\n        \n        cols_for_corr = raw_score_cols + derived_index_cols\n        \n        # Ensure all columns exist before proceeding\n        if not all(col in df.columns for col in cols_for_corr):\n            return None\n\n        correlation_matrix = df[cols_for_corr].corr(method='pearson')\n        \n        return correlation_matrix.to_dict()\n\n    except (KeyError, AttributeError, Exception):\n        return None\n\ndef run_complete_statistical_analysis(data: pd.DataFrame, alpha: float = 0.05) -> Dict[str, Any]:\n    \"\"\"\n    Run complete statistical analysis suite on the dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        alpha: Significance level for hypothesis tests (default: 0.05)\n        \n    Returns:\n        Dictionary with all statistical analysis results\n    \"\"\"\n    results = {\n        'analysis_metadata': {\n            'timestamp': pd.Timestamp.now().isoformat(),\n            'sample_size': len(data),\n            'alpha_level': alpha,\n            'variables_analyzed': list(data.select_dtypes(include=[np.number]).columns)\n        }\n    }\n    \n    # Get all analysis functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith(('calculate_', 'perform_', 'test_')) and \n            name != 'run_complete_statistical_analysis'):\n            try:\n                # Pass alpha parameter to functions that might need it\n                if 'alpha' in inspect.signature(obj).parameters:\n                    results[name] = obj(data, alpha=alpha)\n                else:\n                    results[name] = obj(data)\n            except Exception as e:\n                results[name] = {'error': f'Analysis failed: {str(e)}'}\n                \n    return results\n\n\ndef perform_statistical_analysis(data: pd.DataFrame) -> Dict[str, Any]:\n    \"\"\"\n    Template-compatible wrapper function for statistical analysis.\n    \n    This function is called by the universal notebook template and performs\n    comprehensive statistical analysis on the provided dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores and derived metrics\n        \n    Returns:\n        Dictionary containing all statistical analysis results\n    \"\"\"\n    return run_complete_statistical_analysis(data)\n\n\ndef generate_statistical_summary_report(analysis_results: Dict[str, Any]) -> str:\n    \"\"\"\n    Generate a human-readable summary report from statistical analysis results.\n    \n    Args:\n        analysis_results: Results from run_complete_statistical_analysis()\n        \n    Returns:\n        String containing formatted statistical report\n    \"\"\"\n    report_lines = []\n    report_lines.append(\"STATISTICAL ANALYSIS SUMMARY REPORT\")\n    report_lines.append(\"=\" * 50)\n    \n    metadata = analysis_results.get('analysis_metadata', {})\n    report_lines.append(f\"Analysis Timestamp: {metadata.get('timestamp', 'Unknown')}\")\n    report_lines.append(f\"Sample Size: {metadata.get('sample_size', 'Unknown')}\")\n    report_lines.append(f\"Alpha Level: {metadata.get('alpha_level', 'Unknown')}\")\n    report_lines.append(f\"Variables: {len(metadata.get('variables_analyzed', []))}\")\n    report_lines.append(\"\")\n    \n    # Summarize key findings\n    for analysis_name, result in analysis_results.items():\n        if analysis_name != 'analysis_metadata' and isinstance(result, dict):\n            if 'error' not in result:\n                report_lines.append(f\"{analysis_name.replace('_', ' ').title()}:\")\n                \n                # Extract key statistics based on analysis type\n                if 'p_value' in result:\n                    p_val = result['p_value']\n                    significance = \"significant\" if p_val < metadata.get('alpha_level', 0.05) else \"not significant\"\n                    report_lines.append(f\"  - p-value: {p_val:.4f} ({significance})\")\n                \n                if 'effect_size' in result:\n                    report_lines.append(f\"  - Effect size: {result['effect_size']:.4f}\")\n                \n                if 'correlation_matrix' in result:\n                    report_lines.append(f\"  - Correlation matrix generated with {len(result['correlation_matrix'])} variables\")\n                \n                if 'cronbach_alpha' in result:\n                    alpha_val = result['cronbach_alpha']\n                    reliability = \"excellent\" if alpha_val > 0.9 else \"good\" if alpha_val > 0.8 else \"acceptable\" if alpha_val > 0.7 else \"questionable\"\n                    report_lines.append(f\"  - Cronbach's \u03b1: {alpha_val:.3f} ({reliability})\")\n                \n                report_lines.append(\"\")\n            else:\n                report_lines.append(f\"{analysis_name}: ERROR - {result['error']}\")\n                report_lines.append(\"\")\n    \n    return \"\\n\".join(report_lines)\n",
  "cached_with_code": true
}