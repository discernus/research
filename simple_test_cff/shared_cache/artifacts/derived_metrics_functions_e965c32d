{
  "status": "success",
  "functions_generated": 6,
  "output_file": "automatedderivedmetricsagent_functions.py",
  "module_size": 12748,
  "function_code_content": "\"\"\"\nAutomated Derived Metrics Functions\n===================================\n\nGenerated by AutomatedDerivedMetricsAgent for experiment: Test Experiment\nDescription: Test experiment for derived metrics\nGenerated: 2025-08-24T19:46:49.454400+00:00\n\nThis module contains automatically generated calculation functions for derived metrics\nas specified in the framework's natural language descriptions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom typing import Optional, Dict, Any\n\n\ndef calculate_identity_tension(data, **kwargs):\n    \"\"\"\n    Calculate identity_tension: Conflict between tribal dominance and individual dignity dimensions.\n\n    This metric measures the simultaneous presence of appeals to group-based dominance and\n    individual-based dignity. The tension is highest when both dimensions are strong and\n    balanced, indicating a complex rhetorical appeal. The formula rewards high scores\n    for both dimensions but penalizes large disparities between them.\n\n    Formula: ((tribal_dominance + individual_dignity) / 2) - abs(tribal_dominance - individual_dignity)\n    \n    Args:\n        data (pd.Series or pd.DataFrame): A single row of data containing the necessary columns.\n        **kwargs: Additional parameters (not used in this calculation).\n        \n    Returns:\n        float: The calculated identity tension score, or None if essential data is missing or invalid.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # Infer column names from the description as per standard framework naming conventions.\n        tribal_col = 'tribal_dominance'\n        dignity_col = 'individual_dignity'\n\n        # Extract scores from the data Series/row\n        tribal_score = data[tribal_col]\n        dignity_score = data[dignity_col]\n\n        # Ensure both scores are valid numbers\n        if pd.isna(tribal_score) or pd.isna(dignity_score):\n            return None\n\n        # The formula calculates tension:\n        # (A+B)/2 rewards the average magnitude.\n        # abs(A-B) penalizes the imbalance.\n        # The result is highest when both scores are high and equal.\n        tension = ((tribal_score + dignity_score) / 2.0) - np.abs(tribal_score - dignity_score)\n        \n        return float(tension)\n\n    except (KeyError, TypeError, AttributeError):\n        # KeyError: If columns are not found.\n        # TypeError: If data in columns is not numeric.\n        # AttributeError: If 'data' is not a pandas object.\n        return None\n    except Exception:\n        # Catch any other unexpected errors.\n        return None\n\ndef calculate_emotional_balance(data, **kwargs):\n    \"\"\"\n    Calculate emotional_balance: Difference between hope and fear scores\n\n    Formula: emotional_balance = hope_score - fear_score\n    \n    Args:\n        data (pd.Series): A row of data containing the necessary scores.\n        **kwargs: Additional keyword arguments (not used).\n        \n    Returns:\n        float: Calculated result or None if insufficient data.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # The calculation is defined as the difference between hope and fear scores.\n        # We use generic column names 'hope_score' and 'fear_score' as per instructions.\n        hope_score = data['hope_score']\n        fear_score = data['fear_score']\n\n        # Handle missing data gracefully by returning None if either score is missing.\n        if pd.isna(hope_score) or pd.isna(fear_score):\n            return None\n        \n        # Calculate the difference and ensure the result is a standard float.\n        result = float(hope_score) - float(fear_score)\n        \n        return result\n\n    except (KeyError, TypeError, ValueError):\n        # This error handling block makes the function production-ready.\n        # It catches:\n        # - KeyError: If 'hope_score' or 'fear_score' columns are not found.\n        # - TypeError/ValueError: If score values are not numeric.\n        return None\n    except Exception:\n        # A general catch-all for any other unexpected errors.\n        return None\n\ndef calculate_success_climate(data, **kwargs):\n    \"\"\"\n    Calculate success_climate: Difference between compersion and envy scores\n\n    Formula: success_climate = compersion - envy\n\n    Args:\n        data (pd.Series): A single row of data with dimension scores.\n        **kwargs: Additional parameters (unused).\n\n    Returns:\n        float: Calculated result or None if insufficient data.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # Column names are inferred from the calculation description.\n        compersion_col = 'compersion'\n        envy_col = 'envy'\n\n        compersion_score = data.get(compersion_col)\n        envy_score = data.get(envy_col)\n\n        # Handle missing data gracefully. pd.isna handles both None and np.nan.\n        if pd.isna(compersion_score) or pd.isna(envy_score):\n            return None\n\n        # Perform the calculation and ensure the result is a float.\n        result = float(compersion_score) - float(envy_score)\n        return result\n\n    except Exception:\n        # Return None for any errors during execution, such as non-numeric data.\n        return None\n\ndef calculate_relational_climate(data, **kwargs):\n    \"\"\"\n    Calculate relational_climate: Difference between amity and enmity scores\n\n    Formula: relational_climate = amity - enmity\n\n    Args:\n        data (pd.Series): A single row of data from a pandas DataFrame.\n        **kwargs: Additional keyword arguments (unused).\n\n    Returns:\n        float: The calculated difference between amity and enmity, or None if\n               the necessary data is missing or invalid.\n    \"\"\"\n    import pandas as pd\n\n    try:\n        # The calculation requires 'amity' and 'enmity' scores.\n        amity_score = data.get('amity')\n        enmity_score = data.get('enmity')\n\n        # Check if either of the required columns is missing or contains null values.\n        if pd.isna(amity_score) or pd.isna(enmity_score):\n            return None\n\n        # Ensure scores are numeric before calculation.\n        amity_score = float(amity_score)\n        enmity_score = float(enmity_score)\n\n        # Calculate the difference as per the definition.\n        relational_climate = amity_score - enmity_score\n        \n        return relational_climate\n\n    except (TypeError, ValueError):\n        # This handles cases where scores are not convertible to float.\n        return None\n    except Exception:\n        # A general catch-all for any other unexpected errors.\n        return None\n\ndef calculate_goal_orientation(data, **kwargs):\n    \"\"\"\n    Calculate goal_orientation: Difference between cohesive goals and fragmentative goals\n\n    Formula: goal_orientation = cohesive_goals - fragmentative_goals\n    \n    Args:\n        data (pd.Series): A single row of data from a DataFrame.\n        **kwargs: Additional parameters (not used).\n        \n    Returns:\n        float: Calculated result or None if insufficient data.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # As per the instruction to use generic names, column names are inferred\n        # from the calculation's description.\n        cohesive_col = 'cohesive_goals'\n        fragmentative_col = 'fragmentative_goals'\n        \n        # Check for the presence of the required columns\n        if cohesive_col not in data or fragmentative_col not in data:\n            return None\n            \n        # Safely convert scores to numeric types, coercing errors to NaN\n        cohesive_score = pd.to_numeric(data[cohesive_col], errors='coerce')\n        fragmentative_score = pd.to_numeric(data[fragmentative_col], errors='coerce')\n        \n        # If either value is missing or non-numeric, calculation cannot proceed\n        if pd.isna(cohesive_score) or pd.isna(fragmentative_score):\n            return None\n            \n        # Perform the calculation\n        result = cohesive_score - fragmentative_score\n        \n        return float(result)\n        \n    except Exception:\n        # Return None for any other unexpected errors\n        return None\n\ndef calculate_overall_cohesion_index(data, **kwargs):\n    \"\"\"\n    Calculate overall_cohesion_index: Comprehensive measure combining all dimensions.\n\n    This function calculates a composite score representing the overall health of\n    discourse based on several key sub-indices. It is derived by averaging the\n    scores of the primary dimensions of the Cohesive Flourishing Framework.\n\n    Note: As specific dimension column names were not provided, this function\n    assumes the existence of pre-calculated indices for the core concepts of\n    the framework: Social Solidarity, Trust, and Civic Engagement.\n\n    Formula:\n        mean(social_solidarity_index, trust_index, civic_engagement_index)\n\n    Args:\n        data (pd.Series): A single row of data containing the necessary\n                          dimension scores.\n        **kwargs: Additional parameters (not used in this calculation).\n\n    Returns:\n        float: The calculated overall cohesion index, or None if any of the\n               required dimension scores are missing or non-numeric.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    # As per the framework description, the overall index combines key dimensions.\n    # Since specific column names were not provided, we infer the primary\n    # dimensions from the framework's goals: social solidarity, trust, and\n    # constructive civic engagement.\n    dimension_columns = [\n        'social_solidarity_index',\n        'trust_index',\n        'civic_engagement_index'\n    ]\n\n    try:\n        # Ensure the input is a Series\n        if not isinstance(data, pd.Series):\n            # If a DataFrame is passed, and it has one row, convert to Series\n            if isinstance(data, pd.DataFrame) and len(data) == 1:\n                data = data.iloc[0]\n            else:\n                # Cannot determine the single row to operate on\n                return None\n\n        # Check for the presence of all required columns\n        if not all(col in data.index for col in dimension_columns):\n            return None\n\n        # Extract values and convert to numeric, coercing errors to NaN\n        values = pd.to_numeric(data[dimension_columns], errors='coerce')\n\n        # If any value is NaN (due to being missing or non-numeric), return None\n        if values.isnull().any():\n            return None\n\n        # Calculate the mean of the dimension scores\n        overall_score = np.mean(values)\n\n        return float(overall_score)\n\n    except (KeyError, ValueError, TypeError, AttributeError):\n        # Catch potential errors from data access, type conversion, or attribute access\n        return None\n    except Exception:\n        # A general catch-all for any other unexpected errors\n        return None\n\ndef calculate_all_derived_metrics(data: pd.DataFrame) -> Dict[str, Optional[float]]:\n    \"\"\"\n    Calculate all derived metrics for the given dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        Dictionary mapping metric names to calculated values\n    \"\"\"\n    results = {}\n    \n    # Get all calculation functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith('calculate_') and \n            name not in ['calculate_all_derived_metrics', 'calculate_derived_metrics']):\n            try:\n                results[name.replace('calculate_', '')] = obj(data)\n            except Exception as e:\n                results[name.replace('calculate_', '')] = None\n                \n    return results\n\n\ndef calculate_derived_metrics(data: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Template-compatible wrapper function for derived metrics calculation.\n    \n    This function is called by the universal notebook template and returns\n    the original data with additional derived metric columns.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        DataFrame with original data plus derived metric columns\n    \"\"\"\n    # Calculate all derived metrics\n    derived_metrics = calculate_all_derived_metrics(data)\n    \n    # Create a copy of the original data\n    result = data.copy()\n    \n    # Add derived metrics as new columns\n    for metric_name, metric_value in derived_metrics.items():\n        if metric_value is not None:\n            # For scalar metrics, broadcast to all rows\n            result[metric_name] = metric_value\n        else:\n            # For failed calculations, use NaN\n            result[metric_name] = np.nan\n    \n    return result\n",
  "cached_with_code": true
}