{
  "generation_metadata": {
    "status": "success",
    "functions_generated": 4,
    "output_file": "automatedstatisticalanalysisagent_functions.py",
    "module_size": 18737,
    "function_code_content": "\"\"\"\nAutomated Statistical Analysis Functions\n========================================\n\nGenerated by AutomatedStatisticalAnalysisAgent for experiment: simple_test\nDescription: Statistical analysis experiment\nGenerated: 2025-08-23T20:37:02.808710+00:00\n\nThis module contains automatically generated statistical analysis functions\nfor comprehensive data analysis including ANOVA, correlations, reliability,\nand hypothesis testing as appropriate for the research questions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport scipy.stats as stats\nfrom typing import Dict, Any, Optional, List, Tuple\nimport warnings\n\n# Suppress common statistical warnings for cleaner output\nwarnings.filterwarnings('ignore', category=RuntimeWarning)\n\n\ndef calculate_descriptive_statistics(data, **kwargs):\n    \"\"\"\n    Calculate descriptive statistics for all numeric dimensions, salience, and confidence scores.\n    \n    Methodology:\n    Computes standard descriptive statistics (mean, standard deviation, count, min, max)\n    for all columns ending with '_raw', '_salience', or '_confidence'.\n    \n    Args:\n        data: pandas DataFrame containing the analysis data. Expected columns include\n              '{dimension_name}_raw', '{dimension_name}_salience', and\n              '{dimension_name}_confidence' for each dimension.\n        **kwargs: Additional parameters (not used in this function).\n        \n    Returns:\n        dict: Descriptive statistics for each relevant column or None if insufficient data.\n              Returns a dictionary where keys are column names and values are dictionaries\n              containing 'mean', 'std', 'count', 'min', and 'max'.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        if data is None or data.empty:\n            return None\n            \n        df = data.copy()\n        \n        results = {}\n        # Identify columns that represent raw scores, salience, or confidence\n        relevant_columns = [col for col in df.columns if col.endswith(('_raw', '_salience', '_confidence'))]\n        \n        if not relevant_columns:\n            return None # No relevant columns found\n\n        for col in relevant_columns:\n            if pd.api.types.is_numeric_dtype(df[col]):\n                # Drop NaN values for calculation to avoid propagating NaNs\n                series = df[col].dropna()\n                if not series.empty:\n                    results[col] = {\n                        'mean': float(series.mean()),\n                        'std': float(series.std()),\n                        'count': int(series.count()),\n                        'min': float(series.min()),\n                        'max': float(series.max())\n                    }\n        \n        return results if results else None\n        \n    except Exception as e:\n        print(f\"Error in calculate_descriptive_statistics: {e}\")\n        return None\n\ndef calculate_derived_metrics(data, **kwargs):\n    \"\"\"\n    Calculates all derived metrics (Tension Indices, Strategic Contradiction Index,\n    and Salience-Weighted Cohesion Indices) as defined in the CFF v10.0 framework.\n    Adds these calculated metrics as new columns to the input DataFrame.\n\n    Methodology:\n    Implements the formulas specified in Section 5.4 of the CFF v10.0 Machine-Readable Appendix.\n    - Tension Indices: Calculated for each opposing pair using min(score_A, score_B) * abs(salience_A - salience_B).\n    - Strategic Contradiction Index: Average of all five tension indices.\n    - Salience-Weighted Cohesion Indices: Calculated by summing salience-weighted scores\n      (positive for cohesive dimensions, negative for fragmentative) and normalizing by\n      the sum of relevant salience weights, with an epsilon (0.001) to prevent division by zero.\n      Note: The framework's 'compersion' dimension is mapped to 'compassion' as per the\n      provided 'ACTUAL DATA STRUCTURE'.\n\n    Args:\n        data: pandas DataFrame containing the analysis data. Expected columns include\n              '{dimension_name}_raw' and '{dimension_name}_salience' for all 10 dimensions.\n        **kwargs: Additional parameters (not used in this function).\n\n    Returns:\n        pandas.DataFrame: The input DataFrame with new columns for all derived metrics,\n                          or None if input data is invalid or calculations fail.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        if data is None or data.empty:\n            return None\n\n        df = data.copy()\n\n        # Define dimension prefixes for easier access\n        # CRITICAL: 'compersion' from framework maps to 'compassion' in actual data\n        dim_map = {\n            \"tribal_dominance\": \"tribal_dominance\",\n            \"individual_dignity\": \"individual_dignity\",\n            \"fear\": \"fear\",\n            \"hope\": \"hope\",\n            \"envy\": \"envy\",\n            \"compersion\": \"compassion\", # Mapped to actual data column name\n            \"enmity\": \"enmity\",\n            \"amity\": \"amity\",\n            \"fragmentative_goals\": \"fragmentative_goals\",\n            \"cohesive_goals\": \"cohesive_goals\"\n        }\n\n        # Ensure all required columns exist\n        required_cols = []\n        for dim_framework, dim_data in dim_map.items():\n            required_cols.extend([f\"{dim_data}_raw\", f\"{dim_data}_salience\"])\n        \n        if not all(col in df.columns for col in required_cols):\n            missing_cols = [col for col in required_cols if col not in df.columns]\n            print(f\"Missing required columns for derived metrics calculation: {missing_cols}\")\n            return None\n\n        # --- Tension Indices ---\n        # Identity Tension\n        td_raw = df[f\"{dim_map['tribal_dominance']}_raw\"]\n        id_raw = df[f\"{dim_map['individual_dignity']}_raw\"]\n        td_sal = df[f\"{dim_map['tribal_dominance']}_salience\"]\n        id_sal = df[f\"{dim_map['individual_dignity']}_salience\"]\n        df['identity_tension'] = np.minimum(td_raw, id_raw) * np.abs(td_sal - id_sal)\n\n        # Emotional Tension\n        f_raw = df[f\"{dim_map['fear']}_raw\"]\n        h_raw = df[f\"{dim_map['hope']}_raw\"]\n        f_sal = df[f\"{dim_map['fear']}_salience\"]\n        h_sal = df[f\"{dim_map['hope']}_salience\"]\n        df['emotional_tension'] = np.minimum(f_raw, h_raw) * np.abs(f_sal - h_sal)\n\n        # Success Tension (using 'compassion' for 'compersion')\n        e_raw = df[f\"{dim_map['envy']}_raw\"]\n        c_raw = df[f\"{dim_map['compersion']}_raw\"] # This will be 'compassion_raw'\n        e_sal = df[f\"{dim_map['envy']}_salience\"]\n        c_sal = df[f\"{dim_map['compersion']}_salience\"] # This will be 'compassion_salience'\n        df['success_tension'] = np.minimum(e_raw, c_raw) * np.abs(e_sal - c_sal)\n\n        # Relational Tension\n        enm_raw = df[f\"{dim_map['enmity']}_raw\"]\n        am_raw = df[f\"{dim_map['amity']}_raw\"]\n        enm_sal = df[f\"{dim_map['enmity']}_salience\"]\n        am_sal = df[f\"{dim_map['amity']}_salience\"]\n        df['relational_tension'] = np.minimum(enm_raw, am_raw) * np.abs(enm_sal - am_sal)\n\n        # Goal Tension\n        fg_raw = df[f\"{dim_map['fragmentative_goals']}_raw\"]\n        cg_raw = df[f\"{dim_map['cohesive_goals']}_raw\"]\n        fg_sal = df[f\"{dim_map['fragmentative_goals']}_salience\"]\n        cg_sal = df[f\"{dim_map['cohesive_goals']}_salience\"]\n        df['goal_tension'] = np.minimum(fg_raw, cg_raw) * np.abs(fg_sal - cg_sal)\n\n        # --- Strategic Contradiction Index ---\n        df['strategic_contradiction_index'] = (\n            df['identity_tension'] + df['emotional_tension'] +\n            df['success_tension'] + df['relational_tension'] +\n            df['goal_tension']\n        ) / 5\n\n        # --- Salience-Weighted Cohesion Indices ---\n        EPSILON = 0.001 # To prevent division by zero\n\n        # Components\n        df['emotional_cohesion_component'] = (h_raw * h_sal - f_raw * f_sal)\n        df['success_cohesion_component'] = (c_raw * c_sal - e_raw * e_sal) # Using 'compassion'\n        df['relational_cohesion_component'] = (am_raw * am_sal - enm_raw * enm_sal)\n        df['goal_cohesion_component'] = (cg_raw * cg_sal - fg_raw * fg_sal)\n        df['identity_cohesion_component'] = (id_raw * id_sal - td_raw * td_sal)\n\n        # Salience Totals\n        df['descriptive_salience_total'] = (\n            h_sal + f_sal + c_sal + e_sal + am_sal + enm_sal # Using 'compassion'\n        )\n        df['motivational_salience_total'] = (\n            df['descriptive_salience_total'] + cg_sal + fg_sal\n        )\n        df['full_salience_total'] = (\n            df['motivational_salience_total'] + id_sal + td_sal\n        )\n\n        # Final Cohesion Indices\n        df['descriptive_cohesion_index'] = (\n            df['emotional_cohesion_component'] +\n            df['success_cohesion_component'] +\n            df['relational_cohesion_component']\n        ) / (df['descriptive_salience_total'] + EPSILON)\n\n        df['motivational_cohesion_index'] = (\n            df['emotional_cohesion_component'] +\n            df['success_cohesion_component'] +\n            df['relational_cohesion_component'] +\n            df['goal_cohesion_component']\n        ) / (df['motivational_salience_total'] + EPSILON)\n\n        df['full_cohesion_index'] = (\n            df['identity_cohesion_component'] +\n            df['emotional_cohesion_component'] +\n            df['success_cohesion_component'] +\n            df['relational_cohesion_component'] +\n            df['goal_cohesion_component']\n        ) / (df['full_salience_total'] + EPSILON)\n\n        return df\n\n    except Exception as e:\n        print(f\"Error in calculate_derived_metrics: {e}\")\n        return None\n\ndef calculate_correlation_matrix(data, correlation_type='pearson', **kwargs):\n    \"\"\"\n    Calculates the correlation matrix for all numeric raw scores, salience scores,\n    and derived metrics within the dataset.\n\n    Methodology:\n    Uses the specified correlation method (defaulting to Pearson) to compute\n    the pairwise correlation coefficients between all relevant numeric columns.\n    First, it calls `calculate_derived_metrics` to ensure all derived indices\n    are present in the DataFrame. Then, it selects all numeric columns and\n    computes their correlation matrix.\n\n    Args:\n        data: pandas DataFrame containing the analysis data. Expected to have\n              '{dimension_name}_raw' and '{dimension_name}_salience' columns.\n        correlation_type (str): The type of correlation to compute.\n                                 Options: 'pearson', 'kendall', 'spearman'.\n                                 Defaults to 'pearson'.\n        **kwargs: Additional parameters (not used in this function).\n\n    Returns:\n        pandas.DataFrame: A correlation matrix DataFrame, or None if input data\n                          is invalid or calculations fail.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        if data is None or data.empty:\n            return None\n\n        # Ensure derived metrics are calculated and added to the DataFrame\n        df_with_derived = calculate_derived_metrics(data.copy())\n        if df_with_derived is None:\n            print(\"Failed to calculate derived metrics, cannot compute correlation matrix.\")\n            return None\n\n        # Select only numeric columns for correlation calculation\n        numeric_df = df_with_derived.select_dtypes(include=[np.number])\n\n        if numeric_df.empty:\n            return None # No numeric data to correlate\n\n        # Compute the correlation matrix\n        correlation_matrix = numeric_df.corr(method=correlation_type)\n\n        return correlation_matrix\n\n    except Exception as e:\n        print(f\"Error in calculate_correlation_matrix: {e}\")\n        return None\n\ndef analyze_baseline_cohesion_tension(data, **kwargs):\n    \"\"\"\n    Calculates the baseline cohesion and tension scores for the documents\n    in the sample corpus and provides descriptive statistics for these derived metrics.\n\n    Methodology:\n    1. Calls `calculate_derived_metrics` to compute all tension and cohesion indices\n       for each document in the input DataFrame.\n    2. Extracts the columns corresponding to the derived tension and cohesion indices.\n    3. Computes descriptive statistics (mean, standard deviation, min, max, count)\n       for each of these derived metrics across all documents.\n\n    Args:\n        data: pandas DataFrame containing the analysis data. Expected to have\n              '{dimension_name}_raw' and '{dimension_name}_salience' columns for\n              all 10 dimensions.\n        **kwargs: Additional parameters (not used in this function).\n\n    Returns:\n        dict: A dictionary containing descriptive statistics for each derived\n              tension and cohesion index, or None if input data is invalid or\n              calculations fail.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        if data is None or data.empty:\n            return None\n\n        # Calculate all derived metrics\n        df_with_derived = calculate_derived_metrics(data.copy())\n        if df_with_derived is None:\n            print(\"Failed to calculate derived metrics, cannot analyze baseline cohesion/tension.\")\n            return None\n\n        # Define the list of derived metrics to analyze\n        derived_metric_columns = [\n            'identity_tension', 'emotional_tension', 'success_tension',\n            'relational_tension', 'goal_tension', 'strategic_contradiction_index',\n            'descriptive_cohesion_index', 'motivational_cohesion_index',\n            'full_cohesion_index'\n        ]\n\n        results = {}\n        for col in derived_metric_columns:\n            if col in df_with_derived.columns and pd.api.types.is_numeric_dtype(df_with_derived[col]):\n                series = df_with_derived[col].dropna()\n                if not series.empty:\n                    results[col] = {\n                        'mean': float(series.mean()),\n                        'std': float(series.std()),\n                        'min': float(series.min()),\n                        'max': float(series.max()),\n                        'count': int(series.count())\n                    }\n        \n        return results if results else None\n\n    except Exception as e:\n        print(f\"Error in analyze_baseline_cohesion_tension: {e}\")\n        return None\n\ndef run_complete_statistical_analysis(data: pd.DataFrame, alpha: float = 0.05) -> Dict[str, Any]:\n    \"\"\"\n    Run complete statistical analysis suite on the dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        alpha: Significance level for hypothesis tests (default: 0.05)\n        \n    Returns:\n        Dictionary with all statistical analysis results\n    \"\"\"\n    results = {\n        'analysis_metadata': {\n            'timestamp': pd.Timestamp.now().isoformat(),\n            'sample_size': len(data),\n            'alpha_level': alpha,\n            'variables_analyzed': list(data.select_dtypes(include=[np.number]).columns)\n        }\n    }\n    \n    # Get all analysis functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith(('calculate_', 'perform_', 'test_')) and \n            name != 'run_complete_statistical_analysis'):\n            try:\n                # Pass alpha parameter to functions that might need it\n                if 'alpha' in inspect.signature(obj).parameters:\n                    results[name] = obj(data, alpha=alpha)\n                else:\n                    results[name] = obj(data)\n            except Exception as e:\n                results[name] = {'error': f'Analysis failed: {str(e)}'}\n                \n    return results\n\n\ndef perform_statistical_analysis(data: pd.DataFrame) -> Dict[str, Any]:\n    \"\"\"\n    Template-compatible wrapper function for statistical analysis.\n    \n    This function is called by the universal notebook template and performs\n    comprehensive statistical analysis on the provided dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores and derived metrics\n        \n    Returns:\n        Dictionary containing all statistical analysis results\n    \"\"\"\n    return run_complete_statistical_analysis(data)\n\n\ndef generate_statistical_summary_report(analysis_results: Dict[str, Any]) -> str:\n    \"\"\"\n    Generate a human-readable summary report from statistical analysis results.\n    \n    Args:\n        analysis_results: Results from run_complete_statistical_analysis()\n        \n    Returns:\n        String containing formatted statistical report\n    \"\"\"\n    report_lines = []\n    report_lines.append(\"STATISTICAL ANALYSIS SUMMARY REPORT\")\n    report_lines.append(\"=\" * 50)\n    \n    metadata = analysis_results.get('analysis_metadata', {})\n    report_lines.append(f\"Analysis Timestamp: {metadata.get('timestamp', 'Unknown')}\")\n    report_lines.append(f\"Sample Size: {metadata.get('sample_size', 'Unknown')}\")\n    report_lines.append(f\"Alpha Level: {metadata.get('alpha_level', 'Unknown')}\")\n    report_lines.append(f\"Variables: {len(metadata.get('variables_analyzed', []))}\")\n    report_lines.append(\"\")\n    \n    # Summarize key findings\n    for analysis_name, result in analysis_results.items():\n        if analysis_name != 'analysis_metadata' and isinstance(result, dict):\n            if 'error' not in result:\n                report_lines.append(f\"{analysis_name.replace('_', ' ').title()}:\")\n                \n                # Extract key statistics based on analysis type\n                if 'p_value' in result:\n                    p_val = result['p_value']\n                    significance = \"significant\" if p_val < metadata.get('alpha_level', 0.05) else \"not significant\"\n                    report_lines.append(f\"  - p-value: {p_val:.4f} ({significance})\")\n                \n                if 'effect_size' in result:\n                    report_lines.append(f\"  - Effect size: {result['effect_size']:.4f}\")\n                \n                if 'correlation_matrix' in result:\n                    report_lines.append(f\"  - Correlation matrix generated with {len(result['correlation_matrix'])} variables\")\n                \n                if 'cronbach_alpha' in result:\n                    alpha_val = result['cronbach_alpha']\n                    reliability = \"excellent\" if alpha_val > 0.9 else \"good\" if alpha_val > 0.8 else \"acceptable\" if alpha_val > 0.7 else \"questionable\"\n                    report_lines.append(f\"  - Cronbach's \u03b1: {alpha_val:.3f} ({reliability})\")\n                \n                report_lines.append(\"\")\n            else:\n                report_lines.append(f\"{analysis_name}: ERROR - {result['error']}\")\n                report_lines.append(\"\")\n    \n    return \"\\n\".join(report_lines)\n",
    "cached_with_code": true
  },
  "statistical_data": {
    "status": "success",
    "statistical_results": {
      "analysis_metadata": {
        "timestamp": "2025-08-23T16:44:38.261164",
        "sample_size": 4,
        "alpha_level": 0.05,
        "variables_analyzed": [
          "tribal_dominance_raw",
          "tribal_dominance_salience",
          "tribal_dominance_confidence",
          "individual_dignity_raw",
          "individual_dignity_salience",
          "individual_dignity_confidence",
          "fear_raw",
          "fear_salience",
          "fear_confidence",
          "hope_raw",
          "hope_salience",
          "hope_confidence",
          "envy_raw",
          "envy_salience",
          "envy_confidence",
          "compersion_raw",
          "compersion_salience",
          "compersion_confidence",
          "enmity_raw",
          "enmity_salience",
          "enmity_confidence",
          "amity_raw",
          "amity_salience",
          "amity_confidence",
          "fragmentative_goals_raw",
          "fragmentative_goals_salience",
          "fragmentative_goals_confidence",
          "cohesive_goals_raw",
          "cohesive_goals_salience",
          "cohesive_goals_confidence",
          "compassion_raw",
          "compassion_salience",
          "compassion_confidence"
        ]
      }
    }
  },
  "status": "success_with_data",
  "validation_passed": true
}