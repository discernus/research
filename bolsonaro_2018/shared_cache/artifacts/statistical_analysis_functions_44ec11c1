{
  "status": "success",
  "functions_generated": 8,
  "output_file": "automatedstatisticalanalysisagent_functions.py",
  "module_size": 25193,
  "function_code_content": "\"\"\"\nAutomated Statistical Analysis Functions\n========================================\n\nGenerated by AutomatedStatisticalAnalysisAgent for experiment: bolsonaro_2018_populist_discourse_analysis\nDescription: Statistical analysis experiment\nGenerated: 2025-09-02T03:59:57.972719+00:00\n\nThis module contains automatically generated statistical analysis functions\nfor comprehensive data analysis including ANOVA, correlations, reliability,\nand hypothesis testing as appropriate for the research questions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport scipy.stats as stats\nfrom typing import Dict, Any, Optional, List, Tuple\nimport warnings\n\n# Suppress common statistical warnings for cleaner output\nwarnings.filterwarnings('ignore', category=RuntimeWarning)\n\n\ndef _get_prepared_data(data):\n    \"\"\"\n    Internal helper function to prepare the data for analysis.\n    It calculates all derived metrics from the PDAF v10.0.2 framework and\n    adds grouping variables based on the experiment specification.\n\n    This function is not intended for direct use.\n\n    Args:\n        data (pd.DataFrame): The raw analysis data with one row per document.\n\n    Returns:\n        pd.DataFrame: The input DataFrame with added columns for derived\n                      metrics and experimental groups, or None on error.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    if data is None or data.empty:\n        return None\n\n    df = data.copy()\n\n    # Define dimension base names for easier iteration\n    dims = [\n        \"manichaean_people_elite_framing\", \"crisis_restoration_narrative\",\n        \"popular_sovereignty_claims\", \"anti_pluralist_exclusion\",\n        \"elite_conspiracy_systemic_corruption\", \"authenticity_vs_political_class\",\n        \"homogeneous_people_construction\", \"nationalist_exclusion\",\n        \"economic_populist_appeals\"\n    ]\n\n    # Ensure all required columns exist\n    for dim in dims:\n        for suffix in ['_raw', '_salience']:\n            col_name = f\"{dim}{suffix}\"\n            if col_name not in df.columns:\n                # Attempt to fix common naming inconsistencies, e.g., _raw vs _raw_score\n                alt_col_name = f\"{dim}{suffix}_score\"\n                if alt_col_name in df.columns:\n                    df.rename(columns={alt_col_name: col_name}, inplace=True)\n                else:\n                    # If column is truly missing, cannot proceed\n                    # print(f\"Error: Missing required column '{col_name}'\")\n                    return None\n\n    # Rename raw score columns for consistency in formulas\n    for dim in dims:\n        df.rename(columns={f\"{dim}_raw\": f\"{dim}_raw_score\"}, inplace=True, errors='ignore')\n\n    # --- 1. Calculate Derived Metrics ---\n    # For brevity and clarity, use shorter variable names inside the function\n    psc_raw = df['popular_sovereignty_claims_raw_score']\n    psc_sal = df['popular_sovereignty_claims_salience']\n    ape_raw = df['anti_pluralist_exclusion_raw_score']\n    ape_sal = df['anti_pluralist_exclusion_salience']\n    hpc_raw = df['homogeneous_people_construction_raw_score']\n    hpc_sal = df['homogeneous_people_construction_salience']\n    ne_raw = df['nationalist_exclusion_raw_score']\n    ne_sal = df['nationalist_exclusion_salience']\n    crn_raw = df['crisis_restoration_narrative_raw_score']\n    crn_sal = df['crisis_restoration_narrative_salience']\n    ecs_raw = df['elite_conspiracy_systemic_corruption_raw_score']\n    ecs_sal = df['elite_conspiracy_systemic_corruption_salience']\n\n    # Tension Indices\n    df['democratic_authoritarian_tension'] = np.minimum(psc_raw, ape_raw) * abs(psc_sal - ape_sal)\n    df['internal_external_focus_tension'] = np.minimum(hpc_raw, ne_raw) * abs(hpc_sal - ne_sal)\n    df['crisis_elite_attribution_tension'] = np.minimum(crn_raw, ecs_raw) * abs(crn_sal - ecs_sal)\n\n    # Populist Strategic Contradiction Index (PSCI)\n    df['populist_strategic_contradiction_index'] = (\n        df['democratic_authoritarian_tension'] +\n        df['internal_external_focus_tension'] +\n        df['crisis_elite_attribution_tension']\n    ) / 3\n\n    # Salience-Weighted Indices\n    epsilon = 0.001\n    core_dims = [\"manichaean_people_elite_framing\", \"crisis_restoration_narrative\", \"popular_sovereignty_claims\", \"anti_pluralist_exclusion\"]\n    mech_dims = [\"elite_conspiracy_systemic_corruption\", \"authenticity_vs_political_class\", \"homogeneous_people_construction\"]\n    bound_dims = [\"nationalist_exclusion\", \"economic_populist_appeals\"]\n    all_dims = core_dims + mech_dims + bound_dims\n\n    def sw_index(dim_list):\n        num = sum(df[f'{d}_raw_score'] * df[f'{d}_salience'] for d in dim_list)\n        den = sum(df[f'{d}_salience'] for d in dim_list) + epsilon\n        return num / den\n\n    df['salience_weighted_core_populism_index'] = sw_index(core_dims)\n    df['salience_weighted_populism_mechanisms_index'] = sw_index(mech_dims)\n    df['salience_weighted_boundary_distinctions_index'] = sw_index(bound_dims)\n    df['salience_weighted_overall_populism_index'] = sw_index(all_dims)\n\n    # --- 2. Create Grouping Variables ---\n    # Parse date from document_name\n    df['date'] = pd.to_datetime(df['document_name'].str.extract(r'(\\d{4}-\\d{2}-\\d{2})')[0], errors='coerce')\n\n    # Pre/Post Stabbing Groups\n    stabbing_date = pd.to_datetime('2018-09-06')\n    df['pre_post_stabbing'] = np.where(df['date'] < stabbing_date, 'pre_stabbing', 'post_stabbing')\n\n    # Campaign Stage Groups\n    def map_campaign_stage(d):\n        if d.month == 7 and d.day == 22: return \"early_campaign\"\n        if (d.month == 8 and d.day in [23, 31]) or (d.month == 9 and d.day == 6): return \"mid_campaign\"\n        if d.month == 9 and d.day == 16: return \"campaign_interruption\"\n        if d.month == 9 and d.day == 30: return \"late_campaign\"\n        if d.month == 10 and d.day == 6: return \"final_campaign\"\n        if d.month == 10 and d.day == 7 and 'Morning' in d.name: return \"election_day\"\n        if (d.month == 10 and d.day == 7 and 'Evening' in d.name) or (d.month == 10 and d.day == 16): return \"post_first_round\"\n        if d.month == 10 and d.day in [22, 27]: return \"pre_second_round\"\n        return \"unknown\"\n    df['campaign_stage'] = df.set_index('document_name')['date'].apply(map_campaign_stage).values\n\n    # Audience Type Groups (Hardcoded mapping as per experiment spec interpretation)\n    audience_map = {\n        '2018-07-22_Candidacy_Launch.txt': 'mass_public',\n        '2018-08-23_Aracatuba_Speech_Part_1.txt': 'mass_public',\n        '2018-08-23_Aracatuba_Speech_Part_2.txt': 'mass_public',\n        '2018-08-31_Porto_Velho_Speech.txt': 'mass_public',\n        '2018-09-06_Juiz_de_Fora_Speech.txt': 'mass_public',\n        '2018-09-16_Post-Stabbing_Hospital_Bed.txt': 'online_supporters',\n        '2018-09-30_Avenida_Paulista_Speech.txt': 'national_audience',\n        '2018-10-06_Pre-First-Round_Live.txt': 'online_supporters',\n        '2018-10-07_Morning_Vote_Statement.txt': 'national_audience',\n        '2018-10-07_Evening_Victory_Speech.txt': 'national_audience',\n        '2018-10-16_Business_Leaders_Speech.txt': 'business_leaders',\n        '2018-10-22_Jornal_Nacional_Interview.txt': 'national_audience',\n        '2018-10-27_Pre-Second-Round_Live.txt': 'online_supporters'\n    }\n    df['audience_type'] = df['document_name'].map(audience_map).fillna('unknown')\n\n    return df\n\ndef calculate_overall_descriptive_statistics(data, **kwargs):\n    \"\"\"\n    Calculates overall descriptive statistics for key populist indices.\n    This function addresses RQ1 and H1 by providing a summary of the extent\n    of populism across all speeches.\n\n    Methodology:\n    This function computes the mean, standard deviation, median, min, and max\n    for the main salience-weighted and strategic tension indices. It provides a\n    foundational, descriptive overview of the dataset. No inferential tests are\n    performed due to the small sample size (N=13).\n\n    Args:\n        data (pd.DataFrame): A pandas DataFrame containing the raw analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary of descriptive statistics for key indices,\n              or None if data is insufficient.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        df = _get_prepared_data(data)\n        if df is None:\n            return None\n\n        key_indices = [\n            'salience_weighted_overall_populism_index',\n            'salience_weighted_core_populism_index',\n            'salience_weighted_populism_mechanisms_index',\n            'salience_weighted_boundary_distinctions_index',\n            'populist_strategic_contradiction_index'\n        ]\n\n        results = {}\n        for index in key_indices:\n            if index in df.columns:\n                stats = df[index].describe().to_dict()\n                # Hypothesis H1 check (descriptive)\n                if index == 'salience_weighted_overall_populism_index':\n                    stats['h1_mean_gte_0.5'] = bool(stats.get('mean', 0) >= 0.5)\n                results[index] = stats\n\n        return results if results else None\n\n    except Exception:\n        return None\n\ndef analyze_temporal_evolution(data, **kwargs):\n    \"\"\"\n    Provides descriptive statistics of populist indices across campaign stages.\n    This function addresses RQ2, H2, and H9 by showing how populist rhetoric\n    evolved, but avoids formal significance testing due to insufficient power.\n\n    Methodology:\n    Data is grouped by the 'campaign_stage' variable. For each stage, descriptive\n    statistics (mean, std, count) of the overall populism index are calculated.\n    This allows for a descriptive assessment of trends without the risk of\n    spurious findings from an underpowered regression or ANOVA.\n\n    Args:\n        data (pd.DataFrame): A pandas DataFrame containing the raw analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary containing descriptive statistics per campaign stage,\n              or None if data is insufficient.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        df = _get_prepared_data(data)\n        if df is None or 'campaign_stage' not in df.columns:\n            return None\n\n        # Ensure chronological order for stages\n        stage_order = [\n            \"early_campaign\", \"mid_campaign\", \"campaign_interruption\",\n            \"late_campaign\", \"final_campaign\", \"election_day\",\n            \"post_first_round\", \"pre_second_round\"\n        ]\n        df['campaign_stage'] = pd.Categorical(df['campaign_stage'], categories=stage_order, ordered=True)\n        df.sort_values('campaign_stage', inplace=True)\n\n        results = df.groupby('campaign_stage')['salience_weighted_overall_populism_index'].describe().to_dict('index')\n\n        # Add a note about the underpowered nature of formal tests\n        results['statistical_note'] = \"Analysis is descriptive. Inferential tests like ANOVA or regression were not performed due to the critically low sample size (N=13), which violates assumptions and lacks statistical power.\"\n\n        return results if results else None\n\n    except Exception:\n        return None\n\ndef analyze_dimensional_correlations(data, **kwargs):\n    \"\"\"\n    Calculates the Pearson correlation matrix for all PDAF raw score dimensions.\n    This addresses RQ3, H3, and H13, exploring relationships between dimensions.\n\n    Methodology:\n    A Pearson correlation matrix is computed for the nine raw score dimensions.\n\n    STATISTICAL NOTE: With a sample size of N=13, correlation coefficients are\n    highly unstable and can be misleading. The results are presented for\n    exploratory purposes only and should not be used for confirmatory analysis.\n    P-values are omitted to prevent misinterpretation.\n\n    Args:\n        data (pd.DataFrame): A pandas DataFrame containing the raw analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary containing the correlation matrix, or None if\n              data is insufficient.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        df = _get_prepared_data(data)\n        if df is None:\n            return None\n\n        dim_cols = [col for col in df.columns if col.endswith('_raw_score')]\n        if len(dim_cols) < 2:\n            return None\n\n        corr_matrix = df[dim_cols].corr(method='pearson')\n\n        # Clean up column names for readability\n        corr_matrix.columns = [c.replace('_raw_score', '') for c in corr_matrix.columns]\n        corr_matrix.index = [i.replace('_raw_score', '') for i in corr_matrix.index]\n\n        results = {\n            'correlation_matrix': corr_matrix.to_dict(),\n            'statistical_warning': \"Sample size (N=13) is insufficient for reliable correlation analysis. Results are for exploratory hypothesis generation only.\"\n        }\n        return results\n\n    except Exception:\n        return None\n\ndef analyze_dimensional_salience_profile(data, **kwargs):\n    \"\"\"\n    Calculates the mean salience for each PDAF dimension to create a profile.\n    This addresses RQ5, H5, and H14 by identifying the most rhetorically\n    prominent dimensions in the discourse.\n\n    Methodology:\n    This function computes the mean, std, min, and max for each of the nine\n    salience score columns across all documents. The dimensions are then ranked\n    by mean salience.\n\n    Args:\n        data (pd.DataFrame): A pandas DataFrame containing the raw analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary with descriptive statistics for each dimension's\n              salience, ranked by mean, or None if data is insufficient.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        df = _get_prepared_data(data)\n        if df is None:\n            return None\n\n        salience_cols = [col for col in df.columns if col.endswith('_salience')]\n        if not salience_cols:\n            return None\n\n        salience_stats = df[salience_cols].describe().transpose()\n        salience_stats.index = [c.replace('_salience', '') for c in salience_stats.index]\n        salience_stats = salience_stats.sort_values('mean', ascending=False)\n\n        return salience_stats.to_dict('index')\n\n    except Exception:\n        return None\n\ndef analyze_crisis_impact(data, **kwargs):\n    \"\"\"\n    Provides descriptive statistics comparing populist rhetoric before and after\n    the September 6 stabbing incident. This addresses RQ6, H4, and H8.\n\n    Methodology:\n    Data is grouped by the 'pre_post_stabbing' variable. Descriptive statistics\n    are calculated for each group. To quantify the magnitude of change, Cohen's d\n    is calculated for key dimensions. A formal t-test is not performed due to the\n    extremely small group sizes (n=4, n=9), which would yield unreliable results.\n\n    Args:\n        data (pd.DataFrame): A pandas DataFrame containing the raw analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary with descriptive statistics and effect sizes for\n              pre/post-stabbing groups, or None if data is insufficient.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    def cohen_d(x, y):\n        nx, ny = len(x), len(y)\n        if nx < 2 or ny < 2: return np.nan\n        dof = nx + ny - 2\n        return (np.mean(x) - np.mean(y)) / np.sqrt(((nx-1)*np.std(x, ddof=1)**2 + (ny-1)*np.std(y, ddof=1)**2) / dof)\n\n    try:\n        df = _get_prepared_data(data)\n        if df is None or 'pre_post_stabbing' not in df.columns:\n            return None\n\n        groups = df.groupby('pre_post_stabbing')\n        if len(groups) < 2:\n            return {'statistical_note': 'Only one group (pre or post) found. Cannot perform comparison.'}\n\n        results = {'descriptive_stats': {}}\n        for name, group in groups:\n            results['descriptive_stats'][name] = group.mean(numeric_only=True).to_dict()\n\n        pre_group = groups.get_group('pre_stabbing')\n        post_group = groups.get_group('post_stabbing')\n\n        # Calculate effect sizes for hypotheses H4 and H8\n        effect_sizes = {}\n        h4_dim = 'manichaean_people_elite_framing_raw_score'\n        h8_dim = 'elite_conspiracy_systemic_corruption_raw_score'\n\n        if h4_dim in df.columns:\n            effect_sizes[h4_dim] = cohen_d(post_group[h4_dim], pre_group[h4_dim])\n        if h8_dim in df.columns:\n            effect_sizes[h8_dim] = cohen_d(post_group[h8_dim], pre_group[h8_dim])\n\n        results['effect_sizes_cohens_d'] = effect_sizes\n        results['statistical_note'] = \"Comparison is descriptive. T-tests were not performed due to insufficient statistical power from small group sizes (n_pre=4, n_post=9).\"\n\n        return results\n\n    except Exception:\n        return None\n\ndef analyze_audience_adaptation(data, **kwargs):\n    \"\"\"\n    Provides descriptive statistics of populist rhetoric for different audiences.\n    This addresses RQ8 and H6.\n\n    Methodology:\n    Data is grouped by the 'audience_type' variable. Descriptive statistics\n    are calculated for each audience. A formal t-test or ANOVA is not performed\n    as some groups have n=1, making such tests impossible and statistically invalid.\n    The analysis is purely descriptive.\n\n    Args:\n        data (pd.DataFrame): A pandas DataFrame containing the raw analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary with descriptive statistics for each audience type,\n              or None if data is insufficient.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        df = _get_prepared_data(data)\n        if df is None or 'audience_type' not in df.columns:\n            return None\n\n        # Focus on the dimension from H6\n        h6_dim = 'economic_populist_appeals_raw_score'\n        if h6_dim not in df.columns:\n            return {'error': f\"Required column '{h6_dim}' not found.\"}\n\n        results = df.groupby('audience_type')[h6_dim].describe().to_dict('index')\n        results['statistical_note'] = \"Analysis is descriptive. Inferential tests were not performed as group sizes are too small (e.g., n=1 for 'business_leaders'), making tests statistically invalid.\"\n\n        return results\n\n    except Exception:\n        return None\n\ndef test_dimensional_consistency(data, **kwargs):\n    \"\"\"\n    Calculates Cronbach's alpha for core and auxiliary populist dimensions.\n    This addresses H12.\n\n    Methodology:\n    Cronbach's alpha is calculated for the four core populist dimensions.\n\n    STATISTICAL WARNING: Cronbach's alpha is highly unreliable with very small\n    sample sizes. The provided N=13 is well below the recommended minimum of\n    N=30 (and preferably N=100+). The result should be interpreted with\n    extreme caution and is provided only because it was explicitly requested\n    in the experiment specification.\n\n    Args:\n        data (pd.DataFrame): A pandas DataFrame containing the raw analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary containing the Cronbach's alpha value and a\n              statistical warning, or None if data is insufficient.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        df = _get_prepared_data(data)\n        if df is None:\n            return None\n\n        core_dim_cols = [\n            'manichaean_people_elite_framing_raw_score',\n            'crisis_restoration_narrative_raw_score',\n            'popular_sovereignty_claims_raw_score',\n            'anti_pluralist_exclusion_raw_score'\n        ]\n\n        # Check if all columns exist\n        if not all(col in df.columns for col in core_dim_cols):\n            return None\n\n        # Check for sufficient sample size (N) and items (k)\n        k = len(core_dim_cols)\n        n = len(df)\n        if k < 2 or n < 2:\n            return {\n                'cronbachs_alpha': None,\n                'statistical_warning': \"Insufficient items or samples to calculate Cronbach's alpha.\"\n            }\n\n        # Manual calculation of Cronbach's Alpha\n        items = df[core_dim_cols]\n        item_vars = items.var(axis=0, ddof=1)\n        total_var = items.sum(axis=1).var(ddof=1)\n        sum_item_vars = item_vars.sum()\n\n        if total_var == 0: # Avoid division by zero if all scores are identical\n             alpha = 1.0 if sum_item_vars == 0 else 0.0\n        else:\n             alpha = (k / (k - 1)) * (1 - sum_item_vars / total_var)\n\n        return {\n            'cronbachs_alpha_core_dimensions': alpha,\n            'statistical_warning': f\"Cronbach's alpha is unreliable with the given sample size (N={n}). Recommended N > 30. Interpret with extreme caution.\"\n        }\n\n    except Exception:\n        return None\n\ndef run_complete_statistical_analysis(data: pd.DataFrame, alpha: float = 0.05) -> Dict[str, Any]:\n    \"\"\"\n    Run complete statistical analysis suite on the dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        alpha: Significance level for hypothesis tests (default: 0.05)\n        \n    Returns:\n        Dictionary with all statistical analysis results\n    \"\"\"\n    results = {\n        'analysis_metadata': {\n            'timestamp': pd.Timestamp.now().isoformat(),\n            'sample_size': len(data),\n            'alpha_level': alpha,\n            'variables_analyzed': list(data.select_dtypes(include=[np.number]).columns)\n        }\n    }\n    \n    # Get all analysis functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith(('calculate_', 'perform_', 'test_')) and \n            name != 'run_complete_statistical_analysis'):\n            try:\n                # Pass alpha parameter to functions that might need it\n                if 'alpha' in inspect.signature(obj).parameters:\n                    results[name] = obj(data, alpha=alpha)\n                else:\n                    results[name] = obj(data)\n            except Exception as e:\n                results[name] = {'error': f'Analysis failed: {str(e)}'}\n                \n    return results\n\n\ndef perform_statistical_analysis(data: pd.DataFrame) -> Dict[str, Any]:\n    \"\"\"\n    Template-compatible wrapper function for statistical analysis.\n    \n    This function is called by the universal notebook template and performs\n    comprehensive statistical analysis on the provided dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores and derived metrics\n        \n    Returns:\n        Dictionary containing all statistical analysis results\n    \"\"\"\n    return run_complete_statistical_analysis(data)\n\n\ndef generate_statistical_summary_report(analysis_results: Dict[str, Any]) -> str:\n    \"\"\"\n    Generate a human-readable summary report from statistical analysis results.\n    \n    Args:\n        analysis_results: Results from run_complete_statistical_analysis()\n        \n    Returns:\n        String containing formatted statistical report\n    \"\"\"\n    report_lines = []\n    report_lines.append(\"STATISTICAL ANALYSIS SUMMARY REPORT\")\n    report_lines.append(\"=\" * 50)\n    \n    metadata = analysis_results.get('analysis_metadata', {})\n    report_lines.append(f\"Analysis Timestamp: {metadata.get('timestamp', 'Unknown')}\")\n    report_lines.append(f\"Sample Size: {metadata.get('sample_size', 'Unknown')}\")\n    report_lines.append(f\"Alpha Level: {metadata.get('alpha_level', 'Unknown')}\")\n    report_lines.append(f\"Variables: {len(metadata.get('variables_analyzed', []))}\")\n    report_lines.append(\"\")\n    \n    # Summarize key findings\n    for analysis_name, result in analysis_results.items():\n        if analysis_name != 'analysis_metadata' and isinstance(result, dict):\n            if 'error' not in result:\n                report_lines.append(f\"{analysis_name.replace('_', ' ').title()}:\")\n                \n                # Extract key statistics based on analysis type\n                if 'p_value' in result:\n                    p_val = result['p_value']\n                    significance = \"significant\" if p_val < metadata.get('alpha_level', 0.05) else \"not significant\"\n                    report_lines.append(f\"  - p-value: {p_val:.4f} ({significance})\")\n                \n                if 'effect_size' in result:\n                    report_lines.append(f\"  - Effect size: {result['effect_size']:.4f}\")\n                \n                if 'correlation_matrix' in result:\n                    report_lines.append(f\"  - Correlation matrix generated with {len(result['correlation_matrix'])} variables\")\n                \n                if 'cronbach_alpha' in result:\n                    alpha_val = result['cronbach_alpha']\n                    reliability = \"excellent\" if alpha_val > 0.9 else \"good\" if alpha_val > 0.8 else \"acceptable\" if alpha_val > 0.7 else \"questionable\"\n                    report_lines.append(f\"  - Cronbach's \u03b1: {alpha_val:.3f} ({reliability})\")\n                \n                report_lines.append(\"\")\n            else:\n                report_lines.append(f\"{analysis_name}: ERROR - {result['error']}\")\n                report_lines.append(\"\")\n    \n    return \"\\n\".join(report_lines)\n",
  "cached_with_code": true
}