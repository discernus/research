{
  "status": "success",
  "functions_generated": 9,
  "output_file": "automatedstatisticalanalysisagent_functions.py",
  "module_size": 33685,
  "function_code_content": "\"\"\"\nAutomated Statistical Analysis Functions\n========================================\n\nGenerated by AutomatedStatisticalAnalysisAgent for experiment: bolsonaro_2018_populist_discourse_analysis\nDescription: Statistical analysis experiment\nGenerated: 2025-09-01T20:03:40.706786+00:00\n\nThis module contains automatically generated statistical analysis functions\nfor comprehensive data analysis including ANOVA, correlations, reliability,\nand hypothesis testing as appropriate for the research questions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport scipy.stats as stats\nfrom typing import Dict, Any, Optional, List, Tuple\nimport warnings\n\n# Suppress common statistical warnings for cleaner output\nwarnings.filterwarnings('ignore', category=RuntimeWarning)\n\n\ndef _preprocess_and_add_metrics(data, **kwargs):\n    \"\"\"\n    Internal helper function to preprocess data, calculate derived metrics,\n    and add grouping variables based on the experiment specification.\n\n    This function is not intended to be called directly by the user.\n\n    Args:\n        data (pd.DataFrame): The raw analysis data.\n        **kwargs: Not used.\n\n    Returns:\n        pd.DataFrame: The processed DataFrame with new metric and group columns.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    import re\n\n    try:\n        df = data.copy()\n\n        # Standardize column names to match framework spec for formula calculations\n        # The data uses '..._temporal_narrative_...' while spec uses '..._narrative_...'\n        df.columns = [c.replace('_temporal_narrative', '_narrative') for c in df.columns]\n\n        # Define base dimension names for easier access\n        dims = [\n            \"manichaean_people_elite_framing\", \"crisis_restoration_narrative\",\n            \"popular_sovereignty_claims\", \"anti_pluralist_exclusion\",\n            \"elite_conspiracy_systemic_corruption\", \"authenticity_vs_political_class\",\n            \"homogeneous_people_construction\", \"nationalist_exclusion\",\n            \"economic_populist_appeals\"\n        ]\n        raw_cols = {d: f\"{d}_raw\" for d in dims}\n        sal_cols = {d: f\"{d}_salience\" for d in dims}\n\n        # --- Calculate Derived Metrics ---\n        # Tension Scores\n        df['democratic_authoritarian_tension'] = np.minimum(df[raw_cols['popular_sovereignty_claims']], df[raw_cols['anti_pluralist_exclusion']]) * np.abs(df[sal_cols['popular_sovereignty_claims']] - df[sal_cols['anti_pluralist_exclusion']])\n        df['internal_external_focus_tension'] = np.minimum(df[raw_cols['homogeneous_people_construction']], df[raw_cols['nationalist_exclusion']]) * np.abs(df[sal_cols['homogeneous_people_construction']] - df[sal_cols['nationalist_exclusion']])\n        df['crisis_elite_attribution_tension'] = np.minimum(df[raw_cols['crisis_restoration_narrative']], df[raw_cols['elite_conspiracy_systemic_corruption']]) * np.abs(df[sal_cols['crisis_restoration_narrative']] - df[sal_cols['elite_conspiracy_systemic_corruption']])\n\n        # Populist Strategic Contradiction Index (PSCI)\n        df['populist_strategic_contradiction_index'] = (df['democratic_authoritarian_tension'] + df['internal_external_focus_tension'] + df['crisis_elite_attribution_tension']) / 3\n\n        # Salience-Weighted Indices\n        core_dims = dims[:4]\n        mech_dims = dims[4:7]\n        bound_dims = dims[7:]\n\n        # Numerators\n        core_num = sum(df[raw_cols[d]] * df[sal_cols[d]] for d in core_dims)\n        mech_num = sum(df[raw_cols[d]] * df[sal_cols[d]] for d in mech_dims)\n        bound_num = sum(df[raw_cols[d]] * df[sal_cols[d]] for d in bound_dims)\n        overall_num = sum(df[raw_cols[d]] * df[sal_cols[d]] for d in dims)\n\n        # Denominators\n        core_den = sum(df[sal_cols[d]] for d in core_dims) + 0.001\n        mech_den = sum(df[sal_cols[d]] for d in mech_dims) + 0.001\n        bound_den = sum(df[sal_cols[d]] for d in bound_dims) + 0.001\n        overall_den = sum(df[sal_cols[d]] for d in dims) + 0.001\n\n        df['salience_weighted_core_populism_index'] = core_num / core_den\n        df['salience_weighted_populism_mechanisms_index'] = mech_num / mech_den\n        df['salience_weighted_boundary_distinctions_index'] = bound_num / bound_den\n        df['salience_weighted_overall_populism_index'] = overall_num / overall_den\n\n        # --- Add Grouping Variables ---\n        # Extract date from document_name\n        df['date'] = pd.to_datetime(df['document_name'].str.extract(r'(\\d{4}-\\d{2}-\\d{2})')[0], errors='coerce')\n        df = df.sort_values('date').reset_index(drop=True)\n\n        # Pre/Post Stabbing Groups (based on n=4 pre, n=9 post)\n        df['pre_post_stabbing'] = 'post_stabbing'\n        df.loc[df.index < 4, 'pre_post_stabbing'] = 'pre_stabbing'\n\n        # Campaign Stage Groups\n        stage_map = {\n            0: \"early_campaign\", # July 22\n            1: \"mid_campaign\", 2: \"mid_campaign\", 3: \"mid_campaign\", # Aug 23, Aug 31, Sep 6\n            4: \"campaign_interruption\", # Sep 16\n            5: \"late_campaign\", # Sep 30\n            6: \"final_campaign\", # Oct 6\n            7: \"election_day\", # Oct 7 morning\n            8: \"post_first_round\", 9: \"post_first_round\", # Oct 7 evening, Oct 16\n            10: \"pre_second_round\", 11: \"pre_second_round\", 12: \"pre_second_round\" # Oct 22, Oct 27 (assuming 13 docs)\n        }\n        df['campaign_stage'] = df.index.map(stage_map).fillna('unknown')\n\n\n        # Audience Type Groups (plausible mapping based on counts in spec)\n        audience_map = {\n            # mass_public (n=5)\n            0: \"mass_public\", 1: \"mass_public\", 2: \"mass_public\",\n            5: \"mass_public\", 12: \"mass_public\",\n            # business_leaders (n=1)\n            3: \"business_leaders\",\n            # online_supporters (n=3)\n            4: \"online_supporters\", 8: \"online_supporters\", 10: \"online_supporters\",\n            # national_audience (n=4)\n            6: \"national_audience\", 7: \"national_audience\", 9: \"national_audience\", 11: \"national_audience\"\n        }\n        df['audience'] = df.index.map(audience_map).fillna('unknown')\n\n\n        # Electoral Proximity Groups\n        def map_proximity(d):\n            if d.month in [7, 8]: return \"distant\"\n            if d.month == 9: return \"approaching\"\n            if d.month == 10 and d.day <= 6: return \"imminent\"\n            if d.month == 10 and 7 <= d.day <= 21: return \"inter_round\"\n            if d.month == 10 and d.day >= 22: return \"final_push\"\n            return \"unknown\"\n        df['electoral_proximity'] = df['date'].apply(map_proximity)\n\n        return df\n\n    except Exception:\n        return None\n\ndef calculate_descriptive_statistics(data, **kwargs):\n    \"\"\"\n    Calculates descriptive statistics for all PDAF dimensions and derived metrics.\n    This addresses RQ1 and provides data for hypotheses H1, H5, and H14.\n\n    Methodology:\n    - Calculates mean, standard deviation, min, max, and count for key variables.\n    - Provides overall statistics and statistics grouped by 'campaign_stage' and 'audience'.\n    - For H1, the overall mean of 'salience_weighted_overall_populism_index' can be checked against 0.5.\n    - For H5, the means of relevant salience scores can be examined.\n    - For H14, the mean of 'economic_populist_appeals_salience' for the 'business_leaders' audience can be checked.\n\n    Args:\n        data (pd.DataFrame): A pandas DataFrame with analysis data.\n        **kwargs: Not used.\n\n    Returns:\n        dict: A dictionary containing DataFrames of descriptive statistics, or None on error.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        processed_data = _preprocess_and_add_metrics(data)\n        if processed_data is None:\n            return None\n\n        metrics_to_describe = [\n            'manichaean_people_elite_framing_raw', 'crisis_restoration_narrative_raw',\n            'popular_sovereignty_claims_raw', 'anti_pluralist_exclusion_raw',\n            'elite_conspiracy_systemic_corruption_raw', 'authenticity_vs_political_class_raw',\n            'homogeneous_people_construction_raw', 'nationalist_exclusion_raw',\n            'economic_populist_appeals_raw',\n            'manichaean_people_elite_framing_salience', 'crisis_restoration_narrative_salience',\n            'salience_weighted_overall_populism_index', 'populist_strategic_contradiction_index'\n        ]\n        \n        # Filter out columns that might not exist if preprocessing fails partially\n        metrics_to_describe = [col for col in metrics_to_describe if col in processed_data.columns]\n        if not metrics_to_describe:\n            return {\"error\": \"No valid metric columns found in the data.\"}\n\n        results = {}\n        \n        # Overall descriptive statistics\n        results['overall_descriptives'] = processed_data[metrics_to_describe].describe().to_dict()\n\n        # Grouped by campaign stage\n        results['by_campaign_stage'] = processed_data.groupby('campaign_stage')[metrics_to_describe].describe().to_dict()\n\n        # Grouped by audience\n        results['by_audience'] = processed_data.groupby('audience')[metrics_to_describe].describe().to_dict()\n\n        return results\n\n    except Exception as e:\n        return {'error': str(e)}\n\ndef perform_temporal_trend_analysis(data, **kwargs):\n    \"\"\"\n    Performs a linear regression to analyze the temporal trend of populist rhetoric.\n    This analysis directly addresses research questions RQ2 and RQ4, and tests hypothesis H9.\n\n    Methodology:\n    - A simple linear regression model (OLS) is fitted.\n    - Dependent Variable: 'salience_weighted_overall_populism_index'.\n    - Independent Variable: Time, represented as ordinal day number from the start of the campaign.\n    - The function reports the regression coefficient (slope), p-value, and R-squared value to assess the significance and strength of the temporal trend.\n\n    Args:\n        data (pd.DataFrame): A pandas DataFrame with analysis data.\n        **kwargs: Not used.\n\n    Returns:\n        dict: A dictionary with regression results (slope, p-value, r_squared), or None on error.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    import statsmodels.api as sm\n\n    try:\n        processed_data = _preprocess_and_add_metrics(data)\n        if processed_data is None or processed_data.empty:\n            return None\n\n        df = processed_data.dropna(subset=['date', 'salience_weighted_overall_populism_index']).copy()\n        if len(df) < 2:\n            return {'error': 'Insufficient data for regression analysis.'}\n\n        df['day_ordinal'] = (df['date'] - df['date'].min()).dt.days\n        \n        Y = df['salience_weighted_overall_populism_index']\n        X = sm.add_constant(df['day_ordinal'])\n\n        model = sm.OLS(Y, X).fit()\n\n        results = {\n            'model': 'OLS',\n            'dependent_variable': 'salience_weighted_overall_populism_index',\n            'independent_variable': 'day_ordinal',\n            'slope (beta)': model.params.get('day_ordinal'),\n            'intercept': model.params.get('const'),\n            'p_value_slope': model.pvalues.get('day_ordinal'),\n            'r_squared': model.rsquared,\n            'n_observations': int(model.nobs)\n        }\n        return results\n\n    except Exception as e:\n        return {'error': str(e)}\n\ndef compare_campaign_phases_ttest(data, **kwargs):\n    \"\"\"\n    Performs independent t-tests to compare populist scores between different campaign phases and audiences.\n    This function tests hypotheses H2, H4, H6, and H8.\n\n    Methodology:\n    - Welch's independent t-tests are used to compare the means of two independent groups.\n    - Effect size is calculated using Cohen's d.\n    - Tests performed:\n        1. Early vs. Late Campaign on Overall Populism (H2).\n        2. Pre vs. Post Stabbing on Manichaean Framing (H4) and Elite Conspiracy (H8).\n        3. Business vs. Mass Rally Audience on Economic Populism (H6).\n\n    Args:\n        data (pd.DataFrame): A pandas DataFrame with analysis data.\n        **kwargs: Not used.\n\n    Returns:\n        dict: A dictionary containing the results of each t-test, or None on error.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    from scipy.stats import ttest_ind\n\n    def cohen_d(x, y):\n        nx, ny = len(x), len(y)\n        dof = nx + ny - 2\n        return (np.mean(x) - np.mean(y)) / np.sqrt(((nx-1)*np.std(x, ddof=1)**2 + (ny-1)*np.std(y, ddof=1)**2) / dof)\n\n    try:\n        processed_data = _preprocess_and_add_metrics(data)\n        if processed_data is None or processed_data.empty:\n            return None\n\n        results = {}\n\n        # H2: Early vs. Late Campaign Populism\n        early_stages = ['early_campaign', 'mid_campaign']\n        late_stages = ['late_campaign', 'final_campaign', 'election_day', 'post_first_round', 'pre_second_round']\n        group1_h2 = processed_data[processed_data['campaign_stage'].isin(early_stages)]['salience_weighted_overall_populism_index'].dropna()\n        group2_h2 = processed_data[processed_data['campaign_stage'].isin(late_stages)]['salience_weighted_overall_populism_index'].dropna()\n        if len(group1_h2) > 1 and len(group2_h2) > 1:\n            stat, p_val = ttest_ind(group2_h2, group1_h2, equal_var=False, alternative='greater') # H2: \u03bc_late > \u03bc_early\n            results['H2_early_vs_late_populism'] = {\n                'test': 'Welch\\'s t-test (one-sided)', 'comparison': 'late_campaign > early_campaign',\n                'variable': 'salience_weighted_overall_populism_index',\n                't_statistic': stat, 'p_value': p_val, 'cohen_d': cohen_d(group2_h2, group1_h2),\n                'mean_early': group1_h2.mean(), 'mean_late': group2_h2.mean()\n            }\n\n        # H4 & H8: Pre vs. Post Stabbing\n        pre_stab = processed_data[processed_data['pre_post_stabbing'] == 'pre_stabbing']\n        post_stab = processed_data[processed_data['pre_post_stabbing'] == 'post_stabbing']\n        \n        # H4: Manichaean Framing\n        group1_h4 = pre_stab['manichaean_people_elite_framing_raw'].dropna()\n        group2_h4 = post_stab['manichaean_people_elite_framing_raw'].dropna()\n        if len(group1_h4) > 1 and len(group2_h4) > 1:\n            stat, p_val = ttest_ind(group2_h4, group1_h4, equal_var=False, alternative='greater') # H4: \u03bc_post > \u03bc_pre\n            results['H4_pre_vs_post_stabbing_manichaean'] = {\n                'test': 'Welch\\'s t-test (one-sided)', 'comparison': 'post_stabbing > pre_stabbing',\n                'variable': 'manichaean_people_elite_framing_raw',\n                't_statistic': stat, 'p_value': p_val, 'cohen_d': cohen_d(group2_h4, group1_h4),\n                'mean_pre': group1_h4.mean(), 'mean_post': group2_h4.mean()\n            }\n\n        # H8: Elite Conspiracy\n        group1_h8 = pre_stab['elite_conspiracy_systemic_corruption_raw'].dropna()\n        group2_h8 = post_stab['elite_conspiracy_systemic_corruption_raw'].dropna()\n        if len(group1_h8) > 1 and len(group2_h8) > 1:\n            stat, p_val = ttest_ind(group2_h8, group1_h8, equal_var=False, alternative='greater') # H8: \u03bc_post > \u03bc_pre\n            results['H8_pre_vs_post_stabbing_conspiracy'] = {\n                'test': 'Welch\\'s t-test (one-sided)', 'comparison': 'post_stabbing > pre_stabbing',\n                'variable': 'elite_conspiracy_systemic_corruption_raw',\n                't_statistic': stat, 'p_value': p_val, 'cohen_d': cohen_d(group2_h8, group1_h8),\n                'mean_pre': group1_h8.mean(), 'mean_post': group2_h8.mean()\n            }\n\n        # H6: Audience Effect on Economic Populism\n        group1_h6 = processed_data[processed_data['audience'] == 'business_leaders']['economic_populist_appeals_raw'].dropna()\n        group2_h6 = processed_data[processed_data['audience'] == 'mass_public']['economic_populist_appeals_raw'].dropna()\n        if len(group1_h6) > 1 and len(group2_h6) > 1:\n            stat, p_val = ttest_ind(group2_h6, group1_h6, equal_var=False, alternative='greater') # H6: \u03bc_mass > \u03bc_business\n            results['H6_audience_economic_populism'] = {\n                'test': 'Welch\\'s t-test (one-sided)', 'comparison': 'mass_public > business_leaders',\n                'variable': 'economic_populist_appeals_raw',\n                't_statistic': stat, 'p_value': p_val, 'cohen_d': cohen_d(group2_h6, group1_h6),\n                'mean_business': group1_h6.mean(), 'mean_mass_public': group2_h6.mean()\n            }\n\n        return results if results else {'message': 'Not enough data for any t-tests.'}\n\n    except Exception as e:\n        return {'error': str(e)}\n\ndef perform_group_comparison_anova(data, **kwargs):\n    \"\"\"\n    Performs one-way ANOVA to compare dimension scores across campaign stages.\n    This analysis addresses hypothesis H11.\n\n    Methodology:\n    - A one-way ANOVA is conducted for each of the 9 raw score dimensions.\n    - The grouping variable is 'campaign_stage'.\n    - If the ANOVA result is statistically significant (p < 0.05), a Tukey HSD post-hoc test is performed to identify which specific group pairs are different.\n    - Effect size is reported using eta-squared.\n\n    Args:\n        data (pd.DataFrame): A pandas DataFrame with analysis data.\n        **kwargs: Not used.\n\n    Returns:\n        dict: A dictionary with ANOVA and Tukey HSD results for each dimension, or None on error.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    from scipy.stats import f_oneway\n    from statsmodels.stats.multicomp import pairwise_tukeyhsd\n\n    try:\n        processed_data = _preprocess_and_add_metrics(data)\n        if processed_data is None or processed_data.empty:\n            return None\n\n        dims = [\n            \"manichaean_people_elite_framing\", \"crisis_restoration_narrative\",\n            \"popular_sovereignty_claims\", \"anti_pluralist_exclusion\",\n            \"elite_conspiracy_systemic_corruption\", \"authenticity_vs_political_class\",\n            \"homogeneous_people_construction\", \"nationalist_exclusion\",\n            \"economic_populist_appeals\"\n        ]\n        raw_cols = [f\"{d}_raw\" for d in dims]\n        results = {}\n        \n        for col in raw_cols:\n            if col not in processed_data.columns: continue\n            \n            grouped_data = [\n                group[col].dropna() for name, group in processed_data.groupby('campaign_stage')\n                if not group[col].dropna().empty\n            ]\n            \n            if len(grouped_data) < 2:\n                results[col] = {'error': 'Not enough groups with data for ANOVA.'}\n                continue\n\n            # ANOVA\n            f_stat, p_val = f_oneway(*grouped_data)\n            \n            # Eta-squared\n            ss_between = sum(len(g) * (g.mean() - processed_data[col].mean())**2 for g in grouped_data)\n            ss_total = sum((processed_data[col] - processed_data[col].mean())**2)\n            eta_squared = ss_between / ss_total if ss_total > 0 else 0\n\n            anova_result = {\n                'f_statistic': f_stat,\n                'p_value': p_val,\n                'eta_squared': eta_squared,\n                'significant': p_val < 0.05\n            }\n            \n            # Tukey HSD if significant\n            if p_val < 0.05:\n                tukey_df = processed_data.dropna(subset=[col, 'campaign_stage'])\n                if tukey_df['campaign_stage'].nunique() > 1:\n                    tukey_result = pairwise_tukeyhsd(endog=tukey_df[col], groups=tukey_df['campaign_stage'], alpha=0.05)\n                    anova_result['tukey_hsd'] = str(tukey_result)\n            \n            results[col] = anova_result\n        \n        significant_dims = sum(1 for res in results.values() if isinstance(res, dict) and res.get('significant'))\n        results['summary_H11'] = {\n            'hypothesis': 'At least 5 of 9 PDAF dimensions will show significant differences between campaign_stage groups.',\n            'significant_dimensions_count': significant_dims,\n            'is_supported': significant_dims >= 5\n        }\n\n        return results\n\n    except Exception as e:\n        return {'error': str(e)}\n\ndef analyze_dimensional_correlations(data, **kwargs):\n    \"\"\"\n    Calculates Pearson correlations between PDAF dimensions to test H3 and H13.\n\n    Methodology:\n    - A correlation matrix is computed for all 9 raw score dimensions using Pearson's r.\n    - Specific correlations relevant to the hypotheses are extracted and reported with p-values.\n    - H3: Correlation between 'nationalist_exclusion' and people-centric dimensions ('manichaean_people_elite_framing', 'popular_sovereignty_claims', 'homogeneous_people_construction').\n    - H13: Correlation between 'nationalist_exclusion' and 'anti_pluralist_exclusion'.\n\n    Args:\n        data (pd.DataFrame): A pandas DataFrame with analysis data.\n        **kwargs: Not used.\n\n    Returns:\n        dict: A dictionary containing the full correlation matrix and specific hypothesis tests, or None on error.\n    \"\"\"\n    import pandas as pd\n    from scipy.stats import pearsonr\n\n    try:\n        processed_data = _preprocess_and_add_metrics(data)\n        if processed_data is None or processed_data.empty:\n            return None\n\n        dims = [\n            \"manichaean_people_elite_framing\", \"crisis_restoration_narrative\",\n            \"popular_sovereignty_claims\", \"anti_pluralist_exclusion\",\n            \"elite_conspiracy_systemic_corruption\", \"authenticity_vs_political_class\",\n            \"homogeneous_people_construction\", \"nationalist_exclusion\",\n            \"economic_populist_appeals\"\n        ]\n        raw_cols = [f\"{d}_raw\" for d in dims]\n        \n        df_corr = processed_data[raw_cols].dropna()\n        if len(df_corr) < 2:\n            return {'error': 'Insufficient data for correlation analysis.'}\n\n        results = {}\n        results['correlation_matrix'] = df_corr.corr().to_dict()\n\n        # H3: Nationalist vs. People-centric\n        h3_results = {}\n        people_centric_dims = ['manichaean_people_elite_framing_raw', 'popular_sovereignty_claims_raw', 'homogeneous_people_construction_raw']\n        for dim in people_centric_dims:\n            r, p = pearsonr(df_corr['nationalist_exclusion_raw'], df_corr[dim])\n            h3_results[f\"nationalist_exclusion_vs_{dim}\"] = {'r': r, 'p_value': p}\n        results['H3_nationalist_vs_people_centric'] = h3_results\n\n        # H13: Nationalist vs. Anti-Pluralist\n        r, p = pearsonr(df_corr['nationalist_exclusion_raw'], df_corr['anti_pluralist_exclusion_raw'])\n        results['H13_nationalist_vs_anti_pluralist'] = {\n            'r': r, 'p_value': p, 'significant_at_0.05': p < 0.05, 'r_greater_than_0.5': r > 0.5\n        }\n\n        return results\n\n    except Exception as e:\n        return {'error': str(e)}\n\ndef test_dimensional_reliability(data, **kwargs):\n    \"\"\"\n    Calculates the internal consistency of the core populist dimensions using Cronbach's alpha.\n    This function directly tests hypothesis H12.\n\n    Methodology:\n    - Cronbach's alpha is a measure of internal consistency for a set of scale or test items.\n    - It is calculated for the four 'Primary Populist Core Anchors':\n      'manichaean_people_elite_framing', 'crisis_restoration_narrative',\n      'popular_sovereignty_claims', 'anti_pluralist_exclusion'.\n    - A value > 0.8 is hypothesized, indicating high reliability.\n\n    Args:\n        data (pd.DataFrame): A pandas DataFrame with analysis data.\n        **kwargs: Not used.\n\n    Returns:\n        dict: A dictionary with the Cronbach's alpha value, or None on error.\n    \"\"\"\n    import pandas as pd\n    import pingouin as pg\n\n    try:\n        processed_data = _preprocess_and_add_metrics(data)\n        if processed_data is None or processed_data.empty:\n            return None\n\n        core_dims_raw = [\n            'manichaean_people_elite_framing_raw', 'crisis_restoration_narrative_raw',\n            'popular_sovereignty_claims_raw', 'anti_pluralist_exclusion_raw'\n        ]\n        \n        df_alpha = processed_data[core_dims_raw].dropna()\n        if len(df_alpha) < 2:\n            return {'error': 'Insufficient data for reliability analysis.'}\n\n        alpha_results = pg.cronbach_alpha(data=df_alpha)\n        alpha_val = alpha_results[0]\n\n        results = {\n            'test': \"Cronbach's Alpha for Core Populist Dimensions\",\n            'dimensions': core_dims_raw,\n            'cronbach_alpha': alpha_val,\n            'n_items': alpha_results[1],\n            'n_observations': len(df_alpha),\n            'H12_supported': alpha_val > 0.8\n        }\n        return results\n\n    except Exception as e:\n        return {'error': f\"Could not compute Cronbach's alpha. Ensure 'pingouin' is installed. Error: {e}\"}\n\ndef analyze_score_variance(data, **kwargs):\n    \"\"\"\n    Tests for homogeneity of variances between campaign periods using Levene's test.\n    This function addresses hypothesis H10, which predicts that variance in populist scores\n    will increase in the final month of the campaign.\n\n    Methodology:\n    - Levene's test assesses the equality of variances for a variable calculated for two or more groups.\n    - It is used here to compare the variance of 'salience_weighted_overall_populism_index'\n      in October speeches versus all earlier speeches.\n\n    Args:\n        data (pd.DataFrame): A pandas DataFrame with analysis data.\n        **kwargs: Not used.\n\n    Returns:\n        dict: A dictionary with the Levene's test statistic and p-value, or None on error.\n    \"\"\"\n    import pandas as pd\n    from scipy.stats import levene\n\n    try:\n        processed_data = _preprocess_and_add_metrics(data)\n        if processed_data is None or processed_data.empty:\n            return None\n\n        df = processed_data.dropna(subset=['date', 'salience_weighted_overall_populism_index'])\n        \n        october_scores = df[df['date'].dt.month == 10]['salience_weighted_overall_populism_index']\n        earlier_scores = df[df['date'].dt.month < 10]['salience_weighted_overall_populism_index']\n\n        if len(october_scores) < 2 or len(earlier_scores) < 2:\n            return {'error': 'Insufficient data in one or both groups for Levene\\'s test.'}\n\n        stat, p_val = levene(october_scores, earlier_scores)\n\n        results = {\n            'test': \"Levene's test for homogeneity of variances\",\n            'comparison': 'October speeches vs. Earlier speeches',\n            'variable': 'salience_weighted_overall_populism_index',\n            'levene_statistic': stat,\n            'p_value': p_val,\n            'H10_supported (p < 0.05)': p_val < 0.05,\n            'variance_october': october_scores.var(),\n            'variance_earlier': earlier_scores.var()\n        }\n        return results\n\n    except Exception as e:\n        return {'error': str(e)}\n\ndef analyze_strategic_contradiction(data, **kwargs):\n    \"\"\"\n    Analyzes the Populist Strategic Contradiction Index (PSCI) across the campaign.\n    This function addresses RQ7 and tests hypothesis H7, which posits that the PSCI\n    will be highest in October speeches.\n\n    Methodology:\n    - The function first calculates the mean PSCI for each 'electoral_proximity' group.\n    - It then performs a one-way ANOVA to test for significant differences in PSCI across these groups.\n    - This allows for a robust test of whether strategic contradiction patterns changed as the election neared.\n\n    Args:\n        data (pd.DataFrame): A pandas DataFrame with analysis data.\n        **kwargs: Not used.\n\n    Returns:\n        dict: A dictionary with mean PSCI per group and ANOVA results, or None on error.\n    \"\"\"\n    import pandas as pd\n    from scipy.stats import f_oneway\n\n    try:\n        processed_data = _preprocess_and_add_metrics(data)\n        if processed_data is None or processed_data.empty:\n            return None\n\n        df = processed_data.dropna(subset=['populist_strategic_contradiction_index', 'electoral_proximity'])\n        \n        if df.empty:\n            return {'error': 'No data available for strategic contradiction analysis.'}\n\n        # H7: Descriptive part - mean PSCI per group\n        psci_means = df.groupby('electoral_proximity')['populist_strategic_contradiction_index'].mean().sort_values(ascending=False)\n        \n        # Statistical test: ANOVA on PSCI across electoral proximity groups\n        grouped_data = [\n            group['populist_strategic_contradiction_index'].dropna() \n            for name, group in df.groupby('electoral_proximity')\n            if not group['populist_strategic_contradiction_index'].dropna().empty\n        ]\n\n        anova_result = {}\n        if len(grouped_data) > 1:\n            f_stat, p_val = f_oneway(*grouped_data)\n            anova_result = {'f_statistic': f_stat, 'p_value': p_val}\n        else:\n            anova_result = {'error': 'Not enough groups for ANOVA.'}\n\n        results = {\n            'mean_psci_by_electoral_proximity': psci_means.to_dict(),\n            'anova_on_psci_by_electoral_proximity': anova_result,\n            'H7_summary': {\n                'hypothesis': 'PSCI will be highest in October speeches.',\n                'highest_psci_group': psci_means.index[0] if not psci_means.empty else 'N/A',\n                'is_supported': any(g in psci_means.index[0] for g in ['imminent', 'inter_round', 'final_push']) if not psci_means.empty else False\n            }\n        }\n        return results\n\n    except Exception as e:\n        return {'error': str(e)}\n\ndef run_complete_statistical_analysis(data: pd.DataFrame, alpha: float = 0.05) -> Dict[str, Any]:\n    \"\"\"\n    Run complete statistical analysis suite on the dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        alpha: Significance level for hypothesis tests (default: 0.05)\n        \n    Returns:\n        Dictionary with all statistical analysis results\n    \"\"\"\n    results = {\n        'analysis_metadata': {\n            'timestamp': pd.Timestamp.now().isoformat(),\n            'sample_size': len(data),\n            'alpha_level': alpha,\n            'variables_analyzed': list(data.select_dtypes(include=[np.number]).columns)\n        }\n    }\n    \n    # Get all analysis functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith(('calculate_', 'perform_', 'test_')) and \n            name != 'run_complete_statistical_analysis'):\n            try:\n                # Pass alpha parameter to functions that might need it\n                if 'alpha' in inspect.signature(obj).parameters:\n                    results[name] = obj(data, alpha=alpha)\n                else:\n                    results[name] = obj(data)\n            except Exception as e:\n                results[name] = {'error': f'Analysis failed: {str(e)}'}\n                \n    return results\n\n\ndef perform_statistical_analysis(data: pd.DataFrame) -> Dict[str, Any]:\n    \"\"\"\n    Template-compatible wrapper function for statistical analysis.\n    \n    This function is called by the universal notebook template and performs\n    comprehensive statistical analysis on the provided dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores and derived metrics\n        \n    Returns:\n        Dictionary containing all statistical analysis results\n    \"\"\"\n    return run_complete_statistical_analysis(data)\n\n\ndef generate_statistical_summary_report(analysis_results: Dict[str, Any]) -> str:\n    \"\"\"\n    Generate a human-readable summary report from statistical analysis results.\n    \n    Args:\n        analysis_results: Results from run_complete_statistical_analysis()\n        \n    Returns:\n        String containing formatted statistical report\n    \"\"\"\n    report_lines = []\n    report_lines.append(\"STATISTICAL ANALYSIS SUMMARY REPORT\")\n    report_lines.append(\"=\" * 50)\n    \n    metadata = analysis_results.get('analysis_metadata', {})\n    report_lines.append(f\"Analysis Timestamp: {metadata.get('timestamp', 'Unknown')}\")\n    report_lines.append(f\"Sample Size: {metadata.get('sample_size', 'Unknown')}\")\n    report_lines.append(f\"Alpha Level: {metadata.get('alpha_level', 'Unknown')}\")\n    report_lines.append(f\"Variables: {len(metadata.get('variables_analyzed', []))}\")\n    report_lines.append(\"\")\n    \n    # Summarize key findings\n    for analysis_name, result in analysis_results.items():\n        if analysis_name != 'analysis_metadata' and isinstance(result, dict):\n            if 'error' not in result:\n                report_lines.append(f\"{analysis_name.replace('_', ' ').title()}:\")\n                \n                # Extract key statistics based on analysis type\n                if 'p_value' in result:\n                    p_val = result['p_value']\n                    significance = \"significant\" if p_val < metadata.get('alpha_level', 0.05) else \"not significant\"\n                    report_lines.append(f\"  - p-value: {p_val:.4f} ({significance})\")\n                \n                if 'effect_size' in result:\n                    report_lines.append(f\"  - Effect size: {result['effect_size']:.4f}\")\n                \n                if 'correlation_matrix' in result:\n                    report_lines.append(f\"  - Correlation matrix generated with {len(result['correlation_matrix'])} variables\")\n                \n                if 'cronbach_alpha' in result:\n                    alpha_val = result['cronbach_alpha']\n                    reliability = \"excellent\" if alpha_val > 0.9 else \"good\" if alpha_val > 0.8 else \"acceptable\" if alpha_val > 0.7 else \"questionable\"\n                    report_lines.append(f\"  - Cronbach's \u03b1: {alpha_val:.3f} ({reliability})\")\n                \n                report_lines.append(\"\")\n            else:\n                report_lines.append(f\"{analysis_name}: ERROR - {result['error']}\")\n                report_lines.append(\"\")\n    \n    return \"\\n\".join(report_lines)\n",
  "cached_with_code": true
}