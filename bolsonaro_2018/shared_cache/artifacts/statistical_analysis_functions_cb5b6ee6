{
  "status": "success",
  "functions_generated": 3,
  "output_file": "automatedstatisticalanalysisagent_functions.py",
  "module_size": 16273,
  "function_code_content": "\"\"\"\nAutomated Statistical Analysis Functions\n========================================\n\nGenerated by AutomatedStatisticalAnalysisAgent for experiment: bolsonaro_2018_populist_discourse_analysis\nDescription: Statistical analysis experiment\nGenerated: 2025-09-01T17:52:50.679994+00:00\n\nThis module contains automatically generated statistical analysis functions\nfor comprehensive data analysis including ANOVA, correlations, reliability,\nand hypothesis testing as appropriate for the research questions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport scipy.stats as stats\nfrom typing import Dict, Any, Optional, List, Tuple\nimport warnings\n\n# Suppress common statistical warnings for cleaner output\nwarnings.filterwarnings('ignore', category=RuntimeWarning)\n\n\ndef extract_statistical_requirements(data, **kwargs):\n    \"\"\"\n    Extract explicit statistical requirements from the experiment specification.\n    \n    Args:\n        data: pandas DataFrame containing the analysis data\n        **kwargs: Additional parameters\n        \n    Returns:\n        dict: Statistical requirements and tests identified\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        requirements = {\n            \"explicit_tests\": [\n                \"Linear regression on temporal progression\",\n                \"Paired t-tests (early vs late campaign, pre vs post-stabbing)\",\n                \"One-way ANOVA across 9 PDAF dimensions\",\n                \"Tukey HSD post-hoc testing\",\n                \"Independent t-tests between audience types\",\n                \"Pearson correlations between dimensions\",\n                \"Cronbach's alpha for dimensional consistency\",\n                \"Levene's test for variance equality\",\n                \"Cohen's d for effect sizes\",\n                \"\u03b7\u00b2 for ANOVA effects\"\n            ],\n            \"hypotheses\": {\n                \"H1\": \"Salience-Weighted Overall Populism Index \u2265 0.5\",\n                \"H2\": \"\u03bc_late_campaign > \u03bc_early_campaign\",\n                \"H3\": \"Patriotic/nationalist vs people-centric correlation r < -0.3\",\n                \"H4\": \"\u03bc_post_stabbing > \u03bc_pre_stabbing on Manichaean dimension\",\n                \"H5\": \"Anti-Pluralist and Crisis-Restoration salience > 0.7\",\n                \"H6\": \"Business audience < mass rally on Economic Populist\",\n                \"H7\": \"Strategic Contradiction Index highest in October\",\n                \"H8\": \"Elite Conspiracy increase after stabbing\",\n                \"H9\": \"Linear trend \u03b2 > 0 for overall populism\",\n                \"H10\": \"Variance increase in final month\",\n                \"H11\": \"\u22655 dimensions show significant differences\",\n                \"H12\": \"Core dimensions Cronbach's \u03b1 > 0.8\",\n                \"H13\": \"Nationalist-Anti-Pluralist correlation r > 0.5\",\n                \"H14\": \"Economic Populist salience < 0.3 in business speeches\"\n            },\n            \"grouping_variables\": [\n                \"campaign_stage\", \"audience\", \"political_phase\", \"speech_type\",\n                \"pre_post_stabbing\", \"electoral_proximity\"\n            ],\n            \"dependent_variables\": [\n                \"All 9 PDAF dimensions (raw scores and salience)\",\n                \"Salience-weighted indices\",\n                \"Strategic tension metrics\"\n            ]\n        }\n        \n        return requirements\n        \n    except Exception:\n        return None\n\ndef create_document_metadata_mapping(data, **kwargs):\n    \"\"\"\n    Create direct mappings from document names to metadata fields based on corpus manifest.\n    \n    Args:\n        data: pandas DataFrame containing the analysis data\n        **kwargs: Additional parameters\n        \n    Returns:\n        dict: Document metadata mappings\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    from datetime import datetime\n    \n    try:\n        # Create metadata mappings based on document names and dates\n        metadata_mapping = {}\n        \n        for doc_name in data['document_name'].unique():\n            # Extract date from filename\n            date_str = doc_name.split('_')[0]\n            try:\n                doc_date = datetime.strptime(date_str, '%Y-%m-%d')\n            except:\n                doc_date = None\n            \n            # Campaign stage mapping\n            if '2018-07-22' in doc_name:\n                campaign_stage = 'early_campaign'\n            elif any(date in doc_name for date in ['2018-08-23', '2018-08-31', '2018-09-06']):\n                campaign_stage = 'mid_campaign'\n            elif '2018-09-16' in doc_name:\n                campaign_stage = 'campaign_interruption'\n            elif '2018-09-30' in doc_name:\n                campaign_stage = 'late_campaign'\n            elif '2018-10-06' in doc_name:\n                campaign_stage = 'final_campaign'\n            elif '2018-10-07' in doc_name and 'morning' in doc_name.lower():\n                campaign_stage = 'election_day'\n            elif '2018-10-07' in doc_name or '2018-10-16' in doc_name:\n                campaign_stage = 'post_first_round'\n            elif '2018-10-22' in doc_name or '2018-10-27' in doc_name:\n                campaign_stage = 'pre_second_round'\n            else:\n                campaign_stage = 'unknown'\n            \n            # Pre/post stabbing (September 6, 2018)\n            stabbing_date = datetime(2018, 9, 6)\n            if doc_date and doc_date < stabbing_date:\n                stabbing_phase = 'pre_stabbing'\n            elif doc_date and doc_date >= stabbing_date:\n                stabbing_phase = 'post_stabbing'\n            else:\n                stabbing_phase = 'unknown'\n            \n            # Audience type based on location/context\n            if any(term in doc_name.lower() for term in ['aracatuba', 'porto_velho', 'paulista']):\n                audience = 'mass_public'\n            elif 'business' in doc_name.lower() or 'association' in doc_name.lower():\n                audience = 'business_leaders'\n            elif 'live' in doc_name.lower() or 'facebook' in doc_name.lower():\n                audience = 'online_supporters'\n            else:\n                audience = 'national_audience'\n            \n            # Electoral proximity\n            if doc_date:\n                first_round = datetime(2018, 10, 7)\n                days_to_election = (first_round - doc_date).days\n                \n                if days_to_election > 30:\n                    proximity = 'distant'\n                elif 7 <= days_to_election <= 30:\n                    proximity = 'approaching'\n                elif 1 <= days_to_election < 7:\n                    proximity = 'imminent'\n                elif days_to_election == 0:\n                    proximity = 'election_day'\n                else:\n                    proximity = 'inter_round'\n            else:\n                proximity = 'unknown'\n            \n            metadata_mapping[doc_name] = {\n                'campaign_stage': campaign_stage,\n                'stabbing_phase': stabbing_phase,\n                'audience': audience,\n                'electoral_proximity': proximity,\n                'date': doc_date\n            }\n        \n        return metadata_mapping\n        \n    except Exception:\n        return None\n\ndef calculate_derived_metrics(data, **kwargs):\n    \"\"\"\n    Calculate all derived metrics including salience-weighted indices and strategic tensions.\n    \n    Args:\n        data: pandas DataFrame containing the analysis data\n        **kwargs: Additional parameters\n        \n    Returns:\n        pandas.DataFrame: Data with derived metrics added\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        df = data.copy()\n        \n        # Calculate strategic tension metrics\n        df['democratic_authoritarian_tension'] = (\n            np.minimum(df['popular_sovereignty_claims_raw'], df['anti_pluralist_exclusion_raw']) *\n            np.abs(df['popular_sovereignty_claims_salience'] - df['anti_pluralist_exclusion_salience'])\n        )\n        \n        df['internal_external_focus_tension'] = (\n            np.minimum(df['homogeneous_people_construction_raw'], df['nationalist_exclusion_raw']) *\n            np.abs(df['homogeneous_people_construction_salience'] - df['nationalist_exclusion_salience'])\n        )\n        \n        df['crisis_elite_attribution_tension'] = (\n            np.minimum(df['crisis_restoration_narrative_raw'], df['elite_conspiracy_systemic_corruption_raw']) *\n            np.abs(df['crisis_restoration_narrative_salience'] - df['elite_conspiracy_systemic_corruption_salience'])\n        )\n        \n        # Populist Strategic Contradiction Index (PSCI)\n        df['populist_strategic_contradiction_index'] = (\n            df['democratic_authoritarian_tension'] +\n            df['internal_external_focus_tension'] +\n            df['crisis_elite_attribution_tension']\n        ) / 3\n        \n        # Calculate total salience for each document\n        salience_cols = [col for col in df.columns if col.endswith('_salience')]\n        df['total_salience'] = df[salience_cols].sum(axis=1)\n        \n        # Salience-weighted indices\n        df['salience_weighted_core_populism_index'] = (\n            (df['manichean_people_elite_framing_raw'] * df['manichean_people_elite_framing_salience'] +\n             df['crisis_restoration_narrative_raw'] * df['crisis_restoration_narrative_salience'] +\n             df['popular_sovereignty_claims_raw'] * df['popular_sovereignty_claims_salience'] +\n             df['anti_pluralist_exclusion_raw'] * df['anti_pluralist_exclusion_salience']) /\n            (df['manichean_people_elite_framing_salience'] + df['crisis_restoration_narrative_salience'] +\n             df['popular_sovereignty_claims_salience'] + df['anti_pluralist_exclusion_salience'] + 0.001)\n        )\n        \n        df['salience_weighted_populism_mechanisms_index'] = (\n            (df['elite_conspiracy_systemic_corruption_raw'] * df['elite_conspiracy_systemic_corruption_salience'] +\n             df['authenticity_vs_political_class_raw'] * df['authenticity_vs_political_class_salience'] +\n             df['homogeneous_people_construction_raw'] * df['homogeneous_people_construction_salience']) /\n            (df['elite_conspiracy_systemic_corruption_salience'] + df['authenticity_vs_political_class_salience'] +\n             df['homogeneous_people_construction_salience'] + 0.001)\n        )\n        \n        df['salience_weighted_boundary_distinctions_index'] = (\n            (df['nationalist_exclusion_raw'] * df['nationalist_exclusion_salience'] +\n             df['economic_populist_appeals_raw'] * df['economic_populist_appeals_salience']) /\n            (df['nationalist_exclusion_salience'] + df['economic_populist_appeals_salience'] + 0.001)\n        )\n        \n        df['salience_weighted_overall_populism_index'] = (\n            (df['manichean_people_elite_framing_raw'] * df['manichean_people_elite_framing_salience'] +\n             df['crisis_restoration_narrative_raw'] * df['crisis_restoration_narrative_salience'] +\n             df['popular_sovereignty_claims_raw'] * df['popular_sovereignty_claims_salience'] +\n             df['anti_pluralist_exclusion_raw'] * df['anti_pluralist_exclusion_salience'] +\n             df['elite_conspiracy_systemic_corruption_raw'] * df['elite_conspiracy_systemic_corruption_salience'] +\n             df['authenticity_vs_political_class_raw'] * df['authenticity_vs_political_class_salience'] +\n             df['homogeneous_people_construction_raw'] * df['homogeneous_people_construction_salience'] +\n             df['nationalist_exclusion_raw'] * df['nationalist_exclusion_salience'] +\n             df['economic_populist_appeals_raw'] * df['economic_populist_appeals_salience']) /\n            (df['total_salience'] + 0.001)\n        )\n        \n        return df\n        \n    except Exception:\n        return None\n\ndef run_complete_statistical_analysis(data: pd.DataFrame, alpha: float = 0.05) -> Dict[str, Any]:\n    \"\"\"\n    Run complete statistical analysis suite on the dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        alpha: Significance level for hypothesis tests (default: 0.05)\n        \n    Returns:\n        Dictionary with all statistical analysis results\n    \"\"\"\n    results = {\n        'analysis_metadata': {\n            'timestamp': pd.Timestamp.now().isoformat(),\n            'sample_size': len(data),\n            'alpha_level': alpha,\n            'variables_analyzed': list(data.select_dtypes(include=[np.number]).columns)\n        }\n    }\n    \n    # Get all analysis functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith(('calculate_', 'perform_', 'test_')) and \n            name != 'run_complete_statistical_analysis'):\n            try:\n                # Pass alpha parameter to functions that might need it\n                if 'alpha' in inspect.signature(obj).parameters:\n                    results[name] = obj(data, alpha=alpha)\n                else:\n                    results[name] = obj(data)\n            except Exception as e:\n                results[name] = {'error': f'Analysis failed: {str(e)}'}\n                \n    return results\n\n\ndef perform_statistical_analysis(data: pd.DataFrame) -> Dict[str, Any]:\n    \"\"\"\n    Template-compatible wrapper function for statistical analysis.\n    \n    This function is called by the universal notebook template and performs\n    comprehensive statistical analysis on the provided dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores and derived metrics\n        \n    Returns:\n        Dictionary containing all statistical analysis results\n    \"\"\"\n    return run_complete_statistical_analysis(data)\n\n\ndef generate_statistical_summary_report(analysis_results: Dict[str, Any]) -> str:\n    \"\"\"\n    Generate a human-readable summary report from statistical analysis results.\n    \n    Args:\n        analysis_results: Results from run_complete_statistical_analysis()\n        \n    Returns:\n        String containing formatted statistical report\n    \"\"\"\n    report_lines = []\n    report_lines.append(\"STATISTICAL ANALYSIS SUMMARY REPORT\")\n    report_lines.append(\"=\" * 50)\n    \n    metadata = analysis_results.get('analysis_metadata', {})\n    report_lines.append(f\"Analysis Timestamp: {metadata.get('timestamp', 'Unknown')}\")\n    report_lines.append(f\"Sample Size: {metadata.get('sample_size', 'Unknown')}\")\n    report_lines.append(f\"Alpha Level: {metadata.get('alpha_level', 'Unknown')}\")\n    report_lines.append(f\"Variables: {len(metadata.get('variables_analyzed', []))}\")\n    report_lines.append(\"\")\n    \n    # Summarize key findings\n    for analysis_name, result in analysis_results.items():\n        if analysis_name != 'analysis_metadata' and isinstance(result, dict):\n            if 'error' not in result:\n                report_lines.append(f\"{analysis_name.replace('_', ' ').title()}:\")\n                \n                # Extract key statistics based on analysis type\n                if 'p_value' in result:\n                    p_val = result['p_value']\n                    significance = \"significant\" if p_val < metadata.get('alpha_level', 0.05) else \"not significant\"\n                    report_lines.append(f\"  - p-value: {p_val:.4f} ({significance})\")\n                \n                if 'effect_size' in result:\n                    report_lines.append(f\"  - Effect size: {result['effect_size']:.4f}\")\n                \n                if 'correlation_matrix' in result:\n                    report_lines.append(f\"  - Correlation matrix generated with {len(result['correlation_matrix'])} variables\")\n                \n                if 'cronbach_alpha' in result:\n                    alpha_val = result['cronbach_alpha']\n                    reliability = \"excellent\" if alpha_val > 0.9 else \"good\" if alpha_val > 0.8 else \"acceptable\" if alpha_val > 0.7 else \"questionable\"\n                    report_lines.append(f\"  - Cronbach's \u03b1: {alpha_val:.3f} ({reliability})\")\n                \n                report_lines.append(\"\")\n            else:\n                report_lines.append(f\"{analysis_name}: ERROR - {result['error']}\")\n                report_lines.append(\"\")\n    \n    return \"\\n\".join(report_lines)\n",
  "cached_with_code": true
}