{'generation_metadata': {'status': 'success', 'functions_generated': 11, 'output_file': 'automatedstatisticalanalysisagent_functions.py', 'module_size': 41813, 'function_code_content': '"""\nAutomated Statistical Analysis Functions\n========================================\n\nGenerated by AutomatedStatisticalAnalysisAgent for experiment: bolsonaro_2018_populist_discourse_analysis\nDescription: Statistical analysis experiment\nGenerated: 2025-09-01T03:19:25.788921+00:00\n\nThis module contains automatically generated statistical analysis functions\nfor comprehensive data analysis including ANOVA, correlations, reliability,\nand hypothesis testing as appropriate for the research questions.\n"""\n\nimport pandas as pd\nimport numpy as np\nimport scipy.stats as stats\nfrom typing import Dict, Any, Optional, List, Tuple\nimport warnings\n\n# Suppress common statistical warnings for cleaner output\nwarnings.filterwarnings(\'ignore\', category=RuntimeWarning)\n\n\ndef _create_full_dataset(data):\n    """\n    Internal helper function to preprocess data, add metadata, and calculate derived metrics.\n    This function is not intended for direct use by the user.\n    """\n    import pandas as pd\n    import numpy as np\n\n    if data is None or data.empty:\n        return pd.DataFrame()\n\n    df = data.copy()\n\n    # --- Metadata Mapping ---\n    # As per the experiment spec, we create a direct mapping from document names to metadata.\n    # The date is extracted from the \'document_name\' for mapping.\n    \n    # Define the metadata for each known speech based on the experiment specification\n    metadata_map = {\n        \'2018-07-22\': {\'campaign_stage\': \'early_campaign\', \'audience\': \'mass_public\'},\n        \'2018-08-23\': {\'campaign_stage\': \'mid_campaign\', \'audience\': \'mass_public\'},\n        \'2018-08-28\': {\'campaign_stage\': \'mid_campaign\', \'audience\': \'business_leaders\'}, # Assumed date for the single business speech\n        \'2018-08-31\': {\'campaign_stage\': \'mid_campaign\', \'audience\': \'mass_public\'},\n        \'2018-09-06\': {\'campaign_stage\': \'mid_campaign\', \'audience\': \'online_supporters\'},\n        \'2018-09-16\': {\'campaign_stage\': \'campaign_interruption\', \'audience\': \'online_supporters\'},\n        \'2018-09-30\': {\'campaign_stage\': \'late_campaign\', \'audience\': \'mass_public\'},\n        \'2018-10-06\': {\'campaign_stage\': \'final_campaign\', \'audience\': \'online_supporters\'},\n        \'2018-10-07\': {\'campaign_stage\': \'election_day\', \'audience\': \'national_audience\'}, # Assuming one of the Oct 7 speeches is this\n        \'2018-10-16\': {\'campaign_stage\': \'post_first_round\', \'audience\': \'national_audience\'},\n        \'2018-10-22\': {\'campaign_stage\': \'pre_second_round\', \'audience\': \'national_audience\'},\n        \'2018-10-27\': {\'campaign_stage\': \'pre_second_round\', \'audience\': \'mass_public\'},\n        # Add a placeholder for the second Oct 7 speech if its filename is distinct\n        # For now, we assume filenames are unique enough to be handled by the date prefix.\n        # Let\'s assume one document is named \'2018-10-07_Evening...\'\n        \'2018-10-07_Evening\': {\'campaign_stage\': \'post_first_round\', \'audience\': \'national_audience\'},\n    }\n\n    def get_metadata(doc_name):\n        # Handle cases like \'2018-10-07_Evening...\'\n        if \'2018-10-07\' in doc_name and \'evening\' in doc_name.lower():\n             key = \'2018-10-07_Evening\'\n        else:\n            key = str(doc_name)[:10]\n        \n        meta = metadata_map.get(key, {})\n        \n        # Add date and derived metadata\n        try:\n            date = pd.to_datetime(key.split(\'_\')[0])\n            meta[\'date\'] = date\n            \n            # Pre/Post Stabbing\n            stabbing_date = pd.to_datetime(\'2018-09-06\')\n            meta[\'pre_post_stabbing\'] = \'post_stabbing\' if date > stabbing_date else \'pre_stabbing\'\n            \n            # Electoral Proximity\n            first_round_date = pd.to_datetime(\'2018-10-07\')\n            if date <= pd.to_datetime(\'2018-08-31\'):\n                meta[\'electoral_proximity\'] = \'distant\'\n            elif date <= pd.to_datetime(\'2018-09-30\'):\n                meta[\'electoral_proximity\'] = \'approaching\'\n            elif date < first_round_date:\n                meta[\'electoral_proximity\'] = \'imminent\'\n            elif date <= pd.to_datetime(\'2018-10-21\'):\n                 meta[\'electoral_proximity\'] = \'inter_round\'\n            else:\n                 meta[\'electoral_proximity\'] = \'final_push\'\n\n        except (ValueError, IndexError):\n            meta[\'date\'] = None\n            meta[\'pre_post_stabbing\'] = None\n            meta[\'electoral_proximity\'] = None\n            \n        return pd.Series(meta)\n\n    # Apply metadata mapping\n    # Handle potential duplicate document names by resetting index\n    df_meta = df[\'document_name\'].apply(get_metadata)\n    df = pd.concat([df.reset_index(drop=True), df_meta.reset_index(drop=True)], axis=1)\n\n    # --- Derived Metrics Calculation ---\n    # Translate framework formulas to pandas operations\n    \n    # Define dimension columns for easier access\n    dims = {\n        "manichaean": "manichaean_people_elite_framing",\n        "crisis": "crisis_restoration_narrative",\n        "sovereignty": "popular_sovereignty_claims",\n        "anti_pluralist": "anti_pluralist_exclusion",\n        "conspiracy": "elite_conspiracy_systemic_corruption",\n        "authenticity": "authenticity_vs_political_class",\n        "homogeneous": "homogenous_people_construction",\n        "nationalist": "nationalist_exclusion",\n        "economic": "economic_populist_appeals"\n    }\n    \n    raw_cols = {k: f"{v}_raw" for k, v in dims.items()}\n    sal_cols = {k: f"{v}_salience" for k, v in dims.items()}\n\n    # Tension Indices\n    df[\'democratic_authoritarian_tension\'] = np.minimum(df[raw_cols[\'sovereignty\']], df[raw_cols[\'anti_pluralist\']]) * np.abs(df[sal_cols[\'sovereignty\']] - df[sal_cols[\'anti_pluralist\']])\n    df[\'internal_external_focus_tension\'] = np.minimum(df[raw_cols[\'homogeneous\']], df[raw_cols[\'nationalist\']]) * np.abs(df[sal_cols[\'homogeneous\']] - df[sal_cols[\'nationalist\']])\n    df[\'crisis_elite_attribution_tension\'] = np.minimum(df[raw_cols[\'crisis\']], df[raw_cols[\'conspiracy\']]) * np.abs(df[sal_cols[\'crisis\']] - df[sal_cols[\'conspiracy\']])\n\n    # Populist Strategic Contradiction Index (PSCI)\n    df[\'populist_strategic_contradiction_index\'] = (df[\'democratic_authoritarian_tension\'] + df[\'internal_external_focus_tension\'] + df[\'crisis_elite_attribution_tension\']) / 3\n\n    # Salience-Weighted Indices\n    core_dims = [\'manichaean\', \'crisis\', \'sovereignty\', \'anti_pluralist\']\n    mech_dims = [\'conspiracy\', \'authenticity\', \'homogeneous\']\n    bound_dims = [\'nationalist\', \'economic\']\n    all_dims = list(dims.keys())\n\n    def calc_sw_index(dim_keys):\n        num = sum(df[raw_cols[k]] * df[sal_cols[k]] for k in dim_keys)\n        den = sum(df[sal_cols[k]] for k in dim_keys) + 0.001\n        return num / den\n\n    df[\'salience_weighted_core_populism_index\'] = calc_sw_index(core_dims)\n    df[\'salience_weighted_populism_mechanisms_index\'] = calc_sw_index(mech_dims)\n    df[\'salience_weighted_boundary_distinctions_index\'] = calc_sw_index(bound_dims)\n    df[\'salience_weighted_overall_populism_index\'] = calc_sw_index(all_dims)\n    \n    return df\n\ndef calculate_descriptive_statistics(data, **kwargs):\n    """\n    Calculates descriptive statistics for all raw scores, salience scores, and derived indices.\n    This addresses RQ1, H1, H5, and H14 by providing mean, std, min, and max for key variables.\n\n    Methodology:\n    - The function first enriches the raw data with metadata and derived metrics.\n    - It then calculates standard descriptive statistics (mean, standard deviation, min, max, quartiles)\n      for all numerical columns, focusing on the 9 raw scores, 9 salience scores, and all derived indices.\n    - Results are presented in a structured dictionary for clarity.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the raw analysis data.\n        **kwargs: Not used.\n\n    Returns:\n        dict: A dictionary containing descriptive statistics for scores and indices, or None on error.\n    """\n    import pandas as pd\n    import numpy as np\n\n    try:\n        if data is None or data.empty:\n            return {"error": "Input data is empty or None."}\n\n        df = _create_full_dataset(data)\n        if df.empty:\n            return {"error": "Failed to process data and add metadata."}\n\n        # Identify columns for analysis\n        raw_score_cols = [col for col in df.columns if col.endswith(\'_raw\')]\n        salience_cols = [col for col in df.columns if col.endswith(\'_salience\')]\n        derived_cols = [\n            \'democratic_authoritarian_tension\', \'internal_external_focus_tension\',\n            \'crisis_elite_attribution_tension\', \'populist_strategic_contradiction_index\',\n            \'salience_weighted_core_populism_index\', \'salience_weighted_populism_mechanisms_index\',\n            \'salience_weighted_boundary_distinctions_index\', \'salience_weighted_overall_populism_index\'\n        ]\n        \n        all_numeric_cols = raw_score_cols + salience_cols + derived_cols\n        \n        # Filter out columns that might not exist if data is incomplete\n        existing_cols = [col for col in all_numeric_cols if col in df.columns]\n        \n        if not existing_cols:\n            return {"error": "No numeric score columns found in the data."}\n\n        # Calculate descriptives\n        descriptives = df[existing_cols].describe().to_dict()\n\n        # Hypothesis H1 Check\n        h1_mean = descriptives.get(\'salience_weighted_overall_populism_index\', {}).get(\'mean\', np.nan)\n        h1_result = {\n            "hypothesis": "H1: Bolsonaro\'s Salience-Weighted Overall Populism Index will average >= 0.5",\n            "mean_score": h1_mean,\n            "is_confirmed": bool(h1_mean >= 0.5) if not np.isnan(h1_mean) else "Cannot determine"\n        }\n\n        # Hypothesis H5 Check\n        h5_salience_ap = descriptives.get(\'anti_pluralist_exclusion_salience\', {}).get(\'mean\', np.nan)\n        h5_salience_cr = descriptives.get(\'crisis_restoration_narrative_salience\', {}).get(\'mean\', np.nan)\n        h5_result = {\n            "hypothesis": "H5: Anti-Pluralist Exclusion and Crisis-Restoration dimensions will show highest salience scores (> 0.7)",\n            "mean_salience_anti_pluralist": h5_salience_ap,\n            "mean_salience_crisis_restoration": h5_salience_cr,\n            "is_confirmed": bool(h5_salience_ap > 0.7 and h5_salience_cr > 0.7) if not (np.isnan(h5_salience_ap) or np.isnan(h5_salience_cr)) else "Cannot determine"\n        }\n\n        return {\n            "descriptive_statistics": descriptives,\n            "hypothesis_checks": {\n                "H1": h1_result,\n                "H5": h5_result\n            }\n        }\n\n    except Exception as e:\n        return {"error": f"An unexpected error occurred: {str(e)}"}\n\ndef calculate_derived_metrics(data, **kwargs):\n    """\n    Calculates all derived metrics as defined in the PDAF v10.0.2 framework.\n    This function serves to expose the calculated indices for further analysis.\n\n    Methodology:\n    - The function uses an internal helper to process the raw data.\n    - It calculates three tension indices, the Populist Strategic Contradiction Index (PSCI),\n      and four salience-weighted populism indices based on the formulas in the framework specification.\n    - The output is the DataFrame with these new columns added.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the raw analysis data.\n        **kwargs: Not used.\n\n    Returns:\n        pd.DataFrame: The input DataFrame with derived metric columns appended, or None on error.\n    """\n    import pandas as pd\n    \n    try:\n        if data is None or data.empty:\n            return None\n            \n        df = _create_full_dataset(data)\n        \n        derived_cols = [\n            \'document_name\', \'date\', \'campaign_stage\',\n            \'democratic_authoritarian_tension\', \'internal_external_focus_tension\',\n            \'crisis_elite_attribution_tension\', \'populist_strategic_contradiction_index\',\n            \'salience_weighted_core_populism_index\', \'salience_weighted_populism_mechanisms_index\',\n            \'salience_weighted_boundary_distinctions_index\', \'salience_weighted_overall_populism_index\'\n        ]\n        \n        # Ensure all expected columns exist, fill with None if not\n        for col in derived_cols:\n            if col not in df.columns:\n                df[col] = None\n                \n        return df[derived_cols].to_dict(orient=\'records\')\n\n    except Exception:\n        return None\n\ndef analyze_temporal_trends(data, **kwargs):\n    """\n    Analyzes the temporal evolution of populist discourse using linear regression.\n    This function addresses RQ2 and tests hypotheses H2 and H9.\n\n    Methodology:\n    - The function enriches the data with metadata, including a numeric \'day_of_campaign\' variable.\n    - It performs a linear regression of the \'salience_weighted_overall_populism_index\' against the campaign day.\n    - It reports the slope (beta), p-value, and R-squared of the regression to test H9.\n    - It also performs a t-test between \'early_campaign\' and \'late_campaign\' stages to test H2.\n    - Effect size (Cohen\'s d) is calculated for the t-test.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the raw analysis data.\n        **kwargs: Not used.\n\n    Returns:\n        dict: A dictionary with regression results and t-test results, or None on error.\n    """\n    import pandas as pd\n    import numpy as np\n    import statsmodels.api as sm\n    from scipy.stats import ttest_ind\n\n    try:\n        if data is None or data.empty:\n            return {"error": "Input data is empty or None."}\n\n        df = _create_full_dataset(data)\n        if df.empty or \'date\' not in df.columns or df[\'date\'].isnull().all():\n            return {"error": "Failed to process data or extract dates."}\n\n        df = df.dropna(subset=[\'date\', \'salience_weighted_overall_populism_index\'])\n        df = df.sort_values(\'date\')\n        \n        # --- H9: Linear Trend Analysis ---\n        df[\'day_of_campaign\'] = (df[\'date\'] - df[\'date\'].min()).dt.days\n        \n        X = df[\'day_of_campaign\']\n        y = df[\'salience_weighted_overall_populism_index\']\n        \n        if len(X) < 2:\n            return {"error": "Insufficient data for trend analysis."}\n            \n        X = sm.add_constant(X)\n        model = sm.OLS(y, X).fit()\n        \n        slope = model.params.get(\'day_of_campaign\', np.nan)\n        p_value = model.pvalues.get(\'day_of_campaign\', np.nan)\n        \n        h9_result = {\n            "hypothesis": "H9: Linear trend analysis will show significant positive slope for overall populism",\n            "slope_beta": slope,\n            "p_value": p_value,\n            "r_squared": model.rsquared,\n            "is_confirmed": bool(slope > 0 and p_value < 0.05) if not np.isnan(slope) else "Cannot determine"\n        }\n\n        # --- H2: Early vs. Late Campaign Comparison ---\n        early_scores = df[df[\'campaign_stage\'] == \'early_campaign\'][\'salience_weighted_overall_populism_index\']\n        # Combine all later stages for a robust comparison\n        late_scores = df[df[\'campaign_stage\'].isin([\'late_campaign\', \'final_campaign\', \'post_first_round\', \'pre_second_round\'])][\'salience_weighted_overall_populism_index\']\n\n        h2_result = {"hypothesis": "H2: μ_late_campaign > μ_early_campaign on Salience-Weighted Overall Populism Index"}\n        if len(early_scores) > 0 and len(late_scores) > 0:\n            t_stat, p_val_ttest = ttest_ind(late_scores, early_scores, equal_var=False, nan_policy=\'omit\')\n            \n            # Cohen\'s d for effect size\n            mean_diff = late_scores.mean() - early_scores.mean()\n            pooled_std = np.sqrt(((len(late_scores)-1)*late_scores.std()**2 + (len(early_scores)-1)*early_scores.std()**2) / (len(late_scores) + len(early_scores) - 2))\n            cohens_d = mean_diff / pooled_std if pooled_std > 0 else 0\n\n            h2_result.update({\n                "mean_early_campaign": early_scores.mean(),\n                "mean_late_campaign": late_scores.mean(),\n                "t_statistic": t_stat,\n                "p_value": p_val_ttest,\n                "cohens_d": cohens_d,\n                "is_confirmed": bool(mean_diff > 0 and p_val_ttest < 0.05)\n            })\n        else:\n            h2_result.update({"error": "Insufficient data for early vs. late campaign comparison."})\n\n        return {\n            "linear_trend_analysis_H9": h9_result,\n            "early_vs_late_campaign_H2": h2_result\n        }\n\n    except Exception as e:\n        return {"error": f"An unexpected error occurred: {str(e)}"}\n\ndef analyze_dimensional_correlations(data, **kwargs):\n    """\n    Calculates Pearson correlations between key PDAF dimensions.\n    This function addresses RQ3 and tests hypotheses H3 and H13.\n\n    Methodology:\n    - The function enriches the data with metadata and derived metrics.\n    - It computes a full Pearson correlation matrix for all 9 raw score dimensions.\n    - It specifically extracts and reports the correlation for H3 (Nationalist Exclusion vs. Core Populist dimensions)\n      and H13 (Nationalist Exclusion vs. Anti-Pluralist Exclusion).\n    - P-values are calculated for each correlation.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the raw analysis data.\n        **kwargs: Not used.\n\n    Returns:\n        dict: A dictionary with the correlation matrix and specific hypothesis test results, or None on error.\n    """\n    import pandas as pd\n    import numpy as np\n    from scipy.stats import pearsonr\n\n    try:\n        if data is None or data.empty:\n            return {"error": "Input data is empty or None."}\n\n        df = _create_full_dataset(data)\n        if df.empty:\n            return {"error": "Failed to process data."}\n\n        raw_score_cols = [col for col in df.columns if col.endswith(\'_raw\')]\n        if len(raw_score_cols) < 9:\n            return {"error": "Missing one or more raw score columns."}\n\n        corr_matrix = df[raw_score_cols].corr(method=\'pearson\')\n\n        # --- H13: Nationalist Exclusion vs. Anti-Pluralist Exclusion ---\n        corr_h13, p_val_h13 = pearsonr(df[\'nationalist_exclusion_raw\'], df[\'anti_pluralist_exclusion_raw\'])\n        h13_result = {\n            "hypothesis": "H13: Nationalist Exclusion will correlate positively with Anti-Pluralist Exclusion (r > 0.5)",\n            "correlation_coefficient": corr_h13,\n            "p_value": p_val_h13,\n            "is_confirmed": bool(corr_h13 > 0.5 and p_val_h13 < 0.05)\n        }\n\n        # --- H3: Patriotic/nationalist vs. people-centric populist dimensions ---\n        # \'People-centric\' = Core dimensions: Manichaean, Crisis-Restoration, Popular Sovereignty, Anti-Pluralist\n        core_populist_cols = [\n            \'manichaean_people_elite_framing_raw\', \'crisis_restoration_narrative_raw\',\n            \'popular_sovereignty_claims_raw\', \'anti_pluralist_exclusion_raw\'\n        ]\n        # Create an average score for people-centric dimensions\n        df[\'people_centric_avg\'] = df[core_populist_cols].mean(axis=1)\n        corr_h3, p_val_h3 = pearsonr(df[\'nationalist_exclusion_raw\'], df[\'people_centric_avg\'])\n        h3_result = {\n            "hypothesis": "H3: Patriotic/nationalist framing will show negative correlation with people-centric populist dimensions (r < -0.3)",\n            "correlation_coefficient": corr_h3,\n            "p_value": p_val_h3,\n            "is_confirmed": bool(corr_h3 < -0.3 and p_val_h3 < 0.05)\n        }\n\n        return {\n            "correlation_matrix": corr_matrix.to_dict(),\n            "hypothesis_checks": {\n                "H3": h3_result,\n                "H13": h13_result\n            }\n        }\n\n    except Exception as e:\n        return {"error": f"An unexpected error occurred: {str(e)}"}\n\ndef analyze_crisis_impact(data, **kwargs):\n    """\n    Analyzes the impact of the September 6 stabbing incident on populist discourse.\n    This function addresses RQ6 and tests hypotheses H4 and H8 using t-tests.\n\n    Methodology:\n    - The data is grouped into \'pre_stabbing\' and \'post_stabbing\' based on the speech date.\n    - Independent two-sample t-tests are performed to compare the means of the two groups for:\n      - H4: \'manichaean_people_elite_framing_raw\'\n      - H8: \'elite_conspiracy_systemic_corruption_raw\'\n    - For each test, the function reports means, t-statistic, p-value, and Cohen\'s d for effect size.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the raw analysis data.\n        **kwargs: Not used.\n\n    Returns:\n        dict: A dictionary with t-test results for each hypothesis, or None on error.\n    """\n    import pandas as pd\n    import numpy as np\n    from scipy.stats import ttest_ind\n\n    def cohens_d(group1, group2):\n        mean_diff = group1.mean() - group2.mean()\n        n1, n2 = len(group1), len(group2)\n        if n1 < 2 or n2 < 2: return 0\n        pooled_std = np.sqrt(((n1 - 1) * group1.std()**2 + (n2 - 1) * group2.std()**2) / (n1 + n2 - 2))\n        return mean_diff / pooled_std if pooled_std > 0 else 0\n\n    try:\n        if data is None or data.empty:\n            return {"error": "Input data is empty or None."}\n\n        df = _create_full_dataset(data)\n        if df.empty or \'pre_post_stabbing\' not in df.columns:\n            return {"error": "Failed to process data or create \'pre_post_stabbing\' group."}\n\n        pre_df = df[df[\'pre_post_stabbing\'] == \'pre_stabbing\']\n        post_df = df[df[\'pre_post_stabbing\'] == \'post_stabbing\']\n\n        if pre_df.empty or post_df.empty:\n            return {"error": "Data is missing for either pre or post stabbing groups."}\n\n        results = {}\n\n        # --- H4: Manichaean People-Elite Framing ---\n        dim_h4 = \'manichaean_people_elite_framing_raw\'\n        pre_scores_h4 = pre_df[dim_h4].dropna()\n        post_scores_h4 = post_df[dim_h4].dropna()\n        \n        t_stat_h4, p_val_h4 = ttest_ind(post_scores_h4, pre_scores_h4, equal_var=False)\n        effect_size_h4 = cohens_d(post_scores_h4, pre_scores_h4)\n        \n        results[\'H4_manichaean_framing\'] = {\n            "hypothesis": "H4: μ_post_stabbing > μ_pre_stabbing on Manichaean People-Elite Framing",\n            "mean_pre_stabbing": pre_scores_h4.mean(),\n            "mean_post_stabbing": post_scores_h4.mean(),\n            "t_statistic": t_stat_h4,\n            "p_value": p_val_h4,\n            "cohens_d": effect_size_h4,\n            "is_confirmed": bool(post_scores_h4.mean() > pre_scores_h4.mean() and p_val_h4 < 0.05)\n        }\n\n        # --- H8: Elite Conspiracy ---\n        dim_h8 = \'elite_conspiracy_systemic_corruption_raw\'\n        pre_scores_h8 = pre_df[dim_h8].dropna()\n        post_scores_h8 = post_df[dim_h8].dropna()\n\n        t_stat_h8, p_val_h8 = ttest_ind(post_scores_h8, pre_scores_h8, equal_var=False)\n        effect_size_h8 = cohens_d(post_scores_h8, pre_scores_h8)\n\n        results[\'H8_elite_conspiracy\'] = {\n            "hypothesis": "H8: Elite Conspiracy dimension will show significant increase after stabbing incident",\n            "mean_pre_stabbing": pre_scores_h8.mean(),\n            "mean_post_stabbing": post_scores_h8.mean(),\n            "t_statistic": t_stat_h8,\n            "p_value": p_val_h8,\n            "cohens_d": effect_size_h8,\n            "is_confirmed": bool(post_scores_h8.mean() > pre_scores_h8.mean() and p_val_h8 < 0.05)\n        }\n\n        return results\n\n    except Exception as e:\n        return {"error": f"An unexpected error occurred: {str(e)}"}\n\ndef analyze_audience_adaptation(data, **kwargs):\n    """\n    Analyzes how populist rhetoric is adapted for different audiences.\n    This function addresses RQ8 and tests hypothesis H6.\n\n    Methodology:\n    - The data is grouped by the \'audience\' metadata field.\n    - An independent two-sample t-test is performed to test H6, comparing \'economic_populist_appeals_raw\'\n      scores for \'business_leaders\' vs. \'mass_public\' audiences.\n    - The function reports means, t-statistic, p-value, and Cohen\'s d for effect size.\n    - It also provides descriptive statistics for all audience types for broader context.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the raw analysis data.\n        **kwargs: Not used.\n\n    Returns:\n        dict: A dictionary with t-test results and descriptive stats, or None on error.\n    """\n    import pandas as pd\n    import numpy as np\n    from scipy.stats import ttest_ind\n\n    def cohens_d(group1, group2):\n        mean_diff = group1.mean() - group2.mean()\n        n1, n2 = len(group1), len(group2)\n        if n1 < 2 or n2 < 2: return 0\n        pooled_std = np.sqrt(((n1 - 1) * group1.std()**2 + (n2 - 1) * group2.std()**2) / (n1 + n2 - 2))\n        return mean_diff / pooled_std if pooled_std > 0 else 0\n\n    try:\n        if data is None or data.empty:\n            return {"error": "Input data is empty or None."}\n\n        df = _create_full_dataset(data)\n        if df.empty or \'audience\' not in df.columns:\n            return {"error": "Failed to process data or create \'audience\' groups."}\n\n        # --- H6: Business vs. Mass Rally Audiences ---\n        dim_h6 = \'economic_populist_appeals_raw\'\n        business_scores = df[df[\'audience\'] == \'business_leaders\'][dim_h6].dropna()\n        mass_scores = df[df[\'audience\'] == \'mass_public\'][dim_h6].dropna()\n\n        h6_result = {"hypothesis": "H6: Business audience speeches will score lower on Economic Populist Appeals than mass rally speeches"}\n        if business_scores.empty or mass_scores.empty:\n            h6_result["error"] = "Insufficient data for one or both audience groups (\'business_leaders\', \'mass_public\')."\n        else:\n            t_stat, p_val = ttest_ind(business_scores, mass_scores, equal_var=False)\n            effect_size = cohens_d(business_scores, mass_scores)\n            \n            h6_result.update({\n                "mean_business_audience": business_scores.mean(),\n                "mean_mass_rally_audience": mass_scores.mean(),\n                "t_statistic": t_stat,\n                "p_value": p_val,\n                "cohens_d": effect_size,\n                "is_confirmed": bool(business_scores.mean() < mass_scores.mean() and p_val < 0.05)\n            })\n        \n        # --- H14: Economic Populist Appeals salience in business speeches ---\n        dim_h14_salience = \'economic_populist_appeals_salience\'\n        business_salience = df[df[\'audience\'] == \'business_leaders\'][dim_h14_salience].dropna()\n        h14_result = {"hypothesis": "H14: Economic Populist Appeals will show lowest salience in business/policy speeches (< 0.3)"}\n        if business_salience.empty:\n            h14_result["error"] = "No data for \'business_leaders\' audience."\n        else:\n            mean_salience = business_salience.mean()\n            h14_result.update({\n                "mean_salience_business_audience": mean_salience,\n                "is_confirmed": bool(mean_salience < 0.3)\n            })\n\n        # General descriptives for all audience types\n        audience_descriptives = df.groupby(\'audience\')[dim_h6].describe().to_dict()\n\n        return {\n            "hypothesis_H6_test": h6_result,\n            "hypothesis_H14_check": h14_result,\n            "descriptives_by_audience": audience_descriptives\n        }\n\n    except Exception as e:\n        return {"error": f"An unexpected error occurred: {str(e)}"}\n\ndef analyze_campaign_stage_differences(data, **kwargs):\n    """\n    Analyzes differences in populist dimensions across campaign stages using ANOVA.\n    This function addresses hypothesis H11.\n\n    Methodology:\n    - The data is grouped by the \'campaign_stage\' metadata field.\n    - A one-way ANOVA is performed for each of the 9 raw score dimensions to test for significant\n      differences between the campaign stages.\n    - For dimensions with a significant ANOVA result (p < 0.05), a post-hoc Tukey HSD test is\n      conducted to identify which specific stage pairs are different.\n    - The function reports the F-statistic, p-value, and eta-squared for each ANOVA, and the\n      results of the Tukey HSD tests.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the raw analysis data.\n        **kwargs: Not used.\n\n    Returns:\n        dict: A dictionary with ANOVA and Tukey HSD results for each dimension, or None on error.\n    """\n    import pandas as pd\n    import numpy as np\n    from scipy.stats import f_oneway\n    from statsmodels.stats.multicomp import pairwise_tukeyhsd\n\n    try:\n        if data is None or data.empty:\n            return {"error": "Input data is empty or None."}\n\n        df = _create_full_dataset(data)\n        if df.empty or \'campaign_stage\' not in df.columns:\n            return {"error": "Failed to process data or create \'campaign_stage\' groups."}\n\n        raw_score_cols = [col for col in df.columns if col.endswith(\'_raw\')]\n        results = {}\n        significant_dims_count = 0\n\n        for dim in raw_score_cols:\n            groups = [df[dim][df[\'campaign_stage\'] == stage].dropna() for stage in df[\'campaign_stage\'].unique()]\n            groups = [g for g in groups if len(g) > 0] # Filter out empty groups\n\n            if len(groups) < 2:\n                results[dim] = {"error": "Less than two campaign stages with data for this dimension."}\n                continue\n\n            f_stat, p_val = f_oneway(*groups)\n            \n            # Calculate Eta-squared for effect size\n            ss_between = sum(len(g) * (g.mean() - df[dim].mean())**2 for g in groups)\n            ss_total = sum((df[dim] - df[dim].mean())**2)\n            eta_squared = ss_between / ss_total if ss_total > 0 else 0\n\n            dim_results = {\n                "f_statistic": f_stat,\n                "p_value": p_val,\n                "eta_squared": eta_squared,\n                "is_significant": bool(p_val < 0.05)\n            }\n            \n            if p_val < 0.05:\n                significant_dims_count += 1\n                # Perform Tukey HSD post-hoc test\n                tukey_data = df.dropna(subset=[dim, \'campaign_stage\'])\n                if len(tukey_data[\'campaign_stage\'].unique()) > 1:\n                    tukey_result = pairwise_tukeyhsd(endog=tukey_data[dim], groups=tukey_data[\'campaign_stage\'], alpha=0.05)\n                    dim_results["tukey_hsd"] = str(tukey_result)\n                else:\n                    dim_results["tukey_hsd"] = "Not enough groups for Tukey HSD test."\n\n            results[dim] = dim_results\n        \n        h11_result = {\n            "hypothesis": "H11: At least 5 of 9 PDAF dimensions will show significant differences between campaign_stage groups (ANOVA)",\n            "significant_dimensions_count": significant_dims_count,\n            "is_confirmed": bool(significant_dims_count >= 5)\n        }\n\n        return {\n            "anova_results": results,\n            "hypothesis_H11_check": h11_result\n        }\n\n    except Exception as e:\n        return {"error": f"An unexpected error occurred: {str(e)}"}\n\ndef analyze_strategic_tensions_over_time(data, **kwargs):\n    """\n    Analyzes the evolution of the Populist Strategic Contradiction Index (PSCI) over time.\n    This function addresses RQ7 and tests hypothesis H7.\n\n    Methodology:\n    - The function calculates the PSCI for each speech.\n    - It then calculates the mean PSCI for each month of the campaign (July, Aug, Sep, Oct).\n    - It identifies the month with the highest mean PSCI to test H7.\n    - Results are presented as a summary of mean tension per month.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the raw analysis data.\n        **kwargs: Not used.\n\n    Returns:\n        dict: A dictionary with mean PSCI per month and the H7 test result, or None on error.\n    """\n    import pandas as pd\n    import numpy as np\n\n    try:\n        if data is None or data.empty:\n            return {"error": "Input data is empty or None."}\n\n        df = _create_full_dataset(data)\n        if df.empty or \'date\' not in df.columns or \'populist_strategic_contradiction_index\' not in df.columns:\n            return {"error": "Failed to process data or calculate PSCI."}\n\n        df = df.dropna(subset=[\'date\', \'populist_strategic_contradiction_index\'])\n        df[\'month\'] = df[\'date\'].dt.month_name()\n        \n        monthly_tension = df.groupby(\'month\')[\'populist_strategic_contradiction_index\'].mean().sort_index()\n        \n        if monthly_tension.empty:\n            return {"error": "No data available to analyze monthly tension."}\n\n        max_tension_month = monthly_tension.idxmax()\n\n        h7_result = {\n            "hypothesis": "H7: Populist Strategic Contradiction Index will be highest in October speeches",\n            "max_tension_month": max_tension_month,\n            "is_confirmed": bool(max_tension_month == \'October\')\n        }\n\n        return {\n            "mean_psci_by_month": monthly_tension.to_dict(),\n            "hypothesis_H7_check": h7_result\n        }\n\n    except Exception as e:\n        return {"error": f"An unexpected error occurred: {str(e)}"}\n\ndef test_variance_homogeneity(data, **kwargs):\n    """\n    Tests for homogeneity of variance in populism scores across campaign months.\n    This function addresses hypothesis H10 using Levene\'s test.\n\n    Methodology:\n    - The data is grouped by month.\n    - Levene\'s test is performed on the \'salience_weighted_overall_populism_index\' to compare\n      the variance between the final campaign month (October) and earlier months combined.\n    - The function reports the test statistic and p-value. A significant p-value (< 0.05) indicates\n      unequal variances, supporting the hypothesis.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the raw analysis data.\n        **kwargs: Not used.\n\n    Returns:\n        dict: A dictionary with the Levene\'s test result, or None on error.\n    """\n    import pandas as pd\n    from scipy.stats import levene\n\n    try:\n        if data is None or data.empty:\n            return {"error": "Input data is empty or None."}\n\n        df = _create_full_dataset(data)\n        if df.empty or \'date\' not in df.columns or \'salience_weighted_overall_populism_index\' not in df.columns:\n            return {"error": "Failed to process data or calculate populism index."}\n\n        df = df.dropna(subset=[\'date\', \'salience_weighted_overall_populism_index\'])\n        df[\'month\'] = df[\'date\'].dt.month\n        \n        october_scores = df[df[\'month\'] == 10][\'salience_weighted_overall_populism_index\']\n        earlier_scores = df[df[\'month\'] < 10][\'salience_weighted_overall_populism_index\']\n\n        if len(october_scores) < 2 or len(earlier_scores) < 2:\n            return {"error": "Insufficient data for variance comparison (need at least two data points in each group)."}\n\n        stat, p_val = levene(october_scores, earlier_scores)\n        \n        var_oct = october_scores.var()\n        var_earlier = earlier_scores.var()\n\n        h10_result = {\n            "hypothesis": "H10: Variance in populist scores will increase in final campaign month",\n            "variance_october": var_oct,\n            "variance_earlier_months": var_earlier,\n            "levene_statistic": stat,\n            "p_value": p_val,\n            "is_confirmed": bool(var_oct > var_earlier and p_val < 0.05)\n        }\n\n        return h10_result\n\n    except Exception as e:\n        return {"error": f"An unexpected error occurred: {str(e)}"}\n\ndef test_dimensional_consistency(data, **kwargs):\n    """\n    Tests the internal consistency of the core populist dimensions using Cronbach\'s alpha.\n    This function addresses hypothesis H12.\n\n    Methodology:\n    - The function selects the four core populist dimensions as defined in the framework:\n      Manichaean People-Elite Framing, Crisis-Restoration Narrative, Popular Sovereignty Claims,\n      and Anti-Pluralist Exclusion.\n    - It calculates Cronbach\'s alpha for the raw scores of these four dimensions.\n    - The result is compared against the threshold of 0.8 to test H12.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the raw analysis data.\n        **kwargs: Not used.\n\n    Returns:\n        dict: A dictionary with the Cronbach\'s alpha result, or None on error.\n    """\n    import pandas as pd\n    import pingouin as pg\n\n    try:\n        if data is None or data.empty:\n            return {"error": "Input data is empty or None."}\n\n        df = _create_full_dataset(data)\n        if df.empty:\n            return {"error": "Failed to process data."}\n\n        core_populist_cols = [\n            \'manichaean_people_elite_framing_raw\',\n            \'crisis_restoration_narrative_raw\',\n            \'popular_sovereignty_claims_raw\',\n            \'anti_pluralist_exclusion_raw\'\n        ]\n        \n        # Check if all columns exist\n        if not all(col in df.columns for col in core_populist_cols):\n            return {"error": "One or more core populist dimension columns are missing."}\n            \n        core_df = df[core_populist_cols].dropna()\n        \n        if len(core_df) < 2:\n            return {"error": "Insufficient data to calculate Cronbach\'s alpha."}\n\n        alpha_results = pg.cronbach_alpha(data=core_df)\n        alpha_score = alpha_results[0]\n\n        h12_result = {\n            "hypothesis": "H12: Core populist dimensions will show higher internal consistency (Cronbach\'s α > 0.8)",\n            "cronbach_alpha": alpha_score,\n            "dimensions_tested": core_populist_cols,\n            "is_confirmed": bool(alpha_score > 0.8)\n        }\n\n        return h12_result\n\n    except Exception as e:\n        return {"error": f"An unexpected error occurred: {str(e)}"}\n\ndef run_complete_statistical_analysis(data: pd.DataFrame, alpha: float = 0.05) -> Dict[str, Any]:\n    """\n    Run complete statistical analysis suite on the dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        alpha: Significance level for hypothesis tests (default: 0.05)\n        \n    Returns:\n        Dictionary with all statistical analysis results\n    """\n    results = {\n        \'analysis_metadata\': {\n            \'timestamp\': pd.Timestamp.now().isoformat(),\n            \'sample_size\': len(data),\n            \'alpha_level\': alpha,\n            \'variables_analyzed\': list(data.select_dtypes(include=[np.number]).columns)\n        }\n    }\n    \n    # Get all analysis functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith((\'calculate_\', \'perform_\', \'test_\')) and \n            name != \'run_complete_statistical_analysis\'):\n            try:\n                # Pass alpha parameter to functions that might need it\n                if \'alpha\' in inspect.signature(obj).parameters:\n                    results[name] = obj(data, alpha=alpha)\n                else:\n                    results[name] = obj(data)\n            except Exception as e:\n                results[name] = {\'error\': f\'Analysis failed: {str(e)}\'}\n                \n    return results\n\n\ndef perform_statistical_analysis(data: pd.DataFrame) -> Dict[str, Any]:\n    """\n    Template-compatible wrapper function for statistical analysis.\n    \n    This function is called by the universal notebook template and performs\n    comprehensive statistical analysis on the provided dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores and derived metrics\n        \n    Returns:\n        Dictionary containing all statistical analysis results\n    """\n    return run_complete_statistical_analysis(data)\n\n\ndef generate_statistical_summary_report(analysis_results: Dict[str, Any]) -> str:\n    """\n    Generate a human-readable summary report from statistical analysis results.\n    \n    Args:\n        analysis_results: Results from run_complete_statistical_analysis()\n        \n    Returns:\n        String containing formatted statistical report\n    """\n    report_lines = []\n    report_lines.append("STATISTICAL ANALYSIS SUMMARY REPORT")\n    report_lines.append("=" * 50)\n    \n    metadata = analysis_results.get(\'analysis_metadata\', {})\n    report_lines.append(f"Analysis Timestamp: {metadata.get(\'timestamp\', \'Unknown\')}")\n    report_lines.append(f"Sample Size: {metadata.get(\'sample_size\', \'Unknown\')}")\n    report_lines.append(f"Alpha Level: {metadata.get(\'alpha_level\', \'Unknown\')}")\n    report_lines.append(f"Variables: {len(metadata.get(\'variables_analyzed\', []))}")\n    report_lines.append("")\n    \n    # Summarize key findings\n    for analysis_name, result in analysis_results.items():\n        if analysis_name != \'analysis_metadata\' and isinstance(result, dict):\n            if \'error\' not in result:\n                report_lines.append(f"{analysis_name.replace(\'_\', \' \').title()}:")\n                \n                # Extract key statistics based on analysis type\n                if \'p_value\' in result:\n                    p_val = result[\'p_value\']\n                    significance = "significant" if p_val < metadata.get(\'alpha_level\', 0.05) else "not significant"\n                    report_lines.append(f"  - p-value: {p_val:.4f} ({significance})")\n                \n                if \'effect_size\' in result:\n                    report_lines.append(f"  - Effect size: {result[\'effect_size\']:.4f}")\n                \n                if \'correlation_matrix\' in result:\n                    report_lines.append(f"  - Correlation matrix generated with {len(result[\'correlation_matrix\'])} variables")\n                \n                if \'cronbach_alpha\' in result:\n                    alpha_val = result[\'cronbach_alpha\']\n                    reliability = "excellent" if alpha_val > 0.9 else "good" if alpha_val > 0.8 else "acceptable" if alpha_val > 0.7 else "questionable"\n                    report_lines.append(f"  - Cronbach\'s α: {alpha_val:.3f} ({reliability})")\n                \n                report_lines.append("")\n            else:\n                report_lines.append(f"{analysis_name}: ERROR - {result[\'error\']}")\n                report_lines.append("")\n    \n    return "\\n".join(report_lines)\n', 'cached_with_code': True}, 'statistical_data': {'analyze_audience_adaptation': {'error': "An unexpected error occurred: 'homogenous_people_construction_raw'"}, 'analyze_campaign_stage_differences': {'error': "An unexpected error occurred: 'homogenous_people_construction_raw'"}, 'analyze_crisis_impact': {'error': "An unexpected error occurred: 'homogenous_people_construction_raw'"}, 'analyze_dimensional_correlations': {'error': "An unexpected error occurred: 'homogenous_people_construction_raw'"}, 'analyze_strategic_tensions_over_time': {'error': "An unexpected error occurred: 'homogenous_people_construction_raw'"}, 'analyze_temporal_trends': {'error': "An unexpected error occurred: 'homogenous_people_construction_raw'"}, 'calculate_derived_metrics': None, 'calculate_descriptive_statistics': {'error': "An unexpected error occurred: 'homogenous_people_construction_raw'"}, 'generate_statistical_summary_report': 'STATISTICAL ANALYSIS SUMMARY REPORT\n==================================================\nAnalysis Timestamp: Unknown\nSample Size: Unknown\nAlpha Level: Unknown\nVariables: 0\n', 'perform_statistical_analysis': {'analysis_metadata': {'timestamp': '2025-08-31T23:40:30.008136', 'sample_size': 13, 'alpha_level': 0.05, 'variables_analyzed': ['manichaean_people_elite_framing_raw', 'manichaean_people_elite_framing_salience', 'manichaean_people_elite_framing_confidence', 'crisis_restoration_temporal_narrative_raw', 'crisis_restoration_temporal_narrative_salience', 'crisis_restoration_temporal_narrative_confidence', 'popular_sovereignty_claims_raw', 'popular_sovereignty_claims_salience', 'popular_sovereignty_claims_confidence', 'anti_pluralist_exclusion_raw', 'anti_pluralist_exclusion_salience', 'anti_pluralist_exclusion_confidence', 'elite_conspiracy_systemic_corruption_raw', 'elite_conspiracy_systemic_corruption_salience', 'elite_conspiracy_systemic_corruption_confidence', 'authenticity_vs_political_class_raw', 'authenticity_vs_political_class_salience', 'authenticity_vs_political_class_confidence', 'homogeneous_people_construction_raw', 'homogeneous_people_construction_salience', 'homogeneous_people_construction_confidence', 'nationalist_exclusion_raw', 'nationalist_exclusion_salience', 'nationalist_exclusion_confidence', 'economic_populist_appeals_raw', 'economic_populist_appeals_salience', 'economic_populist_appeals_confidence', 'crisis_restoration_narrative_raw', 'crisis_restoration_narrative_salience', 'crisis_restoration_narrative_confidence', 'manichean_people_elite_framing_raw', 'manichean_people_elite_framing_salience', 'manichean_people_elite_framing_confidence']}}, 'run_complete_statistical_analysis': {'analysis_metadata': {'timestamp': '2025-08-31T23:40:30.016468', 'sample_size': 13, 'alpha_level': 0.05, 'variables_analyzed': ['manichaean_people_elite_framing_raw', 'manichaean_people_elite_framing_salience', 'manichaean_people_elite_framing_confidence', 'crisis_restoration_temporal_narrative_raw', 'crisis_restoration_temporal_narrative_salience', 'crisis_restoration_temporal_narrative_confidence', 'popular_sovereignty_claims_raw', 'popular_sovereignty_claims_salience', 'popular_sovereignty_claims_confidence', 'anti_pluralist_exclusion_raw', 'anti_pluralist_exclusion_salience', 'anti_pluralist_exclusion_confidence', 'elite_conspiracy_systemic_corruption_raw', 'elite_conspiracy_systemic_corruption_salience', 'elite_conspiracy_systemic_corruption_confidence', 'authenticity_vs_political_class_raw', 'authenticity_vs_political_class_salience', 'authenticity_vs_political_class_confidence', 'homogeneous_people_construction_raw', 'homogeneous_people_construction_salience', 'homogeneous_people_construction_confidence', 'nationalist_exclusion_raw', 'nationalist_exclusion_salience', 'nationalist_exclusion_confidence', 'economic_populist_appeals_raw', 'economic_populist_appeals_salience', 'economic_populist_appeals_confidence', 'crisis_restoration_narrative_raw', 'crisis_restoration_narrative_salience', 'crisis_restoration_narrative_confidence', 'manichean_people_elite_framing_raw', 'manichean_people_elite_framing_salience', 'manichean_people_elite_framing_confidence']}}, 'test_dimensional_consistency': {'error': "An unexpected error occurred: 'homogenous_people_construction_raw'"}, 'test_variance_homogeneity': {'error': "An unexpected error occurred: 'homogenous_people_construction_raw'"}}, 'status': 'success_with_data', 'validation_passed': True}