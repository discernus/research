{
  "batch_id": "v2_statistical_20250920_095126",
  "step": "statistical_execution",
  "model_used": "vertex_ai/gemini-2.5-pro",
  "statistical_functions_and_results": "```json\n{\n  \"statistical_functions\": \"import pandas as pd\\nimport numpy as np\\nimport scipy.stats as stats\\nimport pingouin as pg\\nfrom typing import Dict, Any, Optional, List, Tuple\\nimport json\\nimport io\\n\\ndef _get_dataframe(data: List[Dict[str, Any]], corpus_manifest: Dict[str, Any]) -> Optional[pd.DataFrame]:\\n    \\\"\\\"\\\"\\n    Parses analysis artifacts and corpus manifest to create a unified pandas DataFrame.\\n\\n    Args:\\n        data (List[Dict[str, Any]]): A list of analysis artifact dictionaries.\\n        corpus_manifest (Dict[str, Any]): The corpus manifest dictionary.\\n\\n    Returns:\\n        Optional[pd.DataFrame]: A DataFrame containing combined scores and metadata,\\n                                 or None if data cannot be processed.\\n    \\\"\\\"\\\"\\n    try:\\n        scores_artifact = next((a for a in data if a['step'] == 'score_extraction'), None)\\n        derived_artifact = next((a for a in data if a['step'] == 'derived_metrics_generation'), None)\\n\\n        if not scores_artifact or not derived_artifact:\\n            return None\\n\\n        # Safely load JSON from string\\n        scores_data = json.loads(scores_artifact['scores_extraction'].strip('```json\\\\n'))\\n        derived_data = json.loads(derived_artifact['derived_metrics'].strip('```json\\\\n').split('\\\\n```')[0])\\n\\n        # Create document to speaker mapping from the composite analysis artifact\\n        # This is more robust than relying on filename matching if IDs change.\\n        composite_artifact = next((a for a in data if a['step'] == 'enhanced_composite_analysis_generation'), None)\\n        doc_map = {}\\n        if composite_artifact:\\n            analysis_data = json.loads(composite_artifact['raw_analysis_response'].strip('```json\\\\n'))\\n            for doc_analysis in analysis_data.get('document_analyses', []):\\n                doc_id_num = doc_analysis.get('document_id') # e.g., 'document_0'\\n                doc_name_full = doc_analysis.get('document_name') # e.g., 'The Ballot or the Bullet by Malcolm X'\\n                if 'Malcolm X' in doc_name_full:\\n                    doc_map[doc_id_num] = 'Malcolm X'\\n                elif 'Martin Luther King' in doc_name_full:\\n                    doc_map[doc_id_num] = 'Martin Luther King Jr.'\\n\\n        records = []\\n        for doc_id, scores in scores_data.items():\\n            record = {'document_id': doc_id, 'speaker': doc_map.get(doc_id, 'Unknown')}\\n            # Flatten dimensional scores\\n            for dim, values in scores.items():\\n                record[f\\\"{dim}_raw_score\\\"] = values.get('raw_score')\\n                record[f\\\"{dim}_salience\\\"] = values.get('salience')\\n                record[f\\\"{dim}_confidence\\\"] = values.get('confidence')\\n            \\n            # Add derived metrics\\n            if doc_id in derived_data:\\n                for metric, value in derived_data[doc_id].items():\\n                    record[metric] = value\\n            records.append(record)\\n\\n        df = pd.DataFrame(records)\\n        return df\\n\\n    except (json.JSONDecodeError, KeyError, IndexError, StopIteration) as e:\\n        # logging.error(f\\\"Error processing data artifacts: {e}\\\")\\n        return None\\n\\n\\ndef calculate_descriptive_statistics(df: pd.DataFrame) -> Optional[Dict[str, Any]]:\\n    \\\"\\\"\\\"\\n    Calculates descriptive statistics for all numeric columns in the DataFrame.\\n    This provides a Tier 3 overview of the data distribution.\\n\\n    Args:\\n        df (pd.DataFrame): The input DataFrame with analysis data.\\n\\n    Returns:\\n        Optional[Dict[str, Any]]: A dictionary of descriptive statistics, or None if input is invalid.\\n    \\\"\\\"\\\"\\n    if df is None or df.empty:\\n        return {\\\"error\\\": \\\"Input DataFrame is empty or invalid.\\\"}\\n    \\n    try:\\n        numeric_df = df.select_dtypes(include=np.number)\\n        if numeric_df.empty:\\n            return {\\\"error\\\": \\\"No numeric data available for statistics.\\\"}\\n        \\n        # Transposing for a more readable JSON output\\n        desc_stats = numeric_df.describe().transpose().to_dict('index')\\n        return {\\\"summary_statistics\\\": desc_stats}\\n    except Exception as e:\\n        return {\\\"error\\\": f\\\"An unexpected error occurred: {str(e)}\\\"}\\n\\n\\ndef compare_speakers_descriptively(df: pd.DataFrame) -> Optional[Dict[str, Any]]:\\n    \\\"\\\"\\\"\\n    Provides a descriptive comparison of scores between the two speakers.\\n    Given the N=2 sample size (n=1 per group), this Tier 3 analysis replaces a t-test.\\n    It focuses on the raw difference as the primary measure of effect.\\n\\n    Args:\\n        df (pd.DataFrame): The input DataFrame with speaker and score data.\\n\\n    Returns:\\n        Optional[Dict[str, Any]]: A dictionary comparing scores for each metric,\\n                                 or an error message if the comparison is not possible.\\n    \\\"\\\"\\\"\\n    if df is None or df.empty or 'speaker' not in df.columns:\\n        return {\\\"error\\\": \\\"Input DataFrame is invalid or missing 'speaker' column.\\\"}\\n\\n    speakers = df['speaker'].unique()\\n    if len(speakers) != 2:\\n        return {\\n            \\\"status\\\": \\\"Analysis Not Performed\\\",\\n            \\\"reason\\\": f\\\"Expected 2 unique speakers for comparison, but found {len(speakers)}. This is a descriptive comparison, not an inferential test.\\\"\\n        }\\n    \\n    try:\\n        speaker1, speaker2 = speakers[0], speakers[1]\\n        df_pivoted = df.set_index('speaker').select_dtypes(include=np.number)\\n        \\n        if speaker1 not in df_pivoted.index or speaker2 not in df_pivoted.index:\\n            return {\\\"error\\\": \\\"One or both speakers not found in the data index.\\\"}\\n            \\n        comparison_results = {}\\n        for col in df_pivoted.columns:\\n            val1 = df_pivoted.loc[speaker1, col]\\n            val2 = df_pivoted.loc[speaker2, col]\\n            difference = val1 - val2\\n            comparison_results[col] = {\\n                speaker1: val1,\\n                speaker2: val2,\\n                \\\"difference\\\": difference\\n            }\\n            \\n        return {\\n            \\\"analysis_type\\\": \\\"Descriptive Speaker Comparison (Tier 3)\\\",\\n            \\\"note\\\": \\\"Differences are calculated as (Malcolm X - Martin Luther King Jr.). Positive values mean Malcolm X scored higher.\\\",\\n            \\\"comparison\\\": comparison_results\\n        }\\n    except Exception as e:\\n        return {\\\"error\\\": f\\\"An unexpected error occurred during comparison: {str(e)}\\\"}\\n\\n\\ndef perform_correlation_analysis(df: pd.DataFrame) -> Dict[str, Any]:\\n    \\\"\\\"\\\"\\n    Placeholder for correlation analysis. With N<15, this is a Tier 3 exploratory analysis.\\n    Meaningful correlation calculation is not possible with N=2, so this function returns an \\n    informational message.\\n\\n    Args:\\n        df (pd.DataFrame): The input DataFrame.\\n\\n    Returns:\\n        Dict[str, Any]: A dictionary indicating the analysis was not performed.\\n    \\\"\\\"\\\"\\n    if df is None or len(df) < 15:\\n        return {\\n            \\\"status\\\": \\\"Analysis Not Performed\\\",\\n            \\\"reason\\\": f\\\"Insufficient sample size (N={len(df) if df is not None else 0}) for meaningful correlation analysis. Minimum N for exploratory analysis is typically > 5, and for robust analysis N > 15.\\\"\\n        }\\n    # This part would run with more data\\n    try:\\n        numeric_cols = df.select_dtypes(include=np.number)\\n        corr_matrix = numeric_cols.corr()\\n        return {\\\"status\\\": \\\"Success\\\", \\\"correlation_matrix\\\": corr_matrix.to_dict('index')}\\n    except Exception as e:\\n        return {\\\"error\\\": f\\\"An unexpected error occurred: {str(e)}\\\"}\\n\\n\\ndef calculate_internal_consistency(df: pd.DataFrame) -> Dict[str, Any]:\\n    \\\"\\\"\\\"\\n    Placeholder for internal consistency (Cronbach's alpha) analysis.\\n    With N<15, this is a Tier 3 exploratory analysis. Meaningful calculation is not possible with N=2, \\n    so this function returns an informational message.\\n\\n    Args:\\n        df (pd.DataFrame): The input DataFrame.\\n\\n    Returns:\\n        Dict[str, Any]: A dictionary indicating the analysis was not performed.\\n    \\\"\\\"\\\"\\n    if df is None or len(df) < 15:\\n        return {\\n            \\\"status\\\": \\\"Analysis Not Performed\\\",\\n            \\\"reason\\\": f\\\"Insufficient sample size (N={len(df) if df is not None else 0}) for meaningful internal consistency analysis. A minimum of N=15 is recommended.\\\"\\n        }\\n\\n    # This part would run with more data\\n    try:\\n        # Example: calculating alpha for the 'fragmentative' dimensions\\n        fragmentative_dims = [\\n            'tribal_dominance_raw_score', 'fear_raw_score', 'envy_raw_score', \\n            'enmity_raw_score', 'fragmentative_goals_raw_score'\\n        ]\\n        cohesive_dims = [\\n            'individual_dignity_raw_score', 'hope_raw_score', 'compersion_raw_score', \\n            'amity_raw_score', 'cohesive_goals_raw_score'\\n        ]\\n        \\n        alpha_fragmentative = pg.cronbach_alpha(data=df[fragmentative_dims])\\n        alpha_cohesive = pg.cronbach_alpha(data=df[cohesive_dims])\\n        \\n        return {\\n            \\\"status\\\": \\\"Success\\\",\\n            \\\"cohesive_scale_cronbach_alpha\\\": alpha_cohesive[0],\\n            \\\"fragmentative_scale_cronbach_alpha\\\": alpha_fragmentative[0]\\n        }\\n    except Exception as e:\\n        return {\\\"error\\\": f\\\"An unexpected error occurred: {str(e)}\\\"}\\n\\n\\ndef perform_statistical_analysis(data: List[Dict[str, Any]], corpus_manifest: Dict[str, Any]) -> Dict[str, Any]:\\n    \\\"\\\"\\\"\\n    Master function that executes all statistical analyses based on the provided data.\\n    \\n    Args:\\n        data: A list of analysis artifact dictionaries.\\n        corpus_manifest: The corpus manifest dictionary.\\n        \\n    Returns:\\n        dict: Combined results from all statistical analyses.\\n    \\\"\\\"\\\"\\n    df = _get_dataframe(data, corpus_manifest)\\n    \\n    if df is None:\\n        return {\\\"error\\\": \\\"Failed to create DataFrame from artifacts.\\\"}\\n\\n    # Reorder speakers to ensure consistent difference calculation\\n    if 'speaker' in df.columns and set(df['speaker'].unique()) == {'Martin Luther King Jr.', 'Malcolm X'}:\\n        df['speaker'] = pd.Categorical(df['speaker'], categories=['Malcolm X', 'Martin Luther King Jr.'], ordered=True)\\n        df = df.sort_values('speaker').reset_index(drop=True)\\n\\n    results = {}\\n    results['descriptive_statistics'] = calculate_descriptive_statistics(df)\\n    # Renaming for clarity as it's a descriptive comparison, not an inferential test\\n    results['group_comparison'] = compare_speakers_descriptively(df)\\n    results['correlation_analysis'] = perform_correlation_analysis(df)\\n    results['reliability_analysis'] = calculate_internal_consistency(df)\\n    \\n    return results\\n\",\n  \"execution_results\": {\n    \"descriptive_statistics\": {\n      \"summary_statistics\": {\n        \"tribal_dominance_raw_score\": {\n          \"count\": 2.0,\n          \"mean\": 0.55,\n          \"std\": 0.4949747468305833,\n          \"min\": 0.2,\n          \"25%\": 0.375,\n          \"50%\": 0.55,\n          \"75%\": 0.725,\n          \"max\": 0.9\n        },\n        \"tribal_dominance_salience\": {\n          \"count\": 2.0,\n          \"mean\": 0.5,\n          \"std\": 0.565685424949238,\n          \"min\": 0.1,\n          \"25%\": 0.3,\n          \"50%\": 0.5,\n          \"75%\": 0.7,\n          \"max\": 0.9\n        },\n        \"tribal_dominance_confidence\": {\n          \"count\": 2.0,\n          \"mean\": 0.95,\n          \"std\": 0.0,\n          \"min\": 0.95,\n          \"25%\": 0.95,\n          \"50%\": 0.95,\n          \"75%\": 0.95,\n          \"max\": 0.95\n        },\n        \"individual_dignity_raw_score\": {\n          \"count\": 2.0,\n          \"mean\": 0.75,\n          \"std\": 0.21213203435596427,\n          \"min\": 0.6,\n          \"25%\": 0.675,\n          \"50%\": 0.75,\n          \"75%\": 0.825,\n          \"max\": 0.9\n        },\n        \"individual_dignity_salience\": {\n          \"count\": 2.0,\n          \"mean\": 0.7,\n          \"std\": 0.28284271247461906,\n          \"min\": 0.5,\n          \"25%\": 0.6,\n          \"50%\": 0.7,\n          \"75%\": 0.8,\n          \"max\": 0.9\n        },\n        \"individual_dignity_confidence\": {\n          \"count\": 2.0,\n          \"mean\": 0.925,\n          \"std\": 0.03535533905932737,\n          \"min\": 0.9,\n          \"25%\": 0.9125,\n          \"50%\": 0.925,\n          \"75%\": 0.9375,\n          \"max\": 0.95\n        },\n        \"fear_raw_score\": {\n          \"count\": 2.0,\n          \"mean\": 0.7,\n          \"std\": 0.1414213562373095,\n          \"min\": 0.6,\n          \"25%\": 0.65,\n          \"50%\": 0.7,\n          \"75%\": 0.75,\n          \"max\": 0.8\n        },\n        \"fear_salience\": {\n          \"count\": 2.0,\n          \"mean\": 0.65,\n          \"std\": 0.21213203435596427,\n          \"min\": 0.5,\n          \"25%\": 0.575,\n          \"50%\": 0.65,\n          \"75%\": 0.725,\n          \"max\": 0.8\n        },\n        \"fear_confidence\": {\n          \"count\": 2.0,\n          \"mean\": 0.925,\n          \"std\": 0.03535533905932737,\n          \"min\": 0.9,\n          \"25%\": 0.9125,\n          \"50%\": 0.925,\n          \"75%\": 0.9375,\n          \"max\": 0.95\n        },\n        \"hope_raw_score\": {\n          \"count\": 2.0,\n          \"mean\": 0.85,\n          \"std\": 0.07071067811865477,\n          \"min\": 0.8,\n          \"25%\": 0.825,\n          \"50%\": 0.85,\n          \"75%\": 0.875,\n          \"max\": 0.9\n        },\n        \"hope_salience\": {\n          \"count\": 2.0,\n          \"mean\": 0.85,\n          \"std\": 0.07071067811865477,\n          \"min\": 0.8,\n          \"25%\": 0.825,\n          \"50%\": 0.85,\n          \"75%\": 0.875,\n          \"max\": 0.9\n        },\n        \"hope_confidence\": {\n          \"count\": 2.0,\n          \"mean\": 0.95,\n          \"std\": 0.0,\n          \"min\": 0.95,\n          \"25%\": 0.95,\n          \"50%\": 0.95,\n          \"75%\": 0.95,\n          \"max\": 0.95\n        },\n        \"envy_raw_score\": {\n          \"count\": 2.0,\n          \"mean\": 0.25,\n          \"std\": 0.21213203435596427,\n          \"min\": 0.1,\n          \"25%\": 0.175,\n          \"50%\": 0.25,\n          \"75%\": 0.325,\n          \"max\": 0.4\n        },\n        \"envy_salience\": {\n          \"count\": 2.0,\n          \"mean\": 0.2,\n          \"std\": 0.1414213562373095,\n          \"min\": 0.1,\n          \"25%\": 0.15,\n          \"50%\": 0.2,\n          \"75%\": 0.25,\n          \"max\": 0.3\n        },\n        \"envy_confidence\": {\n          \"count\": 2.0,\n          \"mean\": 0.875,\n          \"std\": 0.03535533905932737,\n          \"min\": 0.85,\n          \"25%\": 0.8625,\n          \"50%\": 0.875,\n          \"75%\": 0.8875,\n          \"max\": 0.9\n        },\n        \"compersion_raw_score\": {\n          \"count\": 2.0,\n          \"mean\": 0.2,\n          \"std\": 0.28284271247461906,\n          \"min\": 0.0,\n          \"25%\": 0.1,\n          \"50%\": 0.2,\n          \"75%\": 0.3,\n          \"max\": 0.4\n        },\n        \"compersion_salience\": {\n          \"count\": 2.0,\n          \"mean\": 0.1,\n          \"std\": 0.1414213562373095,\n          \"min\": 0.0,\n          \"25%\": 0.05,\n          \"50%\": 0.1,\n          \"75%\": 0.15,\n          \"max\": 0.2\n        },\n        \"compersion_confidence\": {\n          \"count\": 2.0,\n          \"mean\": 0.9,\n          \"std\": 0.07071067811865477,\n          \"min\": 0.85,\n          \"25%\": 0.875,\n          \"50%\": 0.9,\n          \"75%\": 0.925,\n          \"max\": 0.95\n        },\n        \"enmity_raw_score\": {\n          \"count\": 2.0,\n          \"mean\": 0.8,\n          \"std\": 0.1414213562373095,\n          \"min\": 0.7,\n          \"25%\": 0.75,\n          \"50%\": 0.8,\n          \"75%\": 0.85,\n          \"max\": 0.9\n        },\n        \"enmity_salience\": {\n          \"count\": 2.0,\n          \"mean\": 0.8,\n          \"std\": 0.1414213562373095,\n          \"min\": 0.7,\n          \"25%\": 0.75,\n          \"50%\": 0.8,\n          \"75%\": 0.85,\n          \"max\": 0.9\n        },\n        \"enmity_confidence\": {\n          \"count\": 2.0,\n          \"mean\": 0.95,\n          \"std\": 0.0,\n          \"min\": 0.95,\n          \"25%\": 0.95,\n          \"50%\": 0.95,\n          \"75%\": 0.95,\n          \"max\": 0.95\n        },\n        \"amity_raw_score\": {\n          \"count\": 2.0,\n          \"mean\": 0.8,\n          \"std\": 0.1414213562373095,\n          \"min\": 0.7,\n          \"25%\": 0.75,\n          \"50%\": 0.8,\n          \"75%\": 0.85,\n          \"max\": 0.9\n        },\n        \"amity_salience\": {\n          \"count\": 2.0,\n          \"mean\": 0.75,\n          \"std\": 0.21213203435596427,\n          \"min\": 0.6,\n          \"25%\": 0.675,\n          \"50%\": 0.75,\n          \"75%\": 0.825,\n          \"max\": 0.9\n        },\n        \"amity_confidence\": {\n          \"count\": 2.0,\n          \"mean\": 0.925,\n          \"std\": 0.03535533905932737,\n          \"min\": 0.9,\n          \"25%\": 0.9125,\n          \"50%\": 0.925,\n          \"75%\": 0.9375,\n          \"max\": 0.95\n        },\n        \"fragmentative_goals_raw_score\": {\n          \"count\": 2.0,\n          \"mean\": 0.7,\n          \"std\": 0.1414213562373095,\n          \"min\": 0.6,\n          \"25%\": 0.65,\n          \"50%\": 0.7,\n          \"75%\": 0.75,\n          \"max\": 0.8\n        },\n        \"fragmentative_goals_salience\": {\n          \"count\": 2.0,\n          \"mean\": 0.65,\n          \"std\": 0.21213203435596427,\n          \"min\": 0.5,\n          \"25%\": 0.575,\n          \"50%\": 0.65,\n          \"75%\": 0.725,\n          \"max\": 0.8\n        },\n        \"fragmentative_goals_confidence\": {\n          \"count\": 2.0,\n          \"mean\": 0.925,\n          \"std\": 0.03535533905932737,\n          \"min\": 0.9,\n          \"25%\": 0.9125,\n          \"50%\": 0.925,\n          \"75%\": 0.9375,\n          \"max\": 0.95\n        },\n        \"cohesive_goals_raw_score\": {\n          \"count\": 2.0,\n          \"mean\": 0.9,\n          \"std\": 0.0,\n          \"min\": 0.9,\n          \"25%\": 0.9,\n          \"50%\": 0.9,\n          \"75%\": 0.9,\n          \"max\": 0.9\n        },\n        \"cohesive_goals_salience\": {\n          \"count\": 2.0,\n          \"mean\": 0.9,\n          \"std\": 0.0,\n          \"min\": 0.9,\n          \"25%\": 0.9,\n          \"50%\": 0.9,\n          \"75%\": 0.9,\n          \"max\": 0.9\n        },\n        \"cohesive_goals_confidence\": {\n          \"count\": 2.0,\n          \"mean\": 0.95,\n          \"std\": 0.0,\n          \"min\": 0.95,\n          \"25%\": 0.95,\n          \"50%\": 0.95,\n          \"75%\": 0.95,\n          \"max\": 0.95\n        },\n        \"identity_tension\": {\n          \"count\": 2.0,\n          \"mean\": 0.12,\n          \"std\": 0.1697056274847714,\n          \"min\": 0.0,\n          \"25%\": 0.06,\n          \"50%\": 0.12,\n          \"75%\": 0.18,\n          \"max\": 0.24\n        },\n        \"emotional_tension\": {\n          \"count\": 2.0,\n          \"mean\": 0.12,\n          \"std\": 0.1697056274847714,\n          \"min\": 0.0,\n          \"25%\": 0.06,\n          \"50%\": 0.12,\n          \"75%\": 0.18,\n          \"max\": 0.24\n        },\n        \"success_tension\": {\n          \"count\": 2.0,\n          \"mean\": 0.01,\n          \"std\": 0.01414213562373095,\n          \"min\": 0.0,\n          \"25%\": 0.005,\n          \"50%\": 0.01,\n          \"75%\": 0.015,\n          \"max\": 0.02\n        },\n        \"relational_tension\": {\n          \"count\": 2.0,\n          \"mean\": 0.105,\n          \"std\": 0.14849242404917498,\n          \"min\": 0.0,\n          \"25%\": 0.0525,\n          \"50%\": 0.105,\n          \"75%\": 0.1575,\n          \"max\": 0.21\n        },\n        \"goal_tension\": {\n          \"count\": 2.0,\n          \"mean\": 0.04,\n          \"std\": 0.0565685424949238,\n          \"min\": 0.0,\n          \"25%\": 0.02,\n          \"50%\": 0.04,\n          \"75%\": 0.06,\n          \"max\": 0.08\n        },\n        \"strategic_contradiction_index\": {\n          \"count\": 2.0,\n          \"mean\": 0.079,\n          \"std\": 0.11172287132938392,\n          \"min\": 0.0,\n          \"25%\": 0.0395,\n          \"50%\": 0.079,\n          \"75%\": 0.1185,\n          \"max\": 0.158\n        },\n        \"descriptive_cohesion_index\": {\n          \"count\": 2.0,\n          \"mean\": -0.21204040404040404,\n          \"std\": 0.5898864703565922,\n          \"min\": -0.6259770114942528,\n          \"25%\": -0.4190087077673284,\n          \"50%\": -0.21204040404040404,\n          \"75%\": -0.00507210031347966,\n          \"max\": 0.20189620066042038\n        },\n        \"motivational_cohesion_index\": {\n          \"count\": 2.0,\n          \"mean\": -0.06385226463321566,\n          \"std\": 0.5519808381534346,\n          \"min\": -0.4542372881355932,\n          \"25%\": -0.2590447763844044,\n          \"50%\": -0.06385226463321566,\n          \"75%\": 0.13133994711897305,\n          \"max\": 0.3265321588711618\n        },\n        \"full_cohesion_index\": {\n          \"count\": 2.0,\n          \"mean\": 0.06456722026852336,\n          \"std\": 0.536340621417539,\n          \"min\": -0.31464761477815555,\n          \"25%\": -0.1250401972548161,\n          \"50%\": 0.06456722026852336,\n          \"75%\": 0.25417463779186284,\n          \"max\": 0.4437820553152023\n        }\n      }\n    },\n    \"group_comparison\": {\n      \"analysis_type\": \"Descriptive Speaker Comparison (Tier 3)\",\n      \"note\": \"Differences are calculated as (Malcolm X - Martin Luther King Jr.). Positive values mean Malcolm X scored higher.\",\n      \"comparison\": {\n        \"tribal_dominance_raw_score\": {\n          \"Malcolm X\": 0.9,\n          \"Martin Luther King Jr.\": 0.2,\n          \"difference\": 0.7\n        },\n        \"tribal_dominance_salience\": {\n          \"Malcolm X\": 0.9,\n          \"Martin Luther King Jr.\": 0.1,\n          \"difference\": 0.8\n        },\n        \"tribal_dominance_confidence\": {\n          \"Malcolm X\": 0.95,\n          \"Martin Luther King Jr.\": 0.95,\n          \"difference\": 0.0\n        },\n        \"individual_dignity_raw_score\": {\n          \"Malcolm X\": 0.6,\n          \"Martin Luther King Jr.\": 0.9,\n          \"difference\": -0.3\n        },\n        \"individual_dignity_salience\": {\n          \"Malcolm X\": 0.5,\n          \"Martin Luther King Jr.\": 0.9,\n          \"difference\": -0.4\n        },\n        \"individual_dignity_confidence\": {\n          \"Malcolm X\": 0.9,\n          \"Martin Luther King Jr.\": 0.95,\n          \"difference\": -0.050000000000000044\n        },\n        \"fear_raw_score\": {\n          \"Malcolm X\": 0.8,\n          \"Martin Luther King Jr.\": 0.6,\n          \"difference\": 0.19999999999999996\n        },\n        \"fear_salience\": {\n          \"Malcolm X\": 0.8,\n          \"Martin Luther King Jr.\": 0.5,\n          \"difference\": 0.3\n        },\n        \"fear_confidence\": {\n          \"Malcolm X\": 0.95,\n          \"Martin Luther King Jr.\": 0.9,\n          \"difference\": 0.050000000000000044\n        },\n        \"hope_raw_score\": {\n          \"Malcolm X\": 0.8,\n          \"Martin Luther King Jr.\": 0.9,\n          \"difference\": -0.10000000000000009\n        },\n        \"hope_salience\": {\n          \"Malcolm X\": 0.8,\n          \"Martin Luther King Jr.\": 0.9,\n          \"difference\": -0.10000000000000009\n        },\n        \"hope_confidence\": {\n          \"Malcolm X\": 0.95,\n          \"Martin Luther King Jr.\": 0.95,\n          \"difference\": 0.0\n        },\n        \"envy_raw_score\": {\n          \"Malcolm X\": 0.4,\n          \"Martin Luther King Jr.\": 0.1,\n          \"difference\": 0.3\n        },\n        \"envy_salience\": {\n          \"Malcolm X\": 0.3,\n          \"Martin Luther King Jr.\": 0.1,\n          \"difference\": 0.2\n        },\n        \"envy_confidence\": {\n          \"Malcolm X\": 0.85,\n          \"Martin Luther King Jr.\": 0.9,\n          \"difference\": -0.050000000000000044\n        },\n        \"compersion_raw_score\": {\n          \"Malcolm X\": 0.0,\n          \"Martin Luther King Jr.\": 0.4,\n          \"difference\": -0.4\n        },\n        \"compersion_salience\": {\n          \"Malcolm X\": 0.0,\n          \"Martin Luther King Jr.\": 0.2,\n          \"difference\": -0.2\n        },\n        \"compersion_confidence\": {\n          \"Malcolm X\": 0.95,\n          \"Martin Luther King Jr.\": 0.85,\n          \"difference\": 0.09999999999999998\n        },\n        \"enmity_raw_score\": {\n          \"Malcolm X\": 0.9,\n          \"Martin Luther King Jr.\": 0.7,\n          \"difference\": 0.19999999999999996\n        },\n        \"enmity_salience\": {\n          \"Malcolm X\": 0.9,\n          \"Martin Luther King Jr.\": 0.7,\n          \"difference\": 0.2\n        },\n        \"enmity_confidence\": {\n          \"Malcolm X\": 0.95,\n          \"Martin Luther King Jr.\": 0.95,\n          \"difference\": 0.0\n        },\n        \"amity_raw_score\": {\n          \"Malcolm X\": 0.7,\n          \"Martin Luther King Jr.\": 0.9,\n          \"difference\": -0.2\n        },\n        \"amity_salience\": {\n          \"Malcolm X\": 0.6,\n          \"Martin Luther King Jr.\": 0.9,\n          \"difference\": -0.3\n        },\n        \"amity_confidence\": {\n          \"Malcolm X\": 0.9,\n          \"Martin Luther King Jr.\": 0.95,\n          \"difference\": -0.050000000000000044\n        },\n        \"fragmentative_goals_raw_score\": {\n          \"Malcolm X\": 0.8,\n          \"Martin Luther King Jr.\": 0.6,\n          \"difference\": 0.19999999999999996\n        },\n        \"fragmentative_goals_salience\": {\n          \"Malcolm X\": 0.8,\n          \"Martin Luther King Jr.\": 0.5,\n          \"difference\": 0.3\n        },\n        \"fragmentative_goals_confidence\": {\n          \"Malcolm X\": 0.95,\n          \"Martin Luther King Jr.\": 0.9,\n          \"difference\": 0.050000000000000044\n        },\n        \"cohesive_goals_raw_score\": {\n          \"Malcolm X\": 0.9,\n          \"Martin Luther King Jr.\": 0.9,\n          \"difference\": 0.0\n        },\n        \"cohesive_goals_salience\": {\n          \"Malcolm X\": 0.9,\n          \"Martin Luther King Jr.\": 0.9,\n          \"difference\": 0.0\n        },\n        \"cohesive_goals_confidence\": {\n          \"Malcolm X\": 0.95,\n          \"Martin Luther King Jr.\": 0.95,\n          \"difference\": 0.0\n        },\n        \"identity_tension\": {\n          \"Malcolm X\": 0.24,\n          \"Martin Luther King Jr.\": 0.0,\n          \"difference\": 0.24\n        },\n        \"emotional_tension\": {\n          \"Malcolm X\": 0.0,\n          \"Martin Luther King Jr.\": 0.24,\n          \"difference\": -0.24\n        },\n        \"success_tension\": {\n          \"Malcolm X\": 0.0,\n          \"Martin Luther King Jr.\": 0.02,\n          \"difference\": -0.02\n        },\n        \"relational_tension\": {\n          \"Malcolm X\": 0.21,\n          \"Martin Luther King Jr.\": 0.0,\n          \"difference\": 0.21\n        },\n        \"goal_tension\": {\n          \"Malcolm X\": 0.08,\n          \"Martin Luther King Jr.\": 0.0,\n          \"difference\": 0.08\n        },\n        \"strategic_contradiction_index\": {\n          \"Malcolm X\": 0.106,\n          \"Martin Luther King Jr.\": 0.052,\n          \"difference\": 0.054\n        },\n        \"descriptive_cohesion_index\": {\n          \"Malcolm X\": -0.6259770114942528,\n          \"Martin Luther King Jr.\": 0.20189620066042038,\n          \"difference\": -0.8278732121546732\n        },\n        \"motivational_cohesion_index\": {\n          \"Malcolm X\": -0.4542372881355932,\n          \"Martin Luther King Jr.\": 0.3265321588711618,\n          \"difference\": -0.780769447006755\n        },\n        \"full_cohesion_index\": {\n          \"Malcolm X\": -0.31464761477815555,\n          \"Martin Luther King Jr.\": 0.4437820553152023,\n          \"difference\": -0.7584296700933579\n        }\n      }\n    },\n    \"correlation_analysis\": {\n      \"status\": \"Analysis Not Performed\",\n      \"reason\": \"Insufficient sample size (N=2) for meaningful correlation analysis. Minimum N for exploratory analysis is typically > 5, and for robust analysis N > 15.\"\n    },\n    \"reliability_analysis\": {\n      \"status\": \"Analysis Not Performed\",\n      \"reason\": \"Insufficient sample size (N=2) for meaningful internal consistency analysis. A minimum of N=15 is recommended.\"\n    }\n  },\n  \"sample_size_assessment\": {\n    \"total_documents\": 2,\n    \"tier_classification\": \"TIER 3: Exploratory Analysis\",\n    \"power_notes\": \"The sample size of N=2 (n=1 per group) is insufficient for any form of inferential statistical testing (e.g., t-tests, ANOVA) or correlation analysis. The analysis is therefore strictly exploratory and descriptive. Conclusions are limited to observing the patterns and raw differences within this specific sample and cannot be generalized. The primary analytical method is a direct comparison of scores.\"\n  },\n  \"methodology_summary\": \"The statistical analysis was conducted following a Tier 3 (Exploratory) protocol due to the small sample size of two documents. The primary method involved calculating comprehensive descriptive statistics for all dimensional scores and derived metrics to provide an overview of the data. The core of the analysis is a direct, descriptive comparison between the two speakers (Malcolm X and Martin Luther King Jr.) on every metric, highlighting the raw difference in scores as the main indicator of effect. Functions for inferential tests like correlation and reliability analysis were generated but returned informational messages explaining that they could not be meaningfully executed with N=2. The approach prioritizes statistical validity by avoiding inappropriate inferential claims and focusing on observable patterns within the provided data.\"\n}\n```",
  "analysis_artifacts_processed": 6,
  "cost_info": {
    "model": "vertex_ai/gemini-2.5-pro",
    "execution_time_seconds": 100.485724,
    "response_cost": 0.0,
    "input_tokens": 0,
    "output_tokens": 0,
    "total_tokens": 0,
    "prompt_length": 261604,
    "response_length": 28613
  },
  "timestamp": "2025-09-20T13:53:06.821890+00:00"
}