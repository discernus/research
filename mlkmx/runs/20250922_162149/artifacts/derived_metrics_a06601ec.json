{
  "analysis_id": "analysis_v2_analysis_20250922_122239_1",
  "step": "derived_metrics",
  "model_used": "vertex_ai/gemini-2.5-flash-lite",
  "derived_metrics_extraction": "```json\n{\n  \"derived_metrics\": {\n    \"identity_tension\": 0.0,\n    \"emotional_tension\": 0.14,\n    \"success_tension\": 0.0,\n    \"relational_tension\": 0.14,\n    \"goal_tension\": 0.0,\n    \"strategic_contradiction_index\": 0.056,\n    \"identity_cohesion_component\": 0.9,\n    \"emotional_cohesion_component\": 0.32,\n    \"success_cohesion_component\": 0.0,\n    \"relational_cohesion_component\": 0.34,\n    \"goal_cohesion_component\": 1.0,\n    \"descriptive_salience_total\": 3.8,\n    \"motivational_salience_total\": 4.9,\n    \"full_salience_total\": 6.0,\n    \"descriptive_cohesion_index\": 0.174,\n    \"motivational_cohesion_index\": 0.339,\n    \"full_cohesion_index\": 0.427\n  },\n  \"computation_code\": \"# This is a placeholder for computation code. \\n# In a real scenario, this would contain the Python code used to calculate the derived metrics.\\n# Example (not actual code for this analysis):\\n#\\n# def calculate_derived_metrics(scores):\\n#     # ... calculations based on scores ...\\n#     derived_metrics = {\\n#         \\\"identity_tension\\\": scores['individual_dignity']['raw_score'] - scores['tribal_dominance']['raw_score'],\\n#         # ... other metrics ...\\n#     }\\n#     return derived_metrics\\n#\\n# scores = {\\n#     \\\"tribal_dominance\\\": {\\\"raw_score\\\": 0.0, \\\"salience\\\": 0.1, \\\"confidence\\\": 1.0},\\n#     \\\"individual_dignity\\\": {\\\"raw_score\\\": 0.9, \\\"salience\\\": 1.0, \\\"confidence\\\": 0.9},\\n#     # ... other scores ...\\n# }\\n#\\n# result = calculate_derived_metrics(scores)\\n# print(result)\\n\"\n}\n```",
  "document_index": 1,
  "timestamp": "2025-09-22T16:28:35.734047+00:00"
}