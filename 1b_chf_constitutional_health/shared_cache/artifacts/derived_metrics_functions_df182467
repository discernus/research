{
  "status": "success",
  "functions_generated": 6,
  "output_file": "automatedderivedmetricsagent_functions.py",
  "module_size": 14107,
  "function_code_content": "\"\"\"\nAutomated Derived Metrics Functions\n===================================\n\nGenerated by AutomatedDerivedMetricsAgent for experiment: Test Experiment\nDescription: Test experiment for derived metrics\nGenerated: 2025-08-28T21:56:50.155679+00:00\n\nThis module contains automatically generated calculation functions for derived metrics\nas specified in the framework's natural language descriptions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom typing import Optional, Dict, Any\n\n\ndef calculate_identity_tension(data, **kwargs):\n    \"\"\"\n    Calculate identity_tension: Conflict between tribal dominance and individual dignity dimensions.\n\n    This metric quantifies the tension between discourse emphasizing group-based (tribal)\n    supremacy and discourse upholding the inherent worth and rights of each individual.\n    High tension suggests a polarized environment where group identity is pitted against\n    individual freedoms. The calculation models this as an interaction, where the tension\n    is highest when both dimensions are strongly present.\n\n    Formula: tribal_dominance * individual_dignity\n    \n    Args:\n        data (pd.Series): A single row of data containing the necessary columns.\n        **kwargs: Additional parameters (unused).\n        \n    Returns:\n        float: The calculated identity tension, or None if essential data is missing.\n    \"\"\"\n    import pandas as pd\n    \n    try:\n        # The required columns are inferred from the metric's description.\n        # The user has provided a generic data structure, so we must assume\n        # the framework provides these specific dimension columns for this calculation.\n        tribal_dominance = data['tribal_dominance']\n        individual_dignity = data['individual_dignity']\n        \n        # Check for missing values (NaN, None) before calculation.\n        if pd.isna(tribal_dominance) or pd.isna(individual_dignity):\n            return None\n            \n        # The conflict is conceptualized as the product of the two dimensions.\n        # High scores on both result in a high tension score.\n        result = float(tribal_dominance * individual_dignity)\n        \n        return result\n        \n    except Exception:\n        # Handles errors from missing columns (KeyError), wrong data types (TypeError), etc.\n        # Returning None ensures graceful failure as required.\n        return None\n\ndef calculate_emotional_balance(data, **kwargs):\n    \"\"\"\n    Calculate emotional_balance: Difference between hope and fear scores\n\n    Formula: hope - fear\n\n    Args:\n        data (pd.Series or pd.DataFrame): A single row of data containing the scores.\n                                          Expected to have 'hope' and 'fear' columns/keys.\n        **kwargs: Additional parameters (not used in this calculation).\n\n    Returns:\n        float: The calculated emotional balance score, or None if 'hope' or 'fear'\n               scores are missing, non-numeric, or not available in the data.\n    \"\"\"\n    import pandas as pd\n\n    try:\n        # The calculation requires 'hope' and 'fear' scores.\n        # This will fail gracefully if the columns do not exist in the input data.\n        hope_score = data['hope']\n        fear_score = data['fear']\n\n        # Ensure that both scores are present and are numeric types.\n        if pd.isna(hope_score) or pd.isna(fear_score):\n            return None\n\n        # Perform the calculation\n        return float(hope_score) - float(fear_score)\n\n    except (KeyError, TypeError, ValueError):\n        # KeyError: One of the required columns ('hope', 'fear') is not in the data.\n        # TypeError/ValueError: A score is not a number and cannot be cast to float.\n        return None\n\ndef calculate_success_climate(data, **kwargs):\n    \"\"\"\n    Calculate success_climate: Difference between compersion and envy scores\n\n    Formula: success_climate = compersion - envy\n\n    Args:\n        data (pd.Series): A single row of data representing one document.\n        **kwargs: Additional keyword arguments (ignored).\n\n    Returns:\n        float: The calculated difference between 'compersion' and 'envy' scores,\n               or None if either of the required columns is missing, not a number,\n               or another error occurs.\n    \"\"\"\n    import pandas as pd\n\n    try:\n        # The calculation requires 'compersion' and 'envy' columns,\n        # which are not present in the provided data structure.\n        # This function attempts to access them and will gracefully fail\n        # by returning None as per the requirements.\n        compersion_score = data['compersion']\n        envy_score = data['envy']\n\n        # Check if either of the scores is null or NaN\n        if pd.isna(compersion_score) or pd.isna(envy_score):\n            return None\n\n        # Ensure scores are numeric before calculation\n        if not all(isinstance(score, (int, float)) for score in [compersion_score, envy_score]):\n            return None\n\n        return float(compersion_score - envy_score)\n\n    except (KeyError, TypeError, Exception):\n        # A KeyError will be raised if 'compersion' or 'envy' columns do not exist.\n        # A TypeError might occur if data is not numeric.\n        # A general Exception handles any other unforeseen errors.\n        return None\n\ndef calculate_relational_climate(data, **kwargs):\n    \"\"\"\n    Calculate relational_climate: Difference between amity and enmity scores\n\n    Formula: amity - enmity\n    \n    Args:\n        data: pandas DataFrame or Series with dimension scores. This function\n              is designed to operate on a single row of data.\n        **kwargs: Additional parameters (unused).\n        \n    Returns:\n        float: Calculated result or None if insufficient data.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # The calculation is explicitly \"Difference between amity and enmity scores\".\n        # These column names are therefore requirements for the calculation.\n        amity_col = 'amity'\n        enmity_col = 'enmity'\n\n        # Using .get() is a safe way to access data that might be missing\n        # It works for both pandas Series and DataFrames (on columns)\n        amity_score_raw = data.get(amity_col)\n        enmity_score_raw = data.get(enmity_col)\n\n        # Check if the required columns/keys exist and their data is not None\n        if amity_score_raw is None or enmity_score_raw is None:\n            return None\n\n        # Convert scores to numeric, coercing any non-numeric values into NaN\n        amity_score = pd.to_numeric(amity_score_raw, errors='coerce')\n        enmity_score = pd.to_numeric(enmity_score_raw, errors='coerce')\n\n        # If either value is NaN after conversion, we cannot calculate\n        if pd.isna(amity_score) or pd.isna(enmity_score):\n            return None\n            \n        # Perform the calculation and ensure the result is a standard float\n        result = float(amity_score - enmity_score)\n        \n        return result\n        \n    except Exception:\n        # A general exception handler for any other unforeseen errors during execution\n        return None\n\ndef calculate_goal_orientation(data, **kwargs):\n    \"\"\"\n    Calculate goal_orientation: Difference between cohesive goals and fragmentative goals\n    \n    Formula: cohesive_goals - fragmentative_goals\n    \n    Args:\n        data (pd.Series): A single row of data containing dimension scores.\n        **kwargs: Additional keyword arguments (unused).\n        \n    Returns:\n        float: The calculated goal orientation score, or None if essential\n               data is missing or invalid.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # The calculation is defined as the difference between cohesive and fragmentative goals.\n        # This implementation attempts to access these specific columns.\n        # If the columns do not exist in the data (KeyError) or if the values are\n        # not numerical (TypeError, ValueError), the except block will catch\n        # the error and return None, as per requirements.\n        \n        cohesive_score = data['cohesive_goals']\n        fragmentative_score = data['fragmentative_goals']\n        \n        # Handle missing values within the columns\n        if pd.isna(cohesive_score) or pd.isna(fragmentative_score):\n            return None\n            \n        result = float(cohesive_score) - float(fragmentative_score)\n        \n        # Ensure the result is a finite number (e.g., not NaN from inf - inf)\n        if not np.isfinite(result):\n            return None\n            \n        return result\n        \n    except Exception:\n        # Catches all errors, including KeyError, TypeError, and ValueError,\n        # ensuring robust operation and graceful failure.\n        return None\n\ndef calculate_overall_cohesion_index(data, **kwargs):\n    \"\"\"\n    Calculate overall_cohesion_index: Comprehensive measure combining all dimensions.\n\n    This index is calculated as a weighted average of the three core dimension indices\n    (procedural legitimacy, institutional respect, systemic continuity), with weights\n    determined by their respective rhetorical emphasis patterns as described in the\n    Constitutional Health Framework.\n\n    Formula:\n    OCI = \u03a3(dimension_index * (emphasis / total_emphasis))\n\n    Args:\n        data (pd.Series): A single row of analysis data. Per the provided data\n                          structure, its columns are not used in this calculation.\n                          Required values are passed via kwargs.\n        **kwargs: Keyword arguments containing the required dimension indices and\n                  emphasis scores. Expected keys are:\n                  - 'procedural_legitimacy_index' (float)\n                  - 'institutional_respect_index' (float)\n                  - 'systemic_continuity_index' (float)\n                  - 'procedural_legitimacy_emphasis' (float)\n                  - 'institutional_respect_emphasis' (float)\n                  - 'systemic_continuity_emphasis' (float)\n\n    Returns:\n        float: The calculated Overall Cohesion Index, or None if any of the\n               required data is missing, non-numeric, or if total emphasis is zero or less.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # Define the keys for the required dimension indices and their emphasis scores,\n        # derived from the framework's conceptual structure.\n        dimension_keys = [\n            'procedural_legitimacy_index',\n            'institutional_respect_index',\n            'systemic_continuity_index'\n        ]\n        emphasis_keys = [\n            'procedural_legitimacy_emphasis',\n            'institutional_respect_emphasis',\n            'systemic_continuity_emphasis'\n        ]\n\n        # Extract dimension scores and emphasis values from keyword arguments.\n        dimension_scores = [kwargs.get(key) for key in dimension_keys]\n        emphasis_scores = [kwargs.get(key) for key in emphasis_keys]\n\n        # Combine all required values and check for missing data (None, NaN, etc.).\n        all_values = dimension_scores + emphasis_scores\n        if any(pd.isna(value) for value in all_values):\n            return None\n\n        # Convert to numpy arrays for robust numerical operations.\n        scores_array = np.array(dimension_scores, dtype=float)\n        emphasis_array = np.array(emphasis_scores, dtype=float)\n\n        # Emphasis values must not be negative.\n        if np.any(emphasis_array < 0):\n            return None\n\n        # Calculate total emphasis. A weighted average is undefined if the sum\n        # of weights is not positive.\n        total_emphasis = np.sum(emphasis_array)\n        if total_emphasis <= 0:\n            return None\n\n        # Normalize the emphasis weights so they sum to 1.\n        normalized_weights = emphasis_array / total_emphasis\n\n        # Calculate the weighted average of the dimension scores.\n        overall_cohesion_index = np.sum(scores_array * normalized_weights)\n\n        return float(overall_cohesion_index)\n\n    except Exception:\n        # Catch any unexpected errors during processing (e.g., non-numeric types)\n        # and return None for graceful failure.\n        return None\n\ndef calculate_all_derived_metrics(data: pd.DataFrame) -> Dict[str, Optional[float]]:\n    \"\"\"\n    Calculate all derived metrics for the given dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        Dictionary mapping metric names to calculated values\n    \"\"\"\n    results = {}\n    \n    # Get all calculation functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith('calculate_') and \n            name not in ['calculate_all_derived_metrics', 'calculate_derived_metrics']):\n            try:\n                results[name.replace('calculate_', '')] = obj(data)\n            except Exception as e:\n                results[name.replace('calculate_', '')] = None\n                \n    return results\n\n\ndef calculate_derived_metrics(data: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Template-compatible wrapper function for derived metrics calculation.\n    \n    This function is called by the universal notebook template and returns\n    the original data with additional derived metric columns.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        DataFrame with original data plus derived metric columns\n    \"\"\"\n    # Calculate all derived metrics\n    derived_metrics = calculate_all_derived_metrics(data)\n    \n    # Create a copy of the original data\n    result = data.copy()\n    \n    # Add derived metrics as new columns\n    for metric_name, metric_value in derived_metrics.items():\n        if metric_value is not None:\n            # For scalar metrics, broadcast to all rows\n            result[metric_name] = metric_value\n        else:\n            # For failed calculations, use NaN\n            result[metric_name] = np.nan\n    \n    return result\n",
  "cached_with_code": true
}