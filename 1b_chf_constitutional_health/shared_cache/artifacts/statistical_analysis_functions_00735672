{
  "status": "success",
  "functions_generated": 9,
  "output_file": "automatedstatisticalanalysisagent_functions.py",
  "module_size": 23027,
  "function_code_content": "\"\"\"\nAutomated Statistical Analysis Functions\n========================================\n\nGenerated by AutomatedStatisticalAnalysisAgent for experiment: presidential_sotu_constitutional_health_trends\nDescription: Statistical analysis experiment\nGenerated: 2025-08-28T21:57:46.623079+00:00\n\nThis module contains automatically generated statistical analysis functions\nfor comprehensive data analysis including ANOVA, correlations, reliability,\nand hypothesis testing as appropriate for the research questions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport scipy.stats as stats\nfrom typing import Dict, Any, Optional, List, Tuple\nimport warnings\n\n# Suppress common statistical warnings for cleaner output\nwarnings.filterwarnings('ignore', category=RuntimeWarning)\n\n\ndef _create_metadata_mapping(data):\n    \"\"\"\n    Internal helper function to map document names to administration and speech type.\n    This function uses the corpus manifest information provided in the experiment spec.\n    It is not intended to be called directly by the analysis pipeline.\n    \n    Args:\n        data (pd.DataFrame): The input dataframe with a 'document_name' column.\n        \n    Returns:\n        pd.DataFrame: The dataframe with 'administration' and 'speech_type' columns added.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    if 'document_name' not in data.columns:\n        raise ValueError(\"Input data must contain a 'document_name' column.\")\n\n    conditions_admin = [\n        data['document_name'].str.startswith('Bush_SOTU_1992'),\n        data['document_name'].str.startswith('Clinton_'),\n        data['document_name'].str.startswith('Bush_'),\n        data['document_name'].str.startswith('Obama_'),\n        data['document_name'].str.startswith('Trump_'),\n        data['document_name'].str.startswith('Biden_')\n    ]\n    choices_admin = ['Bush H.W.', 'Clinton', 'Bush W.', 'Obama', 'Trump', 'Biden']\n    data['administration'] = np.select(conditions_admin, choices_admin, default='Unknown')\n\n    conditions_type = [\n        data['document_name'].str.contains('_SOTU_'),\n        data['document_name'].str.contains('_Inaugural_'),\n        data['document_name'].str.contains('_Joint_Session_')\n    ]\n    choices_type = ['SOTU', 'Inaugural', 'Joint Session']\n    data['speech_type'] = np.select(conditions_type, choices_type, default='Other')\n    \n    return data\n\ndef calculate_derived_metrics(data, **kwargs):\n    \"\"\"\n    Calculates all derived metrics as specified in the Constitutional Health Framework v10.0.\n    This function adds new columns to the DataFrame for each derived metric. It is a \n    necessary preprocessing step for most other statistical analyses.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the raw and salience scores for each of the 6 dimensions.\n                             Must use the exact column names from the spec (e.g., 'procedural_legitimacy_raw').\n        **kwargs: Additional parameters (unused).\n\n    Returns:\n        pd.DataFrame: The original DataFrame with added columns for each derived metric, or None on error.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        df = data.copy()\n        \n        # Define required columns\n        required_cols = [\n            'procedural_legitimacy_raw', 'procedural_legitimacy_salience',\n            'procedural_rejection_raw', 'procedural_rejection_salience',\n            'institutional_respect_raw', 'institutional_respect_salience',\n            'institutional_subversion_raw', 'institutional_subversion_salience',\n            'systemic_continuity_raw', 'systemic_continuity_salience',\n            'systemic_replacement_raw', 'systemic_replacement_salience'\n        ]\n        \n        if not all(col in df.columns for col in required_cols):\n            # This is a critical error, as the function cannot operate.\n            return None\n\n        # Intermediate salience totals (with small epsilon to prevent division by zero)\n        df['procedural_health_salience_total'] = df['procedural_legitimacy_salience'] + df['procedural_rejection_salience'] + 0.001\n        df['institutional_health_salience_total'] = df['institutional_respect_salience'] + df['institutional_subversion_salience'] + 0.001\n        df['systemic_health_salience_total'] = df['systemic_continuity_salience'] + df['systemic_replacement_salience'] + 0.001\n        df['total_constitutional_salience'] = df['procedural_health_salience_total'] + df['institutional_health_salience_total'] + df['systemic_health_salience_total']\n\n        # Axis-level health indices\n        df['procedural_health_index'] = ((df['procedural_legitimacy_raw'] * df['procedural_legitimacy_salience']) - (df['procedural_rejection_raw'] * df['procedural_rejection_salience'])) / df['procedural_health_salience_total']\n        df['institutional_health_index'] = ((df['institutional_respect_raw'] * df['institutional_respect_salience']) - (df['institutional_subversion_raw'] * df['institutional_subversion_salience'])) / df['institutional_health_salience_total']\n        df['systemic_health_index'] = ((df['systemic_continuity_raw'] * df['systemic_continuity_salience']) - (df['systemic_replacement_raw'] * df['systemic_replacement_salience'])) / df['systemic_health_salience_total']\n\n        # Summary metrics\n        df['constitutional_health_index'] = ((df['procedural_health_index'] * df['procedural_health_salience_total']) + (df['institutional_health_index'] * df['institutional_health_salience_total']) + (df['systemic_health_index'] * df['systemic_health_salience_total'])) / df['total_constitutional_salience']\n        df['constitutional_pathology_index'] = ((df['procedural_rejection_raw'] * df['procedural_rejection_salience']) + (df['institutional_subversion_raw'] * df['institutional_subversion_salience']) + (df['systemic_replacement_raw'] * df['systemic_replacement_salience'])) / df['total_constitutional_salience']\n        \n        return df\n\n    except Exception:\n        return None\n\ndef calculate_descriptive_statistics(data, **kwargs):\n    \"\"\"\n    Calculates descriptive statistics for key constitutional health metrics, grouped by administration.\n    This addresses RQ1 (pattern discovery) and RQ5 (anomaly detection).\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the analysis data.\n        **kwargs: Additional parameters (unused).\n\n    Returns:\n        dict: A dictionary containing descriptive statistics for each key metric, grouped by administration.\n              Returns None if data processing fails.\n    \"\"\"\n    import pandas as pd\n    \n    try:\n        # Pre-processing\n        df = _create_metadata_mapping(data.copy())\n        df = calculate_derived_metrics(df)\n        if df is None:\n            return None\n\n        metrics_to_describe = [\n            'constitutional_health_index',\n            'constitutional_pathology_index',\n            'procedural_health_index',\n            'institutional_health_index',\n            'systemic_health_index'\n        ]\n        \n        if not all(col in df.columns for col in metrics_to_describe):\n            return None\n\n        # Group by administration and calculate descriptive stats\n        desc_stats = df.groupby('administration')[metrics_to_describe].describe()\n        \n        # Convert to a more JSON-friendly format\n        results = desc_stats.to_dict('index')\n        for admin, stats in results.items():\n            results[admin] = {k: v for k, v in stats.items()}\n            \n        return results\n\n    except Exception:\n        return None\n\ndef perform_anova_and_tukey_test(data, **kwargs):\n    \"\"\"\n    Performs a one-way ANOVA to test for significant differences in the Constitutional Health Index\n    across presidential administrations, followed by a Tukey HSD post-hoc test for pairwise comparisons.\n    This function directly tests hypotheses H1 through H5.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the analysis data.\n        **kwargs: Additional parameters (unused).\n\n    Returns:\n        dict: A dictionary with ANOVA results (F-statistic, p-value, eta-squared) and Tukey HSD results.\n              Returns None if there are not enough groups for the test.\n    \"\"\"\n    import pandas as pd\n    import statsmodels.api as sm\n    from statsmodels.formula.api import ols\n    from statsmodels.stats.multicomp import pairwise_tukeyhsd\n    \n    try:\n        df = _create_metadata_mapping(data.copy())\n        df = calculate_derived_metrics(df)\n        if df is None:\n            return None\n\n        # Per experiment spec, exclude Bush H.W. from inferential tests (n=1)\n        df_filtered = df[df['administration'] != 'Bush H.W.']\n        \n        # Check for sufficient data\n        if df_filtered['administration'].nunique() < 2:\n            return {\"error\": \"Insufficient number of administrations for ANOVA test.\"}\n\n        # ANOVA\n        model = ols('constitutional_health_index ~ C(administration)', data=df_filtered).fit()\n        anova_table = sm.stats.anova_lm(model, typ=2)\n        \n        # Calculate Eta-squared (effect size)\n        ss_between = anova_table['sum_sq'][0]\n        ss_total = anova_table['sum_sq'].sum()\n        eta_squared = ss_between / ss_total\n        \n        anova_results = {\n            'f_statistic': anova_table['F'][0],\n            'p_value': anova_table['PR(>F)'][0],\n            'eta_squared': eta_squared\n        }\n\n        # Tukey HSD post-hoc test\n        tukey_results = pairwise_tukeyhsd(endog=df_filtered['constitutional_health_index'],\n                                          groups=df_filtered['administration'],\n                                          alpha=0.05)\n        \n        tukey_df = pd.DataFrame(data=tukey_results._results_table.data[1:], columns=tukey_results._results_table.data[0])\n        \n        return {\n            \"anova_summary\": anova_results,\n            \"tukey_hsd_pairwise_comparisons\": tukey_df.to_dict('records')\n        }\n\n    except Exception:\n        return None\n\ndef test_variance_homogeneity_levene(data, **kwargs):\n    \"\"\"\n    Performs Levene's test to check for homogeneity of variance in the Constitutional Health Index\n    across administrations. This directly tests hypothesis H6 regarding variance in the Trump administration.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the analysis data.\n        **kwargs: Additional parameters (unused).\n\n    Returns:\n        dict: A dictionary with the Levene test statistic and p-value, or None on error.\n    \"\"\"\n    import pandas as pd\n    from scipy.stats import levene\n\n    try:\n        df = _create_metadata_mapping(data.copy())\n        df = calculate_derived_metrics(df)\n        if df is None: return None\n\n        df_filtered = df[df['administration'] != 'Bush H.W.']\n        \n        if df_filtered['administration'].nunique() < 2:\n            return {\"error\": \"Insufficient number of administrations for Levene's test.\"}\n\n        # Prepare data for Levene's test\n        groups = df_filtered.groupby('administration')['constitutional_health_index'].apply(list)\n        \n        # Unpack the groups for the test\n        samples = [group for group in groups]\n        \n        stat, p_value = levene(*samples)\n        \n        return {\n            'levene_statistic': stat,\n            'p_value': p_value,\n            'interpretation': 'p < 0.05 suggests variances are not equal.'\n        }\n\n    except Exception:\n        return None\n\ndef analyze_dimensional_contribution(data, **kwargs):\n    \"\"\"\n    Analyzes which constitutional dimensions show the most variation across administrations by\n    running a one-way ANOVA on each of the three axis-level health indices. This addresses RQ2.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the analysis data.\n        **kwargs: Additional parameters (unused).\n\n    Returns:\n        dict: A dictionary containing ANOVA results for each axis-level index.\n    \"\"\"\n    import pandas as pd\n    import statsmodels.api as sm\n    from statsmodels.formula.api import ols\n\n    try:\n        df = _create_metadata_mapping(data.copy())\n        df = calculate_derived_metrics(df)\n        if df is None: return None\n\n        df_filtered = df[df['administration'] != 'Bush H.W.']\n        \n        if df_filtered['administration'].nunique() < 2:\n            return {\"error\": \"Insufficient number of administrations for ANOVA.\"}\n\n        results = {}\n        dimensions = ['procedural_health_index', 'institutional_health_index', 'systemic_health_index', 'constitutional_pathology_index']\n\n        for dim in dimensions:\n            try:\n                model = ols(f'{dim} ~ C(administration)', data=df_filtered).fit()\n                anova_table = sm.stats.anova_lm(model, typ=2)\n                results[dim] = {\n                    'f_statistic': anova_table['F'][0],\n                    'p_value': anova_table['PR(>F)'][0]\n                }\n            except Exception:\n                results[dim] = None\n        \n        return results\n\n    except Exception:\n        return None\n\ndef analyze_speech_context_effects(data, **kwargs):\n    \"\"\"\n    Analyzes the effect of speech context (SOTU, Inaugural, Joint Session) on the\n    Constitutional Health Index using a one-way ANOVA. This addresses RQ3.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the analysis data.\n        **kwargs: Additional parameters (unused).\n\n    Returns:\n        dict: A dictionary with ANOVA results for speech context effects.\n    \"\"\"\n    import pandas as pd\n    import statsmodels.api as sm\n    from statsmodels.formula.api import ols\n\n    try:\n        df = _create_metadata_mapping(data.copy())\n        df = calculate_derived_metrics(df)\n        if df is None: return None\n\n        if df['speech_type'].nunique() < 2:\n            return {\"error\": \"Insufficient number of speech types for ANOVA.\"}\n\n        model = ols('constitutional_health_index ~ C(speech_type)', data=df).fit()\n        anova_table = sm.stats.anova_lm(model, typ=2)\n        \n        return {\n            'f_statistic': anova_table['F'][0],\n            'p_value': anova_table['PR(>F)'][0]\n        }\n\n    except Exception:\n        return None\n\ndef perform_cluster_and_distance_analysis(data, **kwargs):\n    \"\"\"\n    Performs hierarchical clustering and calculates Euclidean distances between administration profiles\n    based on the six core constitutional dimensions. This directly tests hypothesis H7.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the analysis data.\n        **kwargs: Additional parameters (unused).\n\n    Returns:\n        dict: A dictionary containing Euclidean distance matrix and clustering results.\n    \"\"\"\n    import pandas as pd\n    from sklearn.metrics.pairwise import euclidean_distances\n    from scipy.cluster.hierarchy import linkage, dendrogram\n    from scipy.spatial.distance import pdist, squareform\n\n    try:\n        df = _create_metadata_mapping(data.copy())\n        df = calculate_derived_metrics(df)\n        if df is None: return None\n\n        df_filtered = df[df['administration'] != 'Bush H.W.']\n        \n        dims = [\n            'procedural_legitimacy_raw', 'procedural_rejection_raw',\n            'institutional_respect_raw', 'institutional_subversion_raw',\n            'systemic_continuity_raw', 'systemic_replacement_raw'\n        ]\n        \n        # Create mean profiles for each administration\n        admin_profiles = df_filtered.groupby('administration')[dims].mean()\n        \n        if len(admin_profiles) < 2:\n            return {\"error\": \"Insufficient administrations for distance/cluster analysis.\"}\n\n        # Euclidean Distance\n        dist_matrix = pd.DataFrame(squareform(pdist(admin_profiles, 'euclidean')), \n                                   columns=admin_profiles.index, \n                                   index=admin_profiles.index)\n\n        # Hierarchical Clustering\n        linked = linkage(admin_profiles, method='ward')\n        \n        # Create a simplified representation of the dendrogram\n        # This is a non-visual representation of the clustering tree structure\n        cluster_tree = []\n        for i, merge in enumerate(linked):\n            cluster_id = len(admin_profiles) + i\n            # Node indices < len(profiles) are original items\n            # Node indices >= len(profiles) are merged clusters\n            node1 = int(merge[0])\n            node2 = int(merge[1])\n            \n            label1 = admin_profiles.index[node1] if node1 < len(admin_profiles) else f\"cluster_{node1}\"\n            label2 = admin_profiles.index[node2] if node2 < len(admin_profiles) else f\"cluster_{node2}\"\n            \n            cluster_tree.append({\n                \"new_cluster_id\": f\"cluster_{cluster_id}\",\n                \"merged\": [label1, label2],\n                \"distance\": merge[2],\n                \"num_items\": int(merge[3])\n            })\n\n        return {\n            \"euclidean_distance_matrix\": dist_matrix.to_dict(),\n            \"hierarchical_clustering_tree\": cluster_tree\n        }\n\n    except Exception:\n        return None\n\ndef calculate_cronbachs_alpha(data, **kwargs):\n    \"\"\"\n    Calculates Cronbach's alpha to assess the internal consistency of the 'health' and 'pathology'\n    sets of dimensions. This serves as a reliability check for the framework's constructs.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the analysis data.\n        **kwargs: Additional parameters (unused).\n\n    Returns:\n        dict: A dictionary with Cronbach's alpha for health and pathology dimensions.\n    \"\"\"\n    import pandas as pd\n    \n    def _cronbach_alpha(df):\n        df_corr = df.corr()\n        N = df.shape[1]\n        rs = df_corr.values.flatten()\n        mean_r = rs.mean()\n        alpha = (N * mean_r) / (1 + (N - 1) * mean_r)\n        return alpha\n\n    try:\n        df = data.copy()\n        \n        health_dims = [\n            'procedural_legitimacy_raw',\n            'institutional_respect_raw',\n            'systemic_continuity_raw'\n        ]\n        pathology_dims = [\n            'procedural_rejection_raw',\n            'institutional_subversion_raw',\n            'systemic_replacement_raw'\n        ]\n\n        if not all(col in df.columns for col in health_dims + pathology_dims):\n            return None\n\n        df_health = df[health_dims]\n        df_pathology = df[pathology_dims]\n\n        alpha_health = _cronbach_alpha(df_health)\n        alpha_pathology = _cronbach_alpha(df_pathology)\n\n        return {\n            'health_dimensions_alpha': alpha_health,\n            'pathology_dimensions_alpha': alpha_pathology\n        }\n    except Exception:\n        return None\n\ndef run_complete_statistical_analysis(data: pd.DataFrame, alpha: float = 0.05) -> Dict[str, Any]:\n    \"\"\"\n    Run complete statistical analysis suite on the dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        alpha: Significance level for hypothesis tests (default: 0.05)\n        \n    Returns:\n        Dictionary with all statistical analysis results\n    \"\"\"\n    results = {\n        'analysis_metadata': {\n            'timestamp': pd.Timestamp.now().isoformat(),\n            'sample_size': len(data),\n            'alpha_level': alpha,\n            'variables_analyzed': list(data.select_dtypes(include=[np.number]).columns)\n        }\n    }\n    \n    # Get all analysis functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith(('calculate_', 'perform_', 'test_')) and \n            name != 'run_complete_statistical_analysis'):\n            try:\n                # Pass alpha parameter to functions that might need it\n                if 'alpha' in inspect.signature(obj).parameters:\n                    results[name] = obj(data, alpha=alpha)\n                else:\n                    results[name] = obj(data)\n            except Exception as e:\n                results[name] = {'error': f'Analysis failed: {str(e)}'}\n                \n    return results\n\n\ndef perform_statistical_analysis(data: pd.DataFrame) -> Dict[str, Any]:\n    \"\"\"\n    Template-compatible wrapper function for statistical analysis.\n    \n    This function is called by the universal notebook template and performs\n    comprehensive statistical analysis on the provided dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores and derived metrics\n        \n    Returns:\n        Dictionary containing all statistical analysis results\n    \"\"\"\n    return run_complete_statistical_analysis(data)\n\n\ndef generate_statistical_summary_report(analysis_results: Dict[str, Any]) -> str:\n    \"\"\"\n    Generate a human-readable summary report from statistical analysis results.\n    \n    Args:\n        analysis_results: Results from run_complete_statistical_analysis()\n        \n    Returns:\n        String containing formatted statistical report\n    \"\"\"\n    report_lines = []\n    report_lines.append(\"STATISTICAL ANALYSIS SUMMARY REPORT\")\n    report_lines.append(\"=\" * 50)\n    \n    metadata = analysis_results.get('analysis_metadata', {})\n    report_lines.append(f\"Analysis Timestamp: {metadata.get('timestamp', 'Unknown')}\")\n    report_lines.append(f\"Sample Size: {metadata.get('sample_size', 'Unknown')}\")\n    report_lines.append(f\"Alpha Level: {metadata.get('alpha_level', 'Unknown')}\")\n    report_lines.append(f\"Variables: {len(metadata.get('variables_analyzed', []))}\")\n    report_lines.append(\"\")\n    \n    # Summarize key findings\n    for analysis_name, result in analysis_results.items():\n        if analysis_name != 'analysis_metadata' and isinstance(result, dict):\n            if 'error' not in result:\n                report_lines.append(f\"{analysis_name.replace('_', ' ').title()}:\")\n                \n                # Extract key statistics based on analysis type\n                if 'p_value' in result:\n                    p_val = result['p_value']\n                    significance = \"significant\" if p_val < metadata.get('alpha_level', 0.05) else \"not significant\"\n                    report_lines.append(f\"  - p-value: {p_val:.4f} ({significance})\")\n                \n                if 'effect_size' in result:\n                    report_lines.append(f\"  - Effect size: {result['effect_size']:.4f}\")\n                \n                if 'correlation_matrix' in result:\n                    report_lines.append(f\"  - Correlation matrix generated with {len(result['correlation_matrix'])} variables\")\n                \n                if 'cronbach_alpha' in result:\n                    alpha_val = result['cronbach_alpha']\n                    reliability = \"excellent\" if alpha_val > 0.9 else \"good\" if alpha_val > 0.8 else \"acceptable\" if alpha_val > 0.7 else \"questionable\"\n                    report_lines.append(f\"  - Cronbach's \u03b1: {alpha_val:.3f} ({reliability})\")\n                \n                report_lines.append(\"\")\n            else:\n                report_lines.append(f\"{analysis_name}: ERROR - {result['error']}\")\n                report_lines.append(\"\")\n    \n    return \"\\n\".join(report_lines)\n",
  "cached_with_code": true
}