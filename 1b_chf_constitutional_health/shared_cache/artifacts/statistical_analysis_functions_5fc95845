{
  "status": "success",
  "functions_generated": 10,
  "output_file": "automatedstatisticalanalysisagent_functions.py",
  "module_size": 30648,
  "function_code_content": "\"\"\"\nAutomated Statistical Analysis Functions\n========================================\n\nGenerated by AutomatedStatisticalAnalysisAgent for experiment: presidential_sotu_constitutional_health_trends\nDescription: Statistical analysis experiment\nGenerated: 2025-08-28T21:22:47.951488+00:00\n\nThis module contains automatically generated statistical analysis functions\nfor comprehensive data analysis including ANOVA, correlations, reliability,\nand hypothesis testing as appropriate for the research questions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport scipy.stats as stats\nfrom typing import Dict, Any, Optional, List, Tuple\nimport warnings\n\n# Suppress common statistical warnings for cleaner output\nwarnings.filterwarnings('ignore', category=RuntimeWarning)\n\n\ndef _add_metadata_to_df(data):\n    \"\"\"\n    Internal helper to add 'administration' and 'speech_type' metadata.\n\n    This function maps document names to administrations and speech types based on\n    the experiment's corpus design. It does not parse external files.\n\n    Args:\n        data (pd.DataFrame): The input dataframe with a 'document_name' column.\n\n    Returns:\n        pd.DataFrame: The dataframe with 'administration' and 'speech_type' columns.\n    \"\"\"\n    if 'document_name' not in data.columns:\n        raise ValueError(\"Input DataFrame must contain a 'document_name' column.\")\n\n    def get_administration(doc_name):\n        doc_name_lower = doc_name.lower()\n        if 'bush_hw' in doc_name_lower or '1992' in doc_name:\n            return 'Bush H.W.'\n        if 'clinton' in doc_name_lower:\n            return 'Clinton'\n        if 'bush' in doc_name_lower and 'hw' not in doc_name_lower:\n            return 'Bush W.'\n        if 'obama' in doc_name_lower:\n            return 'Obama'\n        if 'trump' in doc_name_lower:\n            return 'Trump'\n        if 'biden' in doc_name_lower:\n            return 'Biden'\n        return 'Unknown'\n\n    def get_speech_type(doc_name):\n        doc_name_lower = doc_name.lower()\n        if 'inaugural' in doc_name_lower:\n            return 'Inaugural'\n        if 'sotu' in doc_name_lower or 'state of the union' in doc_name_lower:\n            return 'SOTU'\n        if 'joint_session' in doc_name_lower or 'joint session' in doc_name_lower:\n            return 'Joint Session'\n        return 'Other'\n\n    data['administration'] = data['document_name'].apply(get_administration)\n    data['speech_type'] = data['document_name'].apply(get_speech_type)\n    return data\n\ndef _calculate_derived_metrics(data):\n    \"\"\"\n    Internal helper to calculate all derived metrics from the framework spec.\n\n    Args:\n        data (pd.DataFrame): DataFrame with raw and salience scores.\n\n    Returns:\n        pd.DataFrame: DataFrame with added derived metric columns.\n    \"\"\"\n    # Ensure all required columns exist\n    required_cols = [\n        'procedural_legitimacy_raw', 'procedural_legitimacy_salience',\n        'procedural_rejection_raw', 'procedural_rejection_salience',\n        'institutional_respect_raw', 'institutional_respect_salience',\n        'institutional_subversion_raw', 'institutional_subversion_salience',\n        'systemic_continuity_raw', 'systemic_continuity_salience',\n        'systemic_replacement_raw', 'systemic_replacement_salience'\n    ]\n    for col in required_cols:\n        if col not in data.columns:\n            raise ValueError(f\"Missing required column for calculation: {col}\")\n\n    # Use .get(col, 0) to handle potential missing columns gracefully if needed,\n    # but the check above is stricter.\n    df = data.copy()\n    \n    # Add a small epsilon to avoid division by zero, as per the spec\n    epsilon = 0.001\n\n    # Intermediate salience totals\n    df['procedural_health_salience_total'] = df['procedural_legitimacy_salience'] + df['procedural_rejection_salience'] + epsilon\n    df['institutional_health_salience_total'] = df['institutional_respect_salience'] + df['institutional_subversion_salience'] + epsilon\n    df['systemic_health_salience_total'] = df['systemic_continuity_salience'] + df['systemic_replacement_salience'] + epsilon\n    df['total_constitutional_salience'] = df['procedural_health_salience_total'] + df['institutional_health_salience_total'] + df['systemic_health_salience_total']\n\n    # Axis-level health indices\n    df['procedural_health_index'] = ((df['procedural_legitimacy_raw'] * df['procedural_legitimacy_salience']) - (df['procedural_rejection_raw'] * df['procedural_rejection_salience'])) / df['procedural_health_salience_total']\n    df['institutional_health_index'] = ((df['institutional_respect_raw'] * df['institutional_respect_salience']) - (df['institutional_subversion_raw'] * df['institutional_subversion_salience'])) / df['institutional_health_salience_total']\n    df['systemic_health_index'] = ((df['systemic_continuity_raw'] * df['systemic_continuity_salience']) - (df['systemic_replacement_raw'] * df['systemic_replacement_salience'])) / df['systemic_health_salience_total']\n\n    # Summary metrics\n    numerator_chi = (df['procedural_health_index'] * df['procedural_health_salience_total']) + \\\n                    (df['institutional_health_index'] * df['institutional_health_salience_total']) + \\\n                    (df['systemic_health_index'] * df['systemic_health_salience_total'])\n    df['constitutional_health_index'] = numerator_chi / df['total_constitutional_salience']\n\n    numerator_cpi = (df['procedural_rejection_raw'] * df['procedural_rejection_salience']) + \\\n                    (df['institutional_subversion_raw'] * df['institutional_subversion_salience']) + \\\n                    (df['systemic_replacement_raw'] * df['systemic_replacement_salience'])\n    df['constitutional_pathology_index'] = numerator_cpi / df['total_constitutional_salience']\n\n    return df\n\ndef calculate_descriptive_stats_by_admin(data, **kwargs):\n    \"\"\"\n    Calculates descriptive statistics for key constitutional health metrics, grouped by administration.\n\n    This function computes the mean, standard deviation, and count for the main health and\n    pathology indices for each presidential administration. It also provides a separate\n    entry for the Bush H.W. baseline, as specified in the experiment.\n\n    Args:\n        data (pandas.DataFrame): DataFrame containing the analysis data with a 'document_name' column.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary containing descriptive statistics for each administration and the baseline,\n              or None if an error occurs.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        if data.empty:\n            return {\"error\": \"Input data is empty.\"}\n\n        # Calculate derived metrics and add metadata\n        df = _calculate_derived_metrics(data)\n        df = _add_metadata_to_df(df)\n\n        metrics_to_analyze = [\n            'constitutional_health_index',\n            'constitutional_pathology_index',\n            'procedural_health_index',\n            'institutional_health_index',\n            'systemic_health_index'\n        ]\n\n        # Separate baseline from main analysis groups\n        baseline_df = df[df['administration'] == 'Bush H.W.']\n        analysis_df = df[df['administration'] != 'Bush H.W.']\n\n        if analysis_df.empty:\n            return {\"error\": \"No data available for administrations to analyze.\"}\n\n        # Calculate stats for main groups\n        grouped_stats = analysis_df.groupby('administration')[metrics_to_analyze].agg(['mean', 'std', 'count'])\n        \n        results = {\n            \"administration_stats\": grouped_stats.to_dict(),\n            \"baseline_stats\": None\n        }\n\n        # Handle baseline\n        if not baseline_df.empty:\n            baseline_stats = baseline_df[metrics_to_analyze].mean().to_dict()\n            baseline_stats['count'] = len(baseline_df)\n            results['baseline_stats'] = baseline_stats\n        \n        return results\n\n    except Exception as e:\n        return {\"error\": f\"An error occurred: {str(e)}\"}\n\ndef run_anova_on_health_index(data, **kwargs):\n    \"\"\"\n    Performs a one-way ANOVA on the Constitutional Health Index across presidential administrations.\n\n    This function tests the primary hypothesis (H\u2081) that there is a statistically significant\n    difference in the mean Constitutional Health Index among the Clinton, Bush W., Obama,\n    Trump, and Biden administrations. It calculates the F-statistic, p-value, and the\n    eta-squared (\u03b7\u00b2) effect size. The Bush H.W. administration is excluded due to n=1.\n\n    Args:\n        data (pandas.DataFrame): DataFrame containing the analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary with the F-statistic, p-value, eta-squared, and degrees of freedom,\n              or None if data is insufficient.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    from scipy.stats import f_oneway\n\n    try:\n        if data.empty:\n            return {\"error\": \"Input data is empty.\"}\n\n        df = _calculate_derived_metrics(data)\n        df = _add_metadata_to_df(df)\n\n        # Exclude baseline and administrations with fewer than 2 samples\n        analysis_df = df[df['administration'] != 'Bush H.W.']\n        admin_counts = analysis_df['administration'].value_counts()\n        valid_admins = admin_counts[admin_counts > 1].index\n        \n        if len(valid_admins) < 2:\n            return {\"error\": \"ANOVA requires at least two groups with n > 1.\"}\n            \n        analysis_df = analysis_df[analysis_df['administration'].isin(valid_admins)]\n\n        groups = [group['constitutional_health_index'].values for name, group in analysis_df.groupby('administration')]\n\n        if not groups or len(groups) < 2:\n            return {\"error\": \"Insufficient groups for ANOVA after filtering.\"}\n\n        f_stat, p_value = f_oneway(*groups)\n\n        # Calculate Eta-squared (\u03b7\u00b2)\n        ss_between = sum(len(g) * (np.mean(g) - analysis_df['constitutional_health_index'].mean())**2 for g in groups)\n        ss_total = sum((analysis_df['constitutional_health_index'] - analysis_df['constitutional_health_index'].mean())**2)\n        eta_squared = ss_between / ss_total if ss_total > 0 else 0\n\n        df_between = len(groups) - 1\n        df_within = len(analysis_df) - len(groups)\n\n        return {\n            \"test\": \"One-way ANOVA on Constitutional Health Index\",\n            \"f_statistic\": f_stat,\n            \"p_value\": p_value,\n            \"eta_squared\": eta_squared,\n            \"df_between\": df_between,\n            \"df_within\": df_within,\n            \"groups_tested\": list(valid_admins)\n        }\n\n    except Exception as e:\n        return {\"error\": f\"An error occurred: {str(e)}\"}\n\ndef run_tukey_hsd_test(data, **kwargs):\n    \"\"\"\n    Performs Tukey's Honestly Significant Difference (HSD) post-hoc test for pairwise comparisons.\n\n    Following a significant ANOVA, this test identifies which specific administration pairs have\n    statistically different mean scores on the Constitutional Health Index. This addresses\n    secondary hypotheses H\u2082 through H\u2085.\n\n    Args:\n        data (pandas.DataFrame): DataFrame containing the analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary containing the Tukey HSD results as a summary DataFrame in JSON format,\n              or None if data is insufficient.\n    \"\"\"\n    import pandas as pd\n    from statsmodels.stats.multicomp import pairwise_tukeyhsd\n\n    try:\n        if data.empty:\n            return {\"error\": \"Input data is empty.\"}\n\n        df = _calculate_derived_metrics(data)\n        df = _add_metadata_to_df(df)\n\n        analysis_df = df[df['administration'] != 'Bush H.W.'].dropna(subset=['constitutional_health_index', 'administration'])\n        \n        admin_counts = analysis_df['administration'].value_counts()\n        valid_admins = admin_counts[admin_counts > 1].index\n        \n        if len(valid_admins) < 2:\n            return {\"error\": \"Tukey HSD requires at least two groups with n > 1.\"}\n            \n        analysis_df = analysis_df[analysis_df['administration'].isin(valid_admins)]\n\n        if len(analysis_df['administration'].unique()) < 2:\n            return {\"error\": \"Not enough unique administration groups for Tukey HSD test.\"}\n\n        tukey_result = pairwise_tukeyhsd(\n            endog=analysis_df['constitutional_health_index'],\n            groups=analysis_df['administration'],\n            alpha=0.05\n        )\n\n        results_df = pd.DataFrame(data=tukey_result._results_table.data[1:], columns=tukey_result._results_table.data[0])\n        \n        return {\n            \"test\": \"Tukey HSD on Constitutional Health Index\",\n            \"results_json\": results_df.to_json(orient='records')\n        }\n\n    except Exception as e:\n        return {\"error\": f\"An error occurred: {str(e)}\"}\n\ndef run_levene_test_on_variance(data, **kwargs):\n    \"\"\"\n    Performs Levene's test for homogeneity of variances on the Constitutional Health Index.\n\n    This function tests hypothesis H\u2086, which posits that the Trump administration shows\n    significantly different variance in constitutional health scores compared to other\n    administrations. The test assesses if the variances are equal across all groups.\n\n    Args:\n        data (pandas.DataFrame): DataFrame containing the analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary with the Levene statistic and p-value, or None if data is insufficient.\n    \"\"\"\n    import pandas as pd\n    from scipy.stats import levene\n\n    try:\n        if data.empty:\n            return {\"error\": \"Input data is empty.\"}\n\n        df = _calculate_derived_metrics(data)\n        df = _add_metadata_to_df(df)\n\n        analysis_df = df[df['administration'] != 'Bush H.W.']\n        admin_counts = analysis_df['administration'].value_counts()\n        valid_admins = admin_counts[admin_counts > 1].index\n        \n        if len(valid_admins) < 2:\n            return {\"error\": \"Levene's test requires at least two groups with n > 1.\"}\n            \n        analysis_df = analysis_df[analysis_df['administration'].isin(valid_admins)]\n\n        groups = [group['constitutional_health_index'].dropna().values for name, group in analysis_df.groupby('administration')]\n        \n        # Filter out empty groups after dropping NaNs\n        groups = [g for g in groups if len(g) > 0]\n\n        if len(groups) < 2:\n            return {\"error\": \"Insufficient groups for Levene's test after handling NaNs.\"}\n\n        statistic, p_value = levene(*groups)\n\n        return {\n            \"test\": \"Levene's Test for Homogeneity of Variances\",\n            \"statistic\": statistic,\n            \"p_value\": p_value,\n            \"groups_tested\": list(valid_admins)\n        }\n\n    except Exception as e:\n        return {\"error\": f\"An error occurred: {str(e)}\"}\n\ndef analyze_dimensional_contribution(data, **kwargs):\n    \"\"\"\n    Analyzes the contribution of each constitutional dimension to inter-administration differences.\n\n    This function runs a one-way ANOVA for each of the six primary dimensions and three\n    axis-level indices to determine which dimensions show the most significant variation\n    across administrations. This helps answer Research Question 2.\n\n    Args:\n        data (pandas.DataFrame): DataFrame containing the analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary where keys are dimension names and values are their ANOVA results\n              (F-statistic and p-value), or None on error.\n    \"\"\"\n    import pandas as pd\n    from scipy.stats import f_oneway\n\n    try:\n        if data.empty:\n            return {\"error\": \"Input data is empty.\"}\n\n        df = _calculate_derived_metrics(data)\n        df = _add_metadata_to_df(df)\n\n        analysis_df = df[df['administration'] != 'Bush H.W.']\n        admin_counts = analysis_df['administration'].value_counts()\n        valid_admins = admin_counts[admin_counts > 1].index\n        \n        if len(valid_admins) < 2:\n            return {\"error\": \"Analysis requires at least two groups with n > 1.\"}\n            \n        analysis_df = analysis_df[analysis_df['administration'].isin(valid_admins)]\n\n        dimensions_to_test = [\n            'procedural_legitimacy_raw', 'procedural_rejection_raw',\n            'institutional_respect_raw', 'institutional_subversion_raw',\n            'systemic_continuity_raw', 'systemic_replacement_raw',\n            'procedural_health_index', 'institutional_health_index', 'systemic_health_index'\n        ]\n        \n        results = {}\n        for dim in dimensions_to_test:\n            if dim not in analysis_df.columns:\n                results[dim] = {\"error\": f\"Dimension column '{dim}' not found.\"}\n                continue\n\n            groups = [group[dim].dropna().values for name, group in analysis_df.groupby('administration')]\n            groups = [g for g in groups if len(g) > 0]\n\n            if len(groups) < 2:\n                results[dim] = {\"error\": \"Insufficient groups for ANOVA.\"}\n                continue\n\n            f_stat, p_value = f_oneway(*groups)\n            results[dim] = {\"f_statistic\": f_stat, \"p_value\": p_value}\n\n        return {\n            \"test\": \"Dimensional Contribution Analysis (ANOVA)\",\n            \"results\": results,\n            \"groups_tested\": list(valid_admins)\n        }\n\n    except Exception as e:\n        return {\"error\": f\"An error occurred: {str(e)}\"}\n\ndef calculate_euclidean_distances(data, **kwargs):\n    \"\"\"\n    Calculates the Euclidean distance between mean administration profiles in 6D space.\n\n    This function addresses hypothesis H\u2087 by quantifying the similarity/dissimilarity\n    between administrations. It creates a 6-dimensional vector for each administration\n    based on the mean raw scores of the six primary dimensions and then calculates the\n    pairwise Euclidean distance between them.\n\n    Args:\n        data (pandas.DataFrame): DataFrame containing the analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary containing a matrix of pairwise distances, or None on error.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    from sklearn.metrics.pairwise import euclidean_distances\n\n    try:\n        if data.empty:\n            return {\"error\": \"Input data is empty.\"}\n\n        df = _add_metadata_to_df(data)\n        \n        analysis_df = df[df['administration'] != 'Bush H.W.']\n        \n        dimensions = [\n            'procedural_legitimacy_raw', 'procedural_rejection_raw',\n            'institutional_respect_raw', 'institutional_subversion_raw',\n            'systemic_continuity_raw', 'systemic_replacement_raw'\n        ]\n\n        # Calculate mean profile for each administration\n        mean_profiles = analysis_df.groupby('administration')[dimensions].mean()\n\n        if len(mean_profiles) < 2:\n            return {\"error\": \"Requires at least two administrations to compare.\"}\n\n        # Calculate pairwise distances\n        dist_matrix = euclidean_distances(mean_profiles)\n        \n        dist_df = pd.DataFrame(dist_matrix, index=mean_profiles.index, columns=mean_profiles.index)\n\n        return {\n            \"test\": \"Euclidean Distance Between Administration Profiles\",\n            \"distance_matrix_json\": dist_df.to_json(orient='split')\n        }\n\n    except Exception as e:\n        return {\"error\": f\"An error occurred: {str(e)}\"}\n\ndef perform_hierarchical_clustering(data, **kwargs):\n    \"\"\"\n    Performs hierarchical clustering on administration profiles.\n\n    This function provides another method to test hypothesis H\u2087 by grouping administrations\n    based on their similarity across the six primary constitutional dimensions. The output\n    is intended for visualization (e.g., creating a dendrogram).\n\n    Args:\n        data (pandas.DataFrame): DataFrame containing the analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary with the linkage matrix and labels for plotting, or None on error.\n    \"\"\"\n    import pandas as pd\n    from scipy.cluster.hierarchy import linkage, dendrogram\n\n    try:\n        if data.empty:\n            return {\"error\": \"Input data is empty.\"}\n\n        df = _add_metadata_to_df(data)\n        analysis_df = df[df['administration'] != 'Bush H.W.']\n        \n        dimensions = [\n            'procedural_legitimacy_raw', 'procedural_rejection_raw',\n            'institutional_respect_raw', 'institutional_subversion_raw',\n            'systemic_continuity_raw', 'systemic_replacement_raw'\n        ]\n\n        mean_profiles = analysis_df.groupby('administration')[dimensions].mean()\n\n        if len(mean_profiles) < 2:\n            return {\"error\": \"Clustering requires at least two administrations.\"}\n\n        # Perform hierarchical clustering using Ward's method\n        linkage_matrix = linkage(mean_profiles, method='ward')\n\n        return {\n            \"test\": \"Hierarchical Clustering of Administration Profiles\",\n            \"labels\": list(mean_profiles.index),\n            \"linkage_matrix\": linkage_matrix.tolist()\n        }\n\n    except Exception as e:\n        return {\"error\": f\"An error occurred: {str(e)}\"}\n\ndef calculate_cronbachs_alpha(data, **kwargs):\n    \"\"\"\n    Calculates Cronbach's alpha for the framework's health and pathology dimensions.\n\n    This function assesses the internal consistency and reliability of the measurement scales.\n    It calculates two alpha values:\n    1. 'Health Scale': Based on procedural_legitimacy, institutional_respect, and systemic_continuity.\n    2. 'Pathology Scale': Based on procedural_rejection, institutional_subversion, and systemic_replacement.\n\n    Args:\n        data (pandas.DataFrame): DataFrame containing the raw analysis scores.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary containing the alpha values for the health and pathology scales, or None on error.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    def _cronbach_alpha(df_items):\n        \"\"\"Helper to calculate alpha for a given set of items.\"\"\"\n        items = df_items.shape[1]\n        if items < 2:\n            return np.nan\n        \n        total_variance = df_items.sum(axis=1).var(ddof=1)\n        item_variances = df_items.var(ddof=1).sum()\n        \n        if total_variance == 0:\n            return 1.0 # Perfect correlation if no variance in total\n            \n        return (items / (items - 1)) * (1 - item_variances / total_variance)\n\n    try:\n        if data.empty or len(data) < 2:\n            return {\"error\": \"Insufficient data for Cronbach's alpha (requires >1 observation).\"}\n\n        health_dims = [\n            'procedural_legitimacy_raw',\n            'institutional_respect_raw',\n            'systemic_continuity_raw'\n        ]\n        pathology_dims = [\n            'procedural_rejection_raw',\n            'institutional_subversion_raw',\n            'systemic_replacement_raw'\n        ]\n\n        # Check for missing columns\n        for col in health_dims + pathology_dims:\n            if col not in data.columns:\n                return {\"error\": f\"Missing required column for calculation: {col}\"}\n\n        health_df = data[health_dims].dropna()\n        pathology_df = data[pathology_dims].dropna()\n\n        alpha_health = _cronbach_alpha(health_df) if len(health_df) > 1 else np.nan\n        alpha_pathology = _cronbach_alpha(pathology_df) if len(pathology_df) > 1 else np.nan\n\n        return {\n            \"test\": \"Cronbach's Alpha for Internal Consistency\",\n            \"health_scale_alpha\": alpha_health,\n            \"health_scale_items\": health_dims,\n            \"health_scale_n\": len(health_df),\n            \"pathology_scale_alpha\": alpha_pathology,\n            \"pathology_scale_items\": pathology_dims,\n            \"pathology_scale_n\": len(pathology_df)\n        }\n\n    except Exception as e:\n        return {\"error\": f\"An error occurred: {str(e)}\"}\n\ndef analyze_health_by_speech_type(data, **kwargs):\n    \"\"\"\n    Performs a one-way ANOVA on health indices grouped by speech type.\n\n    This function addresses Research Question 3 by testing whether constitutional health\n    scores differ significantly across different speech contexts (SOTU, Inaugural,\n    Joint Session). It runs an ANOVA for the main health and pathology indices.\n\n    Args:\n        data (pandas.DataFrame): DataFrame containing the analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary with ANOVA results for each tested metric, or None on error.\n    \"\"\"\n    import pandas as pd\n    from scipy.stats import f_oneway\n\n    try:\n        if data.empty:\n            return {\"error\": \"Input data is empty.\"}\n\n        df = _calculate_derived_metrics(data)\n        df = _add_metadata_to_df(df)\n\n        metrics_to_analyze = [\n            'constitutional_health_index',\n            'constitutional_pathology_index'\n        ]\n        \n        results = {}\n        for metric in metrics_to_analyze:\n            # Filter for speech types with more than one data point\n            type_counts = df['speech_type'].value_counts()\n            valid_types = type_counts[type_counts > 1].index\n            \n            if len(valid_types) < 2:\n                results[metric] = {\"error\": \"ANOVA requires at least two speech types with n > 1.\"}\n                continue\n            \n            analysis_df = df[df['speech_type'].isin(valid_types)]\n\n            groups = [group[metric].dropna().values for name, group in analysis_df.groupby('speech_type')]\n            groups = [g for g in groups if len(g) > 0]\n\n            if len(groups) < 2:\n                results[metric] = {\"error\": \"Insufficient groups for ANOVA after filtering.\"}\n                continue\n\n            f_stat, p_value = f_oneway(*groups)\n            results[metric] = {\n                \"f_statistic\": f_stat,\n                \"p_value\": p_value,\n                \"groups_tested\": list(valid_types)\n            }\n\n        return {\n            \"test\": \"ANOVA on Health Indices by Speech Type\",\n            \"results\": results\n        }\n\n    except Exception as e:\n        return {\"error\": f\"An error occurred: {str(e)}\"}\n\ndef run_complete_statistical_analysis(data: pd.DataFrame, alpha: float = 0.05) -> Dict[str, Any]:\n    \"\"\"\n    Run complete statistical analysis suite on the dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        alpha: Significance level for hypothesis tests (default: 0.05)\n        \n    Returns:\n        Dictionary with all statistical analysis results\n    \"\"\"\n    results = {\n        'analysis_metadata': {\n            'timestamp': pd.Timestamp.now().isoformat(),\n            'sample_size': len(data),\n            'alpha_level': alpha,\n            'variables_analyzed': list(data.select_dtypes(include=[np.number]).columns)\n        }\n    }\n    \n    # Get all analysis functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith(('calculate_', 'perform_', 'test_')) and \n            name != 'run_complete_statistical_analysis'):\n            try:\n                # Pass alpha parameter to functions that might need it\n                if 'alpha' in inspect.signature(obj).parameters:\n                    results[name] = obj(data, alpha=alpha)\n                else:\n                    results[name] = obj(data)\n            except Exception as e:\n                results[name] = {'error': f'Analysis failed: {str(e)}'}\n                \n    return results\n\n\ndef perform_statistical_analysis(data: pd.DataFrame) -> Dict[str, Any]:\n    \"\"\"\n    Template-compatible wrapper function for statistical analysis.\n    \n    This function is called by the universal notebook template and performs\n    comprehensive statistical analysis on the provided dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores and derived metrics\n        \n    Returns:\n        Dictionary containing all statistical analysis results\n    \"\"\"\n    return run_complete_statistical_analysis(data)\n\n\ndef generate_statistical_summary_report(analysis_results: Dict[str, Any]) -> str:\n    \"\"\"\n    Generate a human-readable summary report from statistical analysis results.\n    \n    Args:\n        analysis_results: Results from run_complete_statistical_analysis()\n        \n    Returns:\n        String containing formatted statistical report\n    \"\"\"\n    report_lines = []\n    report_lines.append(\"STATISTICAL ANALYSIS SUMMARY REPORT\")\n    report_lines.append(\"=\" * 50)\n    \n    metadata = analysis_results.get('analysis_metadata', {})\n    report_lines.append(f\"Analysis Timestamp: {metadata.get('timestamp', 'Unknown')}\")\n    report_lines.append(f\"Sample Size: {metadata.get('sample_size', 'Unknown')}\")\n    report_lines.append(f\"Alpha Level: {metadata.get('alpha_level', 'Unknown')}\")\n    report_lines.append(f\"Variables: {len(metadata.get('variables_analyzed', []))}\")\n    report_lines.append(\"\")\n    \n    # Summarize key findings\n    for analysis_name, result in analysis_results.items():\n        if analysis_name != 'analysis_metadata' and isinstance(result, dict):\n            if 'error' not in result:\n                report_lines.append(f\"{analysis_name.replace('_', ' ').title()}:\")\n                \n                # Extract key statistics based on analysis type\n                if 'p_value' in result:\n                    p_val = result['p_value']\n                    significance = \"significant\" if p_val < metadata.get('alpha_level', 0.05) else \"not significant\"\n                    report_lines.append(f\"  - p-value: {p_val:.4f} ({significance})\")\n                \n                if 'effect_size' in result:\n                    report_lines.append(f\"  - Effect size: {result['effect_size']:.4f}\")\n                \n                if 'correlation_matrix' in result:\n                    report_lines.append(f\"  - Correlation matrix generated with {len(result['correlation_matrix'])} variables\")\n                \n                if 'cronbach_alpha' in result:\n                    alpha_val = result['cronbach_alpha']\n                    reliability = \"excellent\" if alpha_val > 0.9 else \"good\" if alpha_val > 0.8 else \"acceptable\" if alpha_val > 0.7 else \"questionable\"\n                    report_lines.append(f\"  - Cronbach's \u03b1: {alpha_val:.3f} ({reliability})\")\n                \n                report_lines.append(\"\")\n            else:\n                report_lines.append(f\"{analysis_name}: ERROR - {result['error']}\")\n                report_lines.append(\"\")\n    \n    return \"\\n\".join(report_lines)\n",
  "cached_with_code": true
}