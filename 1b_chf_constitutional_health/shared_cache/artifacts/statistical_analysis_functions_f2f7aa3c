{
  "status": "success",
  "functions_generated": 5,
  "output_file": "automatedstatisticalanalysisagent_functions.py",
  "module_size": 21066,
  "function_code_content": "\"\"\"\nAutomated Statistical Analysis Functions\n========================================\n\nGenerated by AutomatedStatisticalAnalysisAgent for experiment: presidential_sotu_constitutional_health_trends\nDescription: Statistical analysis experiment\nGenerated: 2025-08-27T21:25:32.668762+00:00\n\nThis module contains automatically generated statistical analysis functions\nfor comprehensive data analysis including ANOVA, correlations, reliability,\nand hypothesis testing as appropriate for the research questions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport scipy.stats as stats\nfrom typing import Dict, Any, Optional, List, Tuple\nimport warnings\n\n# Suppress common statistical warnings for cleaner output\nwarnings.filterwarnings('ignore', category=RuntimeWarning)\n\n\ndef _calculate_all_metrics(df):\n    \"\"\"\n    Internal helper to calculate all derived metrics from the framework spec.\n    This function is intended to be used by the main analysis functions.\n    \n    Args:\n        df (pd.DataFrame): DataFrame with the base dimensional scores.\n        \n    Returns:\n        pd.DataFrame: DataFrame with added columns for derived metrics.\n    \"\"\"\n    # Use a copy to avoid SettingWithCopyWarning\n    data = df.copy()\n\n    # Define column names for clarity\n    pl_raw = 'procedural_legitimacy_raw'\n    pl_sal = 'procedural_legitimacy_salience'\n    pr_raw = 'procedural_rejection_raw'\n    pr_sal = 'procedural_rejection_salience'\n    ir_raw = 'institutional_respect_raw'\n    ir_sal = 'institutional_respect_salience'\n    is_raw = 'institutional_subversion_raw'\n    is_sal = 'institutional_subversion_salience'\n    sc_raw = 'systemic_continuity_raw'\n    sc_sal = 'systemic_continuity_salience'\n    sr_raw = 'systemic_replacement_raw'\n    sr_sal = 'systemic_replacement_salience'\n\n    # Ensure required columns exist\n    required_cols = [\n        pl_raw, pl_sal, pr_raw, pr_sal, ir_raw, ir_sal,\n        is_raw, is_sal, sc_raw, sc_sal, sr_raw, sr_sal\n    ]\n    if not all(col in data.columns for col in required_cols):\n        raise ValueError(\"Input DataFrame is missing required score/salience columns.\")\n\n    # Intermediate salience totals (with epsilon for stability)\n    epsilon = 0.001\n    data['procedural_health_salience_total'] = data[pl_sal] + data[pr_sal] + epsilon\n    data['institutional_health_salience_total'] = data[ir_sal] + data[is_sal] + epsilon\n    data['systemic_health_salience_total'] = data[sc_sal] + data[sr_sal] + epsilon\n    data['total_constitutional_salience'] = (\n        data['procedural_health_salience_total'] +\n        data['institutional_health_salience_total'] +\n        data['systemic_health_salience_total']\n    )\n\n    # Axis-level health indices\n    data['procedural_health_index'] = ((data[pl_raw] * data[pl_sal]) - (data[pr_raw] * data[pr_sal])) / data['procedural_health_salience_total']\n    data['institutional_health_index'] = ((data[ir_raw] * data[ir_sal]) - (data[is_raw] * data[is_sal])) / data['institutional_health_salience_total']\n    data['systemic_health_index'] = ((data[sc_raw] * data[sc_sal]) - (data[sr_raw] * data[sr_sal])) / data['systemic_health_salience_total']\n\n    # Summary metrics\n    numerator_chi = (\n        (data['procedural_health_index'] * data['procedural_health_salience_total']) +\n        (data['institutional_health_index'] * data['institutional_health_salience_total']) +\n        (data['systemic_health_index'] * data['systemic_health_salience_total'])\n    )\n    data['constitutional_health_index'] = numerator_chi / data['total_constitutional_salience']\n\n    numerator_cpi = (\n        (data[pr_raw] * data[pr_sal]) +\n        (data[is_raw] * data[is_sal]) +\n        (data[sr_raw] * data[sr_sal])\n    )\n    data['constitutional_pathology_index'] = numerator_cpi / data['total_constitutional_salience']\n    \n    return data\n\ndef calculate_descriptive_statistics(data, **kwargs):\n    \"\"\"\n    Calculates descriptive statistics for key constitutional health metrics.\n    This function computes the derived metrics as defined in the framework\n    and then provides summary statistics (mean, std, min, max, quartiles)\n    for the primary health and pathology indices, as well as axis-level indices.\n    This helps answer RQ1: \"What patterns emerge in constitutional health across presidential rhetoric?\"\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the analysis data with columns\n                             matching the 'ACTUAL DATA STRUCTURE'.\n        **kwargs: Additional parameters (not used in this function).\n\n    Returns:\n        dict: A dictionary containing descriptive statistics for key metrics,\n              or None if an error occurs.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        if data.empty:\n            return {\"message\": \"Input data is empty.\"}\n\n        # Calculate all derived metrics using the helper logic\n        data_with_metrics = _calculate_all_metrics(data)\n\n        # Select key metrics for descriptive analysis\n        metrics_to_describe = [\n            'constitutional_health_index',\n            'constitutional_pathology_index',\n            'procedural_health_index',\n            'institutional_health_index',\n            'systemic_health_index'\n        ]\n        \n        # Ensure the metrics were calculated and exist\n        existing_metrics = [m for m in metrics_to_describe if m in data_with_metrics.columns]\n        if not existing_metrics:\n            return {\"error\": \"Could not calculate any descriptive metrics.\"}\n\n        # Generate descriptive statistics\n        desc_stats = data_with_metrics[existing_metrics].describe()\n\n        return desc_stats.to_dict()\n\n    except Exception as e:\n        # In a real system, one might log the error `e`\n        return None\n\ndef analyze_dimensional_variation(data, **kwargs):\n    \"\"\"\n    Analyzes and ranks the variation of each constitutional dimension.\n    This function calculates the standard deviation for both the raw scores and\n    salience scores of the six core dimensions, as well as the three axis-level\n    health indices. The results are sorted to highlight which dimensions show\n    the most and least variation across the corpus. This helps answer RQ2:\n    \"Which constitutional dimensions show the most variation and why?\"\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the analysis data.\n        **kwargs: Additional parameters (not used in this function).\n\n    Returns:\n        dict: A dictionary with sorted standard deviations for scores and salience,\n              or None if an error occurs.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        if data.empty:\n            return {\"message\": \"Input data is empty.\"}\n\n        # Calculate derived metrics to get axis-level indices\n        data_with_metrics = _calculate_all_metrics(data)\n\n        # Define columns for variation analysis\n        raw_score_cols = [col for col in data.columns if '_raw' in col]\n        salience_cols = [col for col in data.columns if '_salience' in col]\n        index_cols = [\n            'procedural_health_index',\n            'institutional_health_index',\n            'systemic_health_index'\n        ]\n\n        # Calculate standard deviation for each group of columns\n        raw_score_std = data_with_metrics[raw_score_cols].std().sort_values(ascending=False)\n        salience_std = data_with_metrics[salience_cols].std().sort_values(ascending=False)\n        index_std = data_with_metrics[index_cols].std().sort_values(ascending=False)\n\n        results = {\n            \"raw_score_variation (std_dev)\": raw_score_std.to_dict(),\n            \"salience_variation (std_dev)\": salience_std.to_dict(),\n            \"axis_index_variation (std_dev)\": index_std.to_dict()\n        }\n        \n        return results\n\n    except Exception as e:\n        return None\n\ndef analyze_context_effects(data, **kwargs):\n    \"\"\"\n    Analyzes how constitutional health scores vary by speech context.\n    This function attempts to load speaker and context metadata from a corpus\n    manifest file. If successful, it groups the data by speech context (e.g.,\n    'Inaugural', 'SOTU') and calculates the average constitutional health and\n    pathology scores for each context. This addresses RQ3: \"How do different\n    speech contexts affect constitutional health?\"\n\n    CRITICAL: This function requires a corpus manifest file for context metadata.\n    It does NOT parse filenames, per framework specification.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the analysis data.\n        **kwargs:\n            manifest_path (str): The file path to the corpus manifest JSON file.\n                                 The manifest should be a list of dicts, with\n                                 each dict containing 'document_name' and other\n                                 metadata like 'context' and 'speaker'.\n\n    Returns:\n        dict: A dictionary of grouped statistics by context, a message indicating\n              missing metadata, or None if an error occurs.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    import json\n    from pathlib import Path\n\n    try:\n        if data.empty:\n            return {\"message\": \"Input data is empty.\"}\n\n        manifest_path = kwargs.get('manifest_path')\n        if not manifest_path or not Path(manifest_path).is_file():\n            return {\n                \"status\": \"skipped\",\n                \"reason\": \"Cannot perform context analysis. Corpus manifest not found or path not provided in kwargs['manifest_path'].\"\n            }\n\n        # Load manifest and merge with data\n        with open(manifest_path, 'r') as f:\n            manifest = json.load(f)\n        \n        manifest_df = pd.DataFrame(manifest)\n        if 'document_name' not in manifest_df.columns or 'context' not in manifest_df.columns:\n             return {\n                \"status\": \"error\",\n                \"reason\": \"Corpus manifest must contain 'document_name' and 'context' columns.\"\n            }\n\n        # Merge manifest metadata into the main dataframe\n        data_with_meta = pd.merge(data, manifest_df, on='document_name', how='left')\n        \n        if 'context' not in data_with_meta.columns or data_with_meta['context'].isnull().all():\n            return {\n                \"status\": \"skipped\",\n                \"reason\": \"No context information could be merged from the manifest.\"\n            }\n\n        # Calculate derived metrics\n        data_with_metrics = _calculate_all_metrics(data_with_meta)\n\n        # Group by context and calculate mean scores\n        context_analysis = data_with_metrics.groupby('context')[[\n            'constitutional_health_index',\n            'constitutional_pathology_index',\n            'procedural_health_index',\n            'institutional_health_index',\n            'systemic_health_index'\n        ]].mean()\n\n        return context_analysis.to_dict('index')\n\n    except Exception as e:\n        return None\n\ndef calculate_metric_correlations(data, **kwargs):\n    \"\"\"\n    Computes the correlation matrix for all constitutional health metrics.\n    This function first calculates all derived indices, then computes a Pearson\n    correlation matrix for the six base raw scores, six base salience scores,\n    and all derived health and pathology indices. This helps uncover relationships\n    between different dimensions of constitutional discourse, addressing RQ4:\n    \"What rhetorical strategies and linguistic patterns correlate with higher/lower\n    constitutional health scores?\" by examining internal metric correlations.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the analysis data.\n        **kwargs: Additional parameters (not used in this function).\n\n    Returns:\n        dict: A dictionary representing the correlation matrix, or None if an error occurs.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        if data.empty:\n            return {\"message\": \"Input data is empty.\"}\n\n        # Calculate all derived metrics\n        data_with_metrics = _calculate_all_metrics(data)\n\n        # Select all numeric columns for correlation analysis\n        cols_to_correlate = [\n            'procedural_legitimacy_raw', 'procedural_legitimacy_salience',\n            'procedural_rejection_raw', 'procedural_rejection_salience',\n            'institutional_respect_raw', 'institutional_respect_salience',\n            'institutional_subversion_raw', 'institutional_subversion_salience',\n            'systemic_continuity_raw', 'systemic_continuity_salience',\n            'systemic_replacement_raw', 'systemic_replacement_salience',\n            'procedural_health_index', 'institutional_health_index',\n            'systemic_health_index', 'constitutional_health_index',\n            'constitutional_pathology_index'\n        ]\n        \n        # Ensure columns exist before trying to correlate\n        existing_cols = [c for c in cols_to_correlate if c in data_with_metrics.columns]\n        if len(existing_cols) < 2:\n            return {\"error\": \"Not enough numeric columns to calculate correlation.\"}\n\n        correlation_matrix = data_with_metrics[existing_cols].corr()\n\n        # Clean up the result for JSON serialization (remove NaNs)\n        return correlation_matrix.fillna(0).to_dict()\n\n    except Exception as e:\n        return None\n\ndef detect_constitutional_health_anomalies(data, **kwargs):\n    \"\"\"\n    Identifies documents that are statistical outliers in terms of constitutional health.\n    This function calculates the 'constitutional_health_index' and\n    'constitutional_pathology_index' for all documents. It then identifies\n    anomalies as documents where either index is more than a specified number\n    of standard deviations from the corpus mean. This helps answer RQ5:\n    \"Are there unexpected constitutional health patterns, outliers, or anomalies?\"\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the analysis data.\n        **kwargs:\n            std_dev_threshold (float): The number of standard deviations from the mean\n                                       to use as the outlier threshold. Defaults to 2.0.\n\n    Returns:\n        dict: A dictionary containing lists of documents identified as high/low\n              health anomalies and high pathology anomalies, or None if an error occurs.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        if data.empty or len(data) < 2:\n            return {\"message\": \"Insufficient data for anomaly detection (requires at least 2 documents).\"}\n\n        std_dev_threshold = float(kwargs.get('std_dev_threshold', 2.0))\n\n        # Calculate derived metrics\n        data_with_metrics = _calculate_all_metrics(data)\n\n        # Calculate mean and std dev for the two main indices\n        health_mean = data_with_metrics['constitutional_health_index'].mean()\n        health_std = data_with_metrics['constitutional_health_index'].std()\n        pathology_mean = data_with_metrics['constitutional_pathology_index'].mean()\n        pathology_std = data_with_metrics['constitutional_pathology_index'].std()\n\n        # Define anomaly thresholds\n        low_health_threshold = health_mean - (std_dev_threshold * health_std)\n        high_health_threshold = health_mean + (std_dev_threshold * health_std)\n        high_pathology_threshold = pathology_mean + (std_dev_threshold * pathology_std)\n\n        # Find anomalies\n        low_health_anomalies = data_with_metrics[\n            data_with_metrics['constitutional_health_index'] < low_health_threshold\n        ]\n        high_health_anomalies = data_with_metrics[\n            data_with_metrics['constitutional_health_index'] > high_health_threshold\n        ]\n        high_pathology_anomalies = data_with_metrics[\n            data_with_metrics['constitutional_pathology_index'] > high_pathology_threshold\n        ]\n\n        results = {\n            \"analysis_parameters\": {\n                \"std_dev_threshold\": std_dev_threshold,\n                \"health_index_mean\": health_mean,\n                \"health_index_std\": health_std,\n                \"pathology_index_mean\": pathology_mean,\n                \"pathology_index_std\": pathology_std,\n            },\n            \"low_health_anomalies\": low_health_anomalies[['document_name', 'constitutional_health_index']].to_dict('records'),\n            \"high_health_anomalies\": high_health_anomalies[['document_name', 'constitutional_health_index']].to_dict('records'),\n            \"high_pathology_anomalies\": high_pathology_anomalies[['document_name', 'constitutional_pathology_index']].to_dict('records')\n        }\n\n        return results\n\n    except Exception as e:\n        return None\n\ndef run_complete_statistical_analysis(data: pd.DataFrame, alpha: float = 0.05) -> Dict[str, Any]:\n    \"\"\"\n    Run complete statistical analysis suite on the dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        alpha: Significance level for hypothesis tests (default: 0.05)\n        \n    Returns:\n        Dictionary with all statistical analysis results\n    \"\"\"\n    results = {\n        'analysis_metadata': {\n            'timestamp': pd.Timestamp.now().isoformat(),\n            'sample_size': len(data),\n            'alpha_level': alpha,\n            'variables_analyzed': list(data.select_dtypes(include=[np.number]).columns)\n        }\n    }\n    \n    # Get all analysis functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith(('calculate_', 'perform_', 'test_')) and \n            name != 'run_complete_statistical_analysis'):\n            try:\n                # Pass alpha parameter to functions that might need it\n                if 'alpha' in inspect.signature(obj).parameters:\n                    results[name] = obj(data, alpha=alpha)\n                else:\n                    results[name] = obj(data)\n            except Exception as e:\n                results[name] = {'error': f'Analysis failed: {str(e)}'}\n                \n    return results\n\n\ndef perform_statistical_analysis(data: pd.DataFrame) -> Dict[str, Any]:\n    \"\"\"\n    Template-compatible wrapper function for statistical analysis.\n    \n    This function is called by the universal notebook template and performs\n    comprehensive statistical analysis on the provided dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores and derived metrics\n        \n    Returns:\n        Dictionary containing all statistical analysis results\n    \"\"\"\n    return run_complete_statistical_analysis(data)\n\n\ndef generate_statistical_summary_report(analysis_results: Dict[str, Any]) -> str:\n    \"\"\"\n    Generate a human-readable summary report from statistical analysis results.\n    \n    Args:\n        analysis_results: Results from run_complete_statistical_analysis()\n        \n    Returns:\n        String containing formatted statistical report\n    \"\"\"\n    report_lines = []\n    report_lines.append(\"STATISTICAL ANALYSIS SUMMARY REPORT\")\n    report_lines.append(\"=\" * 50)\n    \n    metadata = analysis_results.get('analysis_metadata', {})\n    report_lines.append(f\"Analysis Timestamp: {metadata.get('timestamp', 'Unknown')}\")\n    report_lines.append(f\"Sample Size: {metadata.get('sample_size', 'Unknown')}\")\n    report_lines.append(f\"Alpha Level: {metadata.get('alpha_level', 'Unknown')}\")\n    report_lines.append(f\"Variables: {len(metadata.get('variables_analyzed', []))}\")\n    report_lines.append(\"\")\n    \n    # Summarize key findings\n    for analysis_name, result in analysis_results.items():\n        if analysis_name != 'analysis_metadata' and isinstance(result, dict):\n            if 'error' not in result:\n                report_lines.append(f\"{analysis_name.replace('_', ' ').title()}:\")\n                \n                # Extract key statistics based on analysis type\n                if 'p_value' in result:\n                    p_val = result['p_value']\n                    significance = \"significant\" if p_val < metadata.get('alpha_level', 0.05) else \"not significant\"\n                    report_lines.append(f\"  - p-value: {p_val:.4f} ({significance})\")\n                \n                if 'effect_size' in result:\n                    report_lines.append(f\"  - Effect size: {result['effect_size']:.4f}\")\n                \n                if 'correlation_matrix' in result:\n                    report_lines.append(f\"  - Correlation matrix generated with {len(result['correlation_matrix'])} variables\")\n                \n                if 'cronbach_alpha' in result:\n                    alpha_val = result['cronbach_alpha']\n                    reliability = \"excellent\" if alpha_val > 0.9 else \"good\" if alpha_val > 0.8 else \"acceptable\" if alpha_val > 0.7 else \"questionable\"\n                    report_lines.append(f\"  - Cronbach's \u03b1: {alpha_val:.3f} ({reliability})\")\n                \n                report_lines.append(\"\")\n            else:\n                report_lines.append(f\"{analysis_name}: ERROR - {result['error']}\")\n                report_lines.append(\"\")\n    \n    return \"\\n\".join(report_lines)\n",
  "cached_with_code": true
}