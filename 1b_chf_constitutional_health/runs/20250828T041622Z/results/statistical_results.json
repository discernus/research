{
  "generation_metadata": {
    "status": "success",
    "functions_generated": 11,
    "output_file": "automatedstatisticalanalysisagent_functions.py",
    "module_size": 26335,
    "function_code_content": "\"\"\"\nAutomated Statistical Analysis Functions\n========================================\n\nGenerated by AutomatedStatisticalAnalysisAgent for experiment: presidential_sotu_constitutional_health_trends\nDescription: Statistical analysis experiment\nGenerated: 2025-08-28T04:15:22.797869+00:00\n\nThis module contains automatically generated statistical analysis functions\nfor comprehensive data analysis including ANOVA, correlations, reliability,\nand hypothesis testing as appropriate for the research questions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport scipy.stats as stats\nfrom typing import Dict, Any, Optional, List, Tuple\nimport warnings\n\n# Suppress common statistical warnings for cleaner output\nwarnings.filterwarnings('ignore', category=RuntimeWarning)\n\n\ndef calculate_derived_metrics(data, **kwargs):\n    \"\"\"\n    Calculates all derived metrics based on the Constitutional Health Framework v10.0 specification.\n\n    This function implements the formulas for axis-level and summary metrics, including\n    salience-weighted health indices and the overall constitutional health and pathology indices.\n    It is a necessary precursor to most other statistical analyses.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the raw and salience scores for the 6 base dimensions.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        pd.DataFrame: The input DataFrame with added columns for all derived metrics, or None on error.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # Ensure required columns exist\n        required_cols = [\n            'procedural_legitimacy_raw', 'procedural_legitimacy_salience',\n            'procedural_rejection_raw', 'procedural_rejection_salience',\n            'institutional_respect_raw', 'institutional_respect_salience',\n            'institutional_subversion_raw', 'institutional_subversion_salience',\n            'systemic_continuity_raw', 'systemic_continuity_salience',\n            'systemic_replacement_raw', 'systemic_replacement_salience'\n        ]\n        if not all(col in data.columns for col in required_cols):\n            # This is a critical error, can't proceed\n            return None\n            \n        # Use the internal helper to perform calculations\n        data_with_metrics = _calculate_all_derived_metrics(data.copy())\n        \n        return data_with_metrics\n    except Exception:\n        return None\n\ndef calculate_descriptive_statistics(data, **kwargs):\n    \"\"\"\n    Calculates descriptive statistics for key constitutional health metrics, grouped by administration.\n\n    This analysis addresses RQ1 by providing a summary of central tendency and dispersion\n    for the primary outcome variables, allowing for initial pattern discovery.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary of descriptive statistics tables (as JSON) or None on error.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # Pre-processing\n        df = _extract_metadata_from_filename(data.copy())\n        df = _calculate_all_derived_metrics(df)\n\n        if 'administration' not in df.columns or 'constitutional_health_index' not in df.columns:\n            return None\n\n        metrics_to_describe = [\n            'constitutional_health_index',\n            'constitutional_pathology_index',\n            'procedural_health_index',\n            'institutional_health_index',\n            'systemic_health_index'\n        ]\n        \n        # Group by administration and calculate descriptive stats\n        desc_stats = df.groupby('administration')[metrics_to_describe].agg(['mean', 'std', 'min', 'max', 'count']).reset_index()\n        \n        # Flatten multi-index columns\n        desc_stats.columns = ['_'.join(col).strip() if col[1] else col[0] for col in desc_stats.columns.values]\n        desc_stats = desc_stats.rename(columns={'administration_': 'administration'})\n\n        return {\n            \"descriptive_statistics_by_administration\": json.loads(desc_stats.to_json(orient='records'))\n        }\n    except Exception:\n        return None\n\ndef perform_anova_on_health_index(data, **kwargs):\n    \"\"\"\n    Performs a one-way ANOVA to test for significant differences in the constitutional_health_index\n    across presidential administrations.\n\n    This function directly tests the primary hypothesis (H\u2081) of the experiment. It calculates\n    the F-statistic, p-value, and eta-squared (\u03b7\u00b2) effect size to determine if at least\n    one administration's mean health score is significantly different from the others.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary with ANOVA results (F-statistic, p-value, eta-squared) or None on error.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    from scipy.stats import f_oneway\n\n    try:\n        # Pre-processing\n        df = _extract_metadata_from_filename(data.copy())\n        df = _calculate_all_derived_metrics(df)\n\n        if 'administration' not in df.columns or 'constitutional_health_index' not in df.columns:\n            return None\n        \n        df.dropna(subset=['administration', 'constitutional_health_index'], inplace=True)\n        \n        groups = df.groupby('administration')['constitutional_health_index'].apply(list)\n        \n        if len(groups) < 2:\n            return {\"error\": \"ANOVA requires at least two administration groups.\"}\n\n        # Filter out groups with less than 2 samples\n        valid_groups = [g for g in groups if len(g) >= 2]\n        if len(valid_groups) < 2:\n            return {\"error\": \"ANOVA requires at least two groups with sufficient data.\"}\n\n        f_stat, p_value = f_oneway(*valid_groups)\n\n        # Calculate Eta-squared (\u03b7\u00b2)\n        ss_between = sum(len(g) * (np.mean(g) - df['constitutional_health_index'].mean())**2 for g in valid_groups)\n        ss_total = sum((x - df['constitutional_health_index'].mean())**2 for x in df['constitutional_health_index'])\n        eta_squared = ss_between / ss_total if ss_total > 0 else 0\n\n        return {\n            \"test\": \"One-Way ANOVA on Constitutional Health Index\",\n            \"f_statistic\": f_stat,\n            \"p_value\": p_value,\n            \"eta_squared_effect_size\": eta_squared,\n            \"significant\": p_value < 0.05\n        }\n    except Exception:\n        return None\n\ndef perform_tukey_hsd_test(data, **kwargs):\n    \"\"\"\n    Performs a Tukey HSD post-hoc test for pairwise comparisons of the constitutional_health_index\n    between presidential administrations.\n\n    This function addresses the secondary hypotheses (H\u2082-H\u2085) by identifying which specific\n    pairs of administrations have statistically significant differences in their mean health scores,\n    following a significant ANOVA result.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary containing the Tukey HSD results table (as JSON) or None on error.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    from statsmodels.stats.multicomp import pairwise_tukeyhsd\n\n    try:\n        # Pre-processing\n        df = _extract_metadata_from_filename(data.copy())\n        df = _calculate_all_derived_metrics(df)\n\n        if 'administration' not in df.columns or 'constitutional_health_index' not in df.columns:\n            return None\n            \n        df.dropna(subset=['administration', 'constitutional_health_index'], inplace=True)\n        \n        if df['administration'].nunique() < 2:\n            return {\"error\": \"Tukey HSD requires at least two administration groups.\"}\n\n        tukey_result = pairwise_tukeyhsd(endog=df['constitutional_health_index'],\n                                         groups=df['administration'],\n                                         alpha=0.05)\n        \n        results_df = pd.DataFrame(data=tukey_result._results_table.data[1:], columns=tukey_result._results_table.data[0])\n\n        return {\n            \"test\": \"Tukey HSD for Pairwise Administration Comparisons\",\n            \"results\": json.loads(results_df.to_json(orient='records'))\n        }\n    except Exception:\n        return None\n\ndef perform_levenes_test(data, **kwargs):\n    \"\"\"\n    Performs Levene's test for homogeneity of variances in constitutional_health_index\n    across presidential administrations.\n\n    This function directly tests hypothesis H\u2086, which posits that the Trump administration\n    shows significantly higher variance in constitutional health scores than other administrations.\n    A significant result indicates that the assumption of equal variances for ANOVA is violated.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary with Levene's test results (statistic, p-value) or None on error.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    from scipy.stats import levene\n\n    try:\n        # Pre-processing\n        df = _extract_metadata_from_filename(data.copy())\n        df = _calculate_all_derived_metrics(df)\n\n        if 'administration' not in df.columns or 'constitutional_health_index' not in df.columns:\n            return None\n            \n        df.dropna(subset=['administration', 'constitutional_health_index'], inplace=True)\n        \n        groups = [group['constitutional_health_index'].values for name, group in df.groupby('administration')]\n        \n        if len(groups) < 2:\n            return {\"error\": \"Levene's test requires at least two administration groups.\"}\n\n        # Filter out groups with less than 2 samples\n        valid_groups = [g for g in groups if len(g) >= 2]\n        if len(valid_groups) < 2:\n            return {\"error\": \"Levene's test requires at least two groups with sufficient data.\"}\n\n        stat, p_value = levene(*valid_groups)\n\n        return {\n            \"test\": \"Levene's Test for Homogeneity of Variances\",\n            \"statistic\": stat,\n            \"p_value\": p_value,\n            \"variances_are_equal\": p_value >= 0.05\n        }\n    except Exception:\n        return None\n\ndef analyze_speech_context_effects(data, **kwargs):\n    \"\"\"\n    Analyzes the effect of speech context (SOTU, Inaugural, Joint Session) on constitutional health.\n\n    This function addresses RQ3 by using a one-way ANOVA to determine if there are\n    statistically significant differences in the constitutional_health_index across\n    different types of presidential addresses.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary with ANOVA results for speech context or None on error.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    from scipy.stats import f_oneway\n\n    try:\n        # Pre-processing\n        df = _extract_metadata_from_filename(data.copy())\n        df = _calculate_all_derived_metrics(df)\n\n        if 'speech_type' not in df.columns or 'constitutional_health_index' not in df.columns:\n            return None\n            \n        df.dropna(subset=['speech_type', 'constitutional_health_index'], inplace=True)\n        \n        groups = df.groupby('speech_type')['constitutional_health_index'].apply(list)\n        \n        if len(groups) < 2:\n            return {\"error\": \"Analysis requires at least two speech_type groups.\"}\n\n        valid_groups = [g for g in groups if len(g) >= 2]\n        if len(valid_groups) < 2:\n            return {\"error\": \"ANOVA requires at least two speech_type groups with sufficient data.\"}\n\n        f_stat, p_value = f_oneway(*valid_groups)\n\n        return {\n            \"test\": \"One-Way ANOVA on Constitutional Health Index by Speech Context\",\n            \"f_statistic\": f_stat,\n            \"p_value\": p_value,\n            \"significant\": p_value < 0.05\n        }\n    except Exception:\n        return None\n\ndef calculate_correlation_matrix(data, **kwargs):\n    \"\"\"\n    Calculates the Pearson correlation matrix for the primary and derived constitutional metrics.\n\n    This analysis addresses RQ4 by exploring the relationships between different\n    dimensions of constitutional health. It can help identify which dimensions tend to\n    co-occur, providing insight into rhetorical strategies.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary containing the correlation matrix (as JSON) or None on error.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # Pre-processing\n        df = _calculate_all_derived_metrics(data.copy())\n\n        metrics_to_correlate = [\n            'procedural_legitimacy_raw', 'procedural_rejection_raw',\n            'institutional_respect_raw', 'institutional_subversion_raw',\n            'systemic_continuity_raw', 'systemic_replacement_raw',\n            'procedural_health_index', 'institutional_health_index',\n            'systemic_health_index', 'constitutional_health_index',\n            'constitutional_pathology_index'\n        ]\n        \n        # Ensure all columns exist and are numeric\n        valid_cols = [col for col in metrics_to_correlate if col in df.columns and pd.api.types.is_numeric_dtype(df[col])]\n        if len(valid_cols) < 2:\n            return None\n\n        corr_matrix = df[valid_cols].corr()\n\n        return {\n            \"correlation_matrix\": json.loads(corr_matrix.to_json())\n        }\n    except Exception:\n        return None\n\ndef calculate_cronbachs_alpha(data, **kwargs):\n    \"\"\"\n    Calculates Cronbach's alpha to assess the internal consistency and reliability of the\n    constitutional health and pathology dimensions.\n\n    This function evaluates the reliability of the measurement scales as specified in the\n    experiment's \"Enhanced Statistical Analysis\" section. It computes alpha for two constructs:\n    1. Health (Legitimacy, Respect, Continuity)\n    2. Pathology (Rejection, Subversion, Replacement)\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the raw dimensional scores.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary with Cronbach's alpha for health and pathology scales, or None on error.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    import pingouin as pg\n\n    try:\n        df = data.copy()\n        \n        health_dims = ['procedural_legitimacy_raw', 'institutional_respect_raw', 'systemic_continuity_raw']\n        pathology_dims = ['procedural_rejection_raw', 'institutional_subversion_raw', 'systemic_replacement_raw']\n\n        if not all(col in df.columns for col in health_dims + pathology_dims):\n            return None\n\n        # Calculate alpha for health dimensions\n        health_alpha = pg.cronbach_alpha(data=df[health_dims])\n        \n        # Calculate alpha for pathology dimensions\n        pathology_alpha = pg.cronbach_alpha(data=df[pathology_dims])\n\n        return {\n            \"health_construct_reliability\": {\n                \"cronbachs_alpha\": health_alpha[0],\n                \"confidence_interval_95\": list(health_alpha[1])\n            },\n            \"pathology_construct_reliability\": {\n                \"cronbachs_alpha\": pathology_alpha[0],\n                \"confidence_interval_95\": list(pathology_alpha[1])\n            }\n        }\n    except Exception:\n        return None\n\ndef perform_hierarchical_clustering(data, **kwargs):\n    \"\"\"\n    Performs hierarchical clustering on administration profiles to test for similarity.\n\n    This function addresses hypothesis H\u2087 by grouping administrations based on their\n    mean scores across the six core constitutional dimensions. The resulting dendrogram\n    data can be visualized to see if administrations cluster as expected (e.g., by party)\n    or if there are unexpected similarities, such as between Biden and Trump.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary containing the linkage matrix for dendrogram plotting, or None on error.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    from sklearn.preprocessing import StandardScaler\n    from scipy.cluster.hierarchy import linkage\n\n    try:\n        # Pre-processing\n        df = _extract_metadata_from_filename(data.copy())\n        \n        dims = [\n            'procedural_legitimacy_raw', 'procedural_rejection_raw',\n            'institutional_respect_raw', 'institutional_subversion_raw',\n            'systemic_continuity_raw', 'systemic_replacement_raw'\n        ]\n        if not all(col in df.columns for col in dims):\n            return None\n\n        # Create administration profiles by averaging scores\n        admin_profiles = df.groupby('administration')[dims].mean()\n        \n        if len(admin_profiles) < 2:\n            return {\"error\": \"Clustering requires at least two administration profiles.\"}\n\n        # Scale the data\n        scaler = StandardScaler()\n        scaled_profiles = scaler.fit_transform(admin_profiles)\n\n        # Perform hierarchical clustering using Ward's method\n        linked = linkage(scaled_profiles, method='ward')\n\n        return {\n            \"test\": \"Hierarchical Clustering of Administration Profiles\",\n            \"linkage_matrix\": linked.tolist(),\n            \"labels\": admin_profiles.index.tolist()\n        }\n    except Exception:\n        return None\n\ndef calculate_euclidean_distances(data, **kwargs):\n    \"\"\"\n    Calculates the pairwise Euclidean distances between administration profiles.\n\n    This function provides a quantitative measure for hypothesis H\u2087, allowing for direct\n    comparison of similarity between administrations (e.g., |Biden - Trump| vs.\n    |Clinton - Bush W.|). The profiles are based on mean scores across the six core dimensions.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary containing the distance matrix (as JSON), or None on error.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    from sklearn.metrics.pairwise import euclidean_distances\n\n    try:\n        # Pre-processing\n        df = _extract_metadata_from_filename(data.copy())\n        \n        dims = [\n            'procedural_legitimacy_raw', 'procedural_rejection_raw',\n            'institutional_respect_raw', 'institutional_subversion_raw',\n            'systemic_continuity_raw', 'systemic_replacement_raw'\n        ]\n        if not all(col in df.columns for col in dims):\n            return None\n\n        # Create administration profiles\n        admin_profiles = df.groupby('administration')[dims].mean()\n        \n        if len(admin_profiles) < 2:\n            return {\"error\": \"Distance calculation requires at least two administration profiles.\"}\n\n        # Calculate pairwise Euclidean distances\n        dist_matrix = euclidean_distances(admin_profiles)\n        \n        dist_df = pd.DataFrame(dist_matrix, index=admin_profiles.index, columns=admin_profiles.index)\n\n        return {\n            \"test\": \"Euclidean Distances Between Administration Profiles\",\n            \"distance_matrix\": json.loads(dist_df.to_json())\n        }\n    except Exception:\n        return None\n\ndef analyze_dimensional_contribution(data, **kwargs):\n    \"\"\"\n    Analyzes which constitutional health axes contribute most to inter-administration differences.\n\n    This function addresses the \"Dimensional Contribution Analysis\" requirement by running\n    a separate one-way ANOVA on each of the three axis-level health indices (procedural,\n    institutional, systemic). The effect size (eta-squared) for each ANOVA indicates\n    the proportion of variance in that axis's score that is explained by the administration.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary of ANOVA results for each health axis, or None on error.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    from scipy.stats import f_oneway\n\n    try:\n        # Pre-processing\n        df = _extract_metadata_from_filename(data.copy())\n        df = _calculate_all_derived_metrics(df)\n\n        axes = ['procedural_health_index', 'institutional_health_index', 'systemic_health_index']\n        if not all(col in df.columns for col in axes + ['administration']):\n            return None\n            \n        df.dropna(subset=axes + ['administration'], inplace=True)\n        \n        results = {}\n        \n        for axis in axes:\n            groups = [group[axis].values for name, group in df.groupby('administration')]\n            \n            if len(groups) < 2: continue\n            valid_groups = [g for g in groups if len(g) >= 2]\n            if len(valid_groups) < 2: continue\n\n            f_stat, p_value = f_oneway(*valid_groups)\n\n            # Calculate Eta-squared (\u03b7\u00b2)\n            ss_between = sum(len(g) * (np.mean(g) - df[axis].mean())**2 for g in valid_groups)\n            ss_total = sum((x - df[axis].mean())**2 for x in df[axis])\n            eta_squared = ss_between / ss_total if ss_total > 0 else 0\n\n            results[axis] = {\n                \"f_statistic\": f_stat,\n                \"p_value\": p_value,\n                \"eta_squared_effect_size\": eta_squared,\n                \"significant\": p_value < 0.05\n            }\n\n        return {\n            \"test\": \"ANOVA on Health Axes to Determine Dimensional Contribution\",\n            \"results_by_axis\": results\n        } if results else None\n    except Exception:\n        return None\n\ndef run_complete_statistical_analysis(data: pd.DataFrame, alpha: float = 0.05) -> Dict[str, Any]:\n    \"\"\"\n    Run complete statistical analysis suite on the dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        alpha: Significance level for hypothesis tests (default: 0.05)\n        \n    Returns:\n        Dictionary with all statistical analysis results\n    \"\"\"\n    results = {\n        'analysis_metadata': {\n            'timestamp': pd.Timestamp.now().isoformat(),\n            'sample_size': len(data),\n            'alpha_level': alpha,\n            'variables_analyzed': list(data.select_dtypes(include=[np.number]).columns)\n        }\n    }\n    \n    # Get all analysis functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith(('calculate_', 'perform_', 'test_')) and \n            name != 'run_complete_statistical_analysis'):\n            try:\n                # Pass alpha parameter to functions that might need it\n                if 'alpha' in inspect.signature(obj).parameters:\n                    results[name] = obj(data, alpha=alpha)\n                else:\n                    results[name] = obj(data)\n            except Exception as e:\n                results[name] = {'error': f'Analysis failed: {str(e)}'}\n                \n    return results\n\n\ndef perform_statistical_analysis(data: pd.DataFrame) -> Dict[str, Any]:\n    \"\"\"\n    Template-compatible wrapper function for statistical analysis.\n    \n    This function is called by the universal notebook template and performs\n    comprehensive statistical analysis on the provided dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores and derived metrics\n        \n    Returns:\n        Dictionary containing all statistical analysis results\n    \"\"\"\n    return run_complete_statistical_analysis(data)\n\n\ndef generate_statistical_summary_report(analysis_results: Dict[str, Any]) -> str:\n    \"\"\"\n    Generate a human-readable summary report from statistical analysis results.\n    \n    Args:\n        analysis_results: Results from run_complete_statistical_analysis()\n        \n    Returns:\n        String containing formatted statistical report\n    \"\"\"\n    report_lines = []\n    report_lines.append(\"STATISTICAL ANALYSIS SUMMARY REPORT\")\n    report_lines.append(\"=\" * 50)\n    \n    metadata = analysis_results.get('analysis_metadata', {})\n    report_lines.append(f\"Analysis Timestamp: {metadata.get('timestamp', 'Unknown')}\")\n    report_lines.append(f\"Sample Size: {metadata.get('sample_size', 'Unknown')}\")\n    report_lines.append(f\"Alpha Level: {metadata.get('alpha_level', 'Unknown')}\")\n    report_lines.append(f\"Variables: {len(metadata.get('variables_analyzed', []))}\")\n    report_lines.append(\"\")\n    \n    # Summarize key findings\n    for analysis_name, result in analysis_results.items():\n        if analysis_name != 'analysis_metadata' and isinstance(result, dict):\n            if 'error' not in result:\n                report_lines.append(f\"{analysis_name.replace('_', ' ').title()}:\")\n                \n                # Extract key statistics based on analysis type\n                if 'p_value' in result:\n                    p_val = result['p_value']\n                    significance = \"significant\" if p_val < metadata.get('alpha_level', 0.05) else \"not significant\"\n                    report_lines.append(f\"  - p-value: {p_val:.4f} ({significance})\")\n                \n                if 'effect_size' in result:\n                    report_lines.append(f\"  - Effect size: {result['effect_size']:.4f}\")\n                \n                if 'correlation_matrix' in result:\n                    report_lines.append(f\"  - Correlation matrix generated with {len(result['correlation_matrix'])} variables\")\n                \n                if 'cronbach_alpha' in result:\n                    alpha_val = result['cronbach_alpha']\n                    reliability = \"excellent\" if alpha_val > 0.9 else \"good\" if alpha_val > 0.8 else \"acceptable\" if alpha_val > 0.7 else \"questionable\"\n                    report_lines.append(f\"  - Cronbach's \u03b1: {alpha_val:.3f} ({reliability})\")\n                \n                report_lines.append(\"\")\n            else:\n                report_lines.append(f\"{analysis_name}: ERROR - {result['error']}\")\n                report_lines.append(\"\")\n    \n    return \"\\n\".join(report_lines)\n",
    "cached_with_code": true
  },
  "statistical_data": {
    "analyze_dimensional_contribution": null,
    "analyze_speech_context_effects": null,
    "calculate_correlation_matrix": null,
    "calculate_cronbachs_alpha": {
      "health_construct_reliability": {
        "cronbachs_alpha": 0.98308821488475,
        "confidence_interval_95": [
          0.973,
          0.99
        ]
      },
      "pathology_construct_reliability": {
        "cronbachs_alpha": 0.9383616141330247,
        "confidence_interval_95": [
          0.9,
          0.963
        ]
      }
    },
    "calculate_derived_metrics": null,
    "calculate_descriptive_statistics": null,
    "calculate_euclidean_distances": null,
    "generate_statistical_summary_report": "STATISTICAL ANALYSIS SUMMARY REPORT\n==================================================\nAnalysis Timestamp: Unknown\nSample Size: Unknown\nAlpha Level: Unknown\nVariables: 0\n",
    "perform_anova_on_health_index": null,
    "perform_hierarchical_clustering": null,
    "perform_levenes_test": null,
    "perform_statistical_analysis": {
      "analysis_metadata": {
        "timestamp": "2025-08-28T00:16:27.532659",
        "sample_size": 48,
        "alpha_level": 0.05,
        "variables_analyzed": [
          "procedural_legitimacy_raw",
          "procedural_legitimacy_salience",
          "procedural_legitimacy_confidence",
          "procedural_rejection_raw",
          "procedural_rejection_salience",
          "procedural_rejection_confidence",
          "institutional_respect_raw",
          "institutional_respect_salience",
          "institutional_respect_confidence",
          "institutional_subversion_raw",
          "institutional_subversion_salience",
          "institutional_subversion_confidence",
          "systemic_continuity_raw",
          "systemic_continuity_salience",
          "systemic_continuity_confidence",
          "systemic_replacement_raw",
          "systemic_replacement_salience",
          "systemic_replacement_confidence"
        ]
      }
    },
    "perform_tukey_hsd_test": null,
    "run_complete_statistical_analysis": {
      "analysis_metadata": {
        "timestamp": "2025-08-28T00:16:27.550599",
        "sample_size": 48,
        "alpha_level": 0.05,
        "variables_analyzed": [
          "procedural_legitimacy_raw",
          "procedural_legitimacy_salience",
          "procedural_legitimacy_confidence",
          "procedural_rejection_raw",
          "procedural_rejection_salience",
          "procedural_rejection_confidence",
          "institutional_respect_raw",
          "institutional_respect_salience",
          "institutional_respect_confidence",
          "institutional_subversion_raw",
          "institutional_subversion_salience",
          "institutional_subversion_confidence",
          "systemic_continuity_raw",
          "systemic_continuity_salience",
          "systemic_continuity_confidence",
          "systemic_replacement_raw",
          "systemic_replacement_salience",
          "systemic_replacement_confidence"
        ]
      }
    }
  },
  "status": "success_with_data",
  "validation_passed": true
}