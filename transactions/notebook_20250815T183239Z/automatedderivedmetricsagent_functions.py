"""
Automated Derived Metrics Functions
===================================

Generated by AutomatedDerivedMetricsAgent for experiment: simple_test
Description: No description
Generated: 2025-08-15T18:34:51.850652+00:00

This module contains automatically generated calculation functions for derived metrics
as specified in the framework's natural language descriptions.
"""

import pandas as pd
import numpy as np
from typing import Optional, Dict, Any


def calculate_identity_tension(data, **kwargs):
    """
    Calculate identity_tension: Conflict between tribal dominance and individual dignity dimensions.

    This calculation quantifies the degree of conflict as the absolute difference
    between the mean scores of 'Tribal Dominance' and 'Individual Dignity'
    across the provided DataFrame. A higher value indicates greater tension.

    Formula: |mean(Tribal Dominance) - mean(Individual Dignity)|

    Args:
        data (pd.DataFrame): A pandas DataFrame expected to contain 'Tribal Dominance'
                             and 'Individual Dignity' columns, with scores
                             ranging from 0.0 to 1.0.
        **kwargs: Additional parameters (not used in this calculation but included
                  for framework compatibility).

    Returns:
        float: The calculated identity tension score (0.0-1.0) or None if
               insufficient or invalid data is provided.
    """
    import pandas as pd
    import numpy as np

    try:
        # Ensure the input is a pandas DataFrame
        if not isinstance(data, pd.DataFrame):
            return None

        # Define the required dimension columns
        required_cols = ['Tribal Dominance', 'Individual Dignity']

        # Check if all required columns exist in the DataFrame
        if not all(col in data.columns for col in required_cols):
            return None

        # Calculate the mean scores for Tribal Dominance and Individual Dignity
        # across all rows in the DataFrame. This aggregates potential multiple
        # data points into a single score for each dimension.
        tribal_dominance_score = data['Tribal Dominance'].mean()
        individual_dignity_score = data['Individual Dignity'].mean()

        # Handle cases where the mean might result in NaN (e.g., column exists but all values are NaN
        # or the DataFrame is empty for these columns).
        if pd.isna(tribal_dominance_score) or pd.isna(individual_dignity_score):
            return None

        # Ensure scores are within the valid range [0.0, 1.0] for robustness,
        # although they should ideally be constrained by upstream processes.
        tribal_dominance_score = np.clip(tribal_dominance_score, 0.0, 1.0)
        individual_dignity_score = np.clip(individual_dignity_score, 0.0, 1.0)

        # Calculate the identity tension as the absolute difference between the scores.
        # This naturally yields a result between 0.0 (no tension/conflict) and 1.0 (maximum tension/conflict).
        identity_tension_score = abs(tribal_dominance_score - individual_dignity_score)

        return float(identity_tension_score)

    except Exception:
        # Catch any unexpected errors (e.g., non-numeric data that prevents mean calculation)
        # and return None to indicate a failure in calculation.
        return None

def calculate_emotional_balance(data, **kwargs):
    """
    Calculate emotional_balance: Difference between hope and fear scores, scaled to 0.0-1.0.

    Formula: emotional_balance = (mean(hope_scores) - mean(fear_scores) + 1.0) / 2.0, clamped to [0.0, 1.0].

    Args:
        data: pandas DataFrame expected to contain 'hope' and 'fear' columns.
              Each column should contain numerical scores typically between 0.0 and 1.0.
        **kwargs: Additional parameters (not used in this calculation but maintained for framework consistency).

    Returns:
        float: Calculated emotional balance score (0.0-1.0) or None if insufficient/invalid data.
    """
    import pandas as pd
    import numpy as np

    try:
        # 1. Validate input type
        if not isinstance(data, pd.DataFrame):
            return None

        # 2. Check for required columns
        required_columns = ['hope', 'fear']
        if not all(col in data.columns for col in required_columns):
            return None

        # 3. Extract relevant series and convert to numeric, coercing errors
        hope_scores = pd.to_numeric(data['hope'], errors='coerce')
        fear_scores = pd.to_numeric(data['fear'], errors='coerce')

        # 4. Calculate the mean for each score, ignoring NaN values
        # If all values are NaN, mean will be NaN.
        mean_hope = hope_scores.mean()
        mean_fear = fear_scores.mean()

        # 5. Handle cases where means cannot be calculated (e.g., all NaN values in a column)
        if pd.isna(mean_hope) or pd.isna(mean_fear):
            return None

        # 6. Calculate the raw difference
        raw_difference = mean_hope - mean_fear

        # 7. Scale the difference to the 0.0-1.0 range
        # Assuming hope and fear scores are initially 0.0-1.0,
        # the raw_difference ranges from -1.0 (0.0 - 1.0) to 1.0 (1.0 - 0.0).
        # To scale to 0.0-1.0: (value - min_val) / (max_val - min_val)
        # Here: (raw_difference - (-1.0)) / (1.0 - (-1.0)) = (raw_difference + 1.0) / 2.0
        emotional_balance_score = (raw_difference + 1.0) / 2.0

        # 8. Clamp the result to ensure it strictly stays within 0.0-1.0
        # This handles potential floating point inaccuracies or slight deviations if input scores
        # were not strictly 0.0-1.0 (e.g., from prior calculations)
        emotional_balance_score = np.clip(emotional_balance_score, 0.0, 1.0)

        return float(emotional_balance_score)

    except Exception:
        # Catch any unexpected errors during calculation and return None
        return None

def calculate_success_climate(data, **kwargs):
    """
    Calculate success_climate: Difference between compersion and envy scores.

    Formula: success_climate = compersion_score - envy_score

    Args:
        data (pd.DataFrame): A pandas DataFrame expected to contain 'compersion' and 'envy' scores.
                             It should have these columns. If multiple rows exist, the mean of the
                             'compersion' and 'envy' columns will be used to derive the single scores
                             for calculation.

    Returns:
        float: Calculated success_climate score (range -1.0 to 1.0, assuming input scores are 0.0-1.0),
               or None if required data (columns or valid numeric values) is insufficient to perform
               the calculation.
    """
    import pandas as pd
    import numpy as np

    try:
        # Check if the required columns exist in the DataFrame
        required_columns = ['compersion', 'envy']
        if not all(col in data.columns for col in required_columns):
            # If any required column is missing, we cannot perform the calculation
            return None

        # Extract scores. If the DataFrame has multiple rows, take the mean of each column
        # to derive a single value for calculation. This approach robustly handles
        # single-row DataFrames (mean of one value is the value itself) and multiple rows.
        compersion_score = data['compersion'].mean()
        envy_score = data['envy'].mean()

        # Check if the extracted scores are NaN (e.g., if the columns were empty or contained only NaNs)
        if pd.isna(compersion_score) or pd.isna(envy_score):
            return None

        # Ensure scores are numeric. If they somehow aren't after mean (unlikely but safe check)
        if not isinstance(compersion_score, (int, float)) or \
           not isinstance(envy_score, (int, float)):
            return None

        # Perform the core calculation
        success_climate = compersion_score - envy_score

        return float(success_climate)

    except Exception:
        # Catch any unexpected errors during processing (e.g., data corruption, type issues)
        return None

def calculate_relational_climate(data, **kwargs):
    """
    Calculate relational_climate: Difference between amity and enmity scores.

    Formula: relational_climate = amity_score - enmity_score

    Args:
        data (pd.DataFrame): DataFrame expected to contain 'amity' and 'enmity'
                             columns. It's assumed these columns contain the
                             scalar scores, typically in the first row if
                             the DataFrame represents aggregated results.
        **kwargs: Additional parameters (not used in this calculation).

    Returns:
        float: The calculated relational climate score (amity_score - enmity_score).
               Returns None if 'data' is not a valid DataFrame, is empty,
               lacks required 'amity' or 'enmity' columns, or if
               the extracted scores are NaN or non-numeric.
    """
    import pandas as pd
    import numpy as np

    try:
        # Handle cases where data is not a DataFrame or is empty
        if not isinstance(data, pd.DataFrame) or data.empty:
            return None

        # Check for the presence of required columns
        required_cols = ['amity', 'enmity']
        if not all(col in data.columns for col in required_cols):
            return None

        # Assuming 'amity' and 'enmity' scores are single scalar values,
        # typically found in the first row if the DataFrame contains
        # aggregated results or a single observation.
        amity_score = data['amity'].iloc[0]
        enmity_score = data['enmity'].iloc[0]

        # Handle NaN values explicitly
        if pd.isna(amity_score) or pd.isna(enmity_score):
            return None

        # Ensure extracted scores are numeric
        if not isinstance(amity_score, (int, float)) or not isinstance(enmity_score, (int, float)):
            return None

        # Perform the calculation
        result = amity_score - enmity_score

        # Return the result as a float
        return float(result)

    except Exception:
        # Catch any other unexpected errors during processing and return None
        return None

def calculate_goal_orientation(data, **kwargs):
    """
    Calculate goal_orientation: Difference between cohesive goals and fragmentative goals.
    
    Formula: Mean(Individual Dignity - Tribal Dominance)
    
    Args:
        data: pandas DataFrame with 'Individual Dignity' (cohesive goals)
              and 'Tribal Dominance' (fragmentative goals) dimension scores.
              Scores for these dimensions are expected to be between 0.0 and 1.0.
              If the DataFrame contains multiple rows, the mean of the differences
              across rows will be calculated.
        **kwargs: Additional parameters (not used in this calculation).
        
    Returns:
        float: Calculated result, representing the average difference between
               Individual Dignity and Tribal Dominance. The result range is
               typically -1.0 to 1.0. Returns None if data is insufficient
               (e.g., not a DataFrame, missing required columns, or all
               relevant data points are NaN).
    """
    import pandas as pd
    import numpy as np
    
    try:
        # Ensure data is a pandas DataFrame
        if not isinstance(data, pd.DataFrame):
            return None

        required_columns = ['Individual Dignity', 'Tribal Dominance']
        
        # Check if all required columns exist in the DataFrame
        if not all(col in data.columns for col in required_columns):
            return None # Missing one or more required columns

        # Extract the relevant scores. These will be pandas Series.
        individual_dignity_scores = data['Individual Dignity']
        tribal_dominance_scores = data['Tribal Dominance']

        # Calculate the element-wise difference. NaN values in either Series
        # will result in NaN for that corresponding difference.
        difference_scores = individual_dignity_scores - tribal_dominance_scores

        # Calculate the mean of the differences. By default, pandas' .mean()
        # method skips NaN values. If all values are NaN, it returns NaN.
        result = difference_scores.mean()

        # If the calculated mean is NaN (e.g., if the input DataFrame was empty,
        # or if all relevant rows contained NaN for the required columns),
        # return None to indicate insufficient data.
        if pd.isna(result):
            return None
            
        # Return the result as a standard float
        return float(result)
        
    except Exception:
        # Catch any unexpected errors that might occur during the process
        return None

def calculate_overall_cohesion_index(data, **kwargs):
    """
    Calculate overall_cohesion_index: Comprehensive measure combining all dimensions.

    Formula:
    Overall Cohesion Index = ( SUM(score for d_p in Positive_Dimensions) + SUM(1 - score for d_n in Negative_Dimensions) ) / Total_Number_of_Dimensions
    Where:
    - d_p represents a dimension positively correlated with cohesion (a higher score indicates higher cohesion).
      Examples: 'Individual Dignity'.
    - d_n represents a dimension negatively correlated with cohesion (a higher score indicates lower cohesion).
      Examples: 'Tribal Dominance'.
    - All individual dimension scores are assumed to be normalized between 0.0 and 1.0.
    - The final index is the mean of these calculated scores across all rows in the DataFrame.

    Args:
        data (pandas.DataFrame): DataFrame containing dimension scores. Each row
                                 represents a unit of analysis (e.g., a document,
                                 a time period) and columns are the dimension names.
                                 Scores for each dimension are expected to be between 0.0 and 1.0.
        **kwargs:
            positive_dimensions (list, optional): List of column names (strings) representing
                                                  dimensions where a higher score indicates higher cohesion.
                                                  Defaults to ['Individual Dignity'].
            negative_dimensions (list, optional): List of column names (strings) representing
                                                  dimensions where a higher score indicates lower cohesion.
                                                  Defaults to ['Tribal Dominance'].

    Returns:
        float or None: The calculated overall cohesion index (a single aggregated value),
                       or None if the input data is invalid, essential columns are missing,
                       or no valid scores can be computed.
    """
    import pandas as pd
    import numpy as np

    try:
        # --- Input Validation ---
        if not isinstance(data, pd.DataFrame):
            return None # Input 'data' must be a pandas DataFrame.

        if data.empty:
            return None # Input 'data' DataFrame is empty.

        # Retrieve dimension lists from kwargs or use defaults
        positive_dimensions = kwargs.get('positive_dimensions', ['Individual Dignity'])
        negative_dimensions = kwargs.get('negative_dimensions', ['Tribal Dominance'])

        # Validate dimension list types
        if not isinstance(positive_dimensions, list) or not all(isinstance(d, str) for d in positive_dimensions):
            return None # 'positive_dimensions' must be a list of strings.
        if not isinstance(negative_dimensions, list) or not all(isinstance(d, str) for d in negative_dimensions):
            return None # 'negative_dimensions' must be a list of strings.

        all_dimensions = positive_dimensions + negative_dimensions

        if not all_dimensions:
            return None # No dimensions (positive or negative) specified for calculation.

        # Check if all required dimension columns exist in the DataFrame
        missing_columns = [col for col in all_dimensions if col not in data.columns]
        if missing_columns:
            # Not all required dimension columns are present in the DataFrame.
            return None

        # --- Calculation Logic ---

        # Initialize a Series to sum up the adjusted dimension scores for each row.
        # This will hold the numerator of our formula for each row.
        cohesion_score_numerator_per_row = pd.Series(0.0, index=data.index)

        # Sum contributions from positive dimensions (scores are used directly)
        for dim_name in positive_dimensions:
            # Convert column to numeric, coercing non-numeric values to NaN.
            # Clip values to ensure they are within the 0.0-1.0 range, handling minor deviations.
            scores = np.clip(pd.to_numeric(data[dim_name], errors='coerce'), 0.0, 1.0)
            cohesion_score_numerator_per_row += scores

        # Sum contributions from negative dimensions (scores are inverted: 1 - score)
        for dim_name in negative_dimensions:
            # Convert column to numeric, coercing non-numeric values to NaN.
            # Clip values to ensure they are within the 0.0-1.0 range.
            scores = np.clip(pd.to_numeric(data[dim_name], errors='coerce'), 0.0, 1.0)
            cohesion_score_numerator_per_row += (1.0 - scores)

        # Calculate the cohesion index for each row by dividing by the total number of dimensions.
        total_dimensions_count = len(all_dimensions)
        if total_dimensions_count == 0:
            # This case should ideally be caught by the earlier 'if not all_dimensions:' check,
            # but serves as a robust safeguard against division by zero.
            return None

        cohesion_index_per_row = cohesion_score_numerator_per_row / total_dimensions_count

        # Handle cases where all rows resulted in NaN for their cohesion index (e.g., all input scores were NaN).
        if cohesion_index_per_row.isnull().all():
            return None # All calculated cohesion scores are NaN.

        # Calculate the overall cohesion index by taking the mean across all rows, ignoring NaNs.
        overall_index = cohesion_index_per_row.mean()

        # If the mean calculation still results in NaN (e.g., the Series was empty after dropna, or all values were NaN),
        # return None indicating no valid overall index could be computed.
        if pd.isna(overall_index):
            return None

        # Ensure the final overall index is within the expected 0.0-1.0 range, though the formula
        # should inherently produce values within this range if inputs are correctly clamped.
        overall_index = np.clip(overall_index, 0.0, 1.0)

        return float(overall_index)

    except Exception:
        # Catch any unexpected errors during processing and return None as per requirement.
        return None

def calculate_all_derived_metrics(data: pd.DataFrame) -> Dict[str, Optional[float]]:
    """
    Calculate all derived metrics for the given dataset.
    
    Args:
        data: pandas DataFrame with dimension scores
        
    Returns:
        Dictionary mapping metric names to calculated values
    """
    results = {}
    
    # Get all calculation functions from this module
    import inspect
    current_module = inspect.getmodule(inspect.currentframe())
    
    for name, obj in inspect.getmembers(current_module):
        if (inspect.isfunction(obj) and 
            name.startswith('calculate_') and 
            name != 'calculate_all_derived_metrics'):
            try:
                results[name.replace('calculate_', '')] = obj(data)
            except Exception as e:
                results[name.replace('calculate_', '')] = None
                
    return results
