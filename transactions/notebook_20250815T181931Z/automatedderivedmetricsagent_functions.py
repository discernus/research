"""
Automated Derived Metrics Functions
===================================

Generated by AutomatedDerivedMetricsAgent for experiment: simple_test
Description: No description
Generated: 2025-08-15T18:21:44.557634+00:00

This module contains automatically generated calculation functions for derived metrics
as specified in the framework's natural language descriptions.
"""

import pandas as pd
import numpy as np
from typing import Optional, Dict, Any


def calculate_identity_tension(data, **kwargs):
    """
    Calculate identity_tension: Conflict between tribal dominance and individual dignity dimensions.

    Formula: Tension = sqrt(Tribal_Dominance_Mean^2 + (Individual_Dignity_Mean - 1)^2) / sqrt(2)
    This formula quantifies the normalized Euclidean distance from the ideal state
    (Tribal Dominance = 0.0, Individual Dignity = 1.0).
    A higher score indicates greater tension. It peaks at 1.0 when Tribal Dominance is high (1.0)
    and Individual Dignity is low (0.0), representing maximal conflict.
    It also assigns a substantial tension value (approx. 0.707) when both dimensions are high (1.0, 1.0),
    reflecting an internal contradiction, or when both are low (0.0, 0.0), indicating an absence of both tribalism and dignity.

    Args:
        data (pd.DataFrame): A pandas DataFrame expected to contain 'Tribal Dominance'
                             and 'Individual Dignity' columns. These columns should
                             contain numerical scores (0.0-1.0) for each unit of analysis.
        **kwargs: Additional parameters (not used in this calculation but included for framework compatibility).

    Returns:
        float: The calculated identity_tension score, normalized to a 0.0-1.0 range.
               Returns None if input data is invalid, missing required columns, or
               contains insufficient valid numerical data for calculation.
    """
    import pandas as pd
    import numpy as np

    # Ensure the input is a pandas DataFrame
    if not isinstance(data, pd.DataFrame):
        return None

    required_columns = ['Tribal Dominance', 'Individual Dignity']

    # Check if all required columns exist in the DataFrame
    if not all(col in data.columns for col in required_columns):
        return None

    try:
        # Extract series and convert to numeric, coercing any non-numeric values to NaN
        tribal_dominance_series = pd.to_numeric(data['Tribal Dominance'], errors='coerce')
        individual_dignity_series = pd.to_numeric(data['Individual Dignity'], errors='coerce')

        # Calculate the mean for each dimension. By default, .mean() skips NaN values.
        avg_td = tribal_dominance_series.mean()
        avg_id = individual_dignity_series.mean()

        # If either mean is NaN (e.g., column was entirely non-numeric or empty), return None
        if pd.isna(avg_td) or pd.isna(avg_id):
            return None

        # Clip the average scores to ensure they are within the expected 0.0-1.0 range.
        # This adds robustness against potential out-of-range input data.
        avg_td_clipped = np.clip(avg_td, 0.0, 1.0)
        avg_id_clipped = np.clip(avg_id, 0.0, 1.0)

        # Apply the identity_tension formula (normalized Euclidean distance)
        # Distance = sqrt( (Tribal_Dominance - 0)^2 + (Individual_Dignity - 1)^2 )
        # Normalize by dividing by sqrt(2) to scale to 0-1
        tension_numerator = np.sqrt(avg_td_clipped**2 + (avg_id_clipped - 1)**2)
        tension_denominator = np.sqrt(2)

        identity_tension_score = tension_numerator / tension_denominator

        # Final clip to ensure the output is strictly within 0.0-1.0, though the formula
        # design ensures this under valid input.
        return float(np.clip(identity_tension_score, 0.0, 1.0))

    except Exception:
        # Catch any unexpected errors during processing and return None for graceful failure
        return None

def calculate_emotional_balance(data, **kwargs):
    """
    Calculate emotional_balance: Difference between hope and fear scores.

    Formula: emotional_balance = hope_score - fear_score

    Args:
        data (pd.DataFrame): A pandas DataFrame expected to contain
                             'hope' and 'fear' scores as columns.
                             These scores should be numerical.
        **kwargs: Additional parameters (not used in this calculation but included
                  for framework consistency).

    Returns:
        float: The calculated emotional balance score (hope - fear).
               Returns a value typically between -1.0 and 1.0 if hope/fear
               are within the 0.0-1.0 range, or None if 'hope' or 'fear'
               columns are missing, contain non-numeric data, or the
               result of the calculation is non-finite (e.g., NaN).
    """
    import pandas as pd
    import numpy as np

    try:
        # Ensure data is a pandas DataFrame
        if not isinstance(data, pd.DataFrame):
            return None

        # Check if 'hope' and 'fear' columns exist
        if 'hope' not in data.columns or 'fear' not in data.columns:
            return None

        # Extract the scores. Assuming single values for each dimension
        # If the DataFrame might contain multiple rows, this would typically
        # involve aggregation (e.g., mean), but the problem implies a single score
        # for hope and fear for the calculation of 'emotional_balance'.
        # We will take the first valid numerical entry from each column.
        
        hope_score = data['hope'].dropna().iloc[0] if not data['hope'].dropna().empty else np.nan
        fear_score = data['fear'].dropna().iloc[0] if not data['fear'].dropna().empty else np.nan

        # Check for non-finite values (NaN, inf) after extraction
        if pd.isna(hope_score) or pd.isna(fear_score):
            return None
        
        # Ensure scores are numeric
        if not (isinstance(hope_score, (int, float)) and isinstance(fear_score, (int, float))):
            return None

        # Perform the calculation
        result = float(hope_score - fear_score)

        # Return None if the result itself is NaN or infinity
        if pd.isna(result) or not np.isfinite(result):
            return None

        return result

    except Exception:
        # Catch any unexpected errors during processing
        return None

def calculate_success_climate(data, **kwargs):
    """
    Calculate success_climate: Difference between the average compersion score and the average envy score.

    This function computes a single 'success_climate' score based on the
    mean values of 'compersion' and 'envy' dimensions found in the input DataFrame.

    Args:
        data (pd.DataFrame): pandas DataFrame with 'compersion' and 'envy' dimension scores
                             as columns. Each column should contain numerical scores.
        **kwargs: Additional parameters (currently not used but included for framework consistency).

    Returns:
        float or None: Calculated result (average compersion score - average envy score)
                       if sufficient valid data is available. Returns None if:
                       - data is not a pandas DataFrame.
                       - Required 'compersion' or 'envy' columns are missing.
                       - Either required column contains only NaN values or is empty.
                       - An unexpected error occurs during calculation.
    """
    import pandas as pd
    import numpy as np

    try:
        # Validate input is a pandas DataFrame
        if not isinstance(data, pd.DataFrame):
            return None

        # Define required column names
        required_columns = ['compersion', 'envy']

        # Check if all required columns exist in the DataFrame
        if not all(col in data.columns for col in required_columns):
            return None

        # Extract the relevant series
        compersion_series = data['compersion']
        envy_series = data['envy']

        # Check if the series are entirely empty or contain only NaN values.
        # If so, a meaningful average cannot be calculated.
        # pd.Series.isnull().all() returns True if all elements are NaN or if the series is empty.
        if compersion_series.isnull().all() or envy_series.isnull().all():
            return None

        # Calculate the mean of non-NaN values for each score.
        # pandas .mean() method automatically skips NaN values.
        compersion_mean = compersion_series.mean()
        envy_mean = envy_series.mean()

        # If, after attempting to calculate the mean, either result is NaN (e.g., column contained non-numeric
        # values that coerced to NaN, or other edge cases), return None.
        if pd.isna(compersion_mean) or pd.isna(envy_mean):
            return None

        # Calculate the difference
        result = compersion_mean - envy_mean

        # Ensure the return type is float, even if result is integer (e.g., 0.0)
        return float(result)

    except Exception:
        # Catch any unexpected errors (e.g., type errors if columns contain non-numeric data that can't be averaged)
        return None

def calculate_relational_climate(data, **kwargs):
    """
    Calculate relational_climate: Difference between amity and enmity scores.

    Formula: `relational_climate = mean(amity_scores) - mean(enmity_scores)`

    This function computes the relational climate by taking the mean of all
    available 'amity' scores and subtracting the mean of all available 'enmity' scores
    from a given DataFrame.

    Args:
        data: pandas DataFrame with dimension scores. Expected to have 'amity' and 'enmity' columns.
              The calculation will use the mean of the 'amity' column and the mean of the 'enmity' column
              across all valid (non-NaN) values in those columns.
        **kwargs: Additional parameters (not used in this specific calculation).

    Returns:
        float: Calculated relational climate score (ranging from -1.0 to 1.0, assuming
               amity/enmity scores are 0.0-1.0).
               Returns None if:
               - `data` is not a pandas DataFrame.
               - Required columns ('amity', 'enmity') are missing from the DataFrame.
               - After averaging, either the 'amity' or 'enmity' score is not a valid number
                 (e.g., if a column contains only NaN values or is entirely empty after filtering).
    """
    import pandas as pd
    import numpy as np

    try:
        # 1. Validate input: Ensure data is a pandas DataFrame.
        if not isinstance(data, pd.DataFrame):
            return None

        # 2. Check for required columns.
        required_cols = ['amity', 'enmity']
        if not all(col in data.columns for col in required_cols):
            return None

        # 3. Calculate the mean for 'amity' and 'enmity' scores.
        # .mean() method handles NaN values by skipping them.
        avg_amity = data['amity'].mean()
        avg_enmity = data['enmity'].mean()

        # 4. Check if the calculated means are valid numbers.
        # If a column was entirely NaN or empty, .mean() would return NaN.
        if pd.isna(avg_amity) or pd.isna(avg_enmity):
            return None

        # 5. Calculate the relational climate score.
        relational_climate_score = avg_amity - avg_enmity

        # 6. Ensure the result is a float before returning.
        return float(relational_climate_score)

    except Exception:
        # Catch any unexpected errors during processing and return None.
        return None

def calculate_goal_orientation(data, **kwargs):
    """
    Calculate goal_orientation: Difference between cohesive goals and fragmentative goals.

    Formula: goal_orientation = (Average of 'Individual Dignity' scores) - (Average of 'Tribal Dominance' scores)

    Args:
        data (pd.DataFrame): A pandas DataFrame expected to contain at least
                             'Individual Dignity' and 'Tribal Dominance' columns.
                             These columns should contain numerical scores (0.0-1.0).
        **kwargs: Additional parameters (not used in this calculation but included
                  for API compatibility).

    Returns:
        float: The calculated goal_orientation score (range -1.0 to 1.0).
               Returns None if 'data' is not a DataFrame, required columns are missing,
               or if there is insufficient valid numerical data to perform the calculation.
    """
    import pandas as pd
    import numpy as np
    
    try:
        if not isinstance(data, pd.DataFrame):
            return None

        cohesive_goals_col = 'Individual Dignity'
        fragmentative_goals_col = 'Tribal Dominance'

        # Check if required columns exist in the DataFrame
        if cohesive_goals_col not in data.columns or fragmentative_goals_col not in data.columns:
            return None

        # Calculate the average score for 'Individual Dignity' (cohesive goals)
        # .mean() by default skips NaN values. If all values are NaN, it returns NaN.
        avg_cohesive_goals_score = data[cohesive_goals_col].mean()

        # Calculate the average score for 'Tribal Dominance' (fragmentative goals)
        avg_fragmentative_goals_score = data[fragmentative_goals_col].mean()

        # If either average score is NaN (meaning no valid numerical data for that dimension),
        # return None as calculation cannot be completed.
        if pd.isna(avg_cohesive_goals_score) or pd.isna(avg_fragmentative_goals_score):
            return None
        
        # Calculate the goal orientation score
        # The score range will be [-1.0, 1.0] since input scores are 0.0-1.0
        goal_orientation_score = avg_cohesive_goals_score - avg_fragmentative_goals_score
        
        return float(goal_orientation_score)

    except Exception:
        # Catch any unexpected errors during calculation and return None gracefully.
        return None

def calculate_overall_cohesion_index(data, **kwargs):
    """
    Calculate overall_cohesion_index: Comprehensive measure combining all dimensions.

    Formula:
    overall_cohesion_index = Mean( [score_d for d in D_pos] + [(1 - score_d) for d in D_neg] )
    where:
    - D_pos: Dimensions where higher scores promote cohesion (e.g., 'Individual Dignity').
             These scores are used directly.
    - D_neg: Dimensions where higher scores detract from cohesion (e.g., 'Tribal Dominance').
             These scores are transformed as (1 - score_d).
    All dimension scores are expected to be between 0.0 and 1.0.

    Args:
        data (pd.DataFrame): DataFrame containing columns for dimension scores.
                             Expected columns (defaults, can be overridden by kwargs):
                             - 'Individual Dignity' (default in D_pos)
                             - 'Tribal Dominance' (default in D_neg)
                             Additional dimensions can be specified via kwargs.
        **kwargs:
            - positive_dimensions (list[str], optional): List of column names
              for cohesion-promoting dimensions. Overrides default.
            - negative_dimensions (list[str], optional): List of column names
              for cohesion-detracting dimensions. Overrides default.

    Returns:
        float: Calculated overall cohesion index (0.0-1.0) or None if:
               - Input 'data' is not a pandas DataFrame.
               - Input 'data' is empty.
               - Required dimension columns are missing.
               - All relevant dimension scores are NaN.
               - Any dimension score is outside the [0.0, 1.0] range (excluding NaNs).
    """
    import pandas as pd
    import numpy as np
    
    try:
        if not isinstance(data, pd.DataFrame):
            return None

        if data.empty:
            return None

        # Define default dimensions based on problem description
        default_positive_dimensions = ['Individual Dignity']
        default_negative_dimensions = ['Tribal Dominance']

        # Override defaults with kwargs if provided
        positive_dimensions = kwargs.get('positive_dimensions', default_positive_dimensions)
        negative_dimensions = kwargs.get('negative_dimensions', default_negative_dimensions)

        all_required_dimensions = positive_dimensions + negative_dimensions

        # Check if all required dimension columns exist in the DataFrame
        missing_columns = [col for col in all_required_dimensions if col not in data.columns]
        if missing_columns:
            return None

        # Prepare scores for calculation
        transformed_scores_list = []

        for dim in positive_dimensions:
            # Check if non-NaN scores are within range
            non_nan_scores = data[dim].dropna()
            if not (non_nan_scores.empty or ((non_nan_scores >= 0.0).all() and (non_nan_scores <= 1.0).all())):
                return None
            transformed_scores_list.append(data[dim])

        for dim in negative_dimensions:
            # Check if non-NaN scores are within range
            non_nan_scores = data[dim].dropna()
            if not (non_nan_scores.empty or ((non_nan_scores >= 0.0).all() and (non_nan_scores <= 1.0).all())):
                return None
            transformed_scores_list.append(1.0 - data[dim])
        
        # If no dimensions were specified or found after filtering (e.g., empty positive/negative lists)
        if not transformed_scores_list:
            return None
        
        # Combine all series into a single DataFrame, then flatten to a numpy array for calculation.
        # This handles potential NaNs in individual series correctly when filtering later.
        combined_series_df = pd.concat(transformed_scores_list, axis=1)
        final_scores = combined_series_df.values.flatten()
        
        # Filter out NaNs from the flattened array
        final_scores = final_scores[~np.isnan(final_scores)]

        if final_scores.size == 0:
            # All relevant scores were NaN or there were no valid scores after filtering
            return None

        overall_index = np.mean(final_scores)
        
        # The result of an average of values between 0 and 1 will inherently be between 0 and 1.
        # np.clip adds explicit robustness in case of floating point inaccuracies, though unlikely needed.
        return float(np.clip(overall_index, 0.0, 1.0))
        
    except Exception:
        # Catch any unexpected errors and return None gracefully
        return None

def calculate_all_derived_metrics(data: pd.DataFrame) -> Dict[str, Optional[float]]:
    """
    Calculate all derived metrics for the given dataset.
    
    Args:
        data: pandas DataFrame with dimension scores
        
    Returns:
        Dictionary mapping metric names to calculated values
    """
    results = {}
    
    # Get all calculation functions from this module
    import inspect
    current_module = inspect.getmodule(inspect.currentframe())
    
    for name, obj in inspect.getmembers(current_module):
        if (inspect.isfunction(obj) and 
            name.startswith('calculate_') and 
            name != 'calculate_all_derived_metrics'):
            try:
                results[name.replace('calculate_', '')] = obj(data)
            except Exception as e:
                results[name.replace('calculate_', '')] = None
                
    return results
