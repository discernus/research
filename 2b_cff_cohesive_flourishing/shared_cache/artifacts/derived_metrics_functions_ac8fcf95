{
  "status": "success",
  "functions_generated": 6,
  "output_file": "automatedderivedmetricsagent_functions.py",
  "module_size": 13565,
  "function_code_content": "\"\"\"\nAutomated Derived Metrics Functions\n===================================\n\nGenerated by AutomatedDerivedMetricsAgent for experiment: Test Experiment\nDescription: Test experiment for derived metrics\nGenerated: 2025-08-28T02:35:10.976127+00:00\n\nThis module contains automatically generated calculation functions for derived metrics\nas specified in the framework's natural language descriptions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom typing import Optional, Dict, Any\n\n\ndef calculate_identity_tension(data, **kwargs):\n    \"\"\"\n    Calculate identity_tension: Conflict between tribal dominance and individual dignity dimensions\n\n    This metric quantifies the tension that arises when appeals to group-based dominance and\n    individual-based dignity are present simultaneously in a text. The tension is highest\n    when both dimensions are scored highly, indicating a strong internal conflict in the\n    discourse. The calculation uses the minimum of the two scores, as the tension can only\n    be as strong as its weaker component.\n\n    Formula: min(tribal_dominance, individual_dignity)\n    \n    Args:\n        data (pd.Series): A single row of data representing one document's scores.\n        **kwargs: Additional keyword arguments (unused).\n        \n    Returns:\n        float: The calculated tension score, or None if the necessary dimension\n               scores ('tribal_dominance', 'individual_dignity') are missing or not numeric.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # The calculation requires 'tribal_dominance' and 'individual_dignity' scores.\n        # These column names are inferred from the calculation's description, as the\n        # provided schema in the prompt is a placeholder. This function will fail\n        # gracefully if these columns do not exist in the actual data.\n        tribal_dominance = data['tribal_dominance']\n        individual_dignity = data['individual_dignity']\n        \n        # Ensure both values are valid numbers before calculation.\n        if pd.isna(tribal_dominance) or pd.isna(individual_dignity):\n            return None\n            \n        # The tension is the degree to which both opposing dimensions are present.\n        # This is effectively calculated as the minimum of the two scores.\n        tension = min(float(tribal_dominance), float(individual_dignity))\n        \n        return tension\n        \n    except (KeyError, TypeError, ValueError):\n        # KeyError: One of the required columns is not in the data.\n        # TypeError/ValueError: A score is not a convertible number.\n        # In any of these cases, the calculation cannot be performed.\n        return None\n\ndef calculate_emotional_balance(data, **kwargs):\n    \"\"\"\n    Calculate emotional_balance: Difference between hope and fear scores\n\n    Formula: hope - fear\n\n    Args:\n        data (pd.Series or dict): A single row of data containing the necessary scores.\n                                 Expected to have 'hope' and 'fear' keys.\n        **kwargs: Additional keyword arguments (not used in this calculation).\n\n    Returns:\n        float: The calculated emotional balance, or None if the required\n               scores are missing or not numeric.\n    \"\"\"\n    import pandas as pd\n\n    try:\n        # The calculation requires 'hope' and 'fear' scores.\n        # Access the scores; this will raise a KeyError if the columns are missing,\n        # which is caught by the except block below.\n        hope_score = data['hope']\n        fear_score = data['fear']\n\n        # Ensure both values are numeric types (int, float).\n        # pd.isna handles None, np.nan, etc., but we also check type.\n        if not isinstance(hope_score, (int, float)) or not isinstance(fear_score, (int, float)):\n            # Attempt to convert to numeric, coercing errors to NaN\n            hope_score = pd.to_numeric(hope_score, errors='coerce')\n            fear_score = pd.to_numeric(fear_score, errors='coerce')\n\n        # If after coercion, any value is NaN (due to non-numeric original values\n        # or being missing), the calculation is not possible.\n        if pd.isna(hope_score) or pd.isna(fear_score):\n            return None\n\n        result = float(hope_score - fear_score)\n        return result\n\n    except (KeyError, TypeError):\n        # KeyError: If 'hope' or 'fear' columns are not present in the data.\n        # TypeError: If 'data' is not a dictionary-like object (e.g., None).\n        return None\n\ndef calculate_success_climate(data, **kwargs):\n    \"\"\"\n    Calculate success_climate: Difference between compersion and envy scores\n\n    Formula: success_climate = compersion - envy\n    \n    Args:\n        data (pd.Series): A single row of data as a pandas Series,\n                          containing dimension scores.\n        **kwargs: Additional keyword arguments (unused).\n        \n    Returns:\n        float: The calculated result, or None if the necessary data for\n               'compersion' or 'envy' is missing or non-numeric.\n    \"\"\"\n    import pandas as pd\n\n    try:\n        # Retrieve scores for the required dimensions.\n        # The data is expected to be a pandas Series (a single row).\n        compersion_score = data['compersion']\n        envy_score = data['envy']\n        \n        # Handle cases where data is missing (NaN)\n        if pd.isna(compersion_score) or pd.isna(envy_score):\n            return None\n            \n        # Perform the calculation and ensure the result is a float\n        result = float(compersion_score) - float(envy_score)\n        \n        return result\n\n    except (KeyError, TypeError, ValueError):\n        # KeyError: if 'compersion' or 'envy' columns do not exist.\n        # TypeError/ValueError: if the scores are not in a numeric format.\n        return None\n\ndef calculate_relational_climate(data, **kwargs):\n    \"\"\"\n    Calculate relational_climate: Difference between amity and enmity scores.\n    Formula: amity - enmity\n\n    Args:\n        data (pd.Series): A single row of data containing the necessary dimension scores.\n        **kwargs: Additional keyword arguments (unused).\n\n    Returns:\n        float: The calculated relational climate score, or None if data is missing or invalid.\n    \"\"\"\n    import pandas as pd\n\n    try:\n        # The calculation requires 'amity' and 'enmity' scores. These names are\n        # derived from the calculation's description in the framework.\n        amity_score = data['amity']\n        enmity_score = data['enmity']\n\n        # The calculation cannot be performed if either score is missing.\n        if pd.isna(amity_score) or pd.isna(enmity_score):\n            return None\n\n        # Ensure values are numeric and perform the subtraction.\n        return float(amity_score) - float(enmity_score)\n\n    except (KeyError, TypeError, ValueError):\n        # This handles cases where:\n        # - 'amity' or 'enmity' columns are not present (KeyError).\n        # - The scores are not in a numeric format (TypeError, ValueError).\n        return None\n    except Exception:\n        # A final catch-all for any other unexpected errors to ensure stability.\n        return None\n\ndef calculate_goal_orientation(data, **kwargs):\n    \"\"\"\n    Calculate goal_orientation: Difference between cohesive goals and fragmentative goals\n\n    Formula: cohesive_goals - fragmentative_goals\n\n    Args:\n        data (pd.Series): A single row of data from the analysis DataFrame.\n        **kwargs: Additional parameters (unused).\n\n    Returns:\n        float: The calculated goal orientation score, or None if the necessary\n               data is missing or invalid.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # Column names are derived from the calculation's description.\n        cohesive_col = 'cohesive_goals'\n        fragmentative_col = 'fragmentative_goals'\n\n        # Retrieve the scores, converting to numeric types.\n        # errors='coerce' will turn non-numeric values into NaN.\n        cohesive_score = pd.to_numeric(data.get(cohesive_col), errors='coerce')\n        fragmentative_score = pd.to_numeric(data.get(fragmentative_col), errors='coerce')\n\n        # If either score is missing or could not be converted (is NaN), we cannot calculate.\n        if pd.isna(cohesive_score) or pd.isna(fragmentative_score):\n            return None\n\n        # Calculate the difference and ensure the result is a standard float.\n        result = float(cohesive_score - fragmentative_score)\n\n        return result\n\n    except Exception:\n        # Return None for any unexpected errors during execution.\n        return None\n\ndef calculate_overall_cohesion_index(data, **kwargs):\n    \"\"\"\n    Calculate overall_cohesion_index: Comprehensive measure combining all dimensions.\n\n    This index provides a holistic score of a document's contribution to social cohesion.\n    It balances constructive, unifying themes against divisive, fragmenting themes.\n    The final score is normalized to a range of -1 (maximally divisive) to +1 (maximally cohesive).\n\n    Formula:\n    OCI = Constructive Score - Divisive Score\n\n    where:\n    Constructive Score = Average of (hope, dialogue, trust, solution_focus)\n    Divisive Score = Average of (fear, blame_attribution, polarization, catastrophizing)\n\n    Args:\n        data (pd.Series): A single row of data containing the required dimension scores.\n        **kwargs: Additional parameters (not used in this calculation).\n\n    Returns:\n        float: The calculated Overall Cohesion Index, or None if essential data is missing.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # Define the columns required for the calculation based on the CFF conceptual model.\n        # The code anticipates these columns even if they are not in the provided sample schema.\n        constructive_cols = ['hope', 'dialogue', 'trust', 'solution_focus']\n        divisive_cols = ['fear', 'blame_attribution', 'polarization', 'catastrophizing']\n        \n        required_cols = constructive_cols + divisive_cols\n\n        # Extract scores, ensuring all required columns are present.\n        # The .get() method returns None if a key is missing, which is handled below.\n        scores = {col: data.get(col) for col in required_cols}\n\n        # Validate that all necessary scores are present and are numeric.\n        if any(pd.isna(score) or not isinstance(score, (int, float)) for score in scores.values()):\n            return None\n\n        # Calculate the average score for each dimension set.\n        constructive_values = [scores[col] for col in constructive_cols]\n        constructive_score = sum(constructive_values) / len(constructive_values)\n\n        divisive_values = [scores[col] for col in divisive_cols]\n        divisive_score = sum(divisive_values) / len(divisive_values)\n        \n        # The final index is the difference between the constructive and divisive tendencies.\n        overall_cohesion_index = constructive_score - divisive_score\n        \n        return float(overall_cohesion_index)\n\n    except (KeyError, TypeError, ZeroDivisionError, AttributeError):\n        # KeyError: A required column is missing from the data Series.\n        # TypeError: Data in a column is not numeric.\n        # ZeroDivisionError: The column lists are empty (developer error).\n        # AttributeError: `data` is not a pandas Series or compatible object.\n        # This will gracefully handle cases where the input data schema does not match\n        # the requirements of the calculation, as is the case in the sample provided.\n        return None\n    except Exception:\n        # A general catch-all for any other unexpected errors.\n        return None\n\ndef calculate_all_derived_metrics(data: pd.DataFrame) -> Dict[str, Optional[float]]:\n    \"\"\"\n    Calculate all derived metrics for the given dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        Dictionary mapping metric names to calculated values\n    \"\"\"\n    results = {}\n    \n    # Get all calculation functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith('calculate_') and \n            name not in ['calculate_all_derived_metrics', 'calculate_derived_metrics']):\n            try:\n                results[name.replace('calculate_', '')] = obj(data)\n            except Exception as e:\n                results[name.replace('calculate_', '')] = None\n                \n    return results\n\n\ndef calculate_derived_metrics(data: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Template-compatible wrapper function for derived metrics calculation.\n    \n    This function is called by the universal notebook template and returns\n    the original data with additional derived metric columns.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        DataFrame with original data plus derived metric columns\n    \"\"\"\n    # Calculate all derived metrics\n    derived_metrics = calculate_all_derived_metrics(data)\n    \n    # Create a copy of the original data\n    result = data.copy()\n    \n    # Add derived metrics as new columns\n    for metric_name, metric_value in derived_metrics.items():\n        if metric_value is not None:\n            # For scalar metrics, broadcast to all rows\n            result[metric_name] = metric_value\n        else:\n            # For failed calculations, use NaN\n            result[metric_name] = np.nan\n    \n    return result\n",
  "cached_with_code": true
}