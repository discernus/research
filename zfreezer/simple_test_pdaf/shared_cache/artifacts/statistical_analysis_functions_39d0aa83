{
  "status": "success",
  "functions_generated": 6,
  "output_file": "automatedstatisticalanalysisagent_functions.py",
  "module_size": 26407,
  "function_code_content": "\"\"\"\nAutomated Statistical Analysis Functions\n========================================\n\nGenerated by AutomatedStatisticalAnalysisAgent for experiment: simple_test_pdaf\nDescription: Statistical analysis experiment\nGenerated: 2025-08-30T01:22:41.181376+00:00\n\nThis module contains automatically generated statistical analysis functions\nfor comprehensive data analysis including ANOVA, correlations, reliability,\nand hypothesis testing as appropriate for the research questions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport scipy.stats as stats\nfrom typing import Dict, Any, Optional, List, Tuple\nimport warnings\n\n# Suppress common statistical warnings for cleaner output\nwarnings.filterwarnings('ignore', category=RuntimeWarning)\n\n\ndef calculate_derived_metrics(data, **kwargs):\n    \"\"\"\n    Calculates all derived metrics as specified in the PDAF v10.0.0 framework.\n\n    This function implements the formulas for the three strategic tension metrics,\n    the Populist Strategic Contradiction Index (PSCI), and the four salience-weighted\n    indices. It adds these new metrics as columns to the input DataFrame.\n\n    Methodology:\n    - Tension Metrics: Calculated using the formula:\n      Tension = min(Score_A, Score_B) * |Salience_A - Salience_B|\n    - PSCI: The arithmetic mean of the three tension metrics.\n    - Salience-Weighted Indices: Calculated using the formula:\n      Index = sum(score * salience) / (sum(salience) + 0.001)\n      The 0.001 epsilon prevents division by zero.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the raw analysis data with columns for\n                             raw scores and salience for each of the 9 dimensions.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        pd.DataFrame: The original DataFrame with added columns for each derived metric,\n                      or None if essential columns are missing.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        df = data.copy()\n\n        # Define required columns for validation\n        required_cols = [\n            'popular_sovereignty_claims_raw', 'popular_sovereignty_claims_salience',\n            'anti_pluralist_exclusion_raw', 'anti_pluralist_exclusion_salience',\n            'homogeneous_people_construction_raw', 'homogeneous_people_construction_salience',\n            'nationalist_exclusion_raw', 'nationalist_exclusion_salience',\n            'crisis_restoration_narrative_raw', 'crisis_restoration_narrative_salience',\n            'elite_conspiracy_systemic_corruption_raw', 'elite_conspiracy_systemic_corruption_salience',\n            'manichaean_people_elite_framing_raw', 'manichaean_people_elite_framing_salience',\n            'economic_populist_appeals_raw', 'economic_populist_appeals_salience',\n            'authenticity_vs_political_class_raw', 'authenticity_vs_political_class_salience'\n        ]\n        if not all(col in df.columns for col in required_cols):\n            # Missing one or more essential columns for calculation\n            return None\n\n        # 1. Democratic-Authoritarian Tension\n        df['democratic_authoritarian_tension'] = df.apply(\n            lambda row: min(row['popular_sovereignty_claims_raw'], row['anti_pluralist_exclusion_raw']) *\n                        abs(row['popular_sovereignty_claims_salience'] - row['anti_pluralist_exclusion_salience']),\n            axis=1\n        )\n\n        # 2. Internal-External Focus Tension\n        df['internal_external_focus_tension'] = df.apply(\n            lambda row: min(row['homogeneous_people_construction_raw'], row['nationalist_exclusion_raw']) *\n                        abs(row['homogeneous_people_construction_salience'] - row['nationalist_exclusion_salience']),\n            axis=1\n        )\n\n        # 3. Crisis-Elite Attribution Tension\n        df['crisis_elite_attribution_tension'] = df.apply(\n            lambda row: min(row['crisis_restoration_narrative_raw'], row['elite_conspiracy_systemic_corruption_raw']) *\n                        abs(row['crisis_restoration_narrative_salience'] - row['elite_conspiracy_systemic_corruption_salience']),\n            axis=1\n        )\n\n        # 4. Populist Strategic Contradiction Index (PSCI)\n        df['populist_strategic_contradiction_index'] = (\n            df['democratic_authoritarian_tension'] +\n            df['internal_external_focus_tension'] +\n            df['crisis_elite_attribution_tension']\n        ) / 3\n\n        # 5. Salience-Weighted Core Populism Index\n        core_numerator = (df['manichaean_people_elite_framing_raw'] * df['manichaean_people_elite_framing_salience'] +\n                          df['crisis_restoration_narrative_raw'] * df['crisis_restoration_narrative_salience'] +\n                          df['popular_sovereignty_claims_raw'] * df['popular_sovereignty_claims_salience'] +\n                          df['anti_pluralist_exclusion_raw'] * df['anti_pluralist_exclusion_salience'])\n        core_denominator = (df['manichaean_people_elite_framing_salience'] +\n                            df['crisis_restoration_narrative_salience'] +\n                            df['popular_sovereignty_claims_salience'] +\n                            df['anti_pluralist_exclusion_salience'] + 0.001)\n        df['salience_weighted_core_populism_index'] = core_numerator / core_denominator\n\n        # 6. Salience-Weighted Populism Mechanisms Index\n        mech_numerator = (df['elite_conspiracy_systemic_corruption_raw'] * df['elite_conspiracy_systemic_corruption_salience'] +\n                          df['authenticity_vs_political_class_raw'] * df['authenticity_vs_political_class_salience'] +\n                          df['homogeneous_people_construction_raw'] * df['homogeneous_people_construction_salience'])\n        mech_denominator = (df['elite_conspiracy_systemic_corruption_salience'] +\n                            df['authenticity_vs_political_class_salience'] +\n                            df['homogeneous_people_construction_salience'] + 0.001)\n        df['salience_weighted_populism_mechanisms_index'] = mech_numerator / mech_denominator\n\n        # 7. Salience-Weighted Boundary Distinctions Index\n        bound_numerator = (df['nationalist_exclusion_raw'] * df['nationalist_exclusion_salience'] +\n                           df['economic_populist_appeals_raw'] * df['economic_populist_appeals_salience'])\n        bound_denominator = (df['nationalist_exclusion_salience'] +\n                             df['economic_populist_appeals_salience'] + 0.001)\n        df['salience_weighted_boundary_distinctions_index'] = bound_numerator / bound_denominator\n\n        # 8. Salience-Weighted Overall Populism Index\n        all_dims_salience = [\n            'manichaean_people_elite_framing', 'crisis_restoration_narrative', 'popular_sovereignty_claims',\n            'anti_pluralist_exclusion', 'elite_conspiracy_systemic_corruption', 'authenticity_vs_political_class',\n            'homogeneous_people_construction', 'nationalist_exclusion', 'economic_populist_appeals'\n        ]\n        overall_numerator = sum(df[f'{dim}_raw'] * df[f'{dim}_salience'] for dim in all_dims_salience)\n        overall_denominator = sum(df[f'{dim}_salience'] for dim in all_dims_salience) + 0.001\n        df['salience_weighted_overall_populism_index'] = overall_numerator / overall_denominator\n\n        return df.fillna(0)\n\n    except (KeyError, TypeError, Exception):\n        return None\n\ndef summarize_descriptive_statistics(data, **kwargs):\n    \"\"\"\n    Generates descriptive statistics for all raw and derived populist metrics,\n    grouped by political communication style.\n\n    Methodology:\n    1.  Calculates all derived metrics using the `calculate_derived_metrics` function.\n    2.  Maps each document to a communication style ('Populist', 'Institutional')\n        based on a predefined mapping of document names.\n    3.  Groups the data by this style.\n    4.  Calculates the mean, standard deviation, and median for all 9 raw score\n        dimensions and all 8 derived metrics for each group.\n    5.  Handles documents not in the predefined mapping by assigning them to an 'Unknown' group.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the raw analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary containing descriptive statistics for each communication style,\n              or None if the analysis fails.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # Internal helper to get metadata from document name\n        def get_style_metadata(doc_name):\n            # This mapping is based on the corpus manifest information provided.\n            doc_map = {\n                'bernie_sanders_2025_fighting_oligarchy.txt': {'type': 'Populist'},\n                'alexandria_ocasio_cortez_2025_fighting_oligarchy.txt': {'type': 'Populist'},\n                'steve_king_2017_house_floor.txt': {'type': 'Populist'},\n                'donald_trump_2016_rnc_acceptance.txt': {'type': 'Populist'},\n                'john_mccain_2008_concession.txt': {'type': 'Institutional'},\n                'barack_obama_2012_dnc_acceptance.txt': {'type': 'Institutional'},\n            }\n            return doc_map.get(doc_name, {'type': 'Unknown'})['type']\n\n        # Calculate derived metrics first\n        metrics_df = calculate_derived_metrics(data)\n        if metrics_df is None:\n            return None\n\n        # Add style metadata column\n        metrics_df['style_type'] = metrics_df['document_name'].apply(get_style_metadata)\n\n        # Define columns for analysis\n        raw_score_cols = [col for col in data.columns if col.endswith('_raw')]\n        derived_cols = [\n            'democratic_authoritarian_tension', 'internal_external_focus_tension',\n            'crisis_elite_attribution_tension', 'populist_strategic_contradiction_index',\n            'salience_weighted_core_populism_index', 'salience_weighted_populism_mechanisms_index',\n            'salience_weighted_boundary_distinctions_index', 'salience_weighted_overall_populism_index'\n        ]\n        analysis_cols = raw_score_cols + derived_cols\n\n        # Group by style and calculate stats\n        grouped_stats = metrics_df.groupby('style_type')[analysis_cols].agg(['mean', 'std', 'median'])\n\n        if grouped_stats.empty:\n            return None\n\n        # Format for JSON output\n        results = grouped_stats.to_dict(orient='index')\n        # Convert nested dicts for easier parsing\n        for style, stats in results.items():\n            results[style] = {k: v for k, v in stats.items()}\n\n        return results\n\n    except Exception:\n        return None\n\ndef analyze_communication_style_differences(data, **kwargs):\n    \"\"\"\n    Compares populist dimension scores between 'Populist' and 'Institutional' communication styles.\n\n    Methodology:\n    1.  Calculates derived metrics and adds a 'style_type' column ('Populist' vs. 'Institutional')\n        based on a predefined document name mapping.\n    2.  Separates the dataset into two groups based on 'style_type'.\n    3.  For each of the 9 raw populist dimensions, it performs a non-parametric\n        Mann-Whitney U test to determine if there is a statistically significant\n        difference in the median scores between the two styles. This test is chosen\n        for its robustness with non-normal data and potentially small sample sizes.\n    4.  Returns the test statistic and p-value for each dimension.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the raw analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary with results of the Mann-Whitney U test for each dimension,\n              or None if groups are invalid for comparison.\n    \"\"\"\n    import pandas as pd\n    from scipy.stats import mannwhitneyu\n\n    try:\n        # Internal helper to get metadata from document name\n        def get_style_metadata(doc_name):\n            doc_map = {\n                'bernie_sanders_2025_fighting_oligarchy.txt': {'type': 'Populist'},\n                'alexandria_ocasio_cortez_2025_fighting_oligarchy.txt': {'type': 'Populist'},\n                'steve_king_2017_house_floor.txt': {'type': 'Populist'},\n                'donald_trump_2016_rnc_acceptance.txt': {'type': 'Populist'},\n                'john_mccain_2008_concession.txt': {'type': 'Institutional'},\n                'barack_obama_2012_dnc_acceptance.txt': {'type': 'Institutional'},\n            }\n            return doc_map.get(doc_name, {'type': 'Unknown'})['type']\n\n        df = data.copy()\n        df['style_type'] = df['document_name'].apply(get_style_metadata)\n\n        # Create groups\n        populist_group = df[df['style_type'] == 'Populist']\n        institutional_group = df[df['style_type'] == 'Institutional']\n\n        if populist_group.empty or institutional_group.empty:\n            return None # Not enough data for comparison\n\n        # Dimensions to test\n        dimensions = [col for col in df.columns if col.endswith('_raw')]\n        results = {}\n\n        for dim in dimensions:\n            group1_data = populist_group[dim].dropna()\n            group2_data = institutional_group[dim].dropna()\n\n            if len(group1_data) < 1 or len(group2_data) < 1:\n                results[dim] = {'error': 'Insufficient data for one or both groups.'}\n                continue\n\n            stat, p_value = mannwhitneyu(group1_data, group2_data, alternative='two-sided')\n            results[dim] = {\n                'mann_whitney_u_statistic': stat,\n                'p_value': p_value,\n                'comment': 'Significant difference' if p_value < 0.05 else 'No significant difference'\n            }\n\n        return results if results else None\n\n    except Exception:\n        return None\n\ndef analyze_strategic_tension_patterns(data, **kwargs):\n    \"\"\"\n    Compares strategic tension metrics between 'Populist' and 'Institutional' styles.\n\n    Methodology:\n    1.  Calculates all derived metrics, including the three tension scores and the overall PSCI.\n    2.  Maps documents to 'Populist' or 'Institutional' styles.\n    3.  For each of the four tension-related metrics, it performs a non-parametric\n        Mann-Whitney U test to check for significant differences between the two styles.\n        This addresses RQ2 by quantifying the difference in strategic contradiction patterns.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the raw analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary with results of the Mann-Whitney U test for each tension metric,\n              or None if groups are invalid for comparison.\n    \"\"\"\n    import pandas as pd\n    from scipy.stats import mannwhitneyu\n\n    try:\n        # Internal helper to get metadata from document name\n        def get_style_metadata(doc_name):\n            doc_map = {\n                'bernie_sanders_2025_fighting_oligarchy.txt': {'type': 'Populist'},\n                'alexandria_ocasio_cortez_2025_fighting_oligarchy.txt': {'type': 'Populist'},\n                'steve_king_2017_house_floor.txt': {'type': 'Populist'},\n                'donald_trump_2016_rnc_acceptance.txt': {'type': 'Populist'},\n                'john_mccain_2008_concession.txt': {'type': 'Institutional'},\n                'barack_obama_2012_dnc_acceptance.txt': {'type': 'Institutional'},\n            }\n            return doc_map.get(doc_name, {'type': 'Unknown'})['type']\n\n        metrics_df = calculate_derived_metrics(data)\n        if metrics_df is None:\n            return None\n\n        metrics_df['style_type'] = metrics_df['document_name'].apply(get_style_metadata)\n\n        populist_group = metrics_df[metrics_df['style_type'] == 'Populist']\n        institutional_group = metrics_df[metrics_df['style_type'] == 'Institutional']\n\n        if populist_group.empty or institutional_group.empty:\n            return None\n\n        tension_metrics = [\n            'democratic_authoritarian_tension',\n            'internal_external_focus_tension',\n            'crisis_elite_attribution_tension',\n            'populist_strategic_contradiction_index'\n        ]\n        results = {}\n\n        for metric in tension_metrics:\n            group1_data = populist_group[metric].dropna()\n            group2_data = institutional_group[metric].dropna()\n\n            if len(group1_data) < 1 or len(group2_data) < 1:\n                results[metric] = {'error': 'Insufficient data for one or both groups.'}\n                continue\n\n            stat, p_value = mannwhitneyu(group1_data, group2_data, alternative='two-sided')\n            results[metric] = {\n                'mann_whitney_u_statistic': stat,\n                'p_value': p_value,\n                'comment': 'Significant difference' if p_value < 0.05 else 'No significant difference'\n            }\n\n        return results if results else None\n\n    except Exception:\n        return None\n\ndef compare_populist_ideologies(data, **kwargs):\n    \"\"\"\n    Compares boundary construction and crisis narratives between populist conservative and progressive styles.\n\n    Methodology:\n    1.  Filters the dataset to include only documents classified as 'Populist'.\n    2.  Further divides this subset into 'Populist Progressive' and 'Populist Conservative'\n        based on a predefined document-to-ideology mapping.\n    3.  For the dimensions related to boundary construction (`nationalist_exclusion`,\n        `economic_populist_appeals`, `homogeneous_people_construction`) and crisis\n        narratives (`crisis_restoration_narrative`), it performs a Mann-Whitney U test.\n    4.  This directly addresses RQ3 by testing for significant differences between the\n        two populist ideological variants on specific rhetorical strategies.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the raw analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary with results of the Mann-Whitney U test for each relevant dimension,\n              or None if groups are invalid for comparison.\n    \"\"\"\n    import pandas as pd\n    from scipy.stats import mannwhitneyu\n\n    try:\n        # Internal helper to get detailed metadata from document name\n        def get_ideology_metadata(doc_name):\n            doc_map = {\n                'bernie_sanders_2025_fighting_oligarchy.txt': {'ideology': 'Populist Progressive'},\n                'alexandria_ocasio_cortez_2025_fighting_oligarchy.txt': {'ideology': 'Populist Progressive'},\n                'steve_king_2017_house_floor.txt': {'ideology': 'Populist Conservative'},\n                'donald_trump_2016_rnc_acceptance.txt': {'ideology': 'Populist Conservative'},\n                'john_mccain_2008_concession.txt': {'ideology': 'Institutional'},\n                'barack_obama_2012_dnc_acceptance.txt': {'ideology': 'Institutional'},\n            }\n            return doc_map.get(doc_name, {'ideology': 'Unknown'})['ideology']\n\n        df = data.copy()\n        df['ideology'] = df['document_name'].apply(get_ideology_metadata)\n\n        # Create groups\n        progressive_group = df[df['ideology'] == 'Populist Progressive']\n        conservative_group = df[df['ideology'] == 'Populist Conservative']\n\n        if progressive_group.empty or conservative_group.empty:\n            return None # Not enough data for comparison\n\n        # Dimensions relevant to RQ3\n        dimensions_to_test = [\n            'nationalist_exclusion_raw',\n            'economic_populist_appeals_raw',\n            'homogeneous_people_construction_raw',\n            'crisis_restoration_narrative_raw'\n        ]\n        results = {}\n\n        for dim in dimensions_to_test:\n            group1_data = progressive_group[dim].dropna()\n            group2_data = conservative_group[dim].dropna()\n\n            if len(group1_data) < 1 or len(group2_data) < 1:\n                results[dim] = {'error': 'Insufficient data for one or both groups.'}\n                continue\n\n            stat, p_value = mannwhitneyu(group1_data, group2_data, alternative='two-sided')\n            results[dim] = {\n                'mann_whitney_u_statistic': stat,\n                'p_value': p_value,\n                'comment': 'Significant difference' if p_value < 0.05 else 'No significant difference'\n            }\n\n        return results if results else None\n\n    except Exception:\n        return None\n\ndef generate_correlation_matrix(data, **kwargs):\n    \"\"\"\n    Generates a correlation matrix for the nine raw populist dimension scores.\n\n    Methodology:\n    - Selects the nine columns ending in '_raw'.\n    - Computes the Spearman rank-order correlation coefficient for each pair of dimensions.\n      Spearman correlation is used as it is a non-parametric measure that assesses\n      monotonic relationships and is suitable for the 0.0-1.0 scale of the scores,\n      which may not be normally distributed.\n    - The resulting matrix shows how dimensions tend to co-occur in the analyzed texts.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the raw analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary representing the correlation matrix, or None on failure.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        raw_score_cols = [col for col in data.columns if col.endswith('_raw')]\n        if not raw_score_cols:\n            return None\n\n        raw_df = data[raw_score_cols]\n        \n        # Clean column names for better readability in the output\n        raw_df.columns = [c.replace('_raw', '') for c in raw_df.columns]\n\n        # Calculate Spearman correlation\n        correlation_matrix = raw_df.corr(method='spearman')\n\n        if correlation_matrix.empty:\n            return None\n\n        # Replace NaN with None for JSON compatibility\n        correlation_matrix = correlation_matrix.replace({np.nan: None})\n        \n        return correlation_matrix.to_dict()\n\n    except Exception:\n        return None\n\ndef run_complete_statistical_analysis(data: pd.DataFrame, alpha: float = 0.05) -> Dict[str, Any]:\n    \"\"\"\n    Run complete statistical analysis suite on the dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        alpha: Significance level for hypothesis tests (default: 0.05)\n        \n    Returns:\n        Dictionary with all statistical analysis results\n    \"\"\"\n    results = {\n        'analysis_metadata': {\n            'timestamp': pd.Timestamp.now().isoformat(),\n            'sample_size': len(data),\n            'alpha_level': alpha,\n            'variables_analyzed': list(data.select_dtypes(include=[np.number]).columns)\n        }\n    }\n    \n    # Get all analysis functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith(('calculate_', 'perform_', 'test_')) and \n            name != 'run_complete_statistical_analysis'):\n            try:\n                # Pass alpha parameter to functions that might need it\n                if 'alpha' in inspect.signature(obj).parameters:\n                    results[name] = obj(data, alpha=alpha)\n                else:\n                    results[name] = obj(data)\n            except Exception as e:\n                results[name] = {'error': f'Analysis failed: {str(e)}'}\n                \n    return results\n\n\ndef perform_statistical_analysis(data: pd.DataFrame) -> Dict[str, Any]:\n    \"\"\"\n    Template-compatible wrapper function for statistical analysis.\n    \n    This function is called by the universal notebook template and performs\n    comprehensive statistical analysis on the provided dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores and derived metrics\n        \n    Returns:\n        Dictionary containing all statistical analysis results\n    \"\"\"\n    return run_complete_statistical_analysis(data)\n\n\ndef generate_statistical_summary_report(analysis_results: Dict[str, Any]) -> str:\n    \"\"\"\n    Generate a human-readable summary report from statistical analysis results.\n    \n    Args:\n        analysis_results: Results from run_complete_statistical_analysis()\n        \n    Returns:\n        String containing formatted statistical report\n    \"\"\"\n    report_lines = []\n    report_lines.append(\"STATISTICAL ANALYSIS SUMMARY REPORT\")\n    report_lines.append(\"=\" * 50)\n    \n    metadata = analysis_results.get('analysis_metadata', {})\n    report_lines.append(f\"Analysis Timestamp: {metadata.get('timestamp', 'Unknown')}\")\n    report_lines.append(f\"Sample Size: {metadata.get('sample_size', 'Unknown')}\")\n    report_lines.append(f\"Alpha Level: {metadata.get('alpha_level', 'Unknown')}\")\n    report_lines.append(f\"Variables: {len(metadata.get('variables_analyzed', []))}\")\n    report_lines.append(\"\")\n    \n    # Summarize key findings\n    for analysis_name, result in analysis_results.items():\n        if analysis_name != 'analysis_metadata' and isinstance(result, dict):\n            if 'error' not in result:\n                report_lines.append(f\"{analysis_name.replace('_', ' ').title()}:\")\n                \n                # Extract key statistics based on analysis type\n                if 'p_value' in result:\n                    p_val = result['p_value']\n                    significance = \"significant\" if p_val < metadata.get('alpha_level', 0.05) else \"not significant\"\n                    report_lines.append(f\"  - p-value: {p_val:.4f} ({significance})\")\n                \n                if 'effect_size' in result:\n                    report_lines.append(f\"  - Effect size: {result['effect_size']:.4f}\")\n                \n                if 'correlation_matrix' in result:\n                    report_lines.append(f\"  - Correlation matrix generated with {len(result['correlation_matrix'])} variables\")\n                \n                if 'cronbach_alpha' in result:\n                    alpha_val = result['cronbach_alpha']\n                    reliability = \"excellent\" if alpha_val > 0.9 else \"good\" if alpha_val > 0.8 else \"acceptable\" if alpha_val > 0.7 else \"questionable\"\n                    report_lines.append(f\"  - Cronbach's \u03b1: {alpha_val:.3f} ({reliability})\")\n                \n                report_lines.append(\"\")\n            else:\n                report_lines.append(f\"{analysis_name}: ERROR - {result['error']}\")\n                report_lines.append(\"\")\n    \n    return \"\\n\".join(report_lines)\n",
  "cached_with_code": true
}