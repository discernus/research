{
  "status": "success",
  "functions_generated": 3,
  "output_file": "automatedstatisticalanalysisagent_functions.py",
  "module_size": 22986,
  "function_code_content": "\"\"\"\nAutomated Statistical Analysis Functions\n========================================\n\nGenerated by AutomatedStatisticalAnalysisAgent for experiment: simple_test\nDescription: Statistical analysis experiment\nGenerated: 2025-08-30T02:07:29.917182+00:00\n\nThis module contains automatically generated statistical analysis functions\nfor comprehensive data analysis including ANOVA, correlations, reliability,\nand hypothesis testing as appropriate for the research questions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport scipy.stats as stats\nfrom typing import Dict, Any, Optional, List, Tuple\nimport warnings\n\n# Suppress common statistical warnings for cleaner output\nwarnings.filterwarnings('ignore', category=RuntimeWarning)\n\n\ndef calculate_baseline_scores(data, **kwargs):\n    \"\"\"\n    Calculates and returns baseline descriptive statistics for the derived cohesion and tension scores.\n\n    This function first computes the derived metrics as specified by the Cohesive Flourishing Framework v10,\n    including five tension indices, the Strategic Contradiction Index, and three cohesion indices.\n    It then calculates descriptive statistics (mean, std, min, 25%, 50%, 75%, max) for each of these\n    derived metrics across the entire corpus.\n\n    Methodology:\n    1.  Calculates all 14 derived metrics from the raw and salience scores based on the CFF v10 formulas.\n        - It correctly maps the framework's 'compersion' concept to the available 'compassion' data columns.\n    2.  Uses pandas.DataFrame.describe() to compute summary statistics for the key indices:\n        - All 5 tension indices\n        - Strategic Contradiction Index\n        - Descriptive, Motivational, and Full Cohesion Indices.\n    3.  Returns the statistics in a structured dictionary.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the analysis data with columns for raw scores and salience\n                             for each of the 10 CFF dimensions.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary containing the descriptive statistics for each key derived metric.\n              Returns None if the input data is invalid or calculations fail.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        if data is None or data.empty:\n            return None\n\n        df = data.copy()\n\n        # Define required columns and check for their presence\n        # Note: The framework specifies 'compersion', but the data provides 'compassion'. We use 'compassion'.\n        required_raw = [\n            'tribal_dominance_raw', 'individual_dignity_raw', 'fear_raw', 'hope_raw',\n            'envy_raw', 'compassion_raw', 'enmity_raw', 'amity_raw',\n            'fragmentative_goals_raw', 'cohesive_goals_raw'\n        ]\n        required_salience = [\n            'tribal_dominance_salience', 'individual_dignity_salience', 'fear_salience', 'hope_salience',\n            'envy_salience', 'compassion_salience', 'enmity_salience', 'amity_salience',\n            'fragmentative_goals_salience', 'cohesive_goals_salience'\n        ]\n        \n        if not all(col in df.columns for col in required_raw + required_salience):\n            # Attempt to rename if old format is present, otherwise fail\n            rename_map = {\n                'compersion_raw': 'compassion_raw',\n                'compersion_salience': 'compassion_salience'\n            }\n            df.rename(columns=rename_map, inplace=True)\n            if not all(col in df.columns for col in required_raw + required_salience):\n                return None # Still missing required columns\n\n        # --- Calculate Derived Metrics ---\n\n        # Tension Indices\n        df['identity_tension'] = np.minimum(df['tribal_dominance_raw'], df['individual_dignity_raw']) * \\\n                                 abs(df['tribal_dominance_salience'] - df['individual_dignity_salience'])\n        df['emotional_tension'] = np.minimum(df['fear_raw'], df['hope_raw']) * \\\n                                  abs(df['fear_salience'] - df['hope_salience'])\n        df['success_tension'] = np.minimum(df['envy_raw'], df['compassion_raw']) * \\\n                                abs(df['envy_salience'] - df['compassion_salience'])\n        df['relational_tension'] = np.minimum(df['enmity_raw'], df['amity_raw']) * \\\n                                   abs(df['enmity_salience'] - df['amity_salience'])\n        df['goal_tension'] = np.minimum(df['fragmentative_goals_raw'], df['cohesive_goals_raw']) * \\\n                             abs(df['fragmentative_goals_salience'] - df['cohesive_goals_salience'])\n\n        # Strategic Contradiction Index\n        tension_cols = ['identity_tension', 'emotional_tension', 'success_tension', 'relational_tension', 'goal_tension']\n        df['strategic_contradiction_index'] = df[tension_cols].mean(axis=1)\n\n        # Salience-Weighted Cohesion Indices\n        epsilon = 0.001\n        \n        # Components\n        identity_comp = (df['individual_dignity_raw'] * df['individual_dignity_salience'] - df['tribal_dominance_raw'] * df['tribal_dominance_salience'])\n        emotional_comp = (df['hope_raw'] * df['hope_salience'] - df['fear_raw'] * df['fear_salience'])\n        success_comp = (df['compassion_raw'] * df['compassion_salience'] - df['envy_raw'] * df['envy_salience'])\n        relational_comp = (df['amity_raw'] * df['amity_salience'] - df['enmity_raw'] * df['enmity_salience'])\n        goal_comp = (df['cohesive_goals_raw'] * df['cohesive_goals_salience'] - df['fragmentative_goals_raw'] * df['fragmentative_goals_salience'])\n\n        # Salience Totals\n        descriptive_salience = df['hope_salience'] + df['fear_salience'] + df['compassion_salience'] + df['envy_salience'] + df['amity_salience'] + df['enmity_salience']\n        motivational_salience = descriptive_salience + df['cohesive_goals_salience'] + df['fragmentative_goals_salience']\n        full_salience = motivational_salience + df['individual_dignity_salience'] + df['tribal_dominance_salience']\n\n        # Descriptive Cohesion Index\n        df['descriptive_cohesion_index'] = (emotional_comp + success_comp + relational_comp) / (descriptive_salience + epsilon)\n        \n        # Motivational Cohesion Index\n        df['motivational_cohesion_index'] = (emotional_comp + success_comp + relational_comp + goal_comp) / (motivational_salience + epsilon)\n\n        # Full Cohesion Index\n        df['full_cohesion_index'] = (identity_comp + emotional_comp + success_comp + relational_comp + goal_comp) / (full_salience + epsilon)\n        \n        # Select derived metrics for descriptive statistics\n        derived_metrics_cols = [\n            'identity_tension', 'emotional_tension', 'success_tension', 'relational_tension', 'goal_tension',\n            'strategic_contradiction_index', 'descriptive_cohesion_index', 'motivational_cohesion_index', 'full_cohesion_index'\n        ]\n        \n        # Calculate descriptive statistics\n        stats = df[derived_metrics_cols].describe().to_dict()\n\n        return stats\n\n    except Exception:\n        return None\n\ndef compare_cohesion_by_style(data, **kwargs):\n    \"\"\"\n    Compares cohesion scores between 'Institutional' and 'Populist' rhetorical styles.\n\n    This function addresses the research question: \"Will McCain's institutional discourse show higher cohesion\n    than populist styles?\". It categorizes documents into 'Institutional' (McCain) and 'Populist'\n    (Sanders, Ocasio-Cortez, King) based on speaker names derived from the 'document_name' column.\n    It then performs statistical tests to compare the means of the three cohesion indices between these groups.\n\n    Methodology:\n    1.  Calculates the three CFF v10 cohesion indices.\n    2.  Assigns a 'rhetorical_style' to each document based on the speaker's name.\n    3.  For each cohesion index ('descriptive', 'motivational', 'full'):\n        a.  Performs an independent samples t-test (scipy.stats.ttest_ind) to compare group means.\n        b.  Performs a Mann-Whitney U test (scipy.stats.mannwhitneyu) as a non-parametric alternative.\n    4.  Returns a dictionary containing the results (statistic and p-value) for each test.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the analysis data. Must include a 'document_name' column.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A nested dictionary with results for t-tests and Mann-Whitney U tests for each cohesion index.\n              Returns None if there are not enough data points in each group for comparison.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    from scipy import stats\n\n    try:\n        if data is None or data.empty or 'document_name' not in data.columns:\n            return None\n\n        df = data.copy()\n\n        # Define required columns and check for their presence\n        # Note: The framework specifies 'compersion', but the data provides 'compassion'. We use 'compassion'.\n        required_raw = [\n            'tribal_dominance_raw', 'individual_dignity_raw', 'fear_raw', 'hope_raw',\n            'envy_raw', 'compassion_raw', 'enmity_raw', 'amity_raw',\n            'fragmentative_goals_raw', 'cohesive_goals_raw'\n        ]\n        required_salience = [\n            'tribal_dominance_salience', 'individual_dignity_salience', 'fear_salience', 'hope_salience',\n            'envy_salience', 'compassion_salience', 'enmity_salience', 'amity_salience',\n            'fragmentative_goals_salience', 'cohesive_goals_salience'\n        ]\n        \n        if not all(col in df.columns for col in required_raw + required_salience):\n            rename_map = {'compersion_raw': 'compassion_raw', 'compersion_salience': 'compassion_salience'}\n            df.rename(columns=rename_map, inplace=True)\n            if not all(col in df.columns for col in required_raw + required_salience):\n                return None\n\n        # --- Calculate Cohesion Indices ---\n        epsilon = 0.001\n        identity_comp = (df['individual_dignity_raw'] * df['individual_dignity_salience'] - df['tribal_dominance_raw'] * df['tribal_dominance_salience'])\n        emotional_comp = (df['hope_raw'] * df['hope_salience'] - df['fear_raw'] * df['fear_salience'])\n        success_comp = (df['compassion_raw'] * df['compassion_salience'] - df['envy_raw'] * df['envy_salience'])\n        relational_comp = (df['amity_raw'] * df['amity_salience'] - df['enmity_raw'] * df['enmity_salience'])\n        goal_comp = (df['cohesive_goals_raw'] * df['cohesive_goals_salience'] - df['fragmentative_goals_raw'] * df['fragmentative_goals_salience'])\n        descriptive_salience = df['hope_salience'] + df['fear_salience'] + df['compassion_salience'] + df['envy_salience'] + df['amity_salience'] + df['enmity_salience']\n        motivational_salience = descriptive_salience + df['cohesive_goals_salience'] + df['fragmentative_goals_salience']\n        full_salience = motivational_salience + df['individual_dignity_salience'] + df['tribal_dominance_salience']\n        df['descriptive_cohesion_index'] = (emotional_comp + success_comp + relational_comp) / (descriptive_salience + epsilon)\n        df['motivational_cohesion_index'] = (emotional_comp + success_comp + relational_comp + goal_comp) / (motivational_salience + epsilon)\n        df['full_cohesion_index'] = (identity_comp + emotional_comp + success_comp + relational_comp + goal_comp) / (full_salience + epsilon)\n\n        # --- Group by Rhetorical Style ---\n        def get_style(doc_name):\n            doc_name_lower = doc_name.lower()\n            if 'mccain' in doc_name_lower:\n                return 'Institutional'\n            elif any(p in doc_name_lower for p in ['sanders', 'ocasio_cortez', 'king']):\n                return 'Populist'\n            return 'Other'\n\n        df['rhetorical_style'] = df['document_name'].apply(get_style)\n\n        institutional_group = df[df['rhetorical_style'] == 'Institutional']\n        populist_group = df[df['rhetorical_style'] == 'Populist']\n\n        if institutional_group.empty or populist_group.empty:\n            return {\"error\": \"Insufficient data for one or both rhetorical style groups.\"}\n\n        results = {}\n        cohesion_indices = ['descriptive_cohesion_index', 'motivational_cohesion_index', 'full_cohesion_index']\n\n        for index in cohesion_indices:\n            group1 = institutional_group[index].dropna()\n            group2 = populist_group[index].dropna()\n\n            if len(group1) < 2 or len(group2) < 2:\n                continue\n\n            # T-test\n            ttest_res = stats.ttest_ind(group1, group2, equal_var=False) # Welch's t-test\n            # Mann-Whitney U test\n            mw_res = stats.mannwhitneyu(group1, group2, alternative='two-sided')\n\n            results[index] = {\n                't_test': {'statistic': ttest_res.statistic, 'p_value': ttest_res.pvalue},\n                'mann_whitney_u': {'statistic': mw_res.statistic, 'p_value': mw_res.pvalue},\n                'group_means': {\n                    'Institutional': group1.mean(),\n                    'Populist': group2.mean()\n                }\n            }\n        \n        return results if results else None\n\n    except Exception:\n        return None\n\ndef analyze_score_correlations(data, **kwargs):\n    \"\"\"\n    Calculates the correlation matrix for raw scores and derived CFF metrics.\n\n    This function provides an exploratory analysis of the relationships between different\n    dimensions of the Cohesive Flourishing Framework. It is useful for understanding how\n    different rhetorical strategies co-occur within the corpus.\n\n    Methodology:\n    1.  Calculates all 14 derived metrics from the raw and salience scores.\n    2.  Creates a new DataFrame containing only the raw scores (intensity) for the 10 base dimensions\n        and the key derived indices (tensions and cohesions).\n    3.  Computes the Pearson correlation coefficient between each pair of columns in this new DataFrame.\n    4.  Returns the resulting correlation matrix as a dictionary.\n\n    Args:\n        data (pd.DataFrame): DataFrame containing the analysis data.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary representing the correlation matrix, where keys are variable names\n              and values are dictionaries of their correlations with other variables.\n              Returns None if the input data is invalid or calculations fail.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        if data is None or data.empty:\n            return None\n\n        df = data.copy()\n\n        # Define required columns and check for their presence\n        # Note: The framework specifies 'compersion', but the data provides 'compassion'. We use 'compassion'.\n        required_raw = [\n            'tribal_dominance_raw', 'individual_dignity_raw', 'fear_raw', 'hope_raw',\n            'envy_raw', 'compassion_raw', 'enmity_raw', 'amity_raw',\n            'fragmentative_goals_raw', 'cohesive_goals_raw'\n        ]\n        required_salience = [\n            'tribal_dominance_salience', 'individual_dignity_salience', 'fear_salience', 'hope_salience',\n            'envy_salience', 'compassion_salience', 'enmity_salience', 'amity_salience',\n            'fragmentative_goals_salience', 'cohesive_goals_salience'\n        ]\n        \n        if not all(col in df.columns for col in required_raw + required_salience):\n            rename_map = {'compersion_raw': 'compassion_raw', 'compersion_salience': 'compassion_salience'}\n            df.rename(columns=rename_map, inplace=True)\n            if not all(col in df.columns for col in required_raw + required_salience):\n                return None\n\n        # --- Calculate Derived Metrics ---\n        epsilon = 0.001\n        df['identity_tension'] = np.minimum(df['tribal_dominance_raw'], df['individual_dignity_raw']) * abs(df['tribal_dominance_salience'] - df['individual_dignity_salience'])\n        df['emotional_tension'] = np.minimum(df['fear_raw'], df['hope_raw']) * abs(df['fear_salience'] - df['hope_salience'])\n        df['success_tension'] = np.minimum(df['envy_raw'], df['compassion_raw']) * abs(df['envy_salience'] - df['compassion_salience'])\n        df['relational_tension'] = np.minimum(df['enmity_raw'], df['amity_raw']) * abs(df['enmity_salience'] - df['amity_salience'])\n        df['goal_tension'] = np.minimum(df['fragmentative_goals_raw'], df['cohesive_goals_raw']) * abs(df['fragmentative_goals_salience'] - df['cohesive_goals_salience'])\n        tension_cols = ['identity_tension', 'emotional_tension', 'success_tension', 'relational_tension', 'goal_tension']\n        df['strategic_contradiction_index'] = df[tension_cols].mean(axis=1)\n        identity_comp = (df['individual_dignity_raw'] * df['individual_dignity_salience'] - df['tribal_dominance_raw'] * df['tribal_dominance_salience'])\n        emotional_comp = (df['hope_raw'] * df['hope_salience'] - df['fear_raw'] * df['fear_salience'])\n        success_comp = (df['compassion_raw'] * df['compassion_salience'] - df['envy_raw'] * df['envy_salience'])\n        relational_comp = (df['amity_raw'] * df['amity_salience'] - df['enmity_raw'] * df['enmity_salience'])\n        goal_comp = (df['cohesive_goals_raw'] * df['cohesive_goals_salience'] - df['fragmentative_goals_raw'] * df['fragmentative_goals_salience'])\n        descriptive_salience = df['hope_salience'] + df['fear_salience'] + df['compassion_salience'] + df['envy_salience'] + df['amity_salience'] + df['enmity_salience']\n        motivational_salience = descriptive_salience + df['cohesive_goals_salience'] + df['fragmentative_goals_salience']\n        full_salience = motivational_salience + df['individual_dignity_salience'] + df['tribal_dominance_salience']\n        df['descriptive_cohesion_index'] = (emotional_comp + success_comp + relational_comp) / (descriptive_salience + epsilon)\n        df['motivational_cohesion_index'] = (emotional_comp + success_comp + relational_comp + goal_comp) / (motivational_salience + epsilon)\n        df['full_cohesion_index'] = (identity_comp + emotional_comp + success_comp + relational_comp + goal_comp) / (full_salience + epsilon)\n\n        # --- Calculate Correlation Matrix ---\n        correlation_cols = required_raw + [\n            'strategic_contradiction_index', 'descriptive_cohesion_index', \n            'motivational_cohesion_index', 'full_cohesion_index'\n        ]\n        \n        correlation_matrix = df[correlation_cols].corr(method='pearson')\n        \n        return correlation_matrix.to_dict()\n\n    except Exception:\n        return None\n\ndef run_complete_statistical_analysis(data: pd.DataFrame, alpha: float = 0.05) -> Dict[str, Any]:\n    \"\"\"\n    Run complete statistical analysis suite on the dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        alpha: Significance level for hypothesis tests (default: 0.05)\n        \n    Returns:\n        Dictionary with all statistical analysis results\n    \"\"\"\n    results = {\n        'analysis_metadata': {\n            'timestamp': pd.Timestamp.now().isoformat(),\n            'sample_size': len(data),\n            'alpha_level': alpha,\n            'variables_analyzed': list(data.select_dtypes(include=[np.number]).columns)\n        }\n    }\n    \n    # Get all analysis functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith(('calculate_', 'perform_', 'test_')) and \n            name != 'run_complete_statistical_analysis'):\n            try:\n                # Pass alpha parameter to functions that might need it\n                if 'alpha' in inspect.signature(obj).parameters:\n                    results[name] = obj(data, alpha=alpha)\n                else:\n                    results[name] = obj(data)\n            except Exception as e:\n                results[name] = {'error': f'Analysis failed: {str(e)}'}\n                \n    return results\n\n\ndef perform_statistical_analysis(data: pd.DataFrame) -> Dict[str, Any]:\n    \"\"\"\n    Template-compatible wrapper function for statistical analysis.\n    \n    This function is called by the universal notebook template and performs\n    comprehensive statistical analysis on the provided dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores and derived metrics\n        \n    Returns:\n        Dictionary containing all statistical analysis results\n    \"\"\"\n    return run_complete_statistical_analysis(data)\n\n\ndef generate_statistical_summary_report(analysis_results: Dict[str, Any]) -> str:\n    \"\"\"\n    Generate a human-readable summary report from statistical analysis results.\n    \n    Args:\n        analysis_results: Results from run_complete_statistical_analysis()\n        \n    Returns:\n        String containing formatted statistical report\n    \"\"\"\n    report_lines = []\n    report_lines.append(\"STATISTICAL ANALYSIS SUMMARY REPORT\")\n    report_lines.append(\"=\" * 50)\n    \n    metadata = analysis_results.get('analysis_metadata', {})\n    report_lines.append(f\"Analysis Timestamp: {metadata.get('timestamp', 'Unknown')}\")\n    report_lines.append(f\"Sample Size: {metadata.get('sample_size', 'Unknown')}\")\n    report_lines.append(f\"Alpha Level: {metadata.get('alpha_level', 'Unknown')}\")\n    report_lines.append(f\"Variables: {len(metadata.get('variables_analyzed', []))}\")\n    report_lines.append(\"\")\n    \n    # Summarize key findings\n    for analysis_name, result in analysis_results.items():\n        if analysis_name != 'analysis_metadata' and isinstance(result, dict):\n            if 'error' not in result:\n                report_lines.append(f\"{analysis_name.replace('_', ' ').title()}:\")\n                \n                # Extract key statistics based on analysis type\n                if 'p_value' in result:\n                    p_val = result['p_value']\n                    significance = \"significant\" if p_val < metadata.get('alpha_level', 0.05) else \"not significant\"\n                    report_lines.append(f\"  - p-value: {p_val:.4f} ({significance})\")\n                \n                if 'effect_size' in result:\n                    report_lines.append(f\"  - Effect size: {result['effect_size']:.4f}\")\n                \n                if 'correlation_matrix' in result:\n                    report_lines.append(f\"  - Correlation matrix generated with {len(result['correlation_matrix'])} variables\")\n                \n                if 'cronbach_alpha' in result:\n                    alpha_val = result['cronbach_alpha']\n                    reliability = \"excellent\" if alpha_val > 0.9 else \"good\" if alpha_val > 0.8 else \"acceptable\" if alpha_val > 0.7 else \"questionable\"\n                    report_lines.append(f\"  - Cronbach's \u03b1: {alpha_val:.3f} ({reliability})\")\n                \n                report_lines.append(\"\")\n            else:\n                report_lines.append(f\"{analysis_name}: ERROR - {result['error']}\")\n                report_lines.append(\"\")\n    \n    return \"\\n\".join(report_lines)\n",
  "cached_with_code": true
}