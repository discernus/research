{
  "batch_id": "stats_20250917T000623Z",
  "step": "statistical_execution",
  "model_used": "vertex_ai/gemini-2.5-pro",
  "statistical_functions_and_results": "```json\n{\n  \"statistical_functions\": \"import pandas as pd\\nimport numpy as np\\nimport scipy.stats as stats\\nimport pingouin as pg\\nfrom typing import Dict, Any, List, Optional\\nimport json\\nimport re\\n\\ndef _parse_artifacts(data: List[Dict[str, Any]]) -> Optional[pd.DataFrame]:\\n    \\\"\\\"\\\"\\n    Parses raw analysis artifacts into a structured pandas DataFrame.\\n\\n    Args:\\n        data: A list of analysis artifact dictionaries.\\n\\n    Returns:\\n        A pandas DataFrame with scores and metadata, or None if parsing fails.\\n    \\\"\\\"\\\"\\n    # Map analysis_id to document filename from evidence artifacts\\n    # This is a bit brittle, but necessary given the artifact structure\\n    doc_map = {\\n        'analysis_04a96ccf': 'crisis_management.txt',\\n        'analysis_72dcc424': 'political_attack_ad.txt',\\n        'analysis_38efe84d': 'corporate_apology.txt',\\n        'analysis_ce3684f5': 'policy_advocacy.txt',\\n    }\\n\\n    records = []\\n    for artifact in data:\\n        if artifact.get('step') != 'score_extraction':\\n            continue\\n\\n        analysis_id = artifact.get('analysis_id')\\n        doc_filename = doc_map.get(analysis_id)\\n        if not doc_filename:\\n            continue\\n\\n        scores_text = artifact.get('scores_extraction', '')\\n        # Find the JSON part of the string\\n        match = re.search(r'\\\\{[\\\\s\\\\S]*\\\\}', scores_text)\\n        if not match:\\n            # Handle case where text wraps the json\\n            if 'problem_definition:' in scores_text:\\n                try:\\n                    scores = {}\\n                    lines = scores_text.strip().split('\\\\n')\\n                    current_dim = ''\\n                    for line in lines:\\n                        line = line.strip()\\n                        if line.startswith('*'):\\n                            current_dim = line.split(':')[0].replace('*','').strip()\\n                            current_dim = current_dim.replace(' ', '_')\\n                            scores[current_dim] = {}\\n                        elif ':' in line and current_dim:\\n                            key, val = line.split(':', 1)\\n                            key = key.strip().replace('*','').strip()\\n                            scores[current_dim][key] = float(val.strip())\\n                    score_data = scores\\n                except (ValueError, IndexError):\\n                    continue\\n            else:\\n                continue\\n        else:\\n            try:\\n                score_data = json.loads(match.group(0))\\n            except json.JSONDecodeError:\\n                continue\\n\\n        # Flatten the score data\\n        flat_record = {'document_id': doc_filename.replace('.txt', '')}\\n        for dim, values in score_data.items():\\n            for key, value in values.items():\\n                flat_record[f\\\"{dim}_{key}\\\"] = value\\n        records.append(flat_record)\\n\\n    if not records:\\n        return None\\n\\n    df = pd.DataFrame(records)\\n\\n    # Create grouping mapping from corpus manifest\\n    grouping_info = {\\n        'crisis_management': {'context': 'crisis_response', 'framing_focus': 'problem_definition_treatment'},\\n        'political_attack_ad': {'context': 'campaign_advertisement', 'framing_focus': 'problem_cause_moral'},\\n        'corporate_apology': {'context': 'apology_statement', 'framing_focus': 'cause_moral_treatment'},\\n        'policy_advocacy': {'context': 'policy_advocacy', 'framing_focus': 'problem_treatment'}\\n    }\\n    \\n    meta_df = pd.DataFrame.from_dict(grouping_info, orient='index').reset_index().rename(columns={'index': 'document_id'})\\n    df = pd.merge(df, meta_df, on='document_id', how='left')\\n\\n    return df\\n\\ndef calculate_derived_metrics(df: pd.DataFrame) -> pd.DataFrame:\\n    \\\"\\\"\\\"\\n    Calculates all derived metrics based on the framework specification.\\n    \\n    Args:\\n        df: DataFrame with raw and salience scores.\\n        \\n    Returns:\\n        DataFrame with added columns for derived metrics.\\n    \\\"\\\"\\\"\\n    dims_raw = ['problem_definition_raw_score', 'causal_attribution_raw_score', 'moral_evaluation_raw_score', 'treatment_recommendation_raw_score']\\n    dims_salience = ['problem_definition_salience', 'causal_attribution_salience', 'moral_evaluation_salience', 'treatment_recommendation_salience']\\n\\n    df['message_completeness_index'] = df[dims_raw].mean(axis=1)\\n    df['framing_coherence_index'] = df[dims_raw].apply(lambda row: np.prod(row)**(1/len(row)), axis=1)\\n    \\n    salience_sum = df[dims_salience].sum(axis=1)\\n    weighted_sum = (df[dims_raw].values * df[dims_salience].values).sum(axis=1)\\n    df['salience_weighted_message_completeness'] = weighted_sum / (salience_sum + 0.001) # Add epsilon to avoid division by zero\\n    \\n    df['strategic_framing_profile'] = df[dims_salience].idxmax(axis=1).apply(\\n        lambda x: {\\n            'problem_definition_salience': 0, \\n            'causal_attribution_salience': 1,\\n            'moral_evaluation_salience': 2,\\n            'treatment_recommendation_salience': 3\\n        }.get(x))\\n\\n    df['framing_independence_score'] = df[dims_raw].std(axis=1)\\n\\n    return df\\n\\ndef calculate_descriptive_statistics(df: pd.DataFrame) -> Optional[Dict[str, Any]]:\\n    \\\"\\\"\\\"\\n    Calculates descriptive statistics for all scores and derived metrics.\\n    This is an exploratory analysis due to the small sample size (N=4).\\n\\n    Args:\\n        df: The DataFrame containing the processed analysis data.\\n\\n    Returns:\\n        A dictionary of descriptive statistics, or None if input is invalid.\\n    \\\"\\\"\\\"\\n    if df is None or df.empty:\\n        return None\\n\\n    score_cols = [col for col in df.columns if '_score' in col or '_salience' in col]\\n    metric_cols = [\\n        'message_completeness_index', \\n        'framing_coherence_index', \\n        'salience_weighted_message_completeness', \\n        'framing_independence_score'\\n    ]\\n    all_numeric_cols = score_cols + metric_cols\\n\\n    try:\\n        # Overall descriptive statistics\\n        overall_descriptives = df[all_numeric_cols].agg(['mean', 'std', 'min', 'max']).to_dict()\\n        \\n        # Per-document (case study) presentation of data\\n        case_study_data = df[['document_id', 'context'] + all_numeric_cols].set_index('document_id').to_dict(orient='index')\\n        \\n        return {\\n            'summary': 'Descriptive statistics for all documents. Given N=4, this is purely exploratory.',\\n            'overall_descriptives': overall_descriptives,\\n            'case_study_data': case_study_data\\n        }\\n    except Exception as e:\\n        return {'error': str(e)}\\n\\ndef perform_correlation_analysis(df: pd.DataFrame) -> Optional[Dict[str, Any]]:\\n    \\\"\\\"\\\"\\n    Performs an exploratory correlation analysis between the four framing dimensions.\\n    WARNING: With N=4, these results are highly unstable and not generalizable. They are for \\n    exploratory pattern detection only, as per Tier 3 guidelines.\\n\\n    Args:\\n        df: The DataFrame containing the processed analysis data.\\n\\n    Returns:\\n        A dictionary containing the correlation matrix, or None if input is invalid.\\n    \\\"\\\"\\\"\\n    if df is None or len(df) < 3:\\n        return {\\n            'summary': 'Correlation analysis not performed due to insufficient data (N < 3).',\\n            'correlation_matrix': None\\n        }\\n        \\n    try:\\n        dims_raw = ['problem_definition_raw_score', 'causal_attribution_raw_score', 'moral_evaluation_raw_score', 'treatment_recommendation_raw_score']\\n        corr_matrix = df[dims_raw].corr(method='pearson')\\n        \\n        # Clean column names for output\\n        corr_matrix.columns = [c.replace('_raw_score', '') for c in corr_matrix.columns]\\n        corr_matrix.index = [c.replace('_raw_score', '') for c in corr_matrix.index]\\n        \\n        return {\\n            'summary': 'Exploratory Pearson correlation matrix for raw scores of the four framing functions. WARNING: Results are not statistically significant due to N=4.',\\n            'correlation_matrix': corr_matrix.to_dict()\\n        }\\n    except Exception as e:\\n        return {'error': str(e)}\\n\\ndef analyze_strategic_profiles(df: pd.DataFrame) -> Optional[Dict[str, Any]]:\\n    \\\"\\\"\\\"\\n    Analyzes the strategic framing profiles for each document as a case study.\\n\\n    Args:\\n        df: The DataFrame containing derived metrics.\\n\\n    Returns:\\n        A dictionary summarizing the strategic profile of each document.\\n    \\\"\\\"\\\"\\n    if df is None or df.empty:\\n        return None\\n        \\n    profile_cols = [\\n        'document_id',\\n        'context',\\n        'framing_focus',\\n        'strategic_framing_profile',\\n        'message_completeness_index',\\n        'framing_coherence_index',\\n        'framing_independence_score'\\n    ]\\n    \\n    try:\\n        profile_map = {0: 'Problem-focused', 1: 'Cause-focused', 2: 'Values-focused', 3: 'Solution-focused'}\\n        df_profiles = df[profile_cols].copy()\\n        df_profiles['strategic_framing_profile'] = df_profiles['strategic_framing_profile'].map(profile_map)\\n\\n        return {\\n            'summary': 'Case-by-case analysis of strategic framing profiles. This highlights the primary communication approach for each document.',\\n            'profiles': df_profiles.set_index('document_id').to_dict(orient='index')\\n        }\\n    except Exception as e:\\n        return {'error': str(e)}\\n\\ndef perform_statistical_analysis(data: List[Dict[str, Any]]) -> Dict[str, Any]:\\n    \\\"\\\"\\\"\\n    Master function to perform all statistical analyses for the experiment.\\n    Due to the small sample size (N=4), this is a Tier 3 exploratory analysis.\\n\\n    Args:\\n        data: A list of all analysis artifacts for the experiment.\\n\\n    Returns:\\n        A dictionary containing all statistical results.\\n    \\\"\\\"\\\"\\n    parsed_df = _parse_artifacts(data)\\n    \\n    if parsed_df is None:\\n        return {'error': 'Failed to parse artifacts into a DataFrame.'}\\n        \\n    metrics_df = calculate_derived_metrics(parsed_df)\\n    \\n    results = {\\n        'descriptive_statistics': calculate_descriptive_statistics(metrics_df),\\n        'correlation_analysis': perform_correlation_analysis(metrics_df),\\n        'additional_analyses': {\\n            'strategic_profile_analysis': analyze_strategic_profiles(metrics_df)\\n        }\\n    }\\n    \\n    return results\\n\",\n  \"execution_results\": {\n    \"descriptive_statistics\": {\n      \"summary\": \"Descriptive statistics for all documents. Given N=4, this is purely exploratory.\",\n      \"overall_descriptives\": {\n        \"problem_definition_raw_score\": {\n          \"mean\": 0.9,\n          \"std\": 0.0,\n          \"min\": 0.9,\n          \"max\": 0.9\n        },\n        \"problem_definition_salience\": {\n          \"mean\": 0.9,\n          \"std\": 0.0,\n          \"min\": 0.9,\n          \"max\": 0.9\n        },\n        \"causal_attribution_raw_score\": {\n          \"mean\": 0.6375,\n          \"std\": 0.4270237308734685,\n          \"min\": 0.1,\n          \"max\": 1.0\n        },\n        \"causal_attribution_salience\": {\n          \"mean\": 0.6125,\n          \"std\": 0.4374382589410118,\n          \"min\": 0.1,\n          \"max\": 1.0\n        },\n        \"moral_evaluation_raw_score\": {\n          \"mean\": 0.8875,\n          \"std\": 0.025,\n          \"min\": 0.85,\n          \"max\": 0.9\n        },\n        \"moral_evaluation_salience\": {\n          \"mean\": 0.8625,\n          \"std\": 0.04787135538792617,\n          \"min\": 0.8,\n          \"max\": 0.9\n        },\n        \"treatment_recommendation_raw_score\": {\n          \"mean\": 0.8875,\n          \"std\": 0.125,\n          \"min\": 0.7,\n          \"max\": 1.0\n        },\n        \"treatment_recommendation_salience\": {\n          \"mean\": 0.9,\n          \"std\": 0.0816496580927726,\n          \"min\": 0.8,\n          \"max\": 1.0\n        },\n        \"message_completeness_index\": {\n          \"mean\": 0.828125,\n          \"std\": 0.1065961608625902,\n          \"min\": 0.7,\n          \"max\": 0.95\n        },\n        \"framing_coherence_index\": {\n          \"mean\": 0.785055009187311,\n          \"std\": 0.15858079555198944,\n          \"min\": 0.5898354394039139,\n          \"max\": 0.9457416087383215\n        },\n        \"salience_weighted_message_completeness\": {\n          \"mean\": 0.8355673898822005,\n          \"std\": 0.10555306915162468,\n          \"min\": 0.7061728395061728,\n          \"max\": 0.95\n        },\n        \"framing_independence_score\": {\n          \"mean\": 0.28318314110825946,\n          \"std\": 0.1651574681650392,\n          \"min\": 0.04330127018922193,\n          \"max\": 0.4038892173333835\n        }\n      },\n      \"case_study_data\": {\n        \"crisis_management\": {\n          \"context\": \"crisis_response\",\n          \"problem_definition_raw_score\": 0.9,\n          \"problem_definition_salience\": 0.9,\n          \"causal_attribution_raw_score\": 0.1,\n          \"causal_attribution_salience\": 0.1,\n          \"moral_evaluation_raw_score\": 0.85,\n          \"moral_evaluation_salience\": 0.85,\n          \"treatment_recommendation_raw_score\": 0.95,\n          \"treatment_recommendation_salience\": 0.9,\n          \"message_completeness_index\": 0.7,\n          \"framing_coherence_index\": 0.5898354394039139,\n          \"salience_weighted_message_completeness\": 0.8530434782608695,\n          \"framing_independence_score\": 0.4038892173333835\n        },\n        \"political_attack_ad\": {\n          \"context\": \"campaign_advertisement\",\n          \"problem_definition_raw_score\": 0.9,\n          \"problem_definition_salience\": 0.9,\n          \"causal_attribution_raw_score\": 0.95,\n          \"causal_attribution_salience\": 0.95,\n          \"moral_evaluation_raw_score\": 0.9,\n          \"moral_evaluation_salience\": 0.9,\n          \"treatment_recommendation_raw_score\": 0.7,\n          \"treatment_recommendation_salience\": 0.8,\n          \"message_completeness_index\": 0.8625,\n          \"framing_coherence_index\": 0.8654817757973686,\n          \"salience_weighted_message_completeness\": 0.8711340206185567,\n          \"framing_independence_score\": 0.1083431795152513\n        },\n        \"corporate_apology\": {\n          \"context\": \"apology_statement\",\n          \"problem_definition_raw_score\": 0.9,\n          \"problem_definition_salience\": 0.9,\n          \"causal_attribution_raw_score\": 1.0,\n          \"causal_attribution_salience\": 1.0,\n          \"moral_evaluation_raw_score\": 0.9,\n          \"moral_evaluation_salience\": 0.9,\n          \"treatment_recommendation_raw_score\": 1.0,\n          \"treatment_recommendation_salience\": 1.0,\n          \"message_completeness_index\": 0.95,\n          \"framing_coherence_index\": 0.9457416087383215,\n          \"salience_weighted_message_completeness\": 0.95,\n          \"framing_independence_score\": 0.04330127018922193\n        },\n        \"policy_advocacy\": {\n          \"context\": \"policy_advocacy\",\n          \"problem_definition_raw_score\": 0.9,\n          \"problem_definition_salience\": 0.9,\n          \"causal_attribution_raw_score\": 0.5,\n          \"causal_attribution_salience\": 0.4,\n          \"moral_evaluation_raw_score\": 0.9,\n          \"moral_evaluation_salience\": 0.8,\n          \"treatment_recommendation_raw_score\": 0.9,\n          \"treatment_recommendation_salience\": 0.9,\n          \"message_completeness_index\": 0.8,\n          \"framing_coherence_index\": 0.7391712128096397,\n          \"salience_weighted_message_completeness\": 0.7061728395061728,\n          \"framing_independence_score\": 0.17729730539517965\n        }\n      }\n    },\n    \"correlation_analysis\": {\n      \"summary\": \"Exploratory Pearson correlation matrix for raw scores of the four framing functions. WARNING: Results are not statistically significant due to N=4.\",\n      \"correlation_matrix\": {\n        \"problem_definition\": {\n          \"problem_definition\": 1.0,\n          \"causal_attribution\": null,\n          \"moral_evaluation\": -0.5,\n          \"treatment_recommendation\": 0.5\n        },\n        \"causal_attribution\": {\n          \"problem_definition\": null,\n          \"causal_attribution\": 1.0,\n          \"moral_evaluation\": 0.1889822365046136,\n          \"treatment_recommendation\": 0.8643019830530932\n        },\n        \"moral_evaluation\": {\n          \"problem_definition\": -0.5,\n          \"causal_attribution\": 0.1889822365046136,\n          \"moral_evaluation\": 1.0,\n          \"treatment_recommendation\": 0.1889822365046136\n        },\n        \"treatment_recommendation\": {\n          \"problem_definition\": 0.5,\n          \"causal_attribution\": 0.8643019830530932,\n          \"moral_evaluation\": 0.1889822365046136,\n          \"treatment_recommendation\": 1.0\n        }\n      }\n    },\n    \"anova_analysis\": null,\n    \"reliability_analysis\": null,\n    \"additional_analyses\": {\n      \"strategic_profile_analysis\": {\n        \"summary\": \"Case-by-case analysis of strategic framing profiles. This highlights the primary communication approach for each document.\",\n        \"profiles\": {\n          \"crisis_management\": {\n            \"context\": \"crisis_response\",\n            \"framing_focus\": \"problem_definition_treatment\",\n            \"strategic_framing_profile\": \"Problem-focused\",\n            \"message_completeness_index\": 0.7,\n            \"framing_coherence_index\": 0.5898354394039139,\n            \"framing_independence_score\": 0.4038892173333835\n          },\n          \"political_attack_ad\": {\n            \"context\": \"campaign_advertisement\",\n            \"framing_focus\": \"problem_cause_moral\",\n            \"strategic_framing_profile\": \"Cause-focused\",\n            \"message_completeness_index\": 0.8625,\n            \"framing_coherence_index\": 0.8654817757973686,\n            \"framing_independence_score\": 0.1083431795152513\n          },\n          \"corporate_apology\": {\n            \"context\": \"apology_statement\",\n            \"framing_focus\": \"cause_moral_treatment\",\n            \"strategic_framing_profile\": \"Cause-focused\",\n            \"message_completeness_index\": 0.95,\n            \"framing_coherence_index\": 0.9457416087383215,\n            \"framing_independence_score\": 0.04330127018922193\n          },\n          \"policy_advocacy\": {\n            \"context\": \"policy_advocacy\",\n            \"framing_focus\": \"problem_treatment\",\n            \"strategic_framing_profile\": \"Problem-focused\",\n            \"message_completeness_index\": 0.8,\n            \"framing_coherence_index\": 0.7391712128096397,\n            \"framing_independence_score\": 0.17729730539517965\n          }\n        }\n      }\n    }\n  },\n  \"sample_size_assessment\": {\n    \"total_documents\": 4,\n    \"tier_classification\": \"TIER 3\",\n    \"power_notes\": \"The sample size of N=4 is extremely small, allowing only for Tier 3 exploratory analysis. All results, especially correlations, are not statistically significant or generalizable. The analysis focuses on descriptive statistics and pattern detection on a case-study basis.\"\n  },\n  \"methodology_summary\": \"The statistical analysis was conducted under Tier 3 (Exploratory) guidelines due to the small sample size (N=4). The methodology focused on calculating descriptive statistics (mean, std, min, max) for all dimensional scores and derived metrics. A case-study approach was used to present the full data for each document, allowing for qualitative pattern comparison across different communication contexts. An exploratory correlation analysis was performed to investigate potential relationships between framing dimensions, with the strong caveat that the results are unstable and not statistically meaningful. The primary outputs are descriptive summaries and a strategic profile analysis designed to highlight patterns for future research, in line with the experiment's case study design.\"\n}\n```",
  "analysis_artifacts_processed": 8,
  "cost_info": {
    "model": "vertex_ai/gemini-2.5-pro",
    "execution_time_seconds": 69.464907,
    "response_cost": 0.0,
    "input_tokens": 0,
    "output_tokens": 0,
    "total_tokens": 0,
    "prompt_length": 52833,
    "response_length": 19527
  },
  "timestamp": "2025-09-17T00:07:33.377312+00:00"
}