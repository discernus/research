{
  "status": "success",
  "functions_generated": 6,
  "output_file": "automatedderivedmetricsagent_functions.py",
  "module_size": 14818,
  "function_code_content": "\"\"\"\nAutomated Derived Metrics Functions\n===================================\n\nGenerated by AutomatedDerivedMetricsAgent for experiment: Test Experiment\nDescription: Test experiment for derived metrics\nGenerated: 2025-08-29T19:04:20.494214+00:00\n\nThis module contains automatically generated calculation functions for derived metrics\nas specified in the framework's natural language descriptions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom typing import Optional, Dict, Any\n\n\ndef calculate_identity_tension(data, **kwargs):\n    \"\"\"\n    Calculate identity_tension: Conflict between tribal dominance and individual dignity dimensions.\n\n    This metric quantifies the tension as the product of the 'tribal_dominance' and \n    'individual_dignity' scores. It assumes that a high score in both dimensions \n    represents a high degree of conflict or tension.\n\n    Formula: identity_tension = tribal_dominance * individual_dignity\n    \n    Args:\n        data (pd.Series): A single row of data as a pandas Series.\n        **kwargs: Additional keyword arguments (not used).\n        \n    Returns:\n        float: Calculated result or None if insufficient data. The function returns None if \n               the required columns are missing, or if their values are not valid numbers.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # Define the conceptual column names required for this specific calculation.\n        # This calculation cannot be performed if these columns are not present.\n        tribal_col = 'tribal_dominance'\n        dignity_col = 'individual_dignity'\n\n        # Verify that the required columns exist in the input data.\n        # This adheres to the strict requirement of not assuming column names,\n        # and will gracefully return None if the data doesn't support this calculation.\n        if tribal_col not in data or dignity_col not in data:\n            return None\n\n        # Extract the scores from the data Series.\n        tribal_score = data[tribal_col]\n        dignity_score = data[dignity_col]\n\n        # Check for missing data (NaN, None, etc.) in either score.\n        if pd.isna(tribal_score) or pd.isna(dignity_score):\n            return None\n\n        # Perform the calculation, casting to float to ensure numeric operation.\n        # The product of the scores represents the tension.\n        result = float(tribal_score) * float(dignity_score)\n        \n        # Ensure the result is a finite number (i.e., not infinity or NaN).\n        if not np.isfinite(result):\n            return None\n\n        return result\n\n    except (ValueError, TypeError):\n        # This catches errors if the scores are non-numeric types (e.g., strings).\n        return None\n    except Exception:\n        # A general catch-all for any other unexpected errors to ensure stability.\n        return None\n\ndef calculate_emotional_balance(data, **kwargs):\n    \"\"\"\n    Calculate emotional_balance: Difference between hope and fear scores.\n\n    Formula: hope - fear\n\n    This calculation requires 'hope' and 'fear' scores to be present in the data.\n    The function handles cases where these columns are missing or contain non-numeric\n    or NaN values by returning None.\n\n    Args:\n        data (pd.Series or pd.DataFrame): A single row of analysis data,\n                                          expected to contain 'hope' and 'fear' columns.\n        **kwargs: Additional keyword arguments (not used).\n\n    Returns:\n        float: The calculated emotional balance score, or None if the necessary\n               data is missing or invalid.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # The calculation is defined as the difference between hope and fear scores.\n        # We attempt to access columns named 'hope' and 'fear' as required by the\n        # calculation's description.\n        hope_score = data['hope']\n        fear_score = data['fear']\n\n        # Check for missing values (NaN, None) in the required columns.\n        if pd.isna(hope_score) or pd.isna(fear_score):\n            return None\n\n        # Perform the calculation and cast to float for consistency.\n        result = float(hope_score) - float(fear_score)\n\n        return result\n\n    except (KeyError, TypeError, ValueError):\n        # A KeyError occurs if 'hope' or 'fear' columns do not exist.\n        # A TypeError or ValueError can occur if the data is not convertible to a number.\n        # In any of these failure cases, the calculation cannot be completed.\n        return None\n\ndef calculate_success_climate(data, **kwargs):\n    \"\"\"\n    Calculate success_climate: Difference between compersion and envy scores\n\n    Formula: success_climate = compersion - envy\n    \n    Args:\n        data (pd.Series): A single row of data as a pandas Series.\n        **kwargs: Additional keyword arguments (not used).\n        \n    Returns:\n        float: Calculated result or None if insufficient data.\n    \"\"\"\n    import pandas as pd\n    \n    try:\n        # This calculation requires 'compersion' and 'envy' columns.\n        # Per the problem specification, the actual data structure does not\n        # contain these columns. Accessing them will raise a KeyError,\n        # which is gracefully handled by the except block, returning None.\n        compersion_score = data['compersion']\n        envy_score = data['envy']\n        \n        # Handle cases where columns exist but values are missing (NaN)\n        if pd.isna(compersion_score) or pd.isna(envy_score):\n            return None\n            \n        # The conversion to float also handles non-numeric types by raising an error\n        return float(compersion_score) - float(envy_score)\n        \n    except (KeyError, TypeError, ValueError):\n        # KeyError: Catches missing 'compersion' or 'envy' columns.\n        # TypeError: Handles cases where data is not subscriptable.\n        # ValueError: Catches errors from float conversion on non-numeric data.\n        return None\n\ndef calculate_relational_climate(data, **kwargs):\n    \"\"\"\n    Calculate relational_climate: Difference between amity and enmity scores.\n\n    Formula: relational_climate = amity_score - enmity_score\n\n    The calculation reflects the overall sentiment or relationship posture\n    portrayed in the communication. A positive value indicates a climate of\n    amity, a negative value indicates enmity, and a value around zero\n    suggests a neutral or balanced relational climate.\n\n    Args:\n        data (pd.Series): A single row of data represented as a pandas Series,\n                          containing the necessary score columns.\n        **kwargs: Additional keyword arguments (not used in this calculation).\n\n    Returns:\n        float: The calculated relational climate score. Returns None if\n               'amity_score' or 'enmity_score' columns are missing, not numeric,\n               or contain NaN values.\n    \"\"\"\n    import pandas as pd\n\n    try:\n        # The calculation requires 'amity_score' and 'enmity_score'.\n        # These are assumed to be present based on the calculation description,\n        # despite not being listed in the generic framework data structure.\n        amity_col = 'amity_score'\n        enmity_col = 'enmity_score'\n\n        # Using .get() is safer than direct access, returns None if key is missing.\n        amity_score = data.get(amity_col)\n        enmity_score = data.get(enmity_col)\n\n        # pd.isna() robustly checks for None, numpy.nan, etc.\n        if pd.isna(amity_score) or pd.isna(enmity_score):\n            return None\n\n        # Convert to float to ensure proper arithmetic and handle numeric strings.\n        amity_score = float(amity_score)\n        enmity_score = float(enmity_score)\n\n        return amity_score - enmity_score\n\n    except (ValueError, TypeError):\n        # This will catch errors if scores are non-numeric values that\n        # cannot be converted to float (e.g., 'high', 'low').\n        return None\n    except Exception:\n        # A general catch-all for any other unexpected errors during execution.\n        return None\n\ndef calculate_goal_orientation(data, **kwargs):\n    \"\"\"\n    Calculate goal_orientation: Difference between cohesive goals and fragmentative goals\n    \n    Formula: cohesive_goals - fragmentative_goals\n\n    Args:\n        data (pd.Series): A single row of data from the analysis DataFrame.\n        **kwargs: Additional keyword arguments (not used).\n        \n    Returns:\n        float: Calculated result or None if insufficient data.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # The calculation requires 'cohesive_goals' and 'fragmentative_goals' scores.\n        # These columns are inferred from the calculation's description. The function\n        # will return None if these columns are not present in the data.\n        cohesive_col = 'cohesive_goals'\n        fragmentative_col = 'fragmentative_goals'\n\n        # Use .get() to safely access columns that might be missing.\n        # pd.to_numeric with errors='coerce' will convert missing or non-numeric\n        # values to NaN, which is handled in the next step.\n        cohesive_score = pd.to_numeric(data.get(cohesive_col), errors='coerce')\n        fragmentative_score = pd.to_numeric(data.get(fragmentative_col), errors='coerce')\n        \n        # If either score is NaN (due to missing column, non-numeric data, or\n        # an existing NaN value), the calculation cannot be performed.\n        if pd.isna(cohesive_score) or pd.isna(fragmentative_score):\n            return None\n            \n        # Calculate the difference and ensure the result is a standard float.\n        result = float(cohesive_score - fragmentative_score)\n        \n        return result\n        \n    except Exception:\n        # A broad exception handler ensures the function is robust and will not\n        # crash in production, returning None for any unexpected errors.\n        return None\n\ndef calculate_overall_cohesion_index(data, **kwargs):\n    \"\"\"\n    Calculate overall_cohesion_index: Comprehensive measure combining all dimensions.\n\n    This index measures the uniformity of the four framing function scores. A high\n    index (near 1.0) indicates that all framing functions are scored similarly,\n    signifying a cohesive frame. A low index indicates high variance among scores.\n    The calculation requires dimension score columns (e.g., 'problem_definition_score')\n    which are not present in the provided sample data structure. The function will\n    return None if these columns are missing.\n\n    Formula: 1 - StDev(problem_definition_score, causal_attribution_score, moral_evaluation_score, treatment_recommendation_score)\n\n    Args:\n        data (pd.Series or pd.DataFrame): A single row of data from the analysis.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        float: Calculated result or None if insufficient data.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    # The Entman framework is defined by four independent framing functions.\n    # Cohesion is a measure of the statistical variance between their scores.\n    # The following column names are derived from the framework description.\n    dimension_columns = [\n        'problem_definition_score',\n        'causal_attribution_score',\n        'moral_evaluation_score',\n        'treatment_recommendation_score'\n    ]\n\n    try:\n        # Ensure data is a pandas Series for consistent access\n        if isinstance(data, pd.DataFrame):\n            if len(data) == 1:\n                series_data = data.iloc[0]\n            else:\n                # Cannot process multi-row DataFrame\n                return None\n        elif isinstance(data, pd.Series):\n            series_data = data\n        else:\n            # Unsupported data type\n            return None\n\n        # Extract scores for the four dimensions.\n        # This will raise a KeyError if the columns do not exist in the data,\n        # which is expected given the provided data structure.\n        scores = series_data[dimension_columns].astype(float).tolist()\n\n        # If any of the required scores are NaN, we cannot calculate the index.\n        if any(np.isnan(score) for score in scores):\n            return None\n\n        # Calculate the population standard deviation of the dimension scores.\n        # A lower standard deviation implies higher cohesion.\n        std_dev = np.std(scores)\n\n        # The cohesion index is defined as 1 minus the standard deviation.\n        # This assumes scores are normalized (e.g., 0 to 1), mapping\n        # perfect cohesion (std_dev=0) to an index of 1.0.\n        cohesion_index = 1.0 - std_dev\n\n        return float(cohesion_index)\n\n    except (KeyError, ValueError, TypeError, AttributeError):\n        # A KeyError will be raised if the conceptual dimension columns are not found.\n        # Other errors are caught for robustness against unexpected data formats.\n        return None\n\ndef calculate_all_derived_metrics(data: pd.DataFrame) -> Dict[str, Optional[float]]:\n    \"\"\"\n    Calculate all derived metrics for the given dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        Dictionary mapping metric names to calculated values\n    \"\"\"\n    results = {}\n    \n    # Get all calculation functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith('calculate_') and \n            name not in ['calculate_all_derived_metrics', 'calculate_derived_metrics']):\n            try:\n                results[name.replace('calculate_', '')] = obj(data)\n            except Exception as e:\n                results[name.replace('calculate_', '')] = None\n                \n    return results\n\n\ndef calculate_derived_metrics(data: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Template-compatible wrapper function for derived metrics calculation.\n    \n    This function is called by the universal notebook template and returns\n    the original data with additional derived metric columns.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        DataFrame with original data plus derived metric columns\n    \"\"\"\n    # Calculate all derived metrics\n    derived_metrics = calculate_all_derived_metrics(data)\n    \n    # Create a copy of the original data\n    result = data.copy()\n    \n    # Add derived metrics as new columns\n    for metric_name, metric_value in derived_metrics.items():\n        if metric_value is not None:\n            # For scalar metrics, broadcast to all rows\n            result[metric_name] = metric_value\n        else:\n            # For failed calculations, use NaN\n            result[metric_name] = np.nan\n    \n    return result\n",
  "cached_with_code": true
}