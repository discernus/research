{
  "analysis_id": "analysis_72dcc424",
  "step": "derived_metrics_generation",
  "model_used": "vertex_ai/gemini-2.5-flash-lite",
  "derived_metrics": "```python\nimport numpy as np\nimport json\n\n# Dimensional scores from the analysis\nscores = {\n  \"problem_definition\": {\n    \"raw_score\": 0.9,\n    \"salience\": 0.9,\n    \"confidence\": 0.95\n  },\n  \"causal_attribution\": {\n    \"raw_score\": 0.95,\n    \"salience\": 0.95,\n    \"confidence\": 0.95\n  },\n  \"moral_evaluation\": {\n    \"raw_score\": 0.9,\n    \"salience\": 0.9,\n    \"confidence\": 0.95\n  },\n  \"treatment_recommendation\": {\n    \"raw_score\": 0.7,\n    \"salience\": 0.8,\n    \"confidence\": 0.95\n  }\n}\n\n# --- Derived Metrics Calculations ---\n\n# 1. Message Completeness Index\n# Average coverage across all four framing functions\nproblem_def_score = scores[\"problem_definition\"][\"raw_score\"]\ncausal_attr_score = scores[\"causal_attribution\"][\"raw_score\"]\nmoral_eval_score = scores[\"moral_evaluation\"][\"raw_score\"]\ntreatment_rec_score = scores[\"treatment_recommendation\"][\"raw_score\"]\n\nmessage_completeness_index = (problem_def_score + causal_attr_score + moral_eval_score + treatment_rec_score) / 4\n\n# 2. Framing Coherence Index\n# Geometric mean of framing function scores\nframing_coherence_index = (problem_def_score * causal_attr_score * moral_eval_score * treatment_rec_score) ** 0.25\n\n# 3. Salience-Weighted Message Completeness\n# Message completeness weighted by strategic emphasis\nproblem_def_salience = scores[\"problem_definition\"][\"salience\"]\ncausal_attr_salience = scores[\"causal_attribution\"][\"salience\"]\nmoral_eval_salience = scores[\"moral_evaluation\"][\"salience\"]\ntreatment_rec_salience = scores[\"treatment_recommendation\"][\"salience\"]\n\n# Ensure the sum of salience is not zero to avoid division by zero\nsum_of_salience = (problem_def_salience + causal_attr_salience + moral_eval_salience + treatment_rec_salience)\nif sum_of_salience == 0:\n    sum_of_salience = 0.001 # Add a small epsilon if all saliences are zero\n\nsalience_weighted_message_completeness = (\n    (problem_def_score * problem_def_salience) +\n    (causal_attr_score * causal_attr_salience) +\n    (moral_eval_score * moral_eval_salience) +\n    (treatment_rec_score * treatment_rec_salience)\n) / sum_of_salience\n\n# 4. Strategic Framing Profile\n# Classification of primary communication approach based on salience\nsalience_values = [\n    scores[\"problem_definition\"][\"salience\"],\n    scores[\"causal_attribution\"][\"salience\"],\n    scores[\"moral_evaluation\"][\"salience\"],\n    scores[\"treatment_recommendation\"][\"salience\"]\n]\nstrategic_framing_profile = np.argmax(salience_values)\n\n# 5. Framing Independence Score\n# Standard deviation of framing function raw scores\nraw_scores = [\n    problem_def_score,\n    causal_attr_score,\n    moral_eval_score,\n    treatment_rec_score\n]\nframing_independence_score = np.std(raw_scores)\n\n# Store results in a dictionary\nderived_metrics_results = {\n    \"message_completeness_index\": round(message_completeness_index, 4),\n    \"framing_coherence_index\": round(framing_coherence_index, 4),\n    \"salience_weighted_message_completeness\": round(salience_weighted_message_completeness, 4),\n    \"strategic_framing_profile\": strategic_framing_profile,\n    \"framing_independence_score\": round(framing_independence_score, 4)\n}\n\n# Display the results\nprint(json.dumps(derived_metrics_results, indent=2))\n```\n\n```json\n{\n  \"message_completeness_index\": 0.84,\n  \"framing_coherence_index\": 0.8513,\n  \"salience_weighted_message_completeness\": 0.8789,\n  \"strategic_framing_profile\": 1,\n  \"framing_independence_score\": 0.1041\n}\n```",
  "timestamp": "2025-09-17T00:05:11.254909+00:00"
}