{
  "status": "success",
  "functions_generated": 6,
  "output_file": "automatedstatisticalanalysisagent_functions.py",
  "module_size": 20912,
  "function_code_content": "\"\"\"\nAutomated Statistical Analysis Functions\n========================================\n\nGenerated by AutomatedStatisticalAnalysisAgent for experiment: populist_discourse_factorial_analysis\nDescription: Statistical analysis experiment\nGenerated: 2025-08-28T02:16:19.075944+00:00\n\nThis module contains automatically generated statistical analysis functions\nfor comprehensive data analysis including ANOVA, correlations, reliability,\nand hypothesis testing as appropriate for the research questions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport scipy.stats as stats\nfrom typing import Dict, Any, Optional, List, Tuple\nimport warnings\n\n# Suppress common statistical warnings for cleaner output\nwarnings.filterwarnings('ignore', category=RuntimeWarning)\n\n\ndef calculate_all_derived_metrics(data, **kwargs):\n    \"\"\"\n    Calculates all derived metrics as specified in the PDAF v10.0.0 framework and adds them to the DataFrame.\n\n    This function implements the formulas for strategic tension and salience-weighted indices.\n    It is a foundational step for many other analysis functions.\n\n    Methodology:\n    - Tension Scores: Calculated using the formula `Tension = min(Score_A, Score_B) * |Salience_A - Salience_B|`.\n      This quantifies the contradiction when two populist appeals are used with high intensity but differing emphasis.\n    - Populist Strategic Contradiction Index (PSCI): The average of the three tension scores, providing an\n      overall measure of strategic coherence.\n    - Salience-Weighted Indices: Calculated by weighting each dimension's raw score by its salience score,\n      then normalizing by the sum of salience scores. This captures the rhetorical prominence of populist themes.\n      A small epsilon (0.001) is added to the denominator to prevent division by zero.\n\n    Args:\n        data (pd.DataFrame): The input DataFrame with raw, salience, and confidence scores.\n                             Must contain columns as specified in the PDAF framework.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        pd.DataFrame: A new DataFrame with added columns for each derived metric, or None if an error occurs.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        if data is None or data.empty:\n            return None\n            \n        df = data.copy()\n\n        # --- Tension Metrics ---\n        df['democratic_authoritarian_tension'] = np.minimum(\n            df['popular_sovereignty_claims_raw'], df['anti_pluralist_exclusion_raw']\n        ) * abs(df['popular_sovereignty_claims_salience'] - df['anti_pluralist_exclusion_salience'])\n\n        df['internal_external_focus_tension'] = np.minimum(\n            df['homogeneous_people_construction_raw'], df['nationalist_exclusion_raw']\n        ) * abs(df['homogeneous_people_construction_salience'] - df['nationalist_exclusion_salience'])\n\n        df['crisis_elite_attribution_tension'] = np.minimum(\n            df['crisis_restoration_narrative_raw'], df['elite_conspiracy_systemic_corruption_raw']\n        ) * abs(df['crisis_restoration_narrative_salience'] - df['elite_conspiracy_systemic_corruption_salience'])\n\n        # --- Populist Strategic Contradiction Index (PSCI) ---\n        df['populist_strategic_contradiction_index'] = (\n            df['democratic_authoritarian_tension'] +\n            df['internal_external_focus_tension'] +\n            df['crisis_elite_attribution_tension']\n        ) / 3\n\n        # --- Salience-Weighted Indices ---\n        epsilon = 0.001\n        \n        # Core Populism\n        core_dims = ['manichaean_people_elite_framing', 'crisis_restoration_narrative', 'popular_sovereignty_claims', 'anti_pluralist_exclusion']\n        core_numerator = sum(df[f'{dim}_raw'] * df[f'{dim}_salience'] for dim in core_dims)\n        core_denominator = sum(df[f'{dim}_salience'] for dim in core_dims) + epsilon\n        df['salience_weighted_core_populism_index'] = core_numerator / core_denominator\n\n        # Populism Mechanisms\n        mech_dims = ['elite_conspiracy_systemic_corruption', 'authenticity_vs_political_class', 'homogeneous_people_construction']\n        mech_numerator = sum(df[f'{dim}_raw'] * df[f'{dim}_salience'] for dim in mech_dims)\n        mech_denominator = sum(df[f'{dim}_salience'] for dim in mech_dims) + epsilon\n        df['salience_weighted_populism_mechanisms_index'] = mech_numerator / mech_denominator\n\n        # Boundary Distinctions\n        bound_dims = ['nationalist_exclusion', 'economic_populist_appeals']\n        bound_numerator = sum(df[f'{dim}_raw'] * df[f'{dim}_salience'] for dim in bound_dims)\n        bound_denominator = sum(df[f'{dim}_salience'] for dim in bound_dims) + epsilon\n        df['salience_weighted_boundary_distinctions_index'] = bound_numerator / bound_denominator\n\n        # Overall Populism\n        all_dims = core_dims + mech_dims + bound_dims\n        overall_numerator = sum(df[f'{dim}_raw'] * df[f'{dim}_salience'] for dim in all_dims)\n        overall_denominator = sum(df[f'{dim}_salience'] for dim in all_dims) + epsilon\n        df['salience_weighted_overall_populism_index'] = overall_numerator / overall_denominator\n\n        return df\n\n    except (KeyError, TypeError, Exception):\n        return None\n\ndef descriptive_statistics_summary(data, **kwargs):\n    \"\"\"\n    Generates descriptive statistics for all raw populist dimensions and derived metrics.\n\n    This function first calculates the derived metrics (tensions, indices) and then computes\n    a statistical summary (mean, std, min, max, quartiles) for the nine raw dimension scores\n    and all derived metrics. This provides a foundational overview of the dataset, addressing\n    the research question about typical patterns in populist discourse.\n\n    Args:\n        data (pd.DataFrame): The input DataFrame with raw, salience, and confidence scores.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary of descriptive statistics for each metric, or None if data is insufficient.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        if data is None or data.empty:\n            return None\n\n        # Calculate derived metrics first\n        data_with_metrics = calculate_all_derived_metrics(data)\n        if data_with_metrics is None:\n            return None\n\n        # Define columns for analysis\n        raw_score_cols = [col for col in data.columns if col.endswith('_raw')]\n        derived_metric_cols = [\n            'democratic_authoritarian_tension',\n            'internal_external_focus_tension',\n            'crisis_elite_attribution_tension',\n            'populist_strategic_contradiction_index',\n            'salience_weighted_core_populism_index',\n            'salience_weighted_populism_mechanisms_index',\n            'salience_weighted_boundary_distinctions_index',\n            'salience_weighted_overall_populism_index'\n        ]\n        \n        analysis_cols = raw_score_cols + derived_metric_cols\n        \n        # Ensure all columns exist before proceeding\n        if not all(col in data_with_metrics.columns for col in analysis_cols):\n            return None\n\n        summary = data_with_metrics[analysis_cols].describe().to_dict()\n        return summary\n\n    except (KeyError, TypeError, Exception):\n        return None\n\ndef populist_dimensions_correlation_matrix(data, **kwargs):\n    \"\"\"\n    Calculates the Pearson correlation matrix for the nine core populist dimension raw scores.\n\n    This analysis addresses the research question about the relationships between different\n    populist rhetorical dimensions. A high correlation between two dimensions suggests they\n    are frequently deployed together in the analyzed texts. The output is a matrix where\n    each cell (i, j) contains the correlation coefficient between dimension i and dimension j.\n\n    Args:\n        data (pd.DataFrame): The input DataFrame with raw scores.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary representing the correlation matrix, or None if data is insufficient.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        if data is None or data.empty:\n            return None\n\n        raw_score_cols = [\n            'manichaean_people_elite_framing_raw', 'crisis_restoration_narrative_raw',\n            'popular_sovereignty_claims_raw', 'anti_pluralist_exclusion_raw',\n            'elite_conspiracy_systemic_corruption_raw', 'authenticity_vs_political_class_raw',\n            'homogeneous_people_construction_raw', 'nationalist_exclusion_raw',\n            'economic_populist_appeals_raw'\n        ]\n        \n        if not all(col in data.columns for col in raw_score_cols):\n            return None\n            \n        # Clean column names for better readability in the output\n        clean_names = {col: col.replace('_raw', '') for col in raw_score_cols}\n        renamed_data = data[raw_score_cols].rename(columns=clean_names)\n\n        correlation_matrix = renamed_data.corr(method='pearson')\n        \n        # Replace NaN with None for JSON compatibility\n        correlation_matrix = correlation_matrix.where(pd.notnull(correlation_matrix), None)\n        \n        return correlation_matrix.to_dict()\n\n    except (KeyError, TypeError, Exception):\n        return None\n\ndef strategic_tension_analysis(data, **kwargs):\n    \"\"\"\n    Analyzes the statistical relationship between base populist dimensions and strategic tension measures.\n\n    This function calculates the Pearson correlation between the nine raw dimension scores and the\n    three derived tension metrics, plus the overall Populist Strategic Contradiction Index (PSCI).\n    This helps answer how individual populist appeals contribute to or are associated with\n    rhetorical contradiction and strategic incoherence.\n\n    Args:\n        data (pd.DataFrame): The input DataFrame with raw and salience scores.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A correlation matrix dictionary showing relationships between dimensions and tensions, or None.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        if data is None or data.empty:\n            return None\n\n        data_with_metrics = calculate_all_derived_metrics(data)\n        if data_with_metrics is None:\n            return None\n\n        raw_score_cols = [col for col in data.columns if col.endswith('_raw')]\n        tension_cols = [\n            'democratic_authoritarian_tension',\n            'internal_external_focus_tension',\n            'crisis_elite_attribution_tension',\n            'populist_strategic_contradiction_index'\n        ]\n        \n        analysis_cols = raw_score_cols + tension_cols\n        if not all(col in data_with_metrics.columns for col in analysis_cols):\n            return None\n\n        # Clean column names for readability\n        clean_raw_names = {col: col.replace('_raw', '') for col in raw_score_cols}\n        renamed_data = data_with_metrics[analysis_cols].rename(columns=clean_raw_names)\n        \n        clean_raw_names_list = list(clean_raw_names.values())\n\n        # Calculate full correlation matrix\n        corr_matrix = renamed_data.corr(method='pearson')\n        \n        # Slice to get only the relationships of interest\n        tension_correlations = corr_matrix.loc[clean_raw_names_list, tension_cols]\n        \n        # Replace NaN with None for JSON compatibility\n        tension_correlations = tension_correlations.where(pd.notnull(tension_correlations), None)\n\n        return tension_correlations.to_dict()\n\n    except (KeyError, TypeError, Exception):\n        return None\n\ndef temporal_trend_analysis(data, **kwargs):\n    \"\"\"\n    Analyzes trends in populist discourse measures over time.\n\n    This function extracts the year from the document filename, groups the data by year,\n    and calculates the mean for key populist indices (Overall, Core, Mechanisms, Boundary, PSCI).\n    This addresses the research question about the relationship between temporal factors and\n    populist discourse.\n\n    Note: As no corpus manifest was provided, this function relies on parsing the year from\n    the 'document_name' column (e.g., 'Trump_SOTU_2018.txt'). It looks for a four-digit\n    number between 1900 and 2100. Documents with filenames not matching this pattern will be excluded.\n\n    Args:\n        data (pd.DataFrame): The input DataFrame. Must include a 'document_name' column.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary with years as keys and mean scores for derived indices as values, or None.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    import re\n\n    try:\n        if data is None or data.empty or 'document_name' not in data.columns:\n            return None\n\n        def extract_year(filename):\n            # Find a 4-digit number that looks like a year\n            match = re.search(r'\\b(19[89]\\d|20\\d{2})\\b', str(filename))\n            return int(match.group(0)) if match else None\n\n        df = data.copy()\n        df['year'] = df['document_name'].apply(extract_year)\n        df.dropna(subset=['year'], inplace=True)\n        df['year'] = df['year'].astype(int)\n\n        if df.empty:\n            return None # No documents with valid years found\n\n        data_with_metrics = calculate_all_derived_metrics(df)\n        if data_with_metrics is None:\n            return None\n\n        index_cols = [\n            'salience_weighted_overall_populism_index',\n            'salience_weighted_core_populism_index',\n            'salience_weighted_populism_mechanisms_index',\n            'salience_weighted_boundary_distinctions_index',\n            'populist_strategic_contradiction_index'\n        ]\n\n        if not all(col in data_with_metrics.columns for col in index_cols):\n            return None\n\n        temporal_analysis = data_with_metrics.groupby('year')[index_cols].mean().sort_index()\n        \n        return temporal_analysis.to_dict('index')\n\n    except (KeyError, TypeError, Exception):\n        return None\n\ndef speech_context_comparison(data, **kwargs):\n    \"\"\"\n    Compares populist discourse patterns across different speech contexts.\n\n    This function attempts to identify the speech context (e.g., 'SOTU', 'Inaugural') from the\n    document filename. It then groups the data by this context and calculates the mean scores\n    for key populist indices to see how rhetoric varies by setting.\n\n    Note: As no corpus manifest was provided, this function relies on parsing the context from\n    the 'document_name' column. It looks for keywords like 'SOTU', 'Inaugural', 'Address', etc.\n    Documents with filenames not matching these patterns are categorized as 'other'.\n\n    Args:\n        data (pd.DataFrame): The input DataFrame. Must include a 'document_name' column.\n        **kwargs: Additional parameters (not used).\n\n    Returns:\n        dict: A dictionary with speech contexts as keys and mean scores for derived indices as values, or None.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        if data is None or data.empty or 'document_name' not in data.columns:\n            return None\n\n        def extract_context(filename):\n            fn_lower = str(filename).lower()\n            if 'sotu' in fn_lower or 'state of the union' in fn_lower:\n                return 'SOTU'\n            if 'inaugural' in fn_lower:\n                return 'Inaugural'\n            if 'address' in fn_lower:\n                return 'Address'\n            if 'speech' in fn_lower:\n                return 'Speech'\n            return 'Other'\n\n        df = data.copy()\n        df['speech_context'] = df['document_name'].apply(extract_context)\n\n        data_with_metrics = calculate_all_derived_metrics(df)\n        if data_with_metrics is None:\n            return None\n\n        index_cols = [\n            'salience_weighted_overall_populism_index',\n            'salience_weighted_core_populism_index',\n            'salience_weighted_populism_mechanisms_index',\n            'salience_weighted_boundary_distinctions_index',\n            'populist_strategic_contradiction_index'\n        ]\n        \n        if not all(col in data_with_metrics.columns for col in index_cols):\n            return None\n\n        context_analysis = data_with_metrics.groupby('speech_context')[index_cols].mean()\n        \n        return context_analysis.to_dict('index')\n\n    except (KeyError, TypeError, Exception):\n        return None\n\ndef run_complete_statistical_analysis(data: pd.DataFrame, alpha: float = 0.05) -> Dict[str, Any]:\n    \"\"\"\n    Run complete statistical analysis suite on the dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        alpha: Significance level for hypothesis tests (default: 0.05)\n        \n    Returns:\n        Dictionary with all statistical analysis results\n    \"\"\"\n    results = {\n        'analysis_metadata': {\n            'timestamp': pd.Timestamp.now().isoformat(),\n            'sample_size': len(data),\n            'alpha_level': alpha,\n            'variables_analyzed': list(data.select_dtypes(include=[np.number]).columns)\n        }\n    }\n    \n    # Get all analysis functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith(('calculate_', 'perform_', 'test_')) and \n            name != 'run_complete_statistical_analysis'):\n            try:\n                # Pass alpha parameter to functions that might need it\n                if 'alpha' in inspect.signature(obj).parameters:\n                    results[name] = obj(data, alpha=alpha)\n                else:\n                    results[name] = obj(data)\n            except Exception as e:\n                results[name] = {'error': f'Analysis failed: {str(e)}'}\n                \n    return results\n\n\ndef perform_statistical_analysis(data: pd.DataFrame) -> Dict[str, Any]:\n    \"\"\"\n    Template-compatible wrapper function for statistical analysis.\n    \n    This function is called by the universal notebook template and performs\n    comprehensive statistical analysis on the provided dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores and derived metrics\n        \n    Returns:\n        Dictionary containing all statistical analysis results\n    \"\"\"\n    return run_complete_statistical_analysis(data)\n\n\ndef generate_statistical_summary_report(analysis_results: Dict[str, Any]) -> str:\n    \"\"\"\n    Generate a human-readable summary report from statistical analysis results.\n    \n    Args:\n        analysis_results: Results from run_complete_statistical_analysis()\n        \n    Returns:\n        String containing formatted statistical report\n    \"\"\"\n    report_lines = []\n    report_lines.append(\"STATISTICAL ANALYSIS SUMMARY REPORT\")\n    report_lines.append(\"=\" * 50)\n    \n    metadata = analysis_results.get('analysis_metadata', {})\n    report_lines.append(f\"Analysis Timestamp: {metadata.get('timestamp', 'Unknown')}\")\n    report_lines.append(f\"Sample Size: {metadata.get('sample_size', 'Unknown')}\")\n    report_lines.append(f\"Alpha Level: {metadata.get('alpha_level', 'Unknown')}\")\n    report_lines.append(f\"Variables: {len(metadata.get('variables_analyzed', []))}\")\n    report_lines.append(\"\")\n    \n    # Summarize key findings\n    for analysis_name, result in analysis_results.items():\n        if analysis_name != 'analysis_metadata' and isinstance(result, dict):\n            if 'error' not in result:\n                report_lines.append(f\"{analysis_name.replace('_', ' ').title()}:\")\n                \n                # Extract key statistics based on analysis type\n                if 'p_value' in result:\n                    p_val = result['p_value']\n                    significance = \"significant\" if p_val < metadata.get('alpha_level', 0.05) else \"not significant\"\n                    report_lines.append(f\"  - p-value: {p_val:.4f} ({significance})\")\n                \n                if 'effect_size' in result:\n                    report_lines.append(f\"  - Effect size: {result['effect_size']:.4f}\")\n                \n                if 'correlation_matrix' in result:\n                    report_lines.append(f\"  - Correlation matrix generated with {len(result['correlation_matrix'])} variables\")\n                \n                if 'cronbach_alpha' in result:\n                    alpha_val = result['cronbach_alpha']\n                    reliability = \"excellent\" if alpha_val > 0.9 else \"good\" if alpha_val > 0.8 else \"acceptable\" if alpha_val > 0.7 else \"questionable\"\n                    report_lines.append(f\"  - Cronbach's \u03b1: {alpha_val:.3f} ({reliability})\")\n                \n                report_lines.append(\"\")\n            else:\n                report_lines.append(f\"{analysis_name}: ERROR - {result['error']}\")\n                report_lines.append(\"\")\n    \n    return \"\\n\".join(report_lines)\n",
  "cached_with_code": true
}