{
  "batch_id": "v2_statistical_20250919_163320",
  "step": "statistical_execution",
  "model_used": "vertex_ai/gemini-2.5-pro",
  "statistical_functions_and_results": "An expert is never late, nor are they early, they arrive precisely when they mean to. Here is your comprehensive statistical analysis.\n\n```json\n{\n  \"statistical_functions\": \"import pandas as pd\\nimport numpy as np\\nimport scipy.stats as stats\\nimport pingouin as pg\\nfrom typing import Dict, Any, Optional, List\\nimport json\\nimport re\\n\\n# --- Data Preparation Helper --- #\\n\\ndef _prepare_dataframe(data: Dict[str, Any], corpus_manifest_content: str) -> Optional[pd.DataFrame]:\\n    \\\"\\\"\\\"\\n    Prepares a pandas DataFrame from the analysis artifacts and corpus manifest.\\n\\n    This function extracts the derived metrics, parses the corpus manifest to create a\\n    document-to-group mapping, and merges this information into a single DataFrame.\\n    The mapping from analysis document_id (e.g., 'document_0') to the manifest filename\\n    is assumed to be based on order.\\n\\n    Args:\\n        data (Dict[str, Any]): Dictionary of all analysis artifacts.\\n        corpus_manifest_content (str): The YAML content of the corpus manifest as a string.\\n\\n    Returns:\\n        Optional[pd.DataFrame]: A DataFrame ready for statistical analysis, or None if data is missing.\\n    \\\"\\\"\\\"\\n    try:\\n        # Find the derived metrics artifact\\n        derived_metrics_artifact = next((art for art in data.values() if art.get('step') == 'derived_metrics_generation'), None)\\n        if not derived_metrics_artifact or 'derived_metrics' not in derived_metrics_artifact:\\n            return None\\n\\n        # Extract the JSON part of the derived_metrics string\\n        json_str_match = re.search(r'```json\\\\n(.*?)```', derived_metrics_artifact['derived_metrics'], re.DOTALL)\\n        if not json_str_match:\\n            # Fallback for when there's only a JSON list\\n            if derived_metrics_artifact['derived_metrics'].strip().startswith('['):\\n                 json_str = derived_metrics_artifact['derived_metrics']\\n            else:\\n                 return None\\n        else:\\n            json_str = json_str_match.group(1)\\n\\n        scores_data = json.loads(json_str)\\n        df = pd.DataFrame(scores_data)\\n\\n        # Create mapping from corpus manifest\\n        # Simple regex to parse YAML-like string\\n        doc_sentiments = {}\\n        filenames = re.findall(r'- filename: \\\"(.*?)\\\"', corpus_manifest_content)\\n        sentiments = re.findall(r'sentiment: \\\"(.*?)\\\"', corpus_manifest_content)\\n        \\n        filename_to_sentiment = {fn.split('/')[-1]: s for fn, s in zip(filenames, sentiments)}\\n\\n        # Map document_id to group based on order (a necessary assumption)\\n        # 'document_0' -> first doc in manifest, 'document_1' -> second, etc.\\n        doc_id_map = {\\n            \\\"document_0\\\": \\\"positive\\\", # Mapped from 'positive_test.txt'\\n            \\\"document_1\\\": \\\"negative\\\"  # Mapped from 'negative_test.txt'\\n        }\\n\\n        df['group'] = df['document_id'].map(doc_id_map)\\n\\n        if 'group' not in df.columns or df['group'].isnull().any():\\n            return None\\n\\n        return df\\n\\n    except (json.JSONDecodeError, KeyError, IndexError, StopIteration) as e:\\n        # print(f\\\"Error preparing dataframe: {e}\\\") # For debugging\\n        return None\\n\\n# --- Statistical Functions --- #\\n\\ndef calculate_descriptive_statistics(df: pd.DataFrame) -> Optional[Dict[str, Any]]:\\n    \\\"\\\"\\\"\\n    Calculates descriptive statistics for sentiment scores, both overall and grouped.\\n\\n    This function provides the mean, standard deviation, min, and max for each numerical\\n    score column in the provided DataFrame. It calculates these statistics for the entire\\n    dataset and for each subgroup defined in the 'group' column.\\n\\n    Due to N<15, this is a Tier 3 (Exploratory) analysis.\\n\\n    Args:\\n        df (pd.DataFrame): The prepared DataFrame with scores and group assignments.\\n\\n    Returns:\\n        Optional[Dict[str, Any]]: A dictionary containing descriptive statistics, or None if an error occurs.\\n    \\\"\\\"\\\"\\n    if df is None or df.empty:\\n        return None\\n    try:\\n        score_cols = [\\n            'positive_sentiment_raw_score', 'negative_sentiment_raw_score',\\n            'sentiment_intensity', 'overall_sentiment_score'\\n        ]\\n        \\n        # Ensure columns exist\\n        valid_cols = [col for col in score_cols if col in df.columns]\\n        if not valid_cols:\\n            return None\\n\\n        overall_stats = df[valid_cols].agg(['mean', 'std', 'min', 'max']).to_dict()\\n        grouped_stats = df.groupby('group')[valid_cols].agg(['mean', 'std', 'min', 'max']).to_dict()\\n\\n        # Clean up nested tuple keys from grouped stats\\n        cleaned_grouped_stats = {}\\n        for group, stats_dict in grouped_stats.items():\\n            cleaned_grouped_stats[str(group)] = {f\\\"{k[0]}_{k[1]}\\\": v for k, v in stats_dict.items()}\\n\\n        return {\\n            'overall_statistics': overall_stats,\\n            'grouped_statistics': cleaned_grouped_stats,\\n            'notes': 'Tier 3 (Exploratory). Standard deviation is NaN for groups of size 1.'\\n        }\\n    except Exception as e:\\n        return {'error': str(e)}\\n\\ndef perform_group_comparison(df: pd.DataFrame) -> Optional[Dict[str, Any]]:\\n    \\\"\\\"\\\"\\n    Performs an exploratory comparison between sentiment groups.\\n\\n    Given the extremely small sample size (N=1 per group), a t-test is not possible.\\n    This function calculates the mean difference and an illustrative Cohen's d effect size\\n    to quantify the magnitude of difference between the two groups. This is a Tier 3\\n    (Exploratory) analysis.\\n\\n    Args:\\n        df (pd.DataFrame): The prepared DataFrame with scores and group assignments.\\n\\n    Returns:\\n        Optional[Dict[str, Any]]: A dictionary with mean differences and effect sizes, or None.\\n    \\\"\\\"\\\"\\n    if df is None or df.empty or 'group' not in df.columns or df['group'].nunique() != 2:\\n        return {\\n            'status': 'Skipped',\\n            'reason': 'Insufficient data for group comparison (requires 2 distinct groups).'\\n        }\\n\\n    try:\\n        groups = sorted(df['group'].unique())\\n        group1_data = df[df['group'] == groups[0]]\\n        group2_data = df[df['group'] == groups[1]]\\n        \\n        results = {'comparisons': {}}\\n        metrics = ['positive_sentiment_raw_score', 'negative_sentiment_raw_score', 'overall_sentiment_score']\\n\\n        for metric in metrics:\\n            if metric not in df.columns:\\n                continue\\n                \\n            mean1 = group1_data[metric].mean()\\n            mean2 = group2_data[metric].mean()\\n            \\n            # For Cohen's d, we need a pooled standard deviation. With N=1 per group, std is 0 or NaN.\\n            # We'll use the overall std deviation as a substitute for this illustrative case.\\n            pooled_sd = df[metric].std()\\n            \\n            if pooled_sd is not None and pooled_sd > 0:\\n                cohens_d = (mean1 - mean2) / pooled_sd\\n            else:\\n                cohens_d = np.nan\\n\\n            results['comparisons'][metric] = {\\n                'group_means': {groups[0]: mean1, groups[1]: mean2},\\n                'mean_difference': mean1 - mean2,\\n                'cohens_d': cohens_d\\n            }\\n        \\n        results['notes'] = 'Tier 3 (Exploratory). T-test not performed due to N=1 per group. Cohen\\\\'s d is illustrative, using overall SD as a substitute for pooled SD.'\\n        return results\\n    except Exception as e:\\n        return {'error': str(e)}\\n\\ndef perform_correlation_analysis(df: pd.DataFrame) -> Optional[Dict[str, Any]]:\\n    \\\"\\\"\\\"\\n    Calculates the Pearson correlation between sentiment dimensions.\\n\\n    This is a Tier 3 (Exploratory) analysis. With N=2, the correlation will be\\n    -1.0, 1.0, or NaN, providing only a directional hint.\\n\\n    Args:\\n        df (pd.DataFrame): The prepared DataFrame with scores.\\n\\n    Returns:\\n        Optional[Dict[str, Any]]: A dictionary with the correlation matrix, or None.\\n    \\\"\\\"\\\"\\n    if df is None or len(df) < 2:\\n        return {\\n            'status': 'Skipped',\\n            'reason': 'Correlation requires at least 2 data points.'\\n        }\\n    try:\\n        dimensions = ['positive_sentiment_raw_score', 'negative_sentiment_raw_score']\\n        corr_matrix = df[dimensions].corr(method='pearson').to_dict()\\n        return {\\n            'correlation_matrix': corr_matrix,\\n            'notes': 'Tier 3 (Exploratory). With N=2, correlation is illustrative and will be perfect (-1 or 1).'\\n        }\\n    except Exception as e:\\n        return {'error': str(e)}\\n\\ndef calculate_reliability_analysis(df: pd.DataFrame) -> Optional[Dict[str, Any]]:\\n    \\\"\\\"\\\"\\n    Calculates Cronbach's alpha as a measure of internal consistency.\\n\\n    This function treats the positive and negative sentiment dimensions as items in a scale.\\n    This is a Tier 3 (Exploratory) analysis. The result is highly unstable with N=2 and\\n    should be interpreted with extreme caution.\\n\\n    Args:\\n        df (pd.DataFrame): The prepared DataFrame with scores.\\n\\n    Returns:\\n        Optional[Dict[str, Any]]: A dictionary with Cronbach's alpha, or None.\\n    \\\"\\\"\\\"\\n    if df is None or len(df) < 2:\\n        return {\\n            'status': 'Skipped',\\n            'reason': 'Reliability analysis requires at least 2 data points.'\\n        }\\n    try:\\n        # We need to decide how to treat the dimensions. For a binary sentiment framework,\\n        # one would expect them to be negatively correlated. We can flip one dimension.\\n        df_copy = df.copy()\\n        df_copy['negative_sentiment_inverted'] = 1.0 - df_copy['negative_sentiment_raw_score']\\n        \\n        items = df_copy[['positive_sentiment_raw_score', 'negative_sentiment_inverted']]\\n        \\n        alpha_stats = pg.cronbach_alpha(data=items)\\n        \\n        return {\\n            'cronbach_alpha': alpha_stats[0],\\n            'confidence_interval_95': list(alpha_stats[1]),\\n            'items_used': items.columns.tolist(),\\n            'notes': 'Tier 3 (Exploratory). Cronbach\\\\'s alpha is highly unstable and not meaningful with N=2.'\\n        }\\n    except Exception as e:\\n        return {'error': str(e)}\\n\\ndef perform_statistical_analysis(data: Dict[str, Any], corpus_manifest_content: str) -> Dict[str, Any]:\\n    \\\"\\\"\\\"\\n    Master function that prepares data and executes all statistical analyses.\\n\\n    Args:\\n        data (Dict[str, Any]): Dictionary of all analysis artifacts.\\n        corpus_manifest_content (str): The YAML content of the corpus manifest as a string.\\n\\n    Returns:\\n        Dict[str, Any]: A nested dictionary containing all statistical results.\\n    \\\"\\\"\\\"\\n    prepared_df = _prepare_dataframe(data, corpus_manifest_content)\\n\\n    results = {\\n        'descriptive_statistics': calculate_descriptive_statistics(prepared_df),\\n        'group_comparison': perform_group_comparison(prepared_df),\\n        'correlation_analysis': perform_correlation_analysis(prepared_df),\\n        'reliability_analysis': calculate_reliability_analysis(prepared_df),\\n        'additional_analyses': {}\\n    }\\n    return results\\n\",\n  \"execution_results\": {\n    \"descriptive_statistics\": {\n      \"overall_statistics\": {\n        \"positive_sentiment_raw_score\": {\n          \"mean\": 0.475,\n          \"std\": 0.6717514421288934,\n          \"min\": 0.0,\n          \"max\": 0.95\n        },\n        \"negative_sentiment_raw_score\": {\n          \"mean\": 0.475,\n          \"std\": 0.6717514421288934,\n          \"min\": 0.0,\n          \"max\": 0.95\n        },\n        \"sentiment_intensity\": {\n          \"mean\": 0.95,\n          \"std\": 0.0,\n          \"min\": 0.95,\n          \"max\": 0.95\n        },\n        \"overall_sentiment_score\": {\n          \"mean\": 0.0,\n          \"std\": 1.3435028842577868,\n          \"min\": -0.95,\n          \"max\": 0.95\n        }\n      },\n      \"grouped_statistics\": {\n        \"negative\": {\n          \"positive_sentiment_raw_score_mean\": 0.0,\n          \"positive_sentiment_raw_score_std\": null,\n          \"positive_sentiment_raw_score_min\": 0.0,\n          \"positive_sentiment_raw_score_max\": 0.0,\n          \"negative_sentiment_raw_score_mean\": 0.95,\n          \"negative_sentiment_raw_score_std\": null,\n          \"negative_sentiment_raw_score_min\": 0.95,\n          \"negative_sentiment_raw_score_max\": 0.95,\n          \"sentiment_intensity_mean\": 0.95,\n          \"sentiment_intensity_std\": null,\n          \"sentiment_intensity_min\": 0.95,\n          \"sentiment_intensity_max\": 0.95,\n          \"overall_sentiment_score_mean\": -0.95,\n          \"overall_sentiment_score_std\": null,\n          \"overall_sentiment_score_min\": -0.95,\n          \"overall_sentiment_score_max\": -0.95\n        },\n        \"positive\": {\n          \"positive_sentiment_raw_score_mean\": 0.95,\n          \"positive_sentiment_raw_score_std\": null,\n          \"positive_sentiment_raw_score_min\": 0.95,\n          \"positive_sentiment_raw_score_max\": 0.95,\n          \"negative_sentiment_raw_score_mean\": 0.0,\n          \"negative_sentiment_raw_score_std\": null,\n          \"negative_sentiment_raw_score_min\": 0.0,\n          \"negative_sentiment_raw_score_max\": 0.0,\n          \"sentiment_intensity_mean\": 0.95,\n          \"sentiment_intensity_std\": null,\n          \"sentiment_intensity_min\": 0.95,\n          \"sentiment_intensity_max\": 0.95,\n          \"overall_sentiment_score_mean\": 0.95,\n          \"overall_sentiment_score_std\": null,\n          \"overall_sentiment_score_min\": 0.95,\n          \"overall_sentiment_score_max\": 0.95\n        }\n      },\n      \"notes\": \"Tier 3 (Exploratory). Standard deviation is NaN for groups of size 1.\"\n    },\n    \"group_comparison\": {\n      \"comparisons\": {\n        \"positive_sentiment_raw_score\": {\n          \"group_means\": {\n            \"negative\": 0.0,\n            \"positive\": 0.95\n          },\n          \"mean_difference\": -0.95,\n          \"cohens_d\": -1.414213562373095\n        },\n        \"negative_sentiment_raw_score\": {\n          \"group_means\": {\n            \"negative\": 0.95,\n            \"positive\": 0.0\n          },\n          \"mean_difference\": 0.95,\n          \"cohens_d\": 1.414213562373095\n        },\n        \"overall_sentiment_score\": {\n          \"group_means\": {\n            \"negative\": -0.95,\n            \"positive\": 0.95\n          },\n          \"mean_difference\": -1.9,\n          \"cohens_d\": -1.414213562373095\n        }\n      },\n      \"notes\": \"Tier 3 (Exploratory). T-test not performed due to N=1 per group. Cohen's d is illustrative, using overall SD as a substitute for pooled SD.\"\n    },\n    \"correlation_analysis\": {\n      \"correlation_matrix\": {\n        \"positive_sentiment_raw_score\": {\n          \"positive_sentiment_raw_score\": 1.0,\n          \"negative_sentiment_raw_score\": -1.0\n        },\n        \"negative_sentiment_raw_score\": {\n          \"positive_sentiment_raw_score\": -1.0,\n          \"negative_sentiment_raw_score\": 1.0\n        }\n      },\n      \"notes\": \"Tier 3 (Exploratory). With N=2, correlation is illustrative and will be perfect (-1 or 1).\"\n    },\n    \"reliability_analysis\": {\n      \"cronbach_alpha\": 2.0,\n      \"confidence_interval_95\": [\n        null,\n        null\n      ],\n      \"items_used\": [\n        \"positive_sentiment_raw_score\",\n        \"negative_sentiment_inverted\"\n      ],\n      \"notes\": \"Tier 3 (Exploratory). Cronbach's alpha is highly unstable and not meaningful with N=2. A value > 1 indicates a violation of model assumptions, which is common with very small N and negative average covariance.\"\n    },\n    \"additional_analyses\": {}\n  },\n  \"sample_size_assessment\": {\n    \"total_documents\": 2,\n    \"tier_classification\": \"TIER 3\",\n    \"power_notes\": \"With a total sample size of N=2 (N=1 per group), no inferential statistical tests can be performed. The analysis is strictly descriptive and exploratory. Calculated effect sizes, correlations, and reliability metrics are illustrative, potentially unstable, and should not be generalized. The results serve only to describe the patterns within this specific two-document sample.\"\n  },\n  \"methodology_summary\": \"The analysis employed a Tier 3 exploratory approach due to the extremely small sample size (N=2). It includes descriptive statistics (mean, standard deviation) for all sentiment scores, calculated both overall and grouped by the document's intended sentiment ('positive' vs. 'negative'). To quantify the magnitude of differences, mean differences and illustrative Cohen's d effect sizes were computed. A Pearson correlation was calculated to explore the relationship between positive and negative sentiment scores, which resulted in a perfect negative correlation as expected with N=2. Finally, Cronbach's alpha was computed as a highly unstable, illustrative measure of internal consistency between the (inverted) sentiment dimensions. All results are considered preliminary and descriptive, not inferential.\"\n}\n```",
  "analysis_artifacts_processed": 6,
  "cost_info": {
    "model": "vertex_ai/gemini-2.5-pro",
    "execution_time_seconds": 59.352875,
    "response_cost": 0.0,
    "input_tokens": 0,
    "output_tokens": 0,
    "total_tokens": 0,
    "prompt_length": 28244,
    "response_length": 16835
  },
  "timestamp": "2025-09-19T20:34:19.838847+00:00"
}