{
  "status": "completed",
  "derived_metrics_hash": "479862731f8ccc10676b3639e624d7de8d1f59d05e923afd51345eab66f455f0",
  "functions_generated": 6,
  "derived_metrics_results": {
    "generation_metadata": {
      "status": "success",
      "functions_generated": 6,
      "output_file": "automatedderivedmetricsagent_functions.py",
      "module_size": 12332,
      "function_code_content": "\"\"\"\nAutomated Derived Metrics Functions\n===================================\n\nGenerated by AutomatedDerivedMetricsAgent for experiment: Test Experiment\nDescription: Test experiment for derived metrics\nGenerated: 2025-09-09T17:46:38.942547+00:00\n\nThis module contains automatically generated calculation functions for derived metrics\nas specified in the framework's natural language descriptions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom typing import Optional, Dict, Any\n\n\ndef calculate_identity_tension(data, **kwargs):\n    \"\"\"\n    Calculate identity_tension: Conflict between tribal dominance and individual dignity dimensions.\n\n    This calculation is requested by the research framework but the necessary dimensions\n    ('tribal_dominance', 'individual_dignity') are not present in the provided\n    data structure for the 'Sentiment Binary Framework v1.0'. This function is\n    designed to be forward-compatible and will return None until the required\n    data columns are available.\n\n    Formula: abs(tribal_dominance - individual_dignity)\n    \n    Args:\n        data (pd.Series): A single row of analysis data as a pandas Series.\n        **kwargs: Additional keyword arguments (unused).\n        \n    Returns:\n        float: The calculated identity tension score, or None if the necessary\n               columns ('tribal_dominance', 'individual_dignity') are missing\n               or contain non-numeric data.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # The prompt requires a calculation based on dimensions that are not present\n        # in the specified 'actual data structure'. This function attempts to\n        # access these theoretical columns and will gracefully fail, returning None,\n        # as per the requirements.\n        tribal_dominance = data['tribal_dominance']\n        individual_dignity = data['individual_dignity']\n\n        # Ensure both values are present and numeric before calculation\n        if pd.isna(tribal_dominance) or pd.isna(individual_dignity):\n            return None\n\n        # Calculate the absolute difference to represent tension\n        tension = np.abs(float(tribal_dominance) - float(individual_dignity))\n        \n        return float(tension)\n\n    except (KeyError, TypeError, ValueError):\n        # KeyError: Will trigger because the required columns are not in the data.\n        # TypeError/ValueError: Will trigger if columns exist but are not numeric.\n        # This ensures the function returns None as required by the prompt's constraints.\n        return None\n    except Exception:\n        # A final catch-all for any other unexpected errors.\n        return None\n\ndef calculate_emotional_balance(data, **kwargs):\n    \"\"\"\n    Calculate emotional_balance: Difference between hope and fear scores\n    Formula: hope - fear\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        **kwargs: Additional parameters\n        \n    Returns:\n        float: Calculated result or None if insufficient data\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # The calculation requires 'hope' and 'fear' scores.\n        # Per instructions, we must not assume column names exist if not specified\n        # in the data structure. We use .get() for safe access.\n        hope_score = data.get('hope')\n        fear_score = data.get('fear')\n\n        # The calculation cannot be performed if either score is missing (None)\n        # or is a non-numeric value like NaN.\n        if hope_score is None or fear_score is None or pd.isna(hope_score) or pd.isna(fear_score):\n            return None\n        \n        # Perform the calculation and ensure the result is a standard float.\n        return float(hope_score) - float(fear_score)\n\n    except (TypeError, ValueError):\n        # This handles cases where scores are present but not numeric (e.g., strings).\n        return None\n    except Exception:\n        # A general catch-all for any other unexpected errors, ensuring stability.\n        return None\n\ndef calculate_success_climate(data, **kwargs):\n    \"\"\"\n    Calculate success_climate: Difference between compersion and envy scores\n    \n    Formula: compersion - envy\n    \n    Args:\n        data: pandas DataFrame or Series with dimension scores.\n        **kwargs: Additional parameters (unused).\n        \n    Returns:\n        float: Calculated result or None if insufficient data.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # The calculation requires 'compersion' and 'envy' scores.\n        # .get() is used to safely retrieve values, returning None if the key is missing.\n        compersion_score = data.get('compersion')\n        envy_score = data.get('envy')\n        \n        # Check if either required score is missing (None or NaN).\n        # pd.isna() robustly handles both None and numpy.nan.\n        if pd.isna(compersion_score) or pd.isna(envy_score):\n            return None\n        \n        # Perform the calculation after ensuring data types are numeric.\n        result = float(compersion_score) - float(envy_score)\n        \n        return result\n        \n    except (TypeError, ValueError):\n        # Catches errors if scores are not convertible to float.\n        return None\n    except Exception:\n        # A general catch-all for any other unexpected errors.\n        return None\n\ndef calculate_relational_climate(data, **kwargs):\n    \"\"\"\n    Calculate relational_climate: Difference between amity and enmity scores.\n\n    Formula: 'Positive Sentiment' - 'Negative Sentiment'\n    \n    Args:\n        data (pd.Series): A single row of data with dimension scores.\n        **kwargs: Additional parameters (not used).\n        \n    Returns:\n        float: Calculated result or None if insufficient data.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # Per the 'Sentiment Binary Framework v1.0', amity is mapped to \n        # 'Positive Sentiment' and enmity to 'Negative Sentiment'.\n        amity_col = 'Positive Sentiment'\n        enmity_col = 'Negative Sentiment'\n\n        amity_score = data.get(amity_col)\n        enmity_score = data.get(enmity_col)\n\n        # pd.isna handles both None (from .get() on a missing column) and numpy.nan\n        if pd.isna(amity_score) or pd.isna(enmity_score):\n            return None\n        \n        # Calculate the difference, ensuring types are float for the operation\n        result = float(amity_score) - float(enmity_score)\n        \n        return result\n\n    except Exception:\n        # Catches any other error, such as non-numeric scores, and returns None.\n        return None\n\ndef calculate_goal_orientation(data, **kwargs):\n    \"\"\"\n    Calculate goal_orientation: Difference between cohesive goals and fragmentative goals\n\n    Formula: cohesive_goals - fragmentative_goals\n    \n    Args:\n        data: pandas DataFrame with dimension scores (expects a single row or Series)\n        **kwargs: Additional parameters\n        \n    Returns:\n        float: Calculated result or None if insufficient data\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # The calculation requires 'cohesive_goals' and 'fragmentative_goals' dimensions.\n        # These names are derived from the calculation's description.\n        cohesive_col = 'cohesive_goals'\n        fragmentative_col = 'fragmentative_goals'\n\n        # Accommodate both single-row DataFrame and Series input\n        if isinstance(data, pd.DataFrame):\n            if data.empty:\n                return None\n            s = data.iloc[0]\n        else:\n            s = data\n\n        # Use .get() to safely access values, returns None if key is missing\n        cohesive_score = s.get(cohesive_col)\n        fragmentative_score = s.get(fragmentative_col)\n\n        # Check for missing data (pd.isna handles None, np.nan, etc.)\n        if pd.isna(cohesive_score) or pd.isna(fragmentative_score):\n            return None\n\n        # Perform the calculation and ensure result is a standard float\n        result = float(cohesive_score) - float(fragmentative_score)\n        \n        return result\n\n    except (TypeError, ValueError):\n        # Catches errors if scores are not convertible to float\n        return None\n    except Exception:\n        # General catch-all for any other unexpected errors\n        return None\n\ndef calculate_overall_cohesion_index(data, **kwargs):\n    \"\"\"\n    Calculate overall_cohesion_index: Comprehensive measure combining all dimensions.\n\n    This index measures the degree to which the sentiment expressed is uniform rather than ambivalent.\n    A score of 1.0 indicates perfect cohesion (sentiment is purely positive or purely negative),\n    while a score of 0.0 indicates perfect ambivalence (equal presence of positive and negative sentiment).\n\n    Formula: 1 - abs(positive_sentiment - negative_sentiment)\n    \n    Args:\n        data (pd.Series or pd.DataFrame): A single row of data containing the dimension scores.\n                                           Must have 'positive_sentiment' and 'negative_sentiment' columns.\n        **kwargs: Additional parameters (not used in this calculation).\n        \n    Returns:\n        float: The calculated overall cohesion index, or None if required data is missing.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # The theoretical framework defines 'Positive Sentiment' and 'Negative Sentiment' as the dimensions.\n        # We map these to the expected column names 'positive_sentiment' and 'negative_sentiment'.\n        positive_score = data['positive_sentiment']\n        negative_score = data['negative_sentiment']\n\n        # Ensure both required scores are present and are numeric\n        if pd.isna(positive_score) or pd.isna(negative_score):\n            return None\n        \n        # The formula calculates cohesion. 1 means perfectly cohesive (one-sided sentiment).\n        # 0 means perfectly ambivalent (equal positive and negative sentiment).\n        cohesion_index = 1 - abs(float(positive_score) - float(negative_score))\n        \n        # Ensure the result is within the expected 0.0-1.0 range\n        return max(0.0, min(1.0, cohesion_index))\n\n    except (KeyError, TypeError, ValueError):\n        # KeyError if columns are missing.\n        # TypeError/ValueError if data is not numeric.\n        return None\n    except Exception:\n        # Catch any other unexpected errors\n        return None\n\ndef calculate_all_derived_metrics(data: pd.DataFrame) -> Dict[str, Optional[float]]:\n    \"\"\"\n    Calculate all derived metrics for the given dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        Dictionary mapping metric names to calculated values\n    \"\"\"\n    results = {}\n    \n    # Get all calculation functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith('calculate_') and \n            name not in ['calculate_all_derived_metrics', 'calculate_derived_metrics']):\n            try:\n                results[name.replace('calculate_', '')] = obj(data)\n            except Exception as e:\n                results[name.replace('calculate_', '')] = None\n                \n    return results\n\n\ndef calculate_derived_metrics(data: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Template-compatible wrapper function for derived metrics calculation.\n    \n    This function is called by the universal notebook template and returns\n    the original data with additional derived metric columns.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        DataFrame with original data plus derived metric columns\n    \"\"\"\n    # Calculate all derived metrics\n    derived_metrics = calculate_all_derived_metrics(data)\n    \n    # Create a copy of the original data\n    result = data.copy()\n    \n    # Add derived metrics as new columns\n    for metric_name, metric_value in derived_metrics.items():\n        if metric_value is not None:\n            # For scalar metrics, broadcast to all rows\n            result[metric_name] = metric_value\n        else:\n            # For failed calculations, use NaN\n            result[metric_name] = np.nan\n    \n    return result\n",
      "cached_with_code": true
    },
    "derived_metrics_data": {
      "status": "success",
      "original_count": 2,
      "derived_count": 2,
      "derived_metrics": [
        {
          "analysis_id": "analysis_2101dc6e8361",
          "result_hash": "6b42184255fb2f4857389627f300e5167f51d9685f0a6820d44634cf80b92919",
          "result_content": {
            "analysis_id": "analysis_2101dc6e8361",
            "agent_name": "EnhancedAnalysisAgent",
            "agent_version": "enhanced_v2.1_raw_output",
            "experiment_name": "nano_test_experiment",
            "model_used": "vertex_ai/gemini-2.5-flash",
            "raw_analysis_response": "<<<DISCERNUS_ANALYSIS_JSON_v6>>>\n{\n  \"analysis_metadata\": {\n    \"framework_name\": \"sentiment_binary_v1\",\n    \"framework_version\": \"1.0.0\",\n    \"analyst_confidence\": 0.95,\n    \"analysis_notes\": \"Applied three independent analytical approaches with median aggregation. Document exhibits clear and strong positive sentiment with no discernible negative sentiment.\",\n    \"internal_consistency_approach\": \"3-run median aggregation\"\n  },\n  \"document_analyses\": [\n    {\n      \"document_id\": \"6950ccbc6b14...\",\n      \"document_name\": \"positive_test.txt\",\n      \"dimensional_scores\": {\n        \"positive_sentiment\": {\n          \"raw_score\": 1.0,\n          \"salience\": 1.0,\n          \"confidence\": 0.97\n        },\n        \"negative_sentiment\": {\n          \"raw_score\": 0.0,\n          \"salience\": 0.0,\n          \"confidence\": 1.0\n        }\n      },\n      \"evidence\": [\n        {\n          \"dimension\": \"positive_sentiment\",\n          \"quote_text\": \"This is a wonderful day! Everything is going perfectly. I feel great about the future. Success is everywhere. The team did an excellent job. We're achieving amazing results. Optimism fills the air. What a fantastic opportunity! I'm thrilled with the progress. Everything looks bright and promising.\",\n          \"confidence\": 1.0,\n          \"context_type\": \"entire_document_theme\"\n        },\n        {\n          \"dimension\": \"negative_sentiment\",\n          \"quote_text\": \"\",\n          \"confidence\": 1.0,\n          \"context_type\": \"absence_of_evidence\"\n        }\n      ]\n    }\n  ]\n}\n<<<END_DISCERNUS_ANALYSIS_JSON_v6>>>",
            "evidence_hash": "4879cec64f5057bf7d11bb8430f17eef5bad20755f174dfe6addf98aaf88766c",
            "execution_metadata": {
              "start_time": "2025-09-09T17:42:45.358597+00:00",
              "end_time": "2025-09-09T17:42:59.035268+00:00",
              "duration_seconds": 13.676659
            },
            "input_artifacts": {
              "framework_hash": "f032ff0c1c0b8b990d2cc892b488fe4b09d8837ca2cf4a51b50f6c27256df18f",
              "document_hashes": [
                "6950ccbc6b14eabf43508448cf888b2c590f44e549a32b8ae60e943710e74019"
              ],
              "num_documents": 1
            },
            "provenance": {
              "security_boundary": {
                "experiment_name": "nano_test_experiment",
                "experiment_root": "/Volumes/code/discernus/projects/nano_test_experiment",
                "boundary_type": "filesystem",
                "security_level": "experiment_scoped"
              },
              "audit_session_id": "20250909T174245Z_3c8bce26"
            }
          },
          "cached": true
        },
        {
          "analysis_id": "analysis_4bc6d8eb51af",
          "result_hash": "99e53f629ffbac36506af0c22421eed7551c582a11a871f9fffde2571e93fb4f",
          "result_content": {
            "analysis_id": "analysis_4bc6d8eb51af",
            "agent_name": "EnhancedAnalysisAgent",
            "agent_version": "enhanced_v2.1_raw_output",
            "experiment_name": "nano_test_experiment",
            "model_used": "vertex_ai/gemini-2.5-flash",
            "raw_analysis_response": "<<<DISCERNUS_ANALYSIS_JSON_v6>>>\n{\n  \"analysis_metadata\": {\n    \"framework_name\": \"sentiment_binary_v1\",\n    \"framework_version\": \"1.0.0\",\n    \"analyst_confidence\": 0.98,\n    \"analysis_notes\": \"Applied three independent analytical approaches with median aggregation to a document with clear sentiment.\",\n    \"internal_consistency_approach\": \"3-run median aggregation\"\n  },\n  \"document_analyses\": [\n    {\n      \"document_id\": \"1df25093a747...\",\n      \"document_name\": \"negative_test.txt\",\n      \"dimensional_scores\": {\n        \"positive_sentiment\": {\n          \"raw_score\": 0.0,\n          \"salience\": 0.0,\n          \"confidence\": 1.0\n        },\n        \"negative_sentiment\": {\n          \"raw_score\": 1.0,\n          \"salience\": 1.0,\n          \"confidence\": 1.0\n        }\n      },\n      \"evidence\": [\n        {\n          \"dimension\": \"positive_sentiment\",\n          \"quote_text\": \"\",\n          \"confidence\": 0.0,\n          \"context_type\": \"absence_of_evidence\"\n        },\n        {\n          \"dimension\": \"negative_sentiment\",\n          \"quote_text\": \"This is a terrible situation. Everything is going wrong. I feel awful about the future. Failure surrounds us. The team did a horrible job. We're facing disaster. Pessimism fills the air. What a disastrous outcome! I'm devastated by the results. Everything looks dark and hopeless.\",\n          \"confidence\": 1.0,\n          \"context_type\": \"direct_statement\"\n        }\n      ]\n    }\n  ]\n}\n<<<END_DISCERNUS_ANALYSIS_JSON_v6>>>",
            "evidence_hash": "0f79a62068cbc77b623aa1afecddee6affa212eb2cc038f358b31aa6ba9d7eaa",
            "execution_metadata": {
              "start_time": "2025-09-09T17:42:59.036792+00:00",
              "end_time": "2025-09-09T17:43:17.464846+00:00",
              "duration_seconds": 18.428046
            },
            "input_artifacts": {
              "framework_hash": "f032ff0c1c0b8b990d2cc892b488fe4b09d8837ca2cf4a51b50f6c27256df18f",
              "document_hashes": [
                "1df25093a747678c5dbe724ecfb963b88049f9a7a536a3f23f064fd592744f91"
              ],
              "num_documents": 1
            },
            "provenance": {
              "security_boundary": {
                "experiment_name": "nano_test_experiment",
                "experiment_root": "/Volumes/code/discernus/projects/nano_test_experiment",
                "boundary_type": "filesystem",
                "security_level": "experiment_scoped"
              },
              "audit_session_id": "20250909T174245Z_3c8bce26"
            }
          },
          "cached": true
        }
      ],
      "columns_added": []
    },
    "status": "success_with_data",
    "validation_passed": true
  }
}