{
  "status": "success",
  "functions_generated": 4,
  "output_file": "automatedstatisticalanalysisagent_functions.py",
  "module_size": 17889,
  "function_code_content": "\"\"\"\nAutomated Statistical Analysis Functions\n========================================\n\nGenerated by AutomatedStatisticalAnalysisAgent for experiment: nano_test_experiment\nDescription: Statistical analysis experiment\nGenerated: 2025-09-03T01:53:16.159100+00:00\n\nThis module contains automatically generated statistical analysis functions\nfor comprehensive data analysis including ANOVA, correlations, reliability,\nand hypothesis testing as appropriate for the research questions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport scipy.stats as stats\nfrom typing import Dict, Any, Optional, List, Tuple\nimport warnings\n\n# Suppress common statistical warnings for cleaner output\nwarnings.filterwarnings('ignore', category=RuntimeWarning)\n\n\ndef descriptive_statistics_sentiment(data, **kwargs):\n    \"\"\"\n    Calculate descriptive statistics for sentiment scores.\n    Provides mean, median, standard deviation, min, max for positive and negative sentiment.\n    \n    Args:\n        data: pandas DataFrame containing the analysis data\n        **kwargs: Additional parameters\n        \n    Returns:\n        dict: Descriptive statistics or None if insufficient data\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    import json\n    import glob\n    from pathlib import Path\n    \n    try:\n        # Extract sentiment scores from the nested JSON structure\n        sentiment_data = []\n        \n        for idx, row in data.iterrows():\n            try:\n                # Parse the raw analysis response\n                response_text = row.get('raw_analysis_response', '')\n                if '<<<DISCERNUS_ANALYSIS_JSON_v6>>>' in response_text:\n                    json_part = response_text.split('<<<DISCERNUS_ANALYSIS_JSON_v6>>>')[1].split('<<<END_DISCERNUS_ANALYSIS_JSON_v6>>>')[0].strip()\n                    analysis_data = json.loads(json_part)\n                    \n                    for doc_analysis in analysis_data.get('document_analyses', []):\n                        doc_name = doc_analysis.get('document_name', '')\n                        dimensional_scores = doc_analysis.get('dimensional_scores', {})\n                        \n                        positive_score = dimensional_scores.get('positive_sentiment', {}).get('raw_score', np.nan)\n                        negative_score = dimensional_scores.get('negative_sentiment', {}).get('raw_score', np.nan)\n                        \n                        sentiment_data.append({\n                            'document_name': doc_name,\n                            'positive_sentiment_raw': positive_score,\n                            'negative_sentiment_raw': negative_score\n                        })\n            except (json.JSONDecodeError, KeyError, IndexError):\n                continue\n        \n        if not sentiment_data:\n            return None\n            \n        df = pd.DataFrame(sentiment_data)\n        \n        # Calculate descriptive statistics\n        results = {\n            'positive_sentiment': {\n                'mean': df['positive_sentiment_raw'].mean(),\n                'median': df['positive_sentiment_raw'].median(),\n                'std': df['positive_sentiment_raw'].std(),\n                'min': df['positive_sentiment_raw'].min(),\n                'max': df['positive_sentiment_raw'].max(),\n                'count': len(df['positive_sentiment_raw'].dropna())\n            },\n            'negative_sentiment': {\n                'mean': df['negative_sentiment_raw'].mean(),\n                'median': df['negative_sentiment_raw'].median(),\n                'std': df['negative_sentiment_raw'].std(),\n                'min': df['negative_sentiment_raw'].min(),\n                'max': df['negative_sentiment_raw'].max(),\n                'count': len(df['negative_sentiment_raw'].dropna())\n            },\n            'sample_size_warning': 'N=2 documents - insufficient for inferential statistics. Descriptive statistics only.'\n        }\n        \n        return results\n        \n    except Exception:\n        return None\n\ndef sentiment_correlation_analysis(data, **kwargs):\n    \"\"\"\n    Calculate correlation between positive and negative sentiment scores.\n    Note: With only 2 documents, this is purely descriptive.\n    \n    Args:\n        data: pandas DataFrame containing the analysis data\n        **kwargs: Additional parameters\n        \n    Returns:\n        dict: Correlation analysis results or None if insufficient data\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    import json\n    from scipy import stats\n    \n    try:\n        # Extract sentiment scores from the nested JSON structure\n        sentiment_data = []\n        \n        for idx, row in data.iterrows():\n            try:\n                # Parse the raw analysis response\n                response_text = row.get('raw_analysis_response', '')\n                if '<<<DISCERNUS_ANALYSIS_JSON_v6>>>' in response_text:\n                    json_part = response_text.split('<<<DISCERNUS_ANALYSIS_JSON_v6>>>')[1].split('<<<END_DISCERNUS_ANALYSIS_JSON_v6>>>')[0].strip()\n                    analysis_data = json.loads(json_part)\n                    \n                    for doc_analysis in analysis_data.get('document_analyses', []):\n                        dimensional_scores = doc_analysis.get('dimensional_scores', {})\n                        \n                        positive_score = dimensional_scores.get('positive_sentiment', {}).get('raw_score', np.nan)\n                        negative_score = dimensional_scores.get('negative_sentiment', {}).get('raw_score', np.nan)\n                        \n                        sentiment_data.append({\n                            'positive_sentiment_raw': positive_score,\n                            'negative_sentiment_raw': negative_score\n                        })\n            except (json.JSONDecodeError, KeyError, IndexError):\n                continue\n        \n        if len(sentiment_data) < 2:\n            return None\n            \n        df = pd.DataFrame(sentiment_data)\n        \n        # Calculate correlation (descriptive only due to small sample)\n        corr_coef = df['positive_sentiment_raw'].corr(df['negative_sentiment_raw'])\n        \n        results = {\n            'correlation_coefficient': corr_coef,\n            'sample_size': len(df),\n            'statistical_note': 'N=2 documents - correlation coefficient is purely descriptive, not inferential',\n            'power_analysis': 'Minimum N=20 required for reliable correlation analysis (80% power, \u03b1=0.05)',\n            'recommendation': 'Collect more data before performing inferential correlation analysis'\n        }\n        \n        return results\n        \n    except Exception:\n        return None\n\ndef sentiment_document_comparison(data, **kwargs):\n    \"\"\"\n    Compare sentiment scores between the two test documents.\n    Provides descriptive comparison rather than statistical tests due to small sample.\n    \n    Args:\n        data: pandas DataFrame containing the analysis data\n        **kwargs: Additional parameters\n        \n    Returns:\n        dict: Document comparison results or None if insufficient data\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    import json\n    \n    try:\n        # Extract sentiment scores from the nested JSON structure\n        document_sentiments = {}\n        \n        for idx, row in data.iterrows():\n            try:\n                # Parse the raw analysis response\n                response_text = row.get('raw_analysis_response', '')\n                if '<<<DISCERNUS_ANALYSIS_JSON_v6>>>' in response_text:\n                    json_part = response_text.split('<<<DISCERNUS_ANALYSIS_JSON_v6>>>')[1].split('<<<END_DISCERNUS_ANALYSIS_JSON_v6>>>')[0].strip()\n                    analysis_data = json.loads(json_part)\n                    \n                    for doc_analysis in analysis_data.get('document_analyses', []):\n                        doc_name = doc_analysis.get('document_name', '')\n                        dimensional_scores = doc_analysis.get('dimensional_scores', {})\n                        \n                        positive_score = dimensional_scores.get('positive_sentiment', {}).get('raw_score', np.nan)\n                        negative_score = dimensional_scores.get('negative_sentiment', {}).get('raw_score', np.nan)\n                        \n                        document_sentiments[doc_name] = {\n                            'positive_sentiment': positive_score,\n                            'negative_sentiment': negative_score\n                        }\n            except (json.JSONDecodeError, KeyError, IndexError):\n                continue\n        \n        if len(document_sentiments) < 2:\n            return None\n        \n        # Create document mapping based on known corpus structure\n        document_types = {\n            'positive_test.txt': 'positive_document',\n            'negative_test.txt': 'negative_document'\n        }\n        \n        results = {}\n        for doc_name, scores in document_sentiments.items():\n            doc_type = document_types.get(doc_name, 'unknown')\n            results[doc_type] = scores\n        \n        # Add comparison metrics\n        results['comparison'] = {\n            'positive_difference': abs(results.get('positive_document', {}).get('positive_sentiment', 0) - \n                                     results.get('negative_document', {}).get('positive_sentiment', 0)),\n            'negative_difference': abs(results.get('positive_document', {}).get('negative_sentiment', 0) - \n                                     results.get('negative_document', {}).get('negative_sentiment', 0)),\n            'statistical_note': 'N=2 documents - comparison is descriptive only, no statistical tests performed',\n            'power_analysis': 'Minimum N=15 per group required for t-tests (80% power, \u03b1=0.05)'\n        }\n        \n        return results\n        \n    except Exception:\n        return None\n\ndef sentiment_consistency_check(data, **kwargs):\n    \"\"\"\n    Check internal consistency of sentiment scoring across documents.\n    Validates that positive and negative documents show expected patterns.\n    \n    Args:\n        data: pandas DataFrame containing the analysis data\n        **kwargs: Additional parameters\n        \n    Returns:\n        dict: Consistency check results or None if insufficient data\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    import json\n    \n    try:\n        # Extract sentiment scores from the nested JSON structure\n        document_sentiments = {}\n        \n        for idx, row in data.iterrows():\n            try:\n                # Parse the raw analysis response\n                response_text = row.get('raw_analysis_response', '')\n                if '<<<DISCERNUS_ANALYSIS_JSON_v6>>>' in response_text:\n                    json_part = response_text.split('<<<DISCERNUS_ANALYSIS_JSON_v6>>>')[1].split('<<<END_DISCERNUS_ANALYSIS_JSON_v6>>>')[0].strip()\n                    analysis_data = json.loads(json_part)\n                    \n                    for doc_analysis in analysis_data.get('document_analyses', []):\n                        doc_name = doc_analysis.get('document_name', '')\n                        dimensional_scores = doc_analysis.get('dimensional_scores', {})\n                        \n                        positive_score = dimensional_scores.get('positive_sentiment', {}).get('raw_score', np.nan)\n                        negative_score = dimensional_scores.get('negative_sentiment', {}).get('raw_score', np.nan)\n                        \n                        document_sentiments[doc_name] = {\n                            'positive_sentiment': positive_score,\n                            'negative_sentiment': negative_score\n                        }\n            except (json.JSONDecodeError, KeyError, IndexError):\n                continue\n        \n        if len(document_sentiments) < 2:\n            return None\n        \n        # Check consistency with expected patterns\n        positive_doc = document_sentiments.get('positive_test.txt', {})\n        negative_doc = document_sentiments.get('negative_test.txt', {})\n        \n        results = {\n            'positive_document_check': {\n                'high_positive_score': positive_doc.get('positive_sentiment', 0) > 0.7,\n                'low_negative_score': positive_doc.get('negative_sentiment', 1) < 0.3,\n                'expected_pattern': 'Positive document should have high positive and low negative scores'\n            },\n            'negative_document_check': {\n                'low_positive_score': negative_doc.get('positive_sentiment', 1) < 0.3,\n                'high_negative_score': negative_doc.get('negative_sentiment', 0) > 0.7,\n                'expected_pattern': 'Negative document should have low positive and high negative scores'\n            },\n            'overall_consistency': {\n                'positive_negative_inverse': abs(positive_doc.get('positive_sentiment', 0) - negative_doc.get('negative_sentiment', 0)) < 0.2,\n                'negative_positive_inverse': abs(positive_doc.get('negative_sentiment', 0) - negative_doc.get('positive_sentiment', 0)) < 0.2,\n                'pattern_validation': 'Documents show expected sentiment polarity patterns'\n            },\n            'methodological_note': 'Qualitative consistency check due to small sample size (N=2)'\n        }\n        \n        return results\n        \n    except Exception:\n        return None\n\ndef run_complete_statistical_analysis(data: pd.DataFrame, alpha: float = 0.05) -> Dict[str, Any]:\n    \"\"\"\n    Run complete statistical analysis suite on the dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        alpha: Significance level for hypothesis tests (default: 0.05)\n        \n    Returns:\n        Dictionary with all statistical analysis results\n    \"\"\"\n    results = {\n        'analysis_metadata': {\n            'timestamp': pd.Timestamp.now().isoformat(),\n            'sample_size': len(data),\n            'alpha_level': alpha,\n            'variables_analyzed': list(data.select_dtypes(include=[np.number]).columns)\n        }\n    }\n    \n    # Get all analysis functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith(('calculate_', 'perform_', 'test_')) and \n            name != 'run_complete_statistical_analysis'):\n            try:\n                # Pass alpha parameter to functions that might need it\n                if 'alpha' in inspect.signature(obj).parameters:\n                    results[name] = obj(data, alpha=alpha)\n                else:\n                    results[name] = obj(data)\n            except Exception as e:\n                results[name] = {'error': f'Analysis failed: {str(e)}'}\n                \n    return results\n\n\ndef perform_statistical_analysis(data: pd.DataFrame) -> Dict[str, Any]:\n    \"\"\"\n    Template-compatible wrapper function for statistical analysis.\n    \n    This function is called by the universal notebook template and performs\n    comprehensive statistical analysis on the provided dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores and derived metrics\n        \n    Returns:\n        Dictionary containing all statistical analysis results\n    \"\"\"\n    return run_complete_statistical_analysis(data)\n\n\ndef generate_statistical_summary_report(analysis_results: Dict[str, Any]) -> str:\n    \"\"\"\n    Generate a human-readable summary report from statistical analysis results.\n    \n    Args:\n        analysis_results: Results from run_complete_statistical_analysis()\n        \n    Returns:\n        String containing formatted statistical report\n    \"\"\"\n    report_lines = []\n    report_lines.append(\"STATISTICAL ANALYSIS SUMMARY REPORT\")\n    report_lines.append(\"=\" * 50)\n    \n    metadata = analysis_results.get('analysis_metadata', {})\n    report_lines.append(f\"Analysis Timestamp: {metadata.get('timestamp', 'Unknown')}\")\n    report_lines.append(f\"Sample Size: {metadata.get('sample_size', 'Unknown')}\")\n    report_lines.append(f\"Alpha Level: {metadata.get('alpha_level', 'Unknown')}\")\n    report_lines.append(f\"Variables: {len(metadata.get('variables_analyzed', []))}\")\n    report_lines.append(\"\")\n    \n    # Summarize key findings\n    for analysis_name, result in analysis_results.items():\n        if analysis_name != 'analysis_metadata' and isinstance(result, dict):\n            if 'error' not in result:\n                report_lines.append(f\"{analysis_name.replace('_', ' ').title()}:\")\n                \n                # Extract key statistics based on analysis type\n                if 'p_value' in result:\n                    p_val = result['p_value']\n                    significance = \"significant\" if p_val < metadata.get('alpha_level', 0.05) else \"not significant\"\n                    report_lines.append(f\"  - p-value: {p_val:.4f} ({significance})\")\n                \n                if 'effect_size' in result:\n                    report_lines.append(f\"  - Effect size: {result['effect_size']:.4f}\")\n                \n                if 'correlation_matrix' in result:\n                    report_lines.append(f\"  - Correlation matrix generated with {len(result['correlation_matrix'])} variables\")\n                \n                if 'cronbach_alpha' in result:\n                    alpha_val = result['cronbach_alpha']\n                    reliability = \"excellent\" if alpha_val > 0.9 else \"good\" if alpha_val > 0.8 else \"acceptable\" if alpha_val > 0.7 else \"questionable\"\n                    report_lines.append(f\"  - Cronbach's \u03b1: {alpha_val:.3f} ({reliability})\")\n                \n                report_lines.append(\"\")\n            else:\n                report_lines.append(f\"{analysis_name}: ERROR - {result['error']}\")\n                report_lines.append(\"\")\n    \n    return \"\\n\".join(report_lines)\n",
  "cached_with_code": true
}