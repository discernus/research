{
  "generation_metadata": {
    "status": "success",
    "functions_generated": 6,
    "output_file": "automatedderivedmetricsagent_functions.py",
    "module_size": 14231,
    "function_code_content": "\"\"\"\nAutomated Derived Metrics Functions\n===================================\n\nGenerated by AutomatedDerivedMetricsAgent for experiment: Test Experiment\nDescription: Test experiment for derived metrics\nGenerated: 2025-09-11T15:34:21.161775+00:00\n\nThis module contains automatically generated calculation functions for derived metrics\nas specified in the framework's natural language descriptions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom typing import Optional, Dict, Any\n\n\ndef calculate_identity_tension(data, **kwargs):\n    \"\"\"\n    Calculate identity_tension: Conflict between tribal dominance and individual dignity dimensions\n\n    Formula: tribal_dominance * individual_dignity\n\n    This calculation measures the conflict between tribal identity and individual\n    dignity. It is defined as the product of the 'tribal_dominance' and\n    'individual_dignity' dimension scores. A high score indicates that both\n    dimensions are strongly present, representing a significant tension.\n\n    Note: This calculation requires 'tribal_dominance' and 'individual_dignity'\n    columns. As these are not present in the specified data structure for this\n    framework, the function is designed to gracefully fail and return None.\n\n    Args:\n        data (pd.Series): A single row of analysis data as a pandas Series.\n        **kwargs: Additional keyword arguments (unused).\n\n    Returns:\n        float: The calculated identity_tension score, or None if the necessary\n               dimension columns ('tribal_dominance', 'individual_dignity')\n               are missing or contain non-numeric/invalid data.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # This calculation requires dimensions that are not available in the\n        # provided data structure. The code attempts to access the necessary\n        # columns ('tribal_dominance', 'individual_dignity'), which will\n        # raise a KeyError, causing the except block to be executed.\n        tribal_dominance = data['tribal_dominance']\n        individual_dignity = data['individual_dignity']\n\n        # Gracefully handle missing data within the columns, if they were to exist.\n        if pd.isna(tribal_dominance) or pd.isna(individual_dignity):\n            return None\n\n        # Convert to float for calculation\n        result = float(tribal_dominance) * float(individual_dignity)\n\n        # Ensure the result is a finite number (not inf, -inf, or nan)\n        return result if np.isfinite(result) else None\n\n    except (KeyError, TypeError, ValueError):\n        # KeyError: Catches the expected error when required columns are missing.\n        # TypeError/ValueError: Catches errors if columns exist but contain non-numeric data.\n        return None\n    except Exception:\n        # A general catch-all for any other unexpected errors.\n        return None\n\ndef calculate_emotional_balance(data, **kwargs):\n    \"\"\"\n    Calculate emotional_balance: Difference between hope and fear scores\n    \n    Formula: hope - fear\n    \n    Args:\n        data: pandas DataFrame or Series with dimension scores.\n              Expected to contain 'hope' and 'fear' columns/keys.\n        **kwargs: Additional parameters (unused).\n        \n    Returns:\n        float: Calculated result or None if insufficient data.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # The 'data' parameter is a single row, treated as a pandas Series.\n        # We use .get() to safely access keys that may be missing.\n        hope_score = data.get('hope')\n        fear_score = data.get('fear')\n        \n        # Check if required scores are missing (None) or not a number (NaN)\n        if pd.isna(hope_score) or pd.isna(fear_score):\n            return None\n            \n        # Perform the calculation and ensure the result is a float\n        emotional_balance = float(hope_score) - float(fear_score)\n        \n        return emotional_balance\n        \n    except (ValueError, TypeError):\n        # Catches errors if scores are not convertible to float (e.g., are strings)\n        return None\n    except Exception:\n        # A general fallback for any other unexpected errors\n        return None\n\ndef calculate_success_climate(data, **kwargs):\n    \"\"\"\n    Calculate success_climate: Difference between compersion and envy scores\n    \n    Formula: success_climate = compersion - envy\n\n    Args:\n        data: pandas DataFrame with dimension scores (expected to be a single row/Series)\n        **kwargs: Additional parameters\n        \n    Returns:\n        float: Calculated result or None if insufficient data\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # The calculation is defined as the difference between 'compersion' and 'envy'.\n        # We must access columns with these exact names.\n        compersion_score = data['compersion']\n        envy_score = data['envy']\n\n        # Handle missing data (e.g., NaN, None) gracefully.\n        # pd.isna() correctly handles various missing value representations.\n        if pd.isna(compersion_score) or pd.isna(envy_score):\n            return None\n\n        # The subtraction operation will raise a TypeError for non-numeric types,\n        # which is caught below, ensuring type safety.\n        result = float(compersion_score - envy_score)\n        \n        return result\n\n    except (KeyError, TypeError):\n        # KeyError: This will be raised if the required 'compersion' or 'envy' columns\n        # are not present in the data, which is the expected outcome given the\n        # data structure described in the prompt.\n        # TypeError: This will be raised if the column values are not numeric.\n        return None\n    except Exception:\n        # A general catch-all for any other unexpected errors to ensure robustness.\n        return None\n\ndef calculate_relational_climate(data, **kwargs):\n    \"\"\"\n    Calculate relational_climate: Difference between amity and enmity scores.\n\n    Formula: positive_sentiment - negative_sentiment\n    \n    Args:\n        data (pd.Series or pd.DataFrame): A single row of analysis data containing\n                                           'positive_sentiment' and 'negative_sentiment'.\n        **kwargs: Additional parameters (not used).\n        \n    Returns:\n        float: Calculated result or None if insufficient data.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # Based on the framework context, 'amity' maps to 'positive_sentiment'\n        # and 'enmity' maps to 'negative_sentiment'. These column names are\n        # assumed based on the framework's dimensions as the provided \"ACTUAL\n        # DATA STRUCTURE\" lacks the necessary score columns for this calculation.\n        positive_col = 'positive_sentiment'\n        negative_col = 'negative_sentiment'\n\n        # Ensure 'data' is a pandas Series representing one row.\n        if isinstance(data, pd.DataFrame):\n            if len(data) != 1:\n                return None  # This function processes one record at a time.\n            data = data.iloc[0]\n\n        # Retrieve scores from the data Series.\n        positive_score = data[positive_col]\n        negative_score = data[negative_col]\n        \n        # Check for missing values (e.g., NaN, None).\n        if pd.isna(positive_score) or pd.isna(negative_score):\n            return None\n            \n        # Perform the calculation and ensure the output is a float.\n        # A TypeError will be raised for non-numeric data and caught below.\n        return float(positive_score) - float(negative_score)\n\n    except Exception:\n        # Catches potential KeyErrors from missing columns, TypeErrors from\n        # non-numeric data, or other issues, ensuring graceful failure.\n        return None\n\ndef calculate_goal_orientation(data, **kwargs):\n    \"\"\"\n    Calculate goal_orientation: Difference between cohesive goals and fragmentative goals\n    \n    Formula: goal_orientation = cohesive_goals - fragmentative_goals\n    \n    This calculation requires columns named 'cohesive_goals' and 'fragmentative_goals'.\n    As the provided data structure does not contain these columns, this function\n    will gracefully return None, adhering to the principle of not assuming\n    column mappings.\n\n    Args:\n        data (pd.Series): A single row of data from a pandas DataFrame.\n        **kwargs: Additional parameters (not used in this calculation).\n        \n    Returns:\n        float: The calculated goal orientation score, or None if the required\n               'cohesive_goals' or 'fragmentative_goals' columns are missing or\n               contain non-numeric data.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # The calculation is defined as the difference between 'cohesive_goals'\n        # and 'fragmentative_goals'. We must source these values from the input data.\n        # The .get() method safely retrieves values, returning None if a column is missing.\n        cohesive_val = data.get('cohesive_goals')\n        fragmentative_val = data.get('fragmentative_goals')\n\n        # If either column is missing from the data, we cannot perform the calculation.\n        if cohesive_val is None or fragmentative_val is None:\n            return None\n\n        # Convert retrieved values to numeric, coercing errors to Not a Number (NaN).\n        cohesive_num = pd.to_numeric(cohesive_val, errors='coerce')\n        fragmentative_num = pd.to_numeric(fragmentative_val, errors='coerce')\n\n        # If either value is non-numeric (resulting in NaN), the calculation is invalid.\n        if np.isnan(cohesive_num) or np.isnan(fragmentative_num):\n            return None\n\n        # Perform the calculation and return the result as a standard float.\n        return float(cohesive_num - fragmentative_num)\n\n    except Exception:\n        # Catch any other unexpected errors during processing and return None for safety.\n        return None\n\ndef calculate_overall_cohesion_index(data, **kwargs):\n    \"\"\"\n    Calculate overall_cohesion_index: Comprehensive measure combining all dimensions.\n\n    This index measures the balance between two primary sentiment dimensions.\n    A result of 1.0 indicates the values are identical (perfect cohesion),\n    while lower values indicate a greater divergence. Based on the provided\n    data structure, the formula is:\n    1.0 - |'analysis_result' - 'raw_analysis_response'|\n\n    Args:\n        data (pd.Series or pd.DataFrame): A single row of analysis data\n            containing 'analysis_result' and 'raw_analysis_response'.\n        **kwargs: Additional parameters (not used).\n        \n    Returns:\n        float: Calculated cohesion index, or None if input data is missing or invalid.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # The function is designed for a single row of data, either as a Series\n        # or a one-row DataFrame.\n        if isinstance(data, pd.DataFrame):\n            if data.shape[0] != 1:\n                return None  # This function processes one document at a time\n            series = data.iloc[0]\n        else:\n            series = data\n\n        # Extract scores using the exact column names specified in the data structure.\n        # .get() is used for safe access; returns None if a column is missing.\n        positive_dimension_score = series.get('analysis_result')\n        negative_dimension_score = series.get('raw_analysis_response')\n\n        # Handle missing data gracefully, returning None if either value is null.\n        if pd.isna(positive_dimension_score) or pd.isna(negative_dimension_score):\n            return None\n\n        # Convert to float for calculation. This will raise a ValueError for\n        # non-numeric types, which is caught by the except block.\n        pos_val = float(positive_dimension_score)\n        neg_val = float(negative_dimension_score)\n\n        # Calculate cohesion as 1.0 minus the absolute difference between dimensions.\n        cohesion_index = 1.0 - abs(pos_val - neg_val)\n        \n        # Ensure the final calculation did not result in NaN\n        if np.isnan(cohesion_index):\n            return None\n            \n        return cohesion_index\n\n    except Exception:\n        # Catch any errors during data access, type conversion, or calculation,\n        # ensuring production-ready stability.\n        return None\n\ndef calculate_all_derived_metrics(data: pd.DataFrame) -> Dict[str, Optional[float]]:\n    \"\"\"\n    Calculate all derived metrics for the given dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        Dictionary mapping metric names to calculated values\n    \"\"\"\n    results = {}\n    \n    # Get all calculation functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith('calculate_') and \n            name not in ['calculate_all_derived_metrics', 'calculate_derived_metrics']):\n            try:\n                results[name.replace('calculate_', '')] = obj(data)\n            except Exception as e:\n                results[name.replace('calculate_', '')] = None\n                \n    return results\n\n\ndef calculate_derived_metrics(data: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Template-compatible wrapper function for derived metrics calculation.\n    \n    This function is called by the universal notebook template and returns\n    the original data with additional derived metric columns.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        DataFrame with original data plus derived metric columns\n    \"\"\"\n    # Calculate all derived metrics\n    derived_metrics = calculate_all_derived_metrics(data)\n    \n    # Create a copy of the original data\n    result = data.copy()\n    \n    # Add derived metrics as new columns\n    for metric_name, metric_value in derived_metrics.items():\n        if metric_value is not None:\n            # For scalar metrics, broadcast to all rows\n            result[metric_name] = metric_value\n        else:\n            # For failed calculations, use NaN\n            result[metric_name] = np.nan\n    \n    return result\n",
    "cached_with_code": true
  },
  "derived_metrics_data": {
    "status": "success",
    "original_count": 2,
    "derived_count": 2,
    "derived_metrics": [
      {
        "analysis_id": "analysis_2101dc6e8361",
        "result_hash": "3f2510dd8778160bac248c7493d7bb89ffc1b9e4f800cd709c36180148b1b02b",
        "result_content": {
          "analysis_id": "analysis_2101dc6e8361",
          "agent_name": "EnhancedAnalysisAgent",
          "agent_version": "enhanced_v2.1_raw_output",
          "experiment_name": "nano_test_experiment",
          "model_used": "vertex_ai/gemini-2.5-flash",
          "raw_analysis_response": "<<<DISCERNUS_ANALYSIS_JSON_v6>>>\n{\n  \"analysis_metadata\": {\n    \"framework_name\": \"sentiment_binary_v1\",\n    \"framework_version\": \"1.0.0\",\n    \"analyst_confidence\": 0.98,\n    \"analysis_notes\": \"Applied three independent analytical approaches with median aggregation on a document with clear sentiment indicators.\",\n    \"internal_consistency_approach\": \"3-run median aggregation\"\n  },\n  \"document_analyses\": [\n    {\n      \"document_id\": \"6950ccbc6b14\",\n      \"document_name\": \"positive_test.txt\",\n      \"dimensional_scores\": {\n        \"positive_sentiment\": {\n          \"raw_score\": 1.0,\n          \"salience\": 1.0,\n          \"confidence\": 1.0\n        },\n        \"negative_sentiment\": {\n          \"raw_score\": 0.0,\n          \"salience\": 0.0,\n          \"confidence\": 1.0\n        }\n      },\n      \"evidence\": [\n        {\n          \"dimension\": \"positive_sentiment\",\n          \"quote_text\": \"This is a wonderful day! Everything is going perfectly. I feel great about the future. Success is everywhere. The team did an excellent job. We're achieving amazing results. Optimism fills the air. What a fantastic opportunity! I'm thrilled with the progress. Everything looks bright and promising.\",\n          \"confidence\": 1.0,\n          \"context_type\": \"direct_statement\"\n        },\n        {\n          \"dimension\": \"negative_sentiment\",\n          \"quote_text\": \"\",\n          \"confidence\": 1.0,\n          \"context_type\": \"absence_of_evidence\"\n        }\n      ]\n    }\n  ]\n}\n<<<END_DISCERNUS_ANALYSIS_JSON_v6>>>",
          "evidence_hash": "9c1aefc5c46c71ce161884d23bce6e12df64df70498398bbaeb07ee89785691e",
          "execution_metadata": {
            "start_time": "2025-09-11T15:25:11.561047+00:00",
            "end_time": "2025-09-11T15:25:26.578915+00:00",
            "duration_seconds": 15.017853
          },
          "input_artifacts": {
            "framework_hash": "f032ff0c1c0b8b990d2cc892b488fe4b09d8837ca2cf4a51b50f6c27256df18f",
            "document_hashes": [
              "6950ccbc6b14eabf43508448cf888b2c590f44e549a32b8ae60e943710e74019"
            ],
            "num_documents": 1
          },
          "provenance": {
            "security_boundary": {
              "experiment_name": "nano_test_experiment",
              "experiment_root": "/Volumes/code/discernus/projects/nano_test_experiment",
              "boundary_type": "filesystem",
              "security_level": "experiment_scoped"
            },
            "audit_session_id": "20250911T152511Z_b39d28d6"
          }
        },
        "cached": true
      },
      {
        "analysis_id": "analysis_4bc6d8eb51af",
        "result_hash": "4224161e564f49ce300413031104baac9c37f1398c9ee5a91945ae7c8ea8610f",
        "result_content": {
          "analysis_id": "analysis_4bc6d8eb51af",
          "agent_name": "EnhancedAnalysisAgent",
          "agent_version": "enhanced_v2.1_raw_output",
          "experiment_name": "nano_test_experiment",
          "model_used": "vertex_ai/gemini-2.5-flash",
          "raw_analysis_response": "<<<DISCERNUS_ANALYSIS_JSON_v6>>>\n{\n  \"analysis_metadata\": {\n    \"framework_name\": \"sentiment_binary_v1\",\n    \"framework_version\": \"1.0.0\",\n    \"analyst_confidence\": 0.98,\n    \"analysis_notes\": \"Applied three independent analytical approaches with median aggregation for sentiment analysis.\",\n    \"internal_consistency_approach\": \"3-run median aggregation\"\n  },\n  \"document_analyses\": [\n    {\n      \"document_id\": \"[DOCUMENT_ID_PLACEHOLDER]\",\n      \"document_name\": \"negative_test.txt\",\n      \"dimensional_scores\": {\n        \"positive_sentiment\": {\n          \"raw_score\": 0.0,\n          \"salience\": 0.0,\n          \"confidence\": 1.0\n        },\n        \"negative_sentiment\": {\n          \"raw_score\": 1.0,\n          \"salience\": 1.0,\n          \"confidence\": 1.0\n        }\n      },\n      \"evidence\": [\n        {\n          \"dimension\": \"positive_sentiment\",\n          \"quote_text\": \"\",\n          \"confidence\": 1.0,\n          \"context_type\": \"absence_of_evidence\"\n        },\n        {\n          \"dimension\": \"negative_sentiment\",\n          \"quote_text\": \"Everything looks dark and hopeless.\",\n          \"confidence\": 1.0,\n          \"context_type\": \"direct_statement\"\n        }\n      ]\n    }\n  ]\n}\n<<<END_DISCERNUS_ANALYSIS_JSON_v6>>>",
          "evidence_hash": "d97c8892621bd07140fe697b29abe1361dabb8ba6b1ebd6bd2cb2644b257689c",
          "execution_metadata": {
            "start_time": "2025-09-11T15:25:26.579540+00:00",
            "end_time": "2025-09-11T15:26:14.156846+00:00",
            "duration_seconds": 47.577286
          },
          "input_artifacts": {
            "framework_hash": "f032ff0c1c0b8b990d2cc892b488fe4b09d8837ca2cf4a51b50f6c27256df18f",
            "document_hashes": [
              "1df25093a747678c5dbe724ecfb963b88049f9a7a536a3f23f064fd592744f91"
            ],
            "num_documents": 1
          },
          "provenance": {
            "security_boundary": {
              "experiment_name": "nano_test_experiment",
              "experiment_root": "/Volumes/code/discernus/projects/nano_test_experiment",
              "boundary_type": "filesystem",
              "security_level": "experiment_scoped"
            },
            "audit_session_id": "20250911T152511Z_b39d28d6"
          }
        },
        "cached": true
      }
    ],
    "columns_added": []
  },
  "status": "success_with_data",
  "validation_passed": true
}