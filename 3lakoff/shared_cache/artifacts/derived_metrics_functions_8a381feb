{
  "status": "success",
  "functions_generated": 6,
  "output_file": "automatedderivedmetricsagent_functions.py",
  "module_size": 13249,
  "function_code_content": "\"\"\"\nAutomated Derived Metrics Functions\n===================================\n\nGenerated by AutomatedDerivedMetricsAgent for experiment: Test Experiment\nDescription: Test experiment for derived metrics\nGenerated: 2025-08-29T18:53:05.056271+00:00\n\nThis module contains automatically generated calculation functions for derived metrics\nas specified in the framework's natural language descriptions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom typing import Optional, Dict, Any\n\n\ndef calculate_identity_tension(data, **kwargs):\n    \"\"\"\n    Calculate identity_tension: Conflict between tribal dominance and individual dignity dimensions.\n\n    This metric quantifies the conflict between tribal dominance and individual dignity.\n    It is calculated as the absolute difference between the scores of these two dimensions.\n    A higher value signifies greater tension.\n\n    Formula:\n    identity_tension = |tribal_dominance_score - individual_dignity_score|\n\n    Args:\n        data (pd.Series): A single row of analysis data as a pandas Series.\n        **kwargs: Additional keyword arguments (unused).\n\n    Returns:\n        float: The calculated identity tension, or None if the required columns\n               'tribal_dominance_score' or 'individual_dignity_score' are\n               missing, not numeric, or contain NaN values.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # The calculation is based on conceptual columns derived from the description.\n        # This function anticipates these columns might be generated by a prior step,\n        # as they are not present in the base data structure provided.\n        tribal_col = 'tribal_dominance_score'\n        dignity_col = 'individual_dignity_score'\n\n        # Gracefully handle missing required columns.\n        if tribal_col not in data.index or dignity_col not in data.index:\n            return None\n\n        tribal_score = pd.to_numeric(data[tribal_col], errors='coerce')\n        dignity_score = pd.to_numeric(data[dignity_col], errors='coerce')\n\n        # Handle cases where conversion to numeric fails or data is NaN.\n        if np.isnan(tribal_score) or np.isnan(dignity_score):\n            return None\n\n        # Calculate the absolute difference to represent tension.\n        tension = abs(tribal_score - dignity_score)\n\n        return float(tension)\n\n    except (TypeError, ValueError, AttributeError):\n        # Catch potential errors if data is not a Series or during calculations.\n        return None\n\ndef calculate_emotional_balance(data, **kwargs):\n    \"\"\"\n    Calculate emotional_balance: Difference between hope and fear scores\n\n    Formula: hope - fear\n    \n    Args:\n        data (pd.Series): A single row of data from a DataFrame.\n        **kwargs: Additional parameters (not used).\n        \n    Returns:\n        float: The calculated emotional balance score, or None if input scores\n               are missing or invalid.\n    \"\"\"\n    import pandas as pd\n    \n    try:\n        # This calculation requires 'hope' and 'fear' scores, which are\n        # expected to be present in the input data.\n        hope_score = data['hope']\n        fear_score = data['fear']\n\n        # Handle cases where scores are missing (NaN) or not numeric.\n        if pd.isna(hope_score) or pd.isna(fear_score):\n            return None\n        \n        # Calculate the difference, ensuring the result is a float.\n        emotional_balance = float(hope_score) - float(fear_score)\n        \n        return emotional_balance\n\n    except (KeyError, TypeError, ValueError):\n        # A KeyError occurs if 'hope' or 'fear' columns are missing.\n        # A TypeError or ValueError can occur if values are not numeric.\n        # In any of these cases, the calculation cannot be completed.\n        return None\n\ndef calculate_success_climate(data, **kwargs):\n    \"\"\"\n    Calculate success_climate: Difference between compersion and envy scores\n\n    Formula: success_climate = compersion - envy\n    \n    Args:\n        data (pd.Series): A row of data containing the required scores.\n        **kwargs: Additional keyword arguments (not used).\n        \n    Returns:\n        float: The calculated result, or None if the required columns \n               ('compersion', 'envy') are missing or contain non-numeric data.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # The calculation requires 'compersion' and 'envy' scores.\n        # This attempts to access them, which will fail gracefully if they\n        # do not exist in the provided data, as per the requirements.\n        compersion_score = data['compersion']\n        envy_score = data['envy']\n\n        # Ensure that the required scores are not null or NaN\n        if pd.isna(compersion_score) or pd.isna(envy_score):\n            return None\n        \n        # Calculate the difference and ensure the output is a float\n        return float(compersion_score - envy_score)\n\n    except Exception:\n        # Catches KeyError if columns are missing, TypeError for non-numeric\n        # operations, or any other unexpected error during execution.\n        # Returns None for any failure, ensuring graceful handling.\n        return None\n\ndef calculate_relational_climate(data, **kwargs):\n    \"\"\"\n    Calculate relational_climate: Difference between amity and enmity scores.\n\n    Formula: relational_climate = amity - enmity\n\n    Args:\n        data (pd.Series): A single row of data from the analysis DataFrame.\n        **kwargs: Additional keyword arguments (not used in this calculation).\n\n    Returns:\n        float: The calculated relational climate score, or None if the necessary\n               'amity' or 'enmity' columns are missing or contain non-numeric data.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # The calculation requires 'amity' and 'enmity' columns.\n        # .get() is used to safely access columns that may not exist.\n        amity_score = data.get('amity')\n        enmity_score = data.get('enmity')\n\n        # Check if the required columns exist in the data.\n        if amity_score is None or enmity_score is None:\n            return None\n\n        # Coerce values to numeric, turning non-numeric into NaN.\n        amity_val = pd.to_numeric(amity_score, errors='coerce')\n        enmity_val = pd.to_numeric(enmity_score, errors='coerce')\n\n        # If either value is NaN (due to missing or non-numeric data),\n        # the calculation cannot be completed.\n        if np.isnan(amity_val) or np.isnan(enmity_val):\n            return None\n\n        # Perform the calculation.\n        relational_climate = amity_val - enmity_val\n        return float(relational_climate)\n\n    except Exception:\n        # A general exception handler to catch any unexpected errors during\n        # processing and ensure the function returns None gracefully.\n        return None\n\ndef calculate_goal_orientation(data, **kwargs):\n    \"\"\"\n    Calculates goal_orientation: Difference between cohesive goals and fragmentative goals.\n\n    Formula: goal_orientation = cohesive_goals - fragmentative_goals\n\n    Args:\n        data (pd.Series): A single row of analysis data.\n        **kwargs: Additional keyword arguments (not used).\n\n    Returns:\n        float: The calculated score, or None if required data is missing or invalid.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # This calculation requires 'cohesive_goals' and 'fragmentative_goals' scores.\n        # As these columns are not in the provided data structure, the function is\n        # designed to gracefully fail by returning None.\n        cohesive_goals = pd.to_numeric(data['cohesive_goals'], errors='coerce')\n        fragmentative_goals = pd.to_numeric(data['fragmentative_goals'], errors='coerce')\n\n        # If either required value is missing or non-numeric, return None.\n        if pd.isna(cohesive_goals) or pd.isna(fragmentative_goals):\n            return None\n\n        result = float(cohesive_goals - fragmentative_goals)\n\n        # Return the result only if it's a finite number.\n        return result if np.isfinite(result) else None\n\n    except Exception:\n        # Catches KeyError if columns are missing, or any other runtime error.\n        return None\n\ndef calculate_overall_cohesion_index(data, **kwargs):\n    \"\"\"\n    Calculate overall_cohesion_index: Comprehensive measure combining all dimensions.\n\n    This function measures the internal consistency of the analysis scores for a single\n    document. Cohesion is defined as the statistical consistency (i.e., low variance)\n    among the available numeric scores provided in the data. A higher index signifies\n    that the different scoring dimensions are in close agreement, reflecting a coherent\n    framing application according to the Lakoff model's principles.\n\n    The calculation adheres strictly to the specified column names from the data\n    structure. It computes the sample standard deviation of the non-missing values\n    from these columns and transforms it into a cohesion index.\n\n    Formula:\n        cohesion_index = 1 / (1 + \u03c3)\n    where:\n        - \u03c3 (sigma) is the sample standard deviation of the non-null values.\n        - The dimension columns used are: ['analysis_result', 'raw_analysis_response', 'scores_hash', 'evidence_hash'].\n\n    Args:\n        data (pd.Series): A single row of data from the analysis DataFrame,\n                          represented as a pandas Series.\n        **kwargs: Not used. Included for signature compatibility.\n\n    Returns:\n        float: The calculated overall cohesion index, typically between 0 and 1.\n               Returns None if there are fewer than two valid data points to\n               compute a standard deviation or if an error occurs.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # Per the prompt, this calculation must use the exact column names provided in the\n        # data structure, treating them as the \"dimensions\" to be combined.\n        # Cohesion is interpreted as low statistical variance among these measures.\n        dimension_cols = [\n            'analysis_result',\n            'raw_analysis_response',\n            'scores_hash',\n            'evidence_hash'\n        ]\n\n        # Extract values, drop NaNs, and ensure they are numeric.\n        # This will raise an error if columns are missing or types are wrong,\n        # which is handled by the except block.\n        valid_values = pd.to_numeric(data[dimension_cols], errors='coerce').dropna()\n\n        # Standard deviation requires at least two data points.\n        if len(valid_values) < 2:\n            return None\n\n        # Calculate the sample standard deviation (ddof=1 is the pandas default).\n        std_dev = valid_values.std()\n        \n        # If std_dev is somehow NaN (e.g., if valid_values contains non-numeric data\n        # that slipped through), return None.\n        if pd.isna(std_dev):\n            return None\n\n        # The cohesion index is the inverse of (1 + standard deviation).\n        # This maps a std_dev of 0 (perfect cohesion) to an index of 1.\n        # As std_dev increases (less cohesion), the index approaches 0.\n        cohesion_index = 1.0 / (1.0 + std_dev)\n\n        return cohesion_index\n\n    except Exception:\n        # Handles KeyErrors, TypeErrors, or any other unexpected issues gracefully.\n        return None\n\ndef calculate_all_derived_metrics(data: pd.DataFrame) -> Dict[str, Optional[float]]:\n    \"\"\"\n    Calculate all derived metrics for the given dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        Dictionary mapping metric names to calculated values\n    \"\"\"\n    results = {}\n    \n    # Get all calculation functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith('calculate_') and \n            name not in ['calculate_all_derived_metrics', 'calculate_derived_metrics']):\n            try:\n                results[name.replace('calculate_', '')] = obj(data)\n            except Exception as e:\n                results[name.replace('calculate_', '')] = None\n                \n    return results\n\n\ndef calculate_derived_metrics(data: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Template-compatible wrapper function for derived metrics calculation.\n    \n    This function is called by the universal notebook template and returns\n    the original data with additional derived metric columns.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        DataFrame with original data plus derived metric columns\n    \"\"\"\n    # Calculate all derived metrics\n    derived_metrics = calculate_all_derived_metrics(data)\n    \n    # Create a copy of the original data\n    result = data.copy()\n    \n    # Add derived metrics as new columns\n    for metric_name, metric_value in derived_metrics.items():\n        if metric_value is not None:\n            # For scalar metrics, broadcast to all rows\n            result[metric_name] = metric_value\n        else:\n            # For failed calculations, use NaN\n            result[metric_name] = np.nan\n    \n    return result\n",
  "cached_with_code": true
}