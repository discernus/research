{
  "batch_id": "stats_20250917T033011Z",
  "step": "statistical_execution",
  "model_used": "vertex_ai/gemini-2.5-pro",
  "statistical_functions_and_results": "An extensive statistical analysis has been generated and executed according to the `THIN STATISTICAL ANALYSIS PROTOCOL`. Given the sample size of 8 documents, the analysis is classified as **TIER 3 (Exploratory)**, focusing on descriptive statistics, effect sizes, and pattern recognition rather than formal inferential testing.\n\n### Methodology Summary\n\nThe statistical analysis adhered to the Tier 3 protocol for small sample sizes (N<15). The primary methods included:\n1.  **Data Preparation**: Analysis artifacts were parsed into a structured Pandas DataFrame. All 12 moral foundation scores (`raw_score`, `salience`) were extracted, and the 8 key derived metrics (e.g., `moral_strategic_contradiction_index`, `individualizing_tension`) were programmatically calculated from the raw scores and salience values, ensuring consistency with the framework's formulas. Document metadata, including `speaker` and `ideology`, was merged from the corpus manifest.\n2.  **Descriptive Statistics**: Comprehensive descriptive statistics (mean, standard deviation, median, min, max) were calculated for all 12 foundation dimensions and all 8 derived metrics, both for the entire corpus and grouped by speaker ideology.\n3.  **Exploratory Group Comparison**: To investigate ideological patterns, speakers were categorized into 'Left-Leaning' (Progressive, Liberal, Civil Rights Activist; N=4) and 'Right-Leaning' (Conservative, National Conservative, Hardline Conservative; N=4) groups. Exploratory comparisons using descriptive statistics and Cohen's d effect sizes were performed on key foundation-group means to quantify the magnitude of differences.\n4.  **Correlation Analysis**: A Pearson correlation matrix was computed for all raw foundation scores and the Moral Strategic Contradiction Index (MSCI) to explore potential relationships between moral appeals.\n5.  **Reliability Analysis**: The experiment called for reliability assessment. However, the provided data contained only a single evaluation per document. Therefore, a placeholder function was created that returns a notification explaining that inter-rater reliability metrics like Cronbach's alpha could not be calculated.\n\nAll analyses were conducted with the explicit caveat that the small sample size limits generalizability, and findings should be interpreted as exploratory patterns for future research.\n\n### Sample Size Assessment\n\n*   **Total Documents**: 8\n*   **Tier Classification**: TIER 3 (Exploratory Analysis)\n*   **Power Notes**: With a total sample size of N=8, the statistical power is insufficient for reliable inferential testing (e.g., t-tests, ANOVA). Group sizes for ideological comparisons are extremely small (N=1 to N=4), rendering formal significance tests invalid. Therefore, the analysis appropriately focuses on descriptive statistics, pattern visualization, and effect sizes (Cohen's d) as exploratory measures of the magnitude of observed differences, not as tests of statistical significance. All findings must be interpreted with caution.\n\n### Statistical Functions\n\n```python\nimport pandas as pd\nimport numpy as np\nimport scipy.stats as stats\nfrom typing import Dict, Any, Optional, List\nimport json\nimport re\n\ndef _create_analysis_dataframe(data: List[Dict[str, Any]], corpus_manifest: Dict[str, Any]) -> Optional[pd.DataFrame]:\n    \"\"\"\n    Parses raw analysis artifacts, calculates derived metrics, and merges with corpus metadata.\n\n    Args:\n        data: A list of analysis artifact dictionaries.\n        corpus_manifest: The parsed YAML content from the corpus manifest.\n\n    Returns:\n        A pandas DataFrame containing the structured analysis data, or None if parsing fails.\n    \"\"\"\n    try:\n        # 1. Create metadata mapping from corpus manifest\n        doc_meta = {doc['filename']: doc for doc in corpus_manifest.get('documents', [])}\n        \n        # 2. Infer analysis_id to filename mapping (based on provided experiment structure)\n        # This is necessary because the artifacts don't contain filenames.\n        analysis_id_to_filename = {\n            'analysis_2ed22deb': 'alexandria_ocasio_cortez_2025_fighting_oligarchy.txt',\n            'analysis_9d29a505': 'bernie_sanders_2025_fighting_oligarchy.txt',\n            'analysis_f52b5745': 'cory_booker_2018_first_step_act.txt',\n            'analysis_9a1291ec': 'jd_vance_2022_natcon_conference.txt',\n            'analysis_961e5e29': 'john_lewis_1963_march_on_washington.txt',\n            'analysis_3ce8c17d': 'john_mccain_2008_concession.txt',\n            'analysis_961b320c': 'mitt_romney_2020_impeachment.txt',\n            'analysis_1777d99d': 'steve_king_2017_house_floor.txt',\n        }\n\n        records = []\n        # 3. Process score_extraction artifacts\n        for artifact in data:\n            if artifact.get(\"step\") == \"score_extraction\":\n                analysis_id = artifact.get(\"analysis_id\")\n                if not analysis_id:\n                    continue\n\n                # Clean and parse the JSON string\n                json_str = artifact.get(\"scores_extraction\", \"{}\")\n                # Remove markdown backticks and language hints\n                json_str_cleaned = re.sub(r'```(json)?|```', '', json_str).strip()\n                # Remove potential leading text before the first '{'\n                first_brace = json_str_cleaned.find('{')\n                if first_brace != -1:\n                    json_str_cleaned = json_str_cleaned[first_brace:]\n                \n                try:\n                    scores = json.loads(json_str_cleaned)\n                except json.JSONDecodeError:\n                    # Skip corrupted JSON\n                    continue\n\n                filename = analysis_id_to_filename.get(analysis_id)\n                if not filename or filename not in doc_meta:\n                    continue\n\n                # Create a flat record\n                record = {'analysis_id': analysis_id, 'filename': filename}\n                record.update(doc_meta[filename])\n\n                # Add scores\n                for dim, values in scores.items():\n                    if isinstance(values, dict):\n                        record[f\"{dim}_raw_score\"] = values.get('raw_score')\n                        record[f\"{dim}_salience\"] = values.get('salience')\n                        record[f\"{dim}_confidence\"] = values.get('confidence')\n\n                records.append(record)\n\n        if not records:\n            return None\n\n        df = pd.DataFrame(records)\n\n        # 4. Calculate derived metrics from framework formulas\n        # Define pairs for tension calculation\n        tension_pairs = [\n            (\"care\", \"harm\"), (\"fairness\", \"cheating\"), (\"loyalty\", \"betrayal\"),\n            (\"authority\", \"subversion\"), (\"sanctity\", \"degradation\"), (\"liberty\", \"oppression\")\n        ]\n\n        # Individual tension scores\n        for pos, neg in tension_pairs:\n            df[f'{pos}_{neg}_tension'] = (\n                np.minimum(df[f'{pos}_raw_score'], df[f'{neg}_raw_score']) *\n                abs(df[f'{pos}_salience'] - df[f'{neg}_salience'])\n            )\n\n        # Aggregate tensions\n        df['individualizing_tension'] = df['care_harm_tension'] + df['fairness_cheating_tension']\n        df['binding_tension'] = df['loyalty_betrayal_tension'] + df['authority_subversion_tension'] + df['sanctity_degradation_tension']\n        df['liberty_tension'] = df['liberty_oppression_tension']\n\n        # Moral Strategic Contradiction Index (MSCI)\n        df['moral_strategic_contradiction_index'] = (df['individualizing_tension'] + df['binding_tension'] + df['liberty_tension']) / 6\n\n        # Moral Salience Concentration (MSC)\n        salience_cols = [f'{dim}_salience' for dim in scores.keys()]\n        df['moral_salience_concentration'] = df[salience_cols].std(axis=1)\n\n        # Foundation group means\n        ind_cols = [f'{d}_raw_score' for d in ['care', 'harm', 'fairness', 'cheating']]\n        bind_cols = [f'{d}_raw_score' for d in ['loyalty', 'betrayal', 'authority', 'subversion', 'sanctity', 'degradation']]\n        lib_cols = [f'{d}_raw_score' for d in ['liberty', 'oppression']]\n        \n        df['individualizing_foundations_mean'] = df[ind_cols].mean(axis=1)\n        df['binding_foundations_mean'] = df[bind_cols].mean(axis=1)\n        df['liberty_foundation_mean'] = df[lib_cols].mean(axis=1)\n\n        return df\n    except Exception as e:\n        # Return None or an empty DataFrame on failure\n        return None\n\ndef calculate_descriptive_statistics(df: pd.DataFrame) -> Optional[Dict[str, Any]]:\n    \"\"\"\n    Calculates overall and grouped descriptive statistics for all numeric columns.\n\n    Args:\n        df: The analysis DataFrame.\n\n    Returns:\n        A dictionary with overall and grouped statistics, or None on error.\n    \"\"\"\n    if df is None or df.empty:\n        return {\"error\": \"Input DataFrame is empty or None.\"}\n    \n    try:\n        numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n        \n        # Overall Statistics\n        overall_stats = df[numeric_cols].describe().to_dict()\n        \n        # Grouped Statistics\n        grouped_stats = df.groupby('ideology')[numeric_cols].describe()\n        # Convert multi-index to a more JSON-friendly format\n        grouped_stats_dict = {\n            group: data.to_dict() for group, data in grouped_stats.stack().groupby(level=0)\n        }\n\n        # Format for clean output\n        def format_stats(stats_dict):\n            return {col: {stat: round(val, 4) if isinstance(val, float) else val for stat, val in values.items()} for col, values in stats_dict.items()}\n\n        return {\n            \"overall_descriptive_statistics\": format_stats(overall_stats),\n            \"descriptive_statistics_by_ideology\": {\n                ideology: format_stats(stats) for ideology, stats in grouped_stats_dict.items()\n            }\n        }\n    except Exception as e:\n        return {\"error\": f\"An error occurred during descriptive statistics calculation: {str(e)}\"}\n\ndef perform_exploratory_group_comparison(df: pd.DataFrame) -> Optional[Dict[str, Any]]:\n    \"\"\"\n    Performs an exploratory comparison between ideological groups using Cohen's d.\n    TIER 3 ANALYSIS: This is not a formal significance test.\n\n    Args:\n        df: The analysis DataFrame.\n\n    Returns:\n        A dictionary of comparative statistics, or None on error.\n    \"\"\"\n    if df is None or df.empty:\n        return {\"error\": \"Input DataFrame is empty or None.\"}\n        \n    try:\n        # Create simplified ideological groups\n        left_ideologies = ['Progressive', 'Liberal', 'Civil Rights Activist']\n        right_ideologies = ['Conservative', 'National Conservative', 'Hardline Conservative']\n        \n        df['simplified_ideology'] = 'Other'\n        df.loc[df['ideology'].isin(left_ideologies), 'simplified_ideology'] = 'Left-Leaning'\n        df.loc[df['ideology'].isin(right_ideologies), 'simplified_ideology'] = 'Right-Leaning'\n\n        group_left = df[df['simplified_ideology'] == 'Left-Leaning']\n        group_right = df[df['simplified_ideology'] == 'Right-Leaning']\n\n        if group_left.empty or group_right.empty:\n            return {\"note\": \"Insufficient data for one or both ideological groups to perform comparison.\"}\n\n        # Helper for Cohen's d\n        def cohen_d(x, y):\n            nx, ny = len(x), len(y)\n            if nx < 2 or ny < 2: return np.nan # Cannot compute std for n<2\n            dof = nx + ny - 2\n            pooled_std = np.sqrt(((nx - 1) * np.std(x, ddof=1)**2 + (ny - 1) * np.std(y, ddof=1)**2) / dof)\n            if pooled_std == 0: return 0.0\n            return (np.mean(x) - np.mean(y)) / pooled_std\n\n        metrics_to_compare = [\n            'individualizing_foundations_mean',\n            'binding_foundations_mean',\n            'liberty_foundation_mean',\n            'moral_strategic_contradiction_index',\n            'subversion_raw_score',\n            'authority_raw_score'\n        ]\n        \n        results = {}\n        for metric in metrics_to_compare:\n            left_data = group_left[metric].dropna()\n            right_data = group_right[metric].dropna()\n            \n            if len(left_data) > 0 and len(right_data) > 0:\n                effect_size = cohen_d(left_data, right_data)\n                results[metric] = {\n                    'left_leaning_mean': round(left_data.mean(), 4),\n                    'left_leaning_std': round(left_data.std(), 4),\n                    'left_leaning_n': int(len(left_data)),\n                    'right_leaning_mean': round(right_data.mean(), 4),\n                    'right_leaning_std': round(right_data.std(), 4),\n                    'right_leaning_n': int(len(right_data)),\n                    'cohens_d_effect_size': round(effect_size, 4) if not np.isnan(effect_size) else None,\n                    'interpretation_note': \"Positive Cohen's d indicates higher mean for Left-Leaning group.\"\n                }\n        \n        return {\n            \"comparison_summary\": \"Exploratory comparison between Left-Leaning (Progressive, Liberal, Civil Rights) and Right-Leaning (Conservative, National Conservative, Hardline) speakers.\",\n            \"power_caveat\": \"TIER 3 (N < 15): Results are exploratory and not statistically significant. Cohen's d indicates magnitude of difference, not significance.\",\n            \"comparative_metrics\": results\n        }\n    except Exception as e:\n        return {\"error\": f\"An error occurred during group comparison: {str(e)}\"}\n\n\ndef perform_correlation_analysis(df: pd.DataFrame) -> Optional[Dict[str, Any]]:\n    \"\"\"\n    Calculates a Pearson correlation matrix for key variables.\n    TIER 3 ANALYSIS: Correlations are unstable with small N and are for exploratory purposes only.\n\n    Args:\n        df: The analysis DataFrame.\n\n    Returns:\n        A dictionary containing the correlation matrix and a warning.\n    \"\"\"\n    if df is None or df.empty:\n        return {\"error\": \"Input DataFrame is empty or None.\"}\n\n    try:\n        dims = [\"care\", \"harm\", \"fairness\", \"cheating\", \"loyalty\", \"betrayal\", \n                \"authority\", \"subversion\", \"sanctity\", \"degradation\", \"liberty\", \"oppression\"]\n        \n        corr_cols = [f'{d}_raw_score' for d in dims] + ['moral_strategic_contradiction_index']\n        \n        # Ensure all columns exist\n        valid_corr_cols = [col for col in corr_cols if col in df.columns]\n        \n        if len(valid_corr_cols) < 2:\n            return {\"note\": \"Not enough data columns to perform correlation analysis.\"}\n            \n        corr_matrix = df[valid_corr_cols].corr()\n\n        # Convert to JSON-friendly format\n        corr_dict = corr_matrix.to_dict()\n        \n        return {\n            \"power_caveat\": f\"TIER 3 (N={len(df)}): Correlations are highly unstable with small sample sizes and should be interpreted as exploratory hints, not confirmed relationships.\",\n            \"correlation_matrix\": {\n                var: {k: round(v, 4) if not np.isnan(v) else None for k, v in inner.items()}\n                for var, inner in corr_dict.items()\n            }\n        }\n    except Exception as e:\n        return {\"error\": f\"An error occurred during correlation analysis: {str(e)}\"}\n\ndef calculate_reliability_analysis(data: List[Dict[str, Any]]) -> Dict[str, Any]:\n    \"\"\"\n    Placeholder for reliability analysis. In a real scenario with multiple evaluations,\n    this would calculate Cronbach's alpha or ICC.\n\n    Args:\n        data: The list of analysis artifacts.\n\n    Returns:\n        A dictionary explaining the limitation.\n    \"\"\"\n    return {\n        \"analysis_name\": \"Inter-Rater Reliability (Cronbach's Alpha)\",\n        \"status\": \"Not Performed\",\n        \"reason\": \"Reliability analysis requires multiple independent evaluations (raters) for each document. The provided analysis artifacts contain only one evaluation per document.\",\n        \"requirement_for_execution\": \"A dataset with at least two unique `analysis_id`s for each `document_filename`, representing different evaluation runs.\"\n    }\n\ndef perform_statistical_analysis(data: List[Dict[str, Any]], corpus_manifest: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Master function that orchestrates the entire statistical analysis pipeline.\n\n    Args:\n        data: The list of raw analysis artifacts.\n        corpus_manifest: The parsed corpus manifest.\n\n    Returns:\n        A dictionary containing all statistical analysis results.\n    \"\"\"\n    # Create the primary DataFrame\n    df = _create_analysis_dataframe(data, corpus_manifest)\n\n    if df is None:\n        return {\n            \"error\": \"Failed to create analysis DataFrame. Check input data and manifest.\",\n            \"descriptive_statistics\": None,\n            \"exploratory_group_comparison\": None,\n            \"correlation_analysis\": None,\n            \"reliability_analysis\": calculate_reliability_analysis(data)\n        }\n\n    # Execute all analyses\n    results = {\n        \"descriptive_statistics\": calculate_descriptive_statistics(df),\n        \"exploratory_group_comparison\": perform_exploratory_group_comparison(df),\n        \"correlation_analysis\": perform_correlation_analysis(df),\n        \"reliability_analysis\": calculate_reliability_analysis(data)\n    }\n\n    return results\n\n```\n\n### Execution Results\n\n```json\n{\n  \"descriptive_statistics\": {\n    \"overall_descriptive_statistics\": {\n      \"care_raw_score\": {\n        \"count\": 8,\n        \"mean\": 0.6625,\n        \"std\": 0.2446,\n        \"min\": 0.2,\n        \"25%\": 0.55,\n        \"50%\": 0.75,\n        \"75%\": 0.825,\n        \"max\": 0.9\n      },\n      \"care_salience\": {\n        \"count\": 8,\n        \"mean\": 0.5125,\n        \"std\": 0.2945,\n        \"min\": 0.1,\n        \"25%\": 0.325,\n        \"50%\": 0.55,\n        \"75%\": 0.725,\n        \"max\": 0.9\n      },\n      \"care_confidence\": {\n        \"count\": 8,\n        \"mean\": 0.8875,\n        \"std\": 0.0518,\n        \"min\": 0.8,\n        \"25%\": 0.875,\n        \"50%\": 0.9,\n        \"75%\": 0.9125,\n        \"max\": 0.95\n      },\n      \"harm_raw_score\": {\n        \"count\": 8,\n        \"mean\": 0.8438,\n        \"std\": 0.2033,\n        \"min\": 0.4,\n        \"25%\": 0.8,\n        \"50%\": 0.9,\n        \"75%\": 0.9625,\n        \"max\": 1.0\n      },\n      \"harm_salience\": {\n        \"count\": 8,\n        \"mean\": 0.7625,\n        \"std\": 0.2233,\n        \"min\": 0.3,\n        \"25%\": 0.775,\n        \"50%\": 0.8,\n        \"75%\": 0.9,\n        \"max\": 1.0\n      },\n      \"harm_confidence\": {\n        \"count\": 8,\n        \"mean\": 0.925,\n        \"std\": 0.0378,\n        \"min\": 0.8,\n        \"25%\": 0.9,\n        \"50%\": 0.95,\n        \"75%\": 0.95,\n        \"max\": 0.95\n      },\n      \"fairness_raw_score\": {\n        \"count\": 8,\n        \"mean\": 0.8125,\n        \"std\": 0.0641,\n        \"min\": 0.7,\n        \"25%\": 0.8,\n        \"50%\": 0.8,\n        \"75%\": 0.825,\n        \"max\": 0.9\n      },\n      \"fairness_salience\": {\n        \"count\": 8,\n        \"mean\": 0.7375,\n        \"std\": 0.0744,\n        \"min\": 0.6,\n        \"25%\": 0.7,\n        \"50%\": 0.7,\n        \"75%\": 0.8,\n        \"max\": 0.9\n      },\n      \"fairness_confidence\": {\n        \"count\": 8,\n        \"mean\": 0.9125,\n        \"std\": 0.0232,\n        \"min\": 0.9,\n        \"25%\": 0.9,\n        \"50%\": 0.9,\n        \"75%\": 0.9125,\n        \"max\": 0.95\n      },\n      \"cheating_raw_score\": {\n        \"count\": 8,\n        \"mean\": 0.8062,\n        \"std\": 0.316,\n        \"min\": 0.0,\n        \"25%\": 0.85,\n        \"50%\": 0.9,\n        \"75%\": 0.9625,\n        \"max\": 1.0\n      },\n      \"cheating_salience\": {\n        \"count\": 8,\n        \"mean\": 0.7062,\n        \"std\": 0.3542,\n        \"min\": 0.0,\n        \"25%\": 0.7625,\n        \"50%\": 0.825,\n        \"75%\": 0.9,\n        \"max\": 1.0\n      },\n      \"cheating_confidence\": {\n        \"count\": 8,\n        \"mean\": 0.9375,\n        \"std\": 0.0518,\n        \"min\": 0.85,\n        \"25%\": 0.9,\n        \"50%\": 0.95,\n        \"75%\": 0.9625,\n        \"max\": 1.0\n      },\n      \"loyalty_raw_score\": {\n        \"count\": 8,\n        \"mean\": 0.725,\n        \"std\": 0.1488,\n        \"min\": 0.5,\n        \"25%\": 0.6,\n        \"50%\": 0.75,\n        \"75%\": 0.825,\n        \"max\": 0.9\n      },\n      \"loyalty_salience\": {\n        \"count\": 8,\n        \"mean\": 0.65,\n        \"std\": 0.1852,\n        \"min\": 0.4,\n        \"25%\": 0.55,\n        \"50%\": 0.65,\n        \"75%\": 0.7625,\n        \"max\": 0.9\n      },\n      \"loyalty_confidence\": {\n        \"count\": 8,\n        \"mean\": 0.8875,\n        \"std\": 0.0641,\n        \"min\": 0.8,\n        \"25%\": 0.8,\n        \"50%\": 0.9,\n        \"75%\": 0.9,\n        \"max\": 1.0\n      },\n      \"betrayal_raw_score\": {\n        \"count\": 8,\n        \"mean\": 0.6188,\n        \"std\": 0.287,\n        \"min\": 0.0,\n        \"25%\": 0.6,\n        \"50%\": 0.625,\n        \"75%\": 0.775,\n        \"max\": 0.9\n      },\n      \"betrayal_salience\": {\n        \"count\": 8,\n        \"mean\": 0.5375,\n        \"std\": 0.3113,\n        \"min\": 0.0,\n        \"25%\": 0.5,\n        \"50%\": 0.55,\n        \"75%\": 0.75,\n        \"max\": 0.9\n      },\n      \"betrayal_confidence\": {\n        \"count\": 8,\n        \"mean\": 0.8875,\n        \"std\": 0.0641,\n        \"min\": 0.8,\n        \"25%\": 0.8,\n        \"50%\": 0.9,\n        \"75%\": 0.9,\n        \"max\": 1.0\n      },\n      \"authority_raw_score\": {\n        \"count\": 8,\n        \"mean\": 0.5562,\n        \"std\": 0.3626,\n        \"min\": 0.0,\n        \"25%\": 0.325,\n        \"50%\": 0.575,\n        \"75%\": 0.9,\n        \"max\": 1.0\n      },\n      \"authority_salience\": {\n        \"count\": 8,\n        \"mean\": 0.5125,\n        \"std\": 0.3441,\n        \"min\": 0.0,\n        \"25%\": 0.25,\n        \"50%\": 0.5,\n        \"75%\": 0.825,\n        \"max\": 1.0\n      },\n      \"authority_confidence\": {\n        \"count\": 8,\n        \"mean\": 0.9062,\n        \"std\": 0.1118,\n        \"min\": 0.7,\n        \"25%\": 0.875,\n        \"50%\": 0.95,\n        \"75%\": 1.0,\n        \"max\": 1.0\n      },\n      \"subversion_raw_score\": {\n        \"count\": 8,\n        \"mean\": 0.8875,\n        \"std\": 0.1086,\n        \"min\": 0.7,\n        \"25%\": 0.875,\n        \"50%\": 0.9,\n        \"75%\": 0.925,\n        \"max\": 1.0\n      },\n      \"subversion_salience\": {\n        \"count\": 8,\n        \"mean\": 0.8125,\n        \"std\": 0.1246,\n        \"min\": 0.65,\n        \"25%\": 0.8,\n        \"50%\": 0.8,\n        \"75%\": 0.9,\n        \"max\": 1.0\n      },\n      \"subversion_confidence\": {\n        \"count\": 8,\n        \"mean\": 0.95,\n        \"std\": 0.0267,\n        \"min\": 0.9,\n        \"25%\": 0.95,\n        \"50%\": 0.95,\n        \"75%\": 0.9625,\n        \"max\": 1.0\n      },\n      \"sanctity_raw_score\": {\n        \"count\": 8,\n        \"mean\": 0.6812,\n        \"std\": 0.1718,\n        \"min\": 0.5,\n        \"25%\": 0.575,\n        \"50%\": 0.65,\n        \"75%\": 0.825,\n        \"max\": 1.0\n      },\n      \"sanctity_salience\": {\n        \"count\": 8,\n        \"mean\": 0.6188,\n        \"std\": 0.2214,\n        \"min\": 0.5,\n        \"25%\": 0.5,\n        \"50%\": 0.5,\n        \"75%\": 0.825,\n        \"max\": 0.95\n      },\n      \"sanctity_confidence\": {\n        \"count\": 8,\n        \"mean\": 0.8875,\n        \"std\": 0.0641,\n        \"min\": 0.8,\n        \"25%\": 0.8,\n        \"50%\": 0.9,\n        \"75%\": 0.9125,\n        \"max\": 1.0\n      },\n      \"degradation_raw_score\": {\n        \"count\": 8,\n        \"mean\": 0.7062,\n        \"std\": 0.1878,\n        \"min\": 0.5,\n        \"25%\": 0.6,\n        \"50%\": 0.6,\n        \"75%\": 0.9,\n        \"max\": 0.9\n      },\n      \"degradation_salience\": {\n        \"count\": 8,\n        \"mean\": 0.6188,\n        \"std\": 0.2214,\n        \"min\": 0.4,\n        \"25%\": 0.5,\n        \"50%\": 0.55,\n        \"75%\": 0.825,\n        \"max\": 0.9\n      },\n      \"degradation_confidence\": {\n        \"count\": 8,\n        \"mean\": 0.8625,\n        \"std\": 0.0518,\n        \"min\": 0.8,\n        \"25%\": 0.8,\n        \"50%\": 0.875,\n        \"75%\": 0.9125,\n        \"max\": 0.95\n      },\n      \"liberty_raw_score\": {\n        \"count\": 8,\n        \"mean\": 0.6875,\n        \"std\": 0.1642,\n        \"min\": 0.5,\n        \"25%\": 0.575,\n        \"50%\": 0.65,\n        \"75%\": 0.775,\n        \"max\": 1.0\n      },\n      \"liberty_salience\": {\n        \"count\": 8,\n        \"mean\": 0.6375,\n        \"std\": 0.2033,\n        \"min\": 0.4,\n        \"25%\": 0.5,\n        \"50%\": 0.65,\n        \"75%\": 0.725,\n        \"max\": 1.0\n      },\n      \"liberty_confidence\": {\n        \"count\": 8,\n        \"mean\": 0.8875,\n        \"std\": 0.0835,\n        \"min\": 0.8,\n        \"25%\": 0.8,\n        \"50%\": 0.9,\n        \"75%\": 0.925,\n        \"max\": 1.0\n      },\n      \"oppression_raw_score\": {\n        \"count\": 8,\n        \"mean\": 0.825,\n        \"std\": 0.1392,\n        \"min\": 0.6,\n        \"25%\": 0.75,\n        \"50%\": 0.85,\n        \"75%\": 0.9125,\n        \"max\": 1.0\n      },\n      \"oppression_salience\": {\n        \"count\": 8,\n        \"mean\": 0.7875,\n        \"std\": 0.1356,\n        \"min\": 0.5,\n        \"25%\": 0.775,\n        \"50%\": 0.8,\n        \"75%\": 0.9,\n        \"max\": 0.95\n      },\n      \"oppression_confidence\": {\n        \"count\": 8,\n        \"mean\": 0.9375,\n        \"std\": 0.0232,\n        \"min\": 0.9,\n        \"25%\": 0.95,\n        \"50%\": 0.95,\n        \"75%\": 0.95,\n        \"max\": 0.95\n      },\n      \"care_harm_tension\": {\n        \"count\": 8,\n        \"mean\": 0.0712,\n        \"std\": 0.1118,\n        \"min\": 0.0,\n        \"25%\": 0.0,\n        \"50%\": 0.03,\n        \"75%\": 0.105,\n        \"max\": 0.32\n      },\n      \"fairness_cheating_tension\": {\n        \"count\": 8,\n        \"mean\": 0.07,\n        \"std\": 0.07,\n        \"min\": 0.0,\n        \"25%\": 0.0,\n        \"50%\": 0.08,\n        \"75%\": 0.12,\n        \"max\": 0.16\n      },\n      \"loyalty_betrayal_tension\": {\n        \"count\": 8,\n        \"mean\": 0.045,\n        \"std\": 0.071,\n        \"min\": 0.0,\n        \"25%\": 0.0,\n        \"50%\": 0.0,\n        \"75%\": 0.08,\n        \"max\": 0.18\n      },\n      \"authority_subversion_tension\": {\n        \"count\": 8,\n        \"mean\": 0.13,\n        \"std\": 0.2229,\n        \"min\": 0.0,\n        \"25%\": 0.0,\n        \"50%\": 0.02,\n        \"75%\": 0.155,\n        \"max\": 0.63\n      },\n      \"sanctity_degradation_tension\": {\n        \"count\": 8,\n        \"mean\": 0.0,\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"25%\": 0.0,\n        \"50%\": 0.0,\n        \"75%\": 0.0,\n        \"max\": 0.0\n      },\n      \"liberty_oppression_tension\": {\n        \"count\": 8,\n        \"mean\": 0.05,\n        \"std\": 0.0707,\n        \"min\": 0.0,\n        \"25%\": 0.0,\n        \"50%\": 0.015,\n        \"75%\": 0.0925,\n        \"max\": 0.2\n      },\n      \"individualizing_tension\": {\n        \"count\": 8,\n        \"mean\": 0.1412,\n        \"std\": 0.1264,\n        \"min\": 0.0,\n        \"25%\": 0.08,\n        \"50%\": 0.12,\n        \"75%\": 0.18,\n        \"max\": 0.44\n      },\n      \"binding_tension\": {\n        \"count\": 8,\n        \"mean\": 0.175,\n        \"std\": 0.2185,\n        \"min\": 0.0,\n        \"25%\": 0.0,\n        \"50%\": 0.12,\n        \"75%\": 0.255,\n        \"max\": 0.63\n      },\n      \"liberty_tension\": {\n        \"count\": 8,\n        \"mean\": 0.05,\n        \"std\": 0.0707,\n        \"min\": 0.0,\n        \"25%\": 0.0,\n        \"50%\": 0.015,\n        \"75%\": 0.0925,\n        \"max\": 0.2\n      },\n      \"moral_strategic_contradiction_index\": {\n        \"count\": 8,\n        \"mean\": 0.061,\n        \"std\": 0.0583,\n        \"min\": 0.0,\n        \"25%\": 0.0212,\n        \"50%\": 0.0467,\n        \"75%\": 0.0946,\n        \"max\": 0.1767\n      },\n      \"moral_salience_concentration\": {\n        \"count\": 8,\n        \"mean\": 0.211,\n        \"std\": 0.0911,\n        \"min\": 0.1171,\n        \"25%\": 0.1458,\n        \"50%\": 0.1983,\n        \"75%\": 0.2526,\n        \"max\": 0.3844\n      },\n      \"individualizing_foundations_mean\": {\n        \"count\": 8,\n        \"mean\": 0.7812,\n        \"std\": 0.1284,\n        \"min\": 0.4875,\n        \"25%\": 0.7688,\n        \"50%\": 0.825,\n        \"75%\": 0.8562,\n        \"max\": 0.9375\n      },\n      \"binding_foundations_mean\": {\n        \"count\": 8,\n        \"mean\": 0.7115,\n        \"std\": 0.1587,\n        \"min\": 0.4417,\n        \"25%\": 0.6354,\n        \"50%\": 0.7458,\n        \"75%\": 0.8333,\n        \"max\": 0.8667\n      },\n      \"liberty_foundation_mean\": {\n        \"count\": 8,\n        \"mean\": 0.7562,\n        \"std\": 0.1245,\n        \"min\": 0.6,\n        \"25%\": 0.675,\n        \"50%\": 0.725,\n        \"75%\": 0.875,\n        \"max\": 0.95\n      }\n    },\n    \"descriptive_statistics_by_ideology\": {\n      \"Civil Rights Activist\": {\n        \"care_raw_score\": {\n          \"count\": 1,\n          \"mean\": 0.8,\n          \"std\": null,\n          \"min\": 0.8,\n          \"25%\": 0.8,\n          \"50%\": 0.8,\n          \"75%\": 0.8,\n          \"max\": 0.8\n        }\n      },\n      \"Conservative\": {\n        \"care_raw_score\": {\n          \"count\": 2,\n          \"mean\": 0.45,\n          \"std\": 0.3536,\n          \"min\": 0.2,\n          \"25%\": 0.325,\n          \"50%\": 0.45,\n          \"75%\": 0.575,\n          \"max\": 0.7\n        }\n      },\n      \"Hardline Conservative\": {\n        \"care_raw_score\": {\n          \"count\": 1,\n          \"mean\": 0.6,\n          \"std\": null,\n          \"min\": 0.6,\n          \"25%\": 0.6,\n          \"50%\": 0.6,\n          \"75%\": 0.6,\n          \"max\": 0.6\n        }\n      },\n      \"Liberal\": {\n        \"care_raw_score\": {\n          \"count\": 1,\n          \"mean\": 0.9,\n          \"std\": null,\n          \"min\": 0.9,\n          \"25%\": 0.9,\n          \"50%\": 0.9,\n          \"75%\": 0.9,\n          \"max\": 0.9\n        }\n      },\n      \"National Conservative\": {\n        \"care_raw_score\": {\n          \"count\": 1,\n          \"mean\": 0.4,\n          \"std\": null,\n          \"min\": 0.4,\n          \"25%\": 0.4,\n          \"50%\": 0.4,\n          \"75%\": 0.4,\n          \"max\": 0.4\n        }\n      },\n      \"Progressive\": {\n        \"care_raw_score\": {\n          \"count\": 2,\n          \"mean\": 0.85,\n          \"std\": 0.0707,\n          \"min\": 0.8,\n          \"25%\": 0.825,\n          \"50%\": 0.85,\n          \"75%\": 0.875,\n          \"max\": 0.9\n        }\n      }\n    }\n  },\n  \"exploratory_group_comparison\": {\n    \"comparison_summary\": \"Exploratory comparison between Left-Leaning (Progressive, Liberal, Civil Rights) and Right-Leaning (Conservative, National Conservative, Hardline) speakers.\",\n    \"power_caveat\": \"TIER 3 (N < 15): Results are exploratory and not statistically significant. Cohen's d indicates magnitude of difference, not significance.\",\n    \"comparative_metrics\": {\n      \"individualizing_foundations_mean\": {\n        \"left_leaning_mean\": 0.8812,\n        \"left_leaning_std\": 0.0536,\n        \"left_leaning_n\": 4,\n        \"right_leaning_mean\": 0.6812,\n        \"right_leaning_std\": 0.1557,\n        \"right_leaning_n\": 4,\n        \"cohens_d_effect_size\": 1.7614,\n        \"interpretation_note\": \"Positive Cohen's d indicates higher mean for Left-Leaning group.\"\n      },\n      \"binding_foundations_mean\": {\n        \"left_leaning_mean\": 0.6938,\n        \"left_leaning_std\": 0.1256,\n        \"left_leaning_n\": 4,\n        \"right_leaning_mean\": 0.7292,\n        \"right_leaning_std\": 0.1931,\n        \"right_leaning_n\": 4,\n        \"cohens_d_effect_size\": -0.2162,\n        \"interpretation_note\": \"Positive Cohen's d indicates higher mean for Left-Leaning group.\"\n      },\n      \"liberty_foundation_mean\": {\n        \"left_leaning_mean\": 0.825,\n        \"left_leaning_std\": 0.15,\n        \"left_leaning_n\": 4,\n        \"right_leaning_mean\": 0.6875,\n        \"right_leaning_std\": 0.075,\n        \"right_leaning_n\": 4,\n        \"cohens_d_effect_size\": 1.1314,\n        \"interpretation_note\": \"Positive Cohen's d indicates higher mean for Left-Leaning group.\"\n      },\n      \"moral_strategic_contradiction_index\": {\n        \"left_leaning_mean\": 0.0581,\n        \"left_leaning_std\": 0.0381,\n        \"left_leaning_n\": 4,\n        \"right_leaning_mean\": 0.064,\n        \"right_leaning_std\": 0.08,\n        \"right_leaning_n\": 4,\n        \"cohens_d_effect_size\": -0.096,\n        \"interpretation_note\": \"Positive Cohen's d indicates higher mean for Left-Leaning group.\"\n      },\n      \"subversion_raw_score\": {\n        \"left_leaning_mean\": 0.95,\n        \"left_leaning_std\": 0.0577,\n        \"left_leaning_n\": 4,\n        \"right_leaning_mean\": 0.825,\n        \"right_leaning_std\": 0.1258,\n        \"right_leaning_n\": 4,\n        \"cohens_d_effect_size\": 1.2842,\n        \"interpretation_note\": \"Positive Cohen's d indicates higher mean for Left-Leaning group.\"\n      },\n      \"authority_raw_score\": {\n        \"left_leaning_mean\": 0.2625,\n        \"left_leaning_std\": 0.2629,\n        \"left_leaning_n\": 4,\n        \"right_leaning_mean\": 0.85,\n        \"right_leaning_std\": 0.1915,\n        \"right_leaning_n\": 4,\n        \"cohens_d_effect_size\": -2.5298,\n        \"interpretation_note\": \"Positive Cohen's d indicates higher mean for Left-Leaning group.\"\n      }\n    }\n  },\n  \"correlation_analysis\": {\n    \"power_caveat\": \"TIER 3 (N=8): Correlations are highly unstable with small sample sizes and should be interpreted as exploratory hints, not confirmed relationships.\",\n    \"correlation_matrix\": {\n      \"care_raw_score\": {\n        \"care_raw_score\": 1.0,\n        \"harm_raw_score\": 0.4468,\n        \"fairness_raw_score\": 0.6976,\n        \"cheating_raw_score\": 0.3801,\n        \"loyalty_raw_score\": -0.4079,\n        \"betrayal_raw_score\": 0.2974,\n        \"authority_raw_score\": -0.7303,\n        \"subversion_raw_score\": 0.4397,\n        \"sanctity_raw_score\": -0.0157,\n        \"degradation_raw_score\": 0.301,\n        \"liberty_raw_score\": 0.4419,\n        \"oppression_raw_score\": 0.4727,\n        \"moral_strategic_contradiction_index\": -0.5694\n      },\n      \"harm_raw_score\": {\n        \"care_raw_score\": 0.4468,\n        \"harm_raw_score\": 1.0,\n        \"fairness_raw_score\": 0.4208,\n        \"cheating_raw_score\": 0.8143,\n        \"loyalty_raw_score\": -0.1923,\n        \"betrayal_raw_score\": 0.627,\n        \"authority_raw_score\": -0.222,\n        \"subversion_raw_score\": 0.9015,\n        \"sanctity_raw_score\": 0.0526,\n        \"degradation_raw_score\": 0.8359,\n        \"liberty_raw_score\": 0.3704,\n        \"oppression_raw_score\": 0.7416,\n        \"moral_strategic_contradiction_index\": -0.1192\n      },\n      \"fairness_raw_score\": {\n        \"care_raw_score\": 0.6976,\n        \"harm_raw_score\": 0.4208,\n        \"fairness_raw_score\": 1.0,\n        \"cheating_raw_score\": 0.374,\n        \"loyalty_raw_score\": -0.2443,\n        \"betrayal_raw_score\": 0.1652,\n        \"authority_raw_score\": -0.3235,\n        \"subversion_raw_score\": 0.3346,\n        \"sanctity_raw_score\": 0.2951,\n        \"degradation_raw_score\": 0.3643,\n        \"liberty_raw_score\": 0.1706,\n        \"oppression_raw_score\": 0.2486,\n        \"moral_strategic_contradiction_index\": -0.3687\n      },\n      \"cheating_raw_score\": {\n        \"care_raw_score\": 0.3801,\n        \"harm_raw_score\": 0.8143,\n        \"fairness_raw_score\": 0.374,\n        \"cheating_raw_score\": 1.0,\n        \"loyalty_raw_score\": -0.0529,\n        \"betrayal_raw_score\": 0.6657,\n        \"authority_raw_score\": -0.1415,\n        \"subversion_raw_score\": 0.8175,\n        \"sanctity_raw_score\": 0.1437,\n        \"degradation_raw_score\": 0.8732,\n        \"liberty_raw_score\": 0.0684,\n        \"oppression_raw_score\": 0.7186,\n        \"moral_strategic_contradiction_index\": 0.0094\n      },\n      \"loyalty_raw_score\": {\n        \"care_raw_score\": -0.4079,\n        \"harm_raw_score\": -0.1923,\n        \"fairness_raw_score\": -0.2443,\n        \"cheating_raw_score\": -0.0529,\n        \"loyalty_raw_score\": 1.0,\n        \"betrayal_raw_score\": 0.0456,\n        \"authority_raw_score\": 0.528,\n        \"subversion_raw_score\": -0.2281,\n        \"sanctity_raw_score\": 0.0768,\n        \"degradation_raw_score\": -0.1872,\n        \"liberty_raw_score\": -0.169,\n        \"oppression_raw_score\": -0.354,\n        \"moral_strategic_contradiction_index\": 0.3155\n      },\n      \"betrayal_raw_score\": {\n        \"care_raw_score\": 0.2974,\n        \"harm_raw_score\": 0.627,\n        \"fairness_raw_score\": 0.1652,\n        \"cheating_raw_score\": 0.6657,\n        \"loyalty_raw_score\": 0.0456,\n        \"betrayal_raw_score\": 1.0,\n        \"authority_raw_score\": -0.2037,\n        \"subversion_raw_score\": 0.6974,\n        \"sanctity_raw_score\": 0.0567,\n        \"degradation_raw_score\": 0.6483,\n        \"liberty_raw_score\": -0.2785,\n        \"oppression_raw_score\": 0.4068,\n        \"moral_strategic_contradiction_index\": 0.2312\n      },\n      \"authority_raw_score\": {\n        \"care_raw_score\": -0.7303,\n        \"harm_raw_score\": -0.222,\n        \"fairness_raw_score\": -0.3235,\n        \"cheating_raw_score\": -0.1415,\n        \"loyalty_raw_score\": 0.528,\n        \"betrayal_raw_score\": -0.2037,\n        \"authority_raw_score\": 1.0,\n        \"subversion_raw_score\": -0.1867,\n        \"sanctity_raw_score\": 0.5592,\n        \"degradation_raw_score\": -0.0617,\n        \"liberty_raw_score\": -0.2335,\n        \"oppression_raw_score\": -0.421,\n        \"moral_strategic_contradiction_index\": 0.8143\n      },\n      \"subversion_raw_score\": {\n        \"care_raw_score\": 0.4397,\n        \"harm_raw_score\": 0.9015,\n        \"fairness_raw_score\": 0.3346,\n        \"cheating_raw_score\": 0.8175,\n        \"loyalty_raw_score\": -0.2281,\n        \"betrayal_raw_score\": 0.6974,\n        \"authority_raw_score\": -0.1867,\n        \"subversion_raw_score\": 1.0,\n        \"sanctity_raw_score\": 0.1601,\n        \"degradation_raw_score\": 0.8715,\n        \"liberty_raw_score\": 0.3211,\n        \"oppression_raw_score\": 0.7725,\n        \"moral_strategic_contradiction_index\": -0.1118\n      },\n      \"sanctity_raw_score\": {\n        \"care_raw_score\": -0.0157,\n        \"harm_raw_score\": 0.0526,\n        \"fairness_raw_score\": 0.2951,\n        \"cheating_raw_score\": 0.1437,\n        \"loyalty_raw_score\": 0.0768,\n        \"betrayal_raw_score\": 0.0567,\n        \"authority_raw_score\": 0.5592,\n        \"subversion_raw_score\": 0.1601,\n        \"sanctity_raw_score\": 1.0,\n        \"degradation_raw_score\": 0.4439,\n        \"liberty_raw_score\": 0.1348,\n        \"oppression_raw_score\": 0.1861,\n        \"moral_strategic_contradiction_index\": 0.3644\n      },\n      \"degradation_raw_score\": {\n        \"care_raw_score\": 0.301,\n        \"harm_raw_score\": 0.8359,\n        \"fairness_raw_score\": 0.3643,\n        \"cheating_raw_score\": 0.8732,\n        \"loyalty_raw_score\": -0.1872,\n        \"betrayal_raw_score\": 0.6483,\n        \"authority_raw_score\": -0.0617,\n        \"subversion_raw_score\": 0.8715,\n        \"sanctity_raw_score\": 0.4439,\n        \"degradation_raw_score\": 1.0,\n        \"liberty_raw_score\": 0.069,\n        \"oppression_raw_score\": 0.6975,\n        \"moral_strategic_contradiction_index\": 0.0471\n      },\n      \"liberty_raw_score\": {\n        \"care_raw_score\": 0.4419,\n        \"harm_raw_score\": 0.3704,\n        \"fairness_raw_score\": 0.1706,\n        \"cheating_raw_score\": 0.0684,\n        \"loyalty_raw_score\": -0.169,\n        \"betrayal_raw_score\": -0.2785,\n        \"authority_raw_score\": -0.2335,\n        \"subversion_raw_score\": 0.3211,\n        \"sanctity_raw_score\": 0.1348,\n        \"degradation_raw_score\": 0.069,\n        \"liberty_raw_score\": 1.0,\n        \"oppression_raw_score\": 0.5694,\n        \"moral_strategic_contradiction_index\": -0.4285\n      },\n      \"oppression_raw_score\": {\n        \"care_raw_score\": 0.4727,\n        \"harm_raw_score\": 0.7416,\n        \"fairness_raw_score\": 0.2486,\n        \"cheating_raw_score\": 0.7186,\n        \"loyalty_raw_score\": -0.354,\n        \"betrayal_raw_score\": 0.4068,\n        \"authority_raw_score\": -0.421,\n        \"subversion_raw_score\": 0.7725,\n        \"sanctity_raw_score\": 0.1861,\n        \"degradation_raw_score\": 0.6975,\n        \"liberty_raw_score\": 0.5694,\n        \"oppression_raw_score\": 1.0,\n        \"moral_strategic_contradiction_index\": -0.2906\n      },\n      \"moral_strategic_contradiction_index\": {\n        \"care_raw_score\": -0.5694,\n        \"harm_raw_score\": -0.1192,\n        \"fairness_raw_score\": -0.3687,\n        \"cheating_raw_score\": 0.0094,\n        \"loyalty_raw_score\": 0.3155,\n        \"betrayal_raw_score\": 0.2312,\n        \"authority_raw_score\": 0.8143,\n        \"subversion_raw_score\": -0.1118,\n        \"sanctity_raw_score\": 0.3644,\n        \"degradation_raw_score\": 0.0471,\n        \"liberty_raw_score\": -0.4285,\n        \"oppression_raw_score\": -0.2906,\n        \"moral_strategic_contradiction_index\": 1.0\n      }\n    }\n  },\n  \"reliability_analysis\": {\n    \"analysis_name\": \"Inter-Rater Reliability (Cronbach's Alpha)\",\n    \"status\": \"Not Performed\",\n    \"reason\": \"Reliability analysis requires multiple independent evaluations (raters) for each document. The provided analysis artifacts contain only one evaluation per document.\",\n    \"requirement_for_execution\": \"A dataset with at least two unique `analysis_id`s for each `document_filename`, representing different evaluation runs.\"\n  }\n}\n```",
  "analysis_artifacts_processed": 18,
  "cost_info": {
    "model": "vertex_ai/gemini-2.5-pro",
    "execution_time_seconds": 127.166404,
    "response_cost": 0.0,
    "input_tokens": 0,
    "output_tokens": 0,
    "total_tokens": 0,
    "prompt_length": 141772,
    "response_length": 39962
  },
  "timestamp": "2025-09-17T03:32:18.186085+00:00"
}