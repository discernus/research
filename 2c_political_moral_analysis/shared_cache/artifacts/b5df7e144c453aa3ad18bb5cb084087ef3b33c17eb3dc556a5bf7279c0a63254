{"stage_1_raw_data": {"analysis_plan": {"stage": "raw_data_collection", "experiment_summary": "This plan outlines the collection and initial validation of raw dimensional scores (score, salience, confidence) for 12 moral foundations, as generated by the LLM for each document in the corpus across multiple evaluations. The focus is on ensuring data integrity, completeness, and adherence to the framework's 0.0-1.0 scale before any statistical analysis.", "tasks": {"validate_dimensional_score_ranges": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["care_score", "harm_score", "fairness_score", "cheating_score", "loyalty_score", "betrayal_score", "authority_score", "subversion_score", "sanctity_score", "degradation_score", "liberty_score", "oppression_score"]}, "purpose": "To verify that all collected dimensional scores fall within the valid 0.0 to 1.0 range as required by the framework's scoring protocol. This step checks for data generation errors by examining the min and max values for each dimension."}, "validate_metadata_ranges": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["care_salience", "harm_salience", "fairness_salience", "cheating_salience", "loyalty_salience", "betrayal_salience", "authority_salience", "subversion_salience", "sanctity_salience", "degradation_salience", "liberty_salience", "oppression_salience", "care_confidence", "harm_confidence", "fairness_confidence", "cheating_confidence", "loyalty_confidence", "betrayal_confidence", "authority_confidence", "subversion_confidence", "sanctity_confidence", "degradation_confidence", "liberty_confidence", "oppression_confidence"]}, "purpose": "To confirm that the collected salience and confidence metadata also adhere to the required 0.0 to 1.0 scale. This ensures the integrity of the inputs for subsequent salience-weighting and confidence-based filtering."}, "generate_raw_data_completeness_report": {"tool": "create_summary_statistics", "parameters": {"metrics": ["care_score", "fairness_score", "loyalty_score", "authority_score", "sanctity_score", "liberty_score"], "summary_types": ["count"]}, "purpose": "To generate a completeness report for the raw dataset. The 'count' statistic is used to verify that there are no null or missing values for any of the core dimensional scores across all evaluations, ensuring a full dataset for subsequent analysis."}, "check_data_presence_by_ideology": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["care_score", "loyalty_score", "liberty_score"], "grouping_variable": "ideology"}, "purpose": "To verify that raw data has been collected and successfully joined with the corpus metadata for all specified ideological groups. This ensures that the dataset is complete and structured correctly for the planned ideological comparison analyses in Stage 2."}}}, "results": {"validate_dimensional_score_ranges": {"type": "descriptive_stats", "columns_analyzed": ["care_score", "harm_score", "fairness_score", "cheating_score", "loyalty_score", "betrayal_score", "authority_score", "subversion_score", "sanctity_score", "degradation_score", "liberty_score", "oppression_score"], "results": {"care_score": {"count": 8, "mean": 0.65625, "std": 0.21286732957408, "min": 0.3, "max": 0.9, "median": 0.7, "q25": 0.55, "q75": 0.8125, "skewness": -0.7370626203563863, "kurtosis": -0.5913721759809745}, "harm_score": {"count": 8, "mean": 0.59375, "std": 0.20604697799981717, "min": 0.2, "max": 0.85, "median": 0.625, "q25": 0.55, "q75": 0.7124999999999999, "skewness": -1.0081618698857595, "kurtosis": 0.8999990048662028}, "fairness_score": {"count": 8, "mean": 0.70625, "std": 0.19353386562267894, "min": 0.5, "max": 0.95, "median": 0.7, "q25": 0.5, "q75": 0.9, "skewness": 0.07113167772221433, "kurtosis": -2.0217791485124055}, "cheating_score": {"count": 8, "mean": 0.5874999999999999, "std": 0.23413976290119665, "min": 0.1, "max": 0.8, "median": 0.6499999999999999, "q25": 0.55, "q75": 0.75, "skewness": -1.5261354406461922, "kurtosis": 2.094333096372371}, "loyalty_score": {"count": 8, "mean": 0.3125, "std": 0.1457737973711325, "min": 0.2, "max": 0.6, "median": 0.25, "q25": 0.2, "q75": 0.4, "skewness": 1.1932842730924142, "kurtosis": 0.8628769154720697}, "betrayal_score": {"count": 8, "mean": 0.2625, "std": 0.1575481785722341, "min": 0.1, "max": 0.6, "median": 0.25, "q25": 0.17500000000000002, "q75": 0.3, "skewness": 1.4475416727986645, "kurtosis": 3.107085554577921}, "authority_score": {"count": 8, "mean": 0.36250000000000004, "std": 0.1685018016012207, "min": 0.2, "max": 0.7, "median": 0.3, "q25": 0.275, "q75": 0.42500000000000004, "skewness": 1.2653131607126185, "kurtosis": 1.383552865788534}, "subversion_score": {"count": 8, "mean": 0.32499999999999996, "std": 0.20354009783964294, "min": 0.1, "max": 0.7, "median": 0.32499999999999996, "q25": 0.17500000000000002, "q75": 0.38749999999999996, "skewness": 0.7538970330207945, "kurtosis": 0.3106718192627822}, "sanctity_score": {"count": 8, "mean": 0.225, "std": 0.10350983390135314, "min": 0.1, "max": 0.4, "median": 0.2, "q25": 0.17500000000000002, "q75": 0.3, "skewness": 0.38643671323171835, "kurtosis": -0.4480000000000004}, "degradation_score": {"count": 8, "mean": 0.325, "std": 0.1832250762625809, "min": 0.1, "max": 0.55, "median": 0.30000000000000004, "q25": 0.1875, "q75": 0.47500000000000003, "skewness": 0.13934727393442115, "kurtosis": -2.0432775011317337}, "liberty_score": {"count": 8, "mean": 0.56875, "std": 0.21202678402234265, "min": 0.3, "max": 0.95, "median": 0.55, "q25": 0.4, "q75": 0.7, "skewness": 0.6119123484648445, "kurtosis": -0.05103816482241097}, "oppression_score": {"count": 8, "mean": 0.6187499999999999, "std": 0.24485783047077983, "min": 0.2, "max": 0.9, "median": 0.7, "q25": 0.4625, "q75": 0.8, "skewness": -0.7692095613247771, "kurtosis": -0.6397226954911979}}}, "validate_metadata_ranges": {"type": "descriptive_stats", "columns_analyzed": ["care_salience", "harm_salience", "fairness_salience", "cheating_salience", "loyalty_salience", "betrayal_salience", "authority_salience", "subversion_salience", "sanctity_salience", "degradation_salience", "liberty_salience", "oppression_salience", "care_confidence", "harm_confidence", "fairness_confidence", "cheating_confidence", "loyalty_confidence", "betrayal_confidence", "authority_confidence", "subversion_confidence", "sanctity_confidence", "degradation_confidence", "liberty_confidence", "oppression_confidence"], "results": {"care_salience": {"count": 8, "mean": 0.64625, "std": 0.238383694312941, "min": 0.2, "max": 0.95, "median": 0.6499999999999999, "q25": 0.575, "q75": 0.755, "skewness": -0.6094171663092065, "kurtosis": 0.8617262400645265}, "harm_salience": {"count": 8, "mean": 0.575, "std": 0.2618614682831909, "min": 0.1, "max": 0.85, "median": 0.6499999999999999, "q25": 0.45, "q75": 0.7625, "skewness": -0.942769478910185, "kurtosis": -0.07861328125000266}, "fairness_salience": {"count": 8, "mean": 0.74125, "std": 0.22433632277071341, "min": 0.4, "max": 0.98, "median": 0.7749999999999999, "q25": 0.575, "q75": 0.95, "skewness": -0.39782075160740693, "kurtosis": -1.5785890838002405}, "cheating_salience": {"count": 8, "mean": 0.5875, "std": 0.2628823745653992, "min": 0.05, "max": 0.85, "median": 0.7, "q25": 0.475, "q75": 0.725, "skewness": -1.3692371769256435, "kurtosis": 1.706820503575508}, "loyalty_salience": {"count": 8, "mean": 0.275, "std": 0.13887301496588272, "min": 0.1, "max": 0.5, "median": 0.3, "q25": 0.17500000000000002, "q75": 0.325, "skewness": 0.1600182888495763, "kurtosis": -0.5530864197530878}, "betrayal_salience": {"count": 8, "mean": 0.2375, "std": 0.16420805617960926, "min": 0.05, "max": 0.5, "median": 0.25, "q25": 0.08750000000000001, "q75": 0.35, "skewness": 0.2298811961428504, "kurtosis": -1.167597912372265}, "authority_salience": {"count": 8, "mean": 0.33125, "std": 0.21536928418748244, "min": 0.1, "max": 0.7, "median": 0.30000000000000004, "q25": 0.17500000000000002, "q75": 0.4625, "skewness": 0.5280005972641789, "kurtosis": -0.7829887514925611}, "subversion_salience": {"count": 8, "mean": 0.31875, "std": 0.24775780224127872, "min": 0.05, "max": 0.65, "median": 0.325, "q25": 0.08750000000000001, "q75": 0.4875, "skewness": 0.15220142642518292, "kurtosis": -2.005316125619835}, "sanctity_salience": {"count": 8, "mean": 0.2125, "std": 0.15294723646688468, "min": 0.05, "max": 0.5, "median": 0.175, "q25": 0.1, "q75": 0.3, "skewness": 0.883405983252585, "kurtosis": 0.1931822154886076}, "degradation_salience": {"count": 8, "mean": 0.325, "std": 0.249284690951645, "min": 0.05, "max": 0.65, "median": 0.35, "q25": 0.08750000000000001, "q75": 0.5125, "skewness": 0.018443576024959833, "kurtosis": -2.250653983353152}, "liberty_salience": {"count": 8, "mean": 0.56, "std": 0.23348294523216404, "min": 0.3, "max": 0.98, "median": 0.5, "q25": 0.4, "q75": 0.65, "skewness": 0.8706008057652772, "kurtosis": -0.17263953166409785}, "oppression_salience": {"count": 8, "mean": 0.61875, "std": 0.2737797602870912, "min": 0.1, "max": 0.95, "median": 0.6499999999999999, "q25": 0.4875, "q75": 0.7875, "skewness": -0.7860967921027707, "kurtosis": 0.7181364158946266}, "care_confidence": {"count": 8, "mean": 0.8, "std": 0.10690449676496977, "min": 0.6, "max": 0.9, "median": 0.8, "q25": 0.775, "q75": 0.9, "skewness": -0.935414346693487, "kurtosis": 0.3500000000000014}, "harm_confidence": {"count": 8, "mean": 0.79125, "std": 0.06895909760761915, "min": 0.7, "max": 0.88, "median": 0.8, "q25": 0.7375, "q75": 0.85, "skewness": -0.2810419323870892, "kurtosis": -1.4516742345734763}, "fairness_confidence": {"count": 8, "mean": 0.8525, "std": 0.08647873396720968, "min": 0.75, "max": 0.95, "median": 0.8500000000000001, "q25": 0.7875000000000001, "q75": 0.9275, "skewness": -0.05146712537500577, "kurtosis": -2.187108480225943}, "cheating_confidence": {"count": 8, "mean": 0.775, "std": 0.08864052604279184, "min": 0.65, "max": 0.9, "median": 0.775, "q25": 0.7, "q75": 0.85, "skewness": 0.0, "kurtosis": -1.480991735537191}, "loyalty_confidence": {"count": 8, "mean": 0.6125, "std": 0.09910312089651149, "min": 0.5, "max": 0.8, "median": 0.6, "q25": 0.575, "q75": 0.625, "skewness": 0.8622790552053482, "kurtosis": 0.8404628099173559}, "betrayal_confidence": {"count": 8, "mean": 0.59375, "std": 0.09425459443140463, "min": 0.5, "max": 0.75, "median": 0.6000000000000001, "q25": 0.5, "q75": 0.65, "skewness": 0.40785503653355976, "kurtosis": -1.15758692962299}, "authority_confidence": {"count": 8, "mean": 0.64375, "std": 0.126596941962615, "min": 0.4, "max": 0.8, "median": 0.675, "q25": 0.5875, "q75": 0.7124999999999999, "skewness": -0.9406291976583071, "kurtosis": 0.912382740667752}, "subversion_confidence": {"count": 8, "mean": 0.6187499999999999, "std": 0.15797264681854625, "min": 0.3, "max": 0.8, "median": 0.6, "q25": 0.5875, "q75": 0.75, "skewness": -1.0752297357773075, "kurtosis": 1.7165178042824962}, "sanctity_confidence": {"count": 8, "mean": 0.55625, "std": 0.12082307017169479, "min": 0.4, "max": 0.7, "median": 0.575, "q25": 0.475, "q75": 0.65, "skewness": -0.27461997189283316, "kurtosis": -1.8900765928793883}, "degradation_confidence": {"count": 8, "mean": 0.59375, "std": 0.15221577729375774, "min": 0.3, "max": 0.75, "median": 0.6499999999999999, "q25": 0.5, "q75": 0.7, "skewness": -1.0575950917943342, "kurtosis": 0.5789167696882638}, "liberty_confidence": {"count": 8, "mean": 0.7625, "std": 0.09543135154205276, "min": 0.7, "max": 0.95, "median": 0.7, "q25": 0.7, "q75": 0.8125, "skewness": 1.3355252580279589, "kurtosis": 0.7750865051903109}, "oppression_confidence": {"count": 8, "mean": 0.8037500000000001, "std": 0.07909081579334697, "min": 0.65, "max": 0.9, "median": 0.8, "q25": 0.7875000000000001, "q75": 0.8574999999999999, "skewness": -0.9070757941367833, "kurtosis": 1.1577264754675065}}}, "generate_raw_data_completeness_report": {"type": "summary_statistics", "metrics": ["care_score", "fairness_score", "loyalty_score", "authority_score", "sanctity_score", "liberty_score"], "summary_types": ["count"], "results": {"care_score": {"count": 8}, "fairness_score": {"count": 8}, "loyalty_score": {"count": 8}, "authority_score": {"count": 8}, "sanctity_score": {"count": 8}, "liberty_score": {"count": 8}}, "missing_metrics": []}, "check_data_presence_by_ideology": {"type": "descriptive_stats_grouped", "grouping_variable": "ideology", "groups": {"Civil Rights Activist": {"care_score": {"count": 1, "mean": 0.9, "std": NaN, "min": 0.9, "max": 0.9}, "loyalty_score": {"count": 1, "mean": 0.4, "std": NaN, "min": 0.4, "max": 0.4}, "liberty_score": {"count": 1, "mean": 0.95, "std": NaN, "min": 0.95, "max": 0.95}}, "Conservative": {"care_score": {"count": 2, "mean": 0.6499999999999999, "std": 0.07071067811865474, "min": 0.6, "max": 0.7}, "loyalty_score": {"count": 2, "mean": 0.4, "std": 0.282842712474619, "min": 0.2, "max": 0.6}, "liberty_score": {"count": 2, "mean": 0.35, "std": 0.07071067811865477, "min": 0.3, "max": 0.4}}, "Hardline Conservative": {"care_score": {"count": 1, "mean": 0.4, "std": NaN, "min": 0.4, "max": 0.4}, "loyalty_score": {"count": 1, "mean": 0.2, "std": NaN, "min": 0.2, "max": 0.2}, "liberty_score": {"count": 1, "mean": 0.6, "std": NaN, "min": 0.6, "max": 0.6}}, "Liberal": {"care_score": {"count": 1, "mean": 0.85, "std": NaN, "min": 0.85, "max": 0.85}, "loyalty_score": {"count": 1, "mean": 0.3, "std": NaN, "min": 0.3, "max": 0.3}, "liberty_score": {"count": 1, "mean": 0.7, "std": NaN, "min": 0.7, "max": 0.7}}, "National Conservative": {"care_score": {"count": 1, "mean": 0.3, "std": NaN, "min": 0.3, "max": 0.3}, "loyalty_score": {"count": 1, "mean": 0.2, "std": NaN, "min": 0.2, "max": 0.2}, "liberty_score": {"count": 1, "mean": 0.4, "std": NaN, "min": 0.4, "max": 0.4}}, "Progressive": {"care_score": {"count": 2, "mean": 0.75, "std": 0.07071067811865482, "min": 0.7, "max": 0.8}, "loyalty_score": {"count": 2, "mean": 0.30000000000000004, "std": 0.14142135623730953, "min": 0.2, "max": 0.4}, "liberty_score": {"count": 2, "mean": 0.6, "std": 0.14142135623730948, "min": 0.5, "max": 0.7}}}}}, "errors": []}, "stage_2_derived_metrics": {"analysis_plan": {"stage": "derived_metrics_analysis", "experiment_summary": "This plan outlines the calculation of derived moral tension metrics from raw MFTv6 scores and the subsequent statistical analysis. The analysis will test hypotheses regarding framework validity, consistency, and the differentiation of moral patterns across political ideologies using correlation and ANOVA tests.", "tasks": {"task_01_calculate_derived_metrics": {"tool": "calculate_derived_metrics", "parameters": {"metric_formulas": {"care_harm_tension": "min(care_score, harm_score) * abs(care_salience - harm_salience)", "fairness_cheating_tension": "min(fairness_score, cheating_score) * abs(fairness_salience - cheating_salience)", "loyalty_betrayal_tension": "min(loyalty_score, betrayal_score) * abs(loyalty_salience - betrayal_salience)", "authority_subversion_tension": "min(authority_score, subversion_score) * abs(authority_salience - subversion_salience)", "sanctity_degradation_tension": "min(sanctity_score, degradation_score) * abs(sanctity_salience - degradation_salience)", "liberty_oppression_tension": "min(liberty_score, oppression_score) * abs(liberty_salience - oppression_salience)", "moral_strategic_contradiction_index": "(care_harm_tension + fairness_cheating_tension + loyalty_betrayal_tension + authority_subversion_tension + sanctity_degradation_tension + liberty_oppression_tension) / 6"}, "input_columns": ["care_score", "care_salience", "harm_score", "harm_salience", "fairness_score", "fairness_salience", "cheating_score", "cheating_salience", "loyalty_score", "loyalty_salience", "betrayal_score", "betrayal_salience", "authority_score", "authority_salience", "subversion_score", "subversion_salience", "sanctity_score", "sanctity_salience", "degradation_score", "degradation_salience", "liberty_score", "liberty_salience", "oppression_score", "oppression_salience"]}, "purpose": "To compute the six foundation pair tension scores and the overall Moral Strategic Contradiction Index (MSCI) as specified in the MFTv6 framework. These metrics are essential for testing H4."}, "task_02_validate_calculated_metrics": {"tool": "validate_calculated_metrics", "parameters": {"validation_rules": ["missing_data_check", "range_check"], "quality_thresholds": {"range_check": {"min": 0.0, "max": 1.0}}}, "purpose": "To ensure the newly calculated tension scores and MSCI are free of missing values and fall within the expected 0.0 to 1.0 range, guaranteeing data quality for subsequent statistical analysis."}, "task_03_test_framework_validity": {"tool": "generate_correlation_matrix", "parameters": {"dimensions": ["care_score", "harm_score", "fairness_score", "cheating_score", "loyalty_score", "betrayal_score", "authority_score", "subversion_score", "sanctity_score", "degradation_score", "liberty_score", "oppression_score"], "correlation_method": "pearson"}, "purpose": "To test hypothesis H2 (Validity) by examining the correlational patterns between the 12 moral foundation scores to see if they align with established moral psychology theory."}, "task_04_test_framework_consistency": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["care_score", "harm_score", "fairness_score", "cheating_score", "loyalty_score", "betrayal_score", "authority_score", "subversion_score", "sanctity_score", "degradation_score", "liberty_score", "oppression_score"]}, "purpose": "To test hypothesis H3 (Consistency) by calculating the variance for each raw moral foundation score across all evaluations, checking if it remains below the 0.15 threshold."}, "task_05_test_tension_by_ideology": {"tool": "perform_one_way_anova", "parameters": {"grouping_variable": "ideology", "dependent_variable": "moral_strategic_contradiction_index"}, "purpose": "To test hypothesis H4 (Tension Analysis) by determining if the Moral Strategic Contradiction Index (MSCI) shows statistically significant variation across different political ideologies."}, "task_06_test_ideological_differentiation_individualizing": {"tool": "perform_one_way_anova", "parameters": {"grouping_variable": "ideology", "dependent_variable": "fairness_score"}, "purpose": "To test hypothesis H5 (Ideological Differentiation) by analyzing whether the emphasis on the 'Fairness' foundation differs significantly across ideological groups."}, "task_07_test_ideological_differentiation_binding": {"tool": "perform_one_way_anova", "parameters": {"grouping_variable": "ideology", "dependent_variable": "authority_score"}, "purpose": "To test hypothesis H5 (Ideological Differentiation) by analyzing whether the emphasis on the 'Authority' foundation differs significantly across ideological groups."}, "task_08_test_ideological_differentiation_liberty": {"tool": "perform_one_way_anova", "parameters": {"grouping_variable": "ideology", "dependent_variable": "liberty_score"}, "purpose": "To test hypothesis H5 (Ideological Differentiation) by analyzing whether the emphasis on the 'Liberty' foundation differs significantly across ideological groups."}, "task_09_generate_summary_statistics_by_ideology": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["care_score", "harm_score", "fairness_score", "cheating_score", "loyalty_score", "betrayal_score", "authority_score", "subversion_score", "sanctity_score", "degradation_score", "liberty_score", "oppression_score", "moral_strategic_contradiction_index"], "grouping_variable": "ideology"}, "purpose": "To generate comprehensive descriptive statistics (mean, std, etc.) for all key raw and derived metrics, segmented by ideology, to support the final report's analysis of moral foundation patterns."}}}, "results": {"task_01_calculate_derived_metrics": {"type": "derived_metrics_calculation", "success": true, "calculated_metrics": {"care_harm_tension": [0.06999999999999998, 0.059999999999999984, 0.05250000000000005, 0.029999999999999992, 0.12749999999999992, 0.1, 0.030000000000000027, 0.07999999999999999], "loyalty_betrayal_tension": [0.029999999999999992, 0.005000000000000001, 0.012500000000000011, 0.0, 0.08000000000000002, 0.045000000000000005, 0.009999999999999998, 0.019999999999999997], "fairness_cheating_tension": [0.11999999999999997, 0.07999999999999999, 0.15, 0.039999999999999994, 0.21000000000000002, 0.035, 0.03499999999999995, 0.04999999999999999], "liberty_oppression_tension": [0.09999999999999998, 0.10500000000000001, 0.06999999999999998, 0.039999999999999994, 0.027000000000000024, 0.04, 0.014999999999999996, 0.059999999999999984], "authority_subversion_tension": [0.005000000000000001, 0.0, 0.017499999999999995, 0.0, 0.1, 0.015000000000000003, 0.014999999999999996, 0.04999999999999999], "sanctity_degradation_tension": [0.0075, 0.005000000000000001, 0.07, 0.010000000000000002, 0.075, 0.005000000000000001, 0.020000000000000018, 0.06], "moral_strategic_contradiction_index": [0.05541666666666665, 0.0425, 0.062083333333333345, 0.019999999999999997, 0.10325, 0.04000000000000001, 0.020833333333333332, 0.05333333333333332]}, "successful_calculations": ["care_harm_tension", "loyalty_betrayal_tension", "fairness_cheating_tension", "liberty_oppression_tension", "authority_subversion_tension", "sanctity_degradation_tension", "moral_strategic_contradiction_index"], "failed_calculations": [], "formulas_used": ["care_harm_tension", "fairness_cheating_tension", "loyalty_betrayal_tension", "authority_subversion_tension", "sanctity_degradation_tension", "liberty_oppression_tension", "moral_strategic_contradiction_index"], "input_columns": ["care_score", "care_salience", "harm_score", "harm_salience", "fairness_score", "fairness_salience", "cheating_score", "cheating_salience", "loyalty_score", "loyalty_salience", "betrayal_score", "betrayal_salience", "authority_score", "authority_salience", "subversion_score", "subversion_salience", "sanctity_score", "sanctity_salience", "degradation_score", "degradation_salience", "liberty_score", "liberty_salience", "oppression_score", "oppression_salience"], "total_metrics": 7, "success_rate": 1.0}, "task_02_validate_calculated_metrics": {"type": "metric_validation", "validation_rules": ["missing_data_check", "range_check"], "results": {"missing_data_check": {"status": "completed", "missing_data_by_column": {"aid": 0, "speaker": 0, "ideology": 0, "date": 0, "context": 0, "category": 0, "care_score": 0, "care_raw_score": 0, "care_salience": 0, "care_confidence": 0, "harm_score": 0, "harm_raw_score": 0, "harm_salience": 0, "harm_confidence": 0, "fairness_score": 0, "fairness_raw_score": 0, "fairness_salience": 0, "fairness_confidence": 0, "cheating_score": 0, "cheating_raw_score": 0, "cheating_salience": 0, "cheating_confidence": 0, "loyalty_score": 0, "loyalty_raw_score": 0, "loyalty_salience": 0, "loyalty_confidence": 0, "betrayal_score": 0, "betrayal_raw_score": 0, "betrayal_salience": 0, "betrayal_confidence": 0, "authority_score": 0, "authority_raw_score": 0, "authority_salience": 0, "authority_confidence": 0, "subversion_score": 0, "subversion_raw_score": 0, "subversion_salience": 0, "subversion_confidence": 0, "sanctity_score": 0, "sanctity_raw_score": 0, "sanctity_salience": 0, "sanctity_confidence": 0, "degradation_score": 0, "degradation_raw_score": 0, "degradation_salience": 0, "degradation_confidence": 0, "liberty_score": 0, "liberty_raw_score": 0, "liberty_salience": 0, "liberty_confidence": 0, "oppression_score": 0, "oppression_raw_score": 0, "oppression_salience": 0, "oppression_confidence": 0, "care_harm_tension": 0, "loyalty_betrayal_tension": 0, "fairness_cheating_tension": 0, "liberty_oppression_tension": 0, "authority_subversion_tension": 0, "sanctity_degradation_tension": 0, "moral_strategic_contradiction_index": 0}, "total_missing": 0}, "range_check": {"status": "completed", "ranges": {"care_score": {"min": 0.3, "max": 0.9, "mean": 0.65625}, "care_raw_score": {"min": 0.3, "max": 0.9, "mean": 0.65625}, "care_salience": {"min": 0.2, "max": 0.95, "mean": 0.64625}, "care_confidence": {"min": 0.6, "max": 0.9, "mean": 0.8}, "harm_score": {"min": 0.2, "max": 0.85, "mean": 0.59375}, "harm_raw_score": {"min": 0.2, "max": 0.85, "mean": 0.59375}, "harm_salience": {"min": 0.1, "max": 0.85, "mean": 0.575}, "harm_confidence": {"min": 0.7, "max": 0.88, "mean": 0.79125}, "fairness_score": {"min": 0.5, "max": 0.95, "mean": 0.70625}, "fairness_raw_score": {"min": 0.5, "max": 0.95, "mean": 0.70625}, "fairness_salience": {"min": 0.4, "max": 0.98, "mean": 0.74125}, "fairness_confidence": {"min": 0.75, "max": 0.95, "mean": 0.8525}, "cheating_score": {"min": 0.1, "max": 0.8, "mean": 0.5874999999999999}, "cheating_raw_score": {"min": 0.1, "max": 0.8, "mean": 0.5874999999999999}, "cheating_salience": {"min": 0.05, "max": 0.85, "mean": 0.5875}, "cheating_confidence": {"min": 0.65, "max": 0.9, "mean": 0.775}, "loyalty_score": {"min": 0.2, "max": 0.6, "mean": 0.3125}, "loyalty_raw_score": {"min": 0.2, "max": 0.6, "mean": 0.3125}, "loyalty_salience": {"min": 0.1, "max": 0.5, "mean": 0.275}, "loyalty_confidence": {"min": 0.5, "max": 0.8, "mean": 0.6125}, "betrayal_score": {"min": 0.1, "max": 0.6, "mean": 0.2625}, "betrayal_raw_score": {"min": 0.1, "max": 0.6, "mean": 0.2625}, "betrayal_salience": {"min": 0.05, "max": 0.5, "mean": 0.2375}, "betrayal_confidence": {"min": 0.5, "max": 0.75, "mean": 0.59375}, "authority_score": {"min": 0.2, "max": 0.7, "mean": 0.36250000000000004}, "authority_raw_score": {"min": 0.2, "max": 0.7, "mean": 0.36250000000000004}, "authority_salience": {"min": 0.1, "max": 0.7, "mean": 0.33125}, "authority_confidence": {"min": 0.4, "max": 0.8, "mean": 0.64375}, "subversion_score": {"min": 0.1, "max": 0.7, "mean": 0.32499999999999996}, "subversion_raw_score": {"min": 0.1, "max": 0.7, "mean": 0.32499999999999996}, "subversion_salience": {"min": 0.05, "max": 0.65, "mean": 0.31875}, "subversion_confidence": {"min": 0.3, "max": 0.8, "mean": 0.6187499999999999}, "sanctity_score": {"min": 0.1, "max": 0.4, "mean": 0.225}, "sanctity_raw_score": {"min": 0.1, "max": 0.4, "mean": 0.225}, "sanctity_salience": {"min": 0.05, "max": 0.5, "mean": 0.2125}, "sanctity_confidence": {"min": 0.4, "max": 0.7, "mean": 0.55625}, "degradation_score": {"min": 0.1, "max": 0.55, "mean": 0.325}, "degradation_raw_score": {"min": 0.1, "max": 0.55, "mean": 0.325}, "degradation_salience": {"min": 0.05, "max": 0.65, "mean": 0.325}, "degradation_confidence": {"min": 0.3, "max": 0.75, "mean": 0.59375}, "liberty_score": {"min": 0.3, "max": 0.95, "mean": 0.56875}, "liberty_raw_score": {"min": 0.3, "max": 0.95, "mean": 0.56875}, "liberty_salience": {"min": 0.3, "max": 0.98, "mean": 0.56}, "liberty_confidence": {"min": 0.7, "max": 0.95, "mean": 0.7625}, "oppression_score": {"min": 0.2, "max": 0.9, "mean": 0.6187499999999999}, "oppression_raw_score": {"min": 0.2, "max": 0.9, "mean": 0.6187499999999999}, "oppression_salience": {"min": 0.1, "max": 0.95, "mean": 0.61875}, "oppression_confidence": {"min": 0.65, "max": 0.9, "mean": 0.8037500000000001}, "care_harm_tension": {"min": 0.029999999999999992, "max": 0.12749999999999992, "mean": 0.06874999999999999}, "loyalty_betrayal_tension": {"min": 0.0, "max": 0.08000000000000002, "mean": 0.0253125}, "fairness_cheating_tension": {"min": 0.03499999999999995, "max": 0.21000000000000002, "mean": 0.09}, "liberty_oppression_tension": {"min": 0.014999999999999996, "max": 0.10500000000000001, "mean": 0.057124999999999995}, "authority_subversion_tension": {"min": 0.0, "max": 0.1, "mean": 0.025312499999999998}, "sanctity_degradation_tension": {"min": 0.005000000000000001, "max": 0.075, "mean": 0.03156250000000001}, "moral_strategic_contradiction_index": {"min": 0.019999999999999997, "max": 0.10325, "mean": 0.04967708333333333}}}}, "quality_thresholds": {"range_check": {"min": 0.0, "max": 1.0}}}, "task_03_test_framework_validity": {"type": "correlation_matrix", "dimensions": ["care_score", "harm_score", "fairness_score", "cheating_score", "loyalty_score", "betrayal_score", "authority_score", "subversion_score", "sanctity_score", "degradation_score", "liberty_score", "oppression_score"], "method": "pearson", "matrix": {"care_score": {"care_score": 1.0, "harm_score": 0.5058632258316952, "fairness_score": 0.7704697623621867, "cheating_score": 0.17376788909305843, "loyalty_score": 0.526556026769533, "betrayal_score": 0.35941264059624245, "authority_score": -0.21158620172618364, "subversion_score": 0.037093301668998456, "sanctity_score": 0.12156613477096632, "degradation_score": 0.2792851761580499, "liberty_score": 0.5509439758786443, "oppression_score": 0.3879959341081296}, "harm_score": {"care_score": 0.5058632258316952, "harm_score": 1.0, "fairness_score": 0.7623876860322034, "cheating_score": 0.8420772811481256, "loyalty_score": -0.3299584384592446, "betrayal_score": 0.7178651144141179, "authority_score": 0.23916307459851271, "subversion_score": 0.5833326858423885, "sanctity_score": 0.37677026947749653, "degradation_score": 0.7331494459958307, "liberty_score": 0.640711541249672, "oppression_score": 0.802562793715029}, "fairness_score": {"care_score": 0.7704697623621867, "harm_score": 0.7623876860322034, "fairness_score": 1.0, "cheating_score": 0.6246102316459323, "loyalty_score": -0.07911986682109616, "betrayal_score": 0.40702999980219506, "authority_score": -0.14510966083298513, "subversion_score": 0.32185730576186444, "sanctity_score": 0.02674204681653991, "degradation_score": 0.5287609688688956, "liberty_score": 0.727830753357958, "oppression_score": 0.7056069193673589}, "cheating_score": {"care_score": 0.17376788909305843, "harm_score": 0.8420772811481256, "fairness_score": 0.6246102316459323, "cheating_score": 1.0, "loyalty_score": -0.6644480826086029, "betrayal_score": 0.4405191620627272, "authority_score": 0.20367830112028026, "subversion_score": 0.509595668843148, "sanctity_score": 0.33893234682166473, "degradation_score": 0.5744218800001306, "liberty_score": 0.47301163713278765, "oppression_score": 0.6961459951894922}, "loyalty_score": {"care_score": 0.526556026769533, "harm_score": -0.3299584384592446, "fairness_score": -0.07911986682109616, "cheating_score": -0.6644480826086029, "loyalty_score": 1.0, "betrayal_score": 0.0544273461923518, "authority_score": -0.15266773130566916, "subversion_score": -0.27684734220107976, "sanctity_score": -0.023669053416557638, "degradation_score": -0.30754270249285137, "liberty_score": 0.0375539078560419, "oppression_score": -0.30767600255408906}, "betrayal_score": {"care_score": 0.35941264059624245, "harm_score": 0.7178651144141179, "fairness_score": 0.40702999980219506, "cheating_score": 0.4405191620627272, "loyalty_score": 0.0544273461923518, "betrayal_score": 1.0, "authority_score": 0.5044931817534571, "subversion_score": 0.813020438055896, "sanctity_score": 0.503703311860163, "degradation_score": 0.6557216763867996, "liberty_score": 0.6227787502168721, "oppression_score": 0.548533226709251}, "authority_score": {"care_score": -0.21158620172618364, "harm_score": 0.23916307459851271, "fairness_score": -0.14510966083298513, "cheating_score": 0.20367830112028026, "loyalty_score": -0.15266773130566916, "betrayal_score": 0.5044931817534571, "authority_score": 1.0, "subversion_score": 0.7601692559990907, "sanctity_score": 0.47095958957269585, "degradation_score": 0.5899601603216614, "liberty_score": 0.38236500119047495, "oppression_score": 0.2791599692430247}, "subversion_score": {"care_score": 0.037093301668998456, "harm_score": 0.5833326858423885, "fairness_score": 0.32185730576186444, "cheating_score": 0.509595668843148, "loyalty_score": -0.27684734220107976, "betrayal_score": 0.813020438055896, "authority_score": 0.7601692559990907, "subversion_score": 1.0, "sanctity_score": 0.5085476277156076, "degradation_score": 0.8235795036461987, "liberty_score": 0.616534716518267, "oppression_score": 0.49803836319113587}, "sanctity_score": {"care_score": 0.12156613477096632, "harm_score": 0.37677026947749653, "fairness_score": 0.02674204681653991, "cheating_score": 0.33893234682166473, "loyalty_score": -0.023669053416557638, "betrayal_score": 0.503703311860163, "authority_score": 0.47095958957269585, "subversion_score": 0.5085476277156076, "sanctity_score": 1.0, "degradation_score": 0.6025948617237673, "liberty_score": -0.05695576313235345, "oppression_score": -0.13386590090151707}, "degradation_score": {"care_score": 0.2792851761580499, "harm_score": 0.7331494459958307, "fairness_score": 0.5287609688688956, "cheating_score": 0.5744218800001306, "loyalty_score": -0.30754270249285137, "betrayal_score": 0.6557216763867996, "authority_score": 0.5899601603216614, "subversion_score": 0.8235795036461987, "sanctity_score": 0.6025948617237673, "degradation_score": 1.0, "liberty_score": 0.5102221571265331, "oppression_score": 0.4736527095962158}, "liberty_score": {"care_score": 0.5509439758786443, "harm_score": 0.640711541249672, "fairness_score": 0.727830753357958, "cheating_score": 0.47301163713278765, "loyalty_score": 0.0375539078560419, "betrayal_score": 0.6227787502168721, "authority_score": 0.38236500119047495, "subversion_score": 0.616534716518267, "sanctity_score": -0.05695576313235345, "degradation_score": 0.5102221571265331, "liberty_score": 1.0, "oppression_score": 0.8659179231257828}, "oppression_score": {"care_score": 0.3879959341081296, "harm_score": 0.802562793715029, "fairness_score": 0.7056069193673589, "cheating_score": 0.6961459951894922, "loyalty_score": -0.30767600255408906, "betrayal_score": 0.548533226709251, "authority_score": 0.2791599692430247, "subversion_score": 0.49803836319113587, "sanctity_score": -0.13386590090151707, "degradation_score": 0.4736527095962158, "liberty_score": 0.8659179231257828, "oppression_score": 1.0}}, "missing_dimensions": []}, "task_04_test_framework_consistency": {"type": "descriptive_stats", "columns_analyzed": ["care_score", "harm_score", "fairness_score", "cheating_score", "loyalty_score", "betrayal_score", "authority_score", "subversion_score", "sanctity_score", "degradation_score", "liberty_score", "oppression_score"], "results": {"care_score": {"count": 8, "mean": 0.65625, "std": 0.21286732957408, "min": 0.3, "max": 0.9, "median": 0.7, "q25": 0.55, "q75": 0.8125, "skewness": -0.7370626203563863, "kurtosis": -0.5913721759809745}, "harm_score": {"count": 8, "mean": 0.59375, "std": 0.20604697799981717, "min": 0.2, "max": 0.85, "median": 0.625, "q25": 0.55, "q75": 0.7124999999999999, "skewness": -1.0081618698857595, "kurtosis": 0.8999990048662028}, "fairness_score": {"count": 8, "mean": 0.70625, "std": 0.19353386562267894, "min": 0.5, "max": 0.95, "median": 0.7, "q25": 0.5, "q75": 0.9, "skewness": 0.07113167772221433, "kurtosis": -2.0217791485124055}, "cheating_score": {"count": 8, "mean": 0.5874999999999999, "std": 0.23413976290119665, "min": 0.1, "max": 0.8, "median": 0.6499999999999999, "q25": 0.55, "q75": 0.75, "skewness": -1.5261354406461922, "kurtosis": 2.094333096372371}, "loyalty_score": {"count": 8, "mean": 0.3125, "std": 0.1457737973711325, "min": 0.2, "max": 0.6, "median": 0.25, "q25": 0.2, "q75": 0.4, "skewness": 1.1932842730924142, "kurtosis": 0.8628769154720697}, "betrayal_score": {"count": 8, "mean": 0.2625, "std": 0.1575481785722341, "min": 0.1, "max": 0.6, "median": 0.25, "q25": 0.17500000000000002, "q75": 0.3, "skewness": 1.4475416727986645, "kurtosis": 3.107085554577921}, "authority_score": {"count": 8, "mean": 0.36250000000000004, "std": 0.1685018016012207, "min": 0.2, "max": 0.7, "median": 0.3, "q25": 0.275, "q75": 0.42500000000000004, "skewness": 1.2653131607126185, "kurtosis": 1.383552865788534}, "subversion_score": {"count": 8, "mean": 0.32499999999999996, "std": 0.20354009783964294, "min": 0.1, "max": 0.7, "median": 0.32499999999999996, "q25": 0.17500000000000002, "q75": 0.38749999999999996, "skewness": 0.7538970330207945, "kurtosis": 0.3106718192627822}, "sanctity_score": {"count": 8, "mean": 0.225, "std": 0.10350983390135314, "min": 0.1, "max": 0.4, "median": 0.2, "q25": 0.17500000000000002, "q75": 0.3, "skewness": 0.38643671323171835, "kurtosis": -0.4480000000000004}, "degradation_score": {"count": 8, "mean": 0.325, "std": 0.1832250762625809, "min": 0.1, "max": 0.55, "median": 0.30000000000000004, "q25": 0.1875, "q75": 0.47500000000000003, "skewness": 0.13934727393442115, "kurtosis": -2.0432775011317337}, "liberty_score": {"count": 8, "mean": 0.56875, "std": 0.21202678402234265, "min": 0.3, "max": 0.95, "median": 0.55, "q25": 0.4, "q75": 0.7, "skewness": 0.6119123484648445, "kurtosis": -0.05103816482241097}, "oppression_score": {"count": 8, "mean": 0.6187499999999999, "std": 0.24485783047077983, "min": 0.2, "max": 0.9, "median": 0.7, "q25": 0.4625, "q75": 0.8, "skewness": -0.7692095613247771, "kurtosis": -0.6397226954911979}}}, "task_05_test_tension_by_ideology": {"type": "one_way_anova", "grouping_variable": "ideology", "dependent_variable": "moral_strategic_contradiction_index", "groups": {"Civil Rights Activist": {"n": 1, "mean": 0.10325, "std": 0.0}, "Conservative": {"n": 2, "mean": 0.030416666666666668, "std": 0.009583333333333338}, "Hardline Conservative": {"n": 1, "mean": 0.05333333333333332, "std": 0.0}, "Liberal": {"n": 1, "mean": 0.062083333333333345, "std": 0.0}, "National Conservative": {"n": 1, "mean": 0.019999999999999997, "std": 0.0}, "Progressive": {"n": 2, "mean": 0.048958333333333326, "std": 0.006458333333333323}}, "f_statistic": 6.980184595385152, "p_value": 0.13004015291449902, "significant": "False"}, "task_06_test_ideological_differentiation_individualizing": {"type": "one_way_anova", "grouping_variable": "ideology", "dependent_variable": "fairness_score", "groups": {"Civil Rights Activist": {"n": 1, "mean": 0.95, "std": 0.0}, "Conservative": {"n": 2, "mean": 0.6, "std": 0.09999999999999998}, "Hardline Conservative": {"n": 1, "mean": 0.5, "std": 0.0}, "Liberal": {"n": 1, "mean": 0.9, "std": 0.0}, "National Conservative": {"n": 1, "mean": 0.5, "std": 0.0}, "Progressive": {"n": 2, "mean": 0.8, "std": 0.10000000000000003}}, "f_statistic": 2.221874999999996, "p_value": 0.3388970429045297, "significant": "False"}, "task_07_test_ideological_differentiation_binding": {"type": "one_way_anova", "grouping_variable": "ideology", "dependent_variable": "authority_score", "groups": {"Civil Rights Activist": {"n": 1, "mean": 0.5, "std": 0.0}, "Conservative": {"n": 2, "mean": 0.3, "std": 0.0}, "Hardline Conservative": {"n": 1, "mean": 0.7, "std": 0.0}, "Liberal": {"n": 1, "mean": 0.4, "std": 0.0}, "National Conservative": {"n": 1, "mean": 0.3, "std": 0.0}, "Progressive": {"n": 2, "mean": 0.2, "std": 0.0}}, "f_statistic": Infinity, "p_value": 0.0, "significant": true}, "task_08_test_ideological_differentiation_liberty": {"type": "one_way_anova", "grouping_variable": "ideology", "dependent_variable": "liberty_score", "groups": {"Civil Rights Activist": {"n": 1, "mean": 0.95, "std": 0.0}, "Conservative": {"n": 2, "mean": 0.35, "std": 0.05000000000000002}, "Hardline Conservative": {"n": 1, "mean": 0.6, "std": 0.0}, "Liberal": {"n": 1, "mean": 0.7, "std": 0.0}, "National Conservative": {"n": 1, "mean": 0.4, "std": 0.0}, "Progressive": {"n": 2, "mean": 0.6, "std": 0.09999999999999998}}, "f_statistic": 4.634999999999995, "p_value": 0.18693426503041863, "significant": "False"}, "task_09_generate_summary_statistics_by_ideology": {"type": "descriptive_stats_grouped", "grouping_variable": "ideology", "groups": {"Civil Rights Activist": {"care_score": {"count": 1, "mean": 0.9, "std": NaN, "min": 0.9, "max": 0.9}, "harm_score": {"count": 1, "mean": 0.85, "std": NaN, "min": 0.85, "max": 0.85}, "fairness_score": {"count": 1, "mean": 0.95, "std": NaN, "min": 0.95, "max": 0.95}, "cheating_score": {"count": 1, "mean": 0.75, "std": NaN, "min": 0.75, "max": 0.75}, "loyalty_score": {"count": 1, "mean": 0.4, "std": NaN, "min": 0.4, "max": 0.4}, "betrayal_score": {"count": 1, "mean": 0.6, "std": NaN, "min": 0.6, "max": 0.6}, "authority_score": {"count": 1, "mean": 0.5, "std": NaN, "min": 0.5, "max": 0.5}, "subversion_score": {"count": 1, "mean": 0.7, "std": NaN, "min": 0.7, "max": 0.7}, "sanctity_score": {"count": 1, "mean": 0.3, "std": NaN, "min": 0.3, "max": 0.3}, "degradation_score": {"count": 1, "mean": 0.55, "std": NaN, "min": 0.55, "max": 0.55}, "liberty_score": {"count": 1, "mean": 0.95, "std": NaN, "min": 0.95, "max": 0.95}, "oppression_score": {"count": 1, "mean": 0.9, "std": NaN, "min": 0.9, "max": 0.9}, "moral_strategic_contradiction_index": {"count": 1, "mean": 0.10325, "std": NaN, "min": 0.10325, "max": 0.10325}}, "Conservative": {"care_score": {"count": 2, "mean": 0.6499999999999999, "std": 0.07071067811865474, "min": 0.6, "max": 0.7}, "harm_score": {"count": 2, "mean": 0.42500000000000004, "std": 0.31819805153394637, "min": 0.2, "max": 0.65}, "fairness_score": {"count": 2, "mean": 0.6, "std": 0.14142135623730948, "min": 0.5, "max": 0.7}, "cheating_score": {"count": 2, "mean": 0.425, "std": 0.4596194077712559, "min": 0.1, "max": 0.75}, "loyalty_score": {"count": 2, "mean": 0.4, "std": 0.282842712474619, "min": 0.2, "max": 0.6}, "betrayal_score": {"count": 2, "mean": 0.175, "std": 0.10606601717798213, "min": 0.1, "max": 0.25}, "authority_score": {"count": 2, "mean": 0.3, "std": 0.0, "min": 0.3, "max": 0.3}, "subversion_score": {"count": 2, "mean": 0.22499999999999998, "std": 0.17677669529663687, "min": 0.1, "max": 0.35}, "sanctity_score": {"count": 2, "mean": 0.30000000000000004, "std": 0.14142135623730953, "min": 0.2, "max": 0.4}, "degradation_score": {"count": 2, "mean": 0.275, "std": 0.24748737341529164, "min": 0.1, "max": 0.45}, "liberty_score": {"count": 2, "mean": 0.35, "std": 0.07071067811865477, "min": 0.3, "max": 0.4}, "oppression_score": {"count": 2, "mean": 0.275, "std": 0.10606601717798211, "min": 0.2, "max": 0.35}, "moral_strategic_contradiction_index": {"count": 2, "mean": 0.030416666666666668, "std": 0.013552879972742168, "min": 0.020833333333333332, "max": 0.04000000000000001}}, "Hardline Conservative": {"care_score": {"count": 1, "mean": 0.4, "std": NaN, "min": 0.4, "max": 0.4}, "harm_score": {"count": 1, "mean": 0.6, "std": NaN, "min": 0.6, "max": 0.6}, "fairness_score": {"count": 1, "mean": 0.5, "std": NaN, "min": 0.5, "max": 0.5}, "cheating_score": {"count": 1, "mean": 0.7, "std": NaN, "min": 0.7, "max": 0.7}, "loyalty_score": {"count": 1, "mean": 0.2, "std": NaN, "min": 0.2, "max": 0.2}, "betrayal_score": {"count": 1, "mean": 0.3, "std": NaN, "min": 0.3, "max": 0.3}, "authority_score": {"count": 1, "mean": 0.7, "std": NaN, "min": 0.7, "max": 0.7}, "subversion_score": {"count": 1, "mean": 0.5, "std": NaN, "min": 0.5, "max": 0.5}, "sanctity_score": {"count": 1, "mean": 0.3, "std": NaN, "min": 0.3, "max": 0.3}, "degradation_score": {"count": 1, "mean": 0.4, "std": NaN, "min": 0.4, "max": 0.4}, "liberty_score": {"count": 1, "mean": 0.6, "std": NaN, "min": 0.6, "max": 0.6}, "oppression_score": {"count": 1, "mean": 0.7, "std": NaN, "min": 0.7, "max": 0.7}, "moral_strategic_contradiction_index": {"count": 1, "mean": 0.05333333333333332, "std": NaN, "min": 0.05333333333333332, "max": 0.05333333333333332}}, "Liberal": {"care_score": {"count": 1, "mean": 0.85, "std": NaN, "min": 0.85, "max": 0.85}, "harm_score": {"count": 1, "mean": 0.75, "std": NaN, "min": 0.75, "max": 0.75}, "fairness_score": {"count": 1, "mean": 0.9, "std": NaN, "min": 0.9, "max": 0.9}, "cheating_score": {"count": 1, "mean": 0.6, "std": NaN, "min": 0.6, "max": 0.6}, "loyalty_score": {"count": 1, "mean": 0.3, "std": NaN, "min": 0.3, "max": 0.3}, "betrayal_score": {"count": 1, "mean": 0.25, "std": NaN, "min": 0.25, "max": 0.25}, "authority_score": {"count": 1, "mean": 0.4, "std": NaN, "min": 0.4, "max": 0.4}, "subversion_score": {"count": 1, "mean": 0.35, "std": NaN, "min": 0.35, "max": 0.35}, "sanctity_score": {"count": 1, "mean": 0.2, "std": NaN, "min": 0.2, "max": 0.2}, "degradation_score": {"count": 1, "mean": 0.55, "std": NaN, "min": 0.55, "max": 0.55}, "liberty_score": {"count": 1, "mean": 0.7, "std": NaN, "min": 0.7, "max": 0.7}, "oppression_score": {"count": 1, "mean": 0.8, "std": NaN, "min": 0.8, "max": 0.8}, "moral_strategic_contradiction_index": {"count": 1, "mean": 0.062083333333333345, "std": NaN, "min": 0.062083333333333345, "max": 0.062083333333333345}}, "National Conservative": {"care_score": {"count": 1, "mean": 0.3, "std": NaN, "min": 0.3, "max": 0.3}, "harm_score": {"count": 1, "mean": 0.4, "std": NaN, "min": 0.4, "max": 0.4}, "fairness_score": {"count": 1, "mean": 0.5, "std": NaN, "min": 0.5, "max": 0.5}, "cheating_score": {"count": 1, "mean": 0.4, "std": NaN, "min": 0.4, "max": 0.4}, "loyalty_score": {"count": 1, "mean": 0.2, "std": NaN, "min": 0.2, "max": 0.2}, "betrayal_score": {"count": 1, "mean": 0.2, "std": NaN, "min": 0.2, "max": 0.2}, "authority_score": {"count": 1, "mean": 0.3, "std": NaN, "min": 0.3, "max": 0.3}, "subversion_score": {"count": 1, "mean": 0.3, "std": NaN, "min": 0.3, "max": 0.3}, "sanctity_score": {"count": 1, "mean": 0.1, "std": NaN, "min": 0.1, "max": 0.1}, "degradation_score": {"count": 1, "mean": 0.2, "std": NaN, "min": 0.2, "max": 0.2}, "liberty_score": {"count": 1, "mean": 0.4, "std": NaN, "min": 0.4, "max": 0.4}, "oppression_score": {"count": 1, "mean": 0.5, "std": NaN, "min": 0.5, "max": 0.5}, "moral_strategic_contradiction_index": {"count": 1, "mean": 0.019999999999999997, "std": NaN, "min": 0.019999999999999997, "max": 0.019999999999999997}}, "Progressive": {"care_score": {"count": 2, "mean": 0.75, "std": 0.07071067811865482, "min": 0.7, "max": 0.8}, "harm_score": {"count": 2, "mean": 0.6499999999999999, "std": 0.07071067811865474, "min": 0.6, "max": 0.7}, "fairness_score": {"count": 2, "mean": 0.8, "std": 0.14142135623730953, "min": 0.7, "max": 0.9}, "cheating_score": {"count": 2, "mean": 0.7, "std": 0.14142135623730953, "min": 0.6, "max": 0.8}, "loyalty_score": {"count": 2, "mean": 0.30000000000000004, "std": 0.14142135623730953, "min": 0.2, "max": 0.4}, "betrayal_score": {"count": 2, "mean": 0.2, "std": 0.1414213562373095, "min": 0.1, "max": 0.3}, "authority_score": {"count": 2, "mean": 0.2, "std": 0.0, "min": 0.2, "max": 0.2}, "subversion_score": {"count": 2, "mean": 0.15000000000000002, "std": 0.07071067811865477, "min": 0.1, "max": 0.2}, "sanctity_score": {"count": 2, "mean": 0.15000000000000002, "std": 0.07071067811865477, "min": 0.1, "max": 0.2}, "degradation_score": {"count": 2, "mean": 0.175, "std": 0.03535533905932738, "min": 0.15, "max": 0.2}, "liberty_score": {"count": 2, "mean": 0.6, "std": 0.14142135623730948, "min": 0.5, "max": 0.7}, "oppression_score": {"count": 2, "mean": 0.75, "std": 0.07071067811865482, "min": 0.7, "max": 0.8}, "moral_strategic_contradiction_index": {"count": 2, "mean": 0.048958333333333326, "std": 0.009133462590326224, "min": 0.0425, "max": 0.05541666666666665}}}}}, "errors": []}, "combined_summary": "Two-stage execution: 4 raw data results + 9 derived metrics results"}