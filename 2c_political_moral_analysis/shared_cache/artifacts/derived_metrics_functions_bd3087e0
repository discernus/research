{
  "status": "success",
  "functions_generated": 6,
  "output_file": "automatedderivedmetricsagent_functions.py",
  "module_size": 13057,
  "function_code_content": "\"\"\"\nAutomated Derived Metrics Functions\n===================================\n\nGenerated by AutomatedDerivedMetricsAgent for experiment: Test Experiment\nDescription: Test experiment for derived metrics\nGenerated: 2025-08-28T02:59:50.048269+00:00\n\nThis module contains automatically generated calculation functions for derived metrics\nas specified in the framework's natural language descriptions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom typing import Optional, Dict, Any\n\n\ndef calculate_identity_tension(data, **kwargs):\n    \"\"\"\n    Calculate identity_tension: Conflict between tribal dominance and individual dignity dimensions.\n\n    The formula measures tension as highest when both the tribal dominance and individual\n    dignity dimensions are strongly and simultaneously present.\n\n    Formula: Tension = (D_tribal + D_dignity) - abs(D_tribal - D_dignity)\n    This is equivalent to: 2 * min(D_tribal, D_dignity)\n\n    Args:\n        data (pandas.DataFrame): A single data row, passed for framework compatibility.\n        **kwargs: Keyword arguments must contain the following pre-calculated scores:\n            'tribal_dominance' (float): The score for the tribal dominance dimension.\n            'individual_dignity' (float): The score for the individual dignity dimension.\n\n    Returns:\n        float: The calculated identity tension score, or None if required scores are\n               missing, non-numeric, or if an error occurs.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # Retrieve scores from keyword arguments. This design assumes the primary\n        # dimension scores are calculated elsewhere and passed into this function.\n        tribal_dominance = kwargs.get('tribal_dominance')\n        individual_dignity = kwargs.get('individual_dignity')\n\n        # Gracefully handle cases where data is missing (None) or is NaN.\n        if pd.isna(tribal_dominance) or pd.isna(individual_dignity):\n            return None\n\n        # Convert to float for calculation. This raises an error for non-numeric\n        # types (e.g., strings), which is caught by the except block.\n        d_tribal = float(tribal_dominance)\n        d_dignity = float(individual_dignity)\n\n        # Calculate tension. The score is highest when both d_tribal and d_dignity are high.\n        tension_score = (d_tribal + d_dignity) - abs(d_tribal - d_dignity)\n\n        return tension_score\n\n    except Exception:\n        # Return None if scores are not numeric or any other error occurs.\n        return None\n\ndef calculate_emotional_balance(data, **kwargs):\n    \"\"\"\n    Calculate emotional_balance: Difference between hope and fear scores\n    Formula: emotional_balance = hope - fear\n\n    Args:\n        data (pd.Series): A single row of data containing foundation scores.\n        **kwargs: Additional parameters (unused).\n\n    Returns:\n        float: The calculated emotional balance score, or None if 'hope' or 'fear'\n               scores are missing or non-numeric.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # The calculation requires 'hope' and 'fear' columns.\n        # This implementation assumes they will be present in the data passed\n        # to this function, as per the calculation description.\n        # Using .get() is safe and returns None if a key is missing.\n        hope_score = data.get('hope')\n        fear_score = data.get('fear')\n\n        # Convert to numeric, coercing errors to NaN (Not a Number).\n        # This handles cases where columns are missing (get -> None) or contain non-numeric data.\n        hope_numeric = pd.to_numeric(hope_score, errors='coerce')\n        fear_numeric = pd.to_numeric(fear_score, errors='coerce')\n\n        # If either value is NaN (due to missing columns, None values, or non-numeric text),\n        # the calculation is not possible.\n        if pd.isna(hope_numeric) or pd.isna(fear_numeric):\n            return None\n\n        # Perform the calculation and return the result as a standard float.\n        result = float(hope_numeric - fear_numeric)\n        \n        # Final check to ensure we don't return a numpy NaN value.\n        return result if not np.isnan(result) else None\n\n    except (TypeError, AttributeError, Exception):\n        # Catch any other unexpected errors during processing and return None\n        # to ensure robust, production-ready execution.\n        return None\n\ndef calculate_success_climate(data, **kwargs):\n    \"\"\"\n    Calculate success_climate: Difference between compersion and envy scores\n\n    Formula: compersion - envy\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        **kwargs: Additional parameters\n        \n    Returns:\n        float: Calculated result or None if insufficient data\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # The calculation requires 'compersion' and 'envy' scores.\n        # This implementation attempts to access these columns and will\n        # return None if they are missing or contain invalid data,\n        # which is expected given the provided data structure.\n        compersion_score = data.get('compersion')\n        envy_score = data.get('envy')\n\n        # Check for missing data. pd.isna handles both None and np.nan.\n        if pd.isna(compersion_score) or pd.isna(envy_score):\n            return None\n            \n        # Ensure values are numeric and perform the calculation.\n        result = float(compersion_score) - float(envy_score)\n        \n        return result\n\n    except Exception:\n        # Gracefully handle any other errors, such as non-numeric types\n        # that cannot be cast to float, and return None.\n        return None\n\ndef calculate_relational_climate(data, **kwargs):\n    \"\"\"\n    Calculate relational_climate: Difference between amity and enmity scores\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        **kwargs: Additional parameters\n        \n    Returns:\n        float: Calculated result or None if insufficient data\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # Use .get() to safely access keys that might not exist.\n        # pd.to_numeric with errors='coerce' will turn non-numeric values (including None from .get()) into NaN.\n        amity_score = pd.to_numeric(data.get('amity'), errors='coerce')\n        enmity_score = pd.to_numeric(data.get('enmity'), errors='coerce')\n        \n        # Check if either score is NaN, which indicates missing or invalid data.\n        if pd.isna(amity_score) or pd.isna(enmity_score):\n            return None\n            \n        # Calculate the difference.\n        result = float(amity_score - enmity_score)\n        \n        # Ensure the result is a finite number (not infinity or NaN).\n        if not np.isfinite(result):\n            return None\n            \n        return result\n        \n    except Exception:\n        # A broad exception handler for any other unexpected errors.\n        return None\n\ndef calculate_goal_orientation(data, **kwargs):\n    \"\"\"\n    Calculate goal_orientation: Difference between cohesive goals and fragmentative goals\n    \n    Formula: cohesive_goals - fragmentative_goals\n    \n    Args:\n        data (pd.Series): A single row of data from the analysis DataFrame.\n                          This parameter is part of the framework's standard\n                          function signature but is not used in this calculation.\n        **kwargs: Keyword arguments containing the component scores.\n                  Expected keys: 'cohesive_goals', 'fragmentative_goals'.\n        \n    Returns:\n        float: Calculated goal orientation score or None if insufficient data.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        cohesive_goals = kwargs.get('cohesive_goals')\n        fragmentative_goals = kwargs.get('fragmentative_goals')\n\n        # Check if the necessary scores are present and are numeric\n        if cohesive_goals is None or fragmentative_goals is None:\n            return None\n            \n        if pd.isna(cohesive_goals) or pd.isna(fragmentative_goals):\n            return None\n\n        # Ensure values are numeric before calculation\n        cohesive_goals = float(cohesive_goals)\n        fragmentative_goals = float(fragmentative_goals)\n        \n        # Perform the calculation\n        goal_orientation = cohesive_goals - fragmentative_goals\n        \n        return goal_orientation\n\n    except (ValueError, TypeError):\n        # Catches errors if score values are not convertible to float\n        return None\n    except Exception:\n        # Catch-all for any other unexpected errors\n        return None\n\ndef calculate_overall_cohesion_index(data, **kwargs):\n    \"\"\"\n    Calculate overall_cohesion_index: Comprehensive measure combining all dimensions.\n\n    This index measures the consistency of moral dimension salience. A higher value \n    (closer to 1) indicates a more focused and cohesive moral profile, while a lower \n    value suggests a more diffuse or internally conflicted profile. It is calculated \n    as 1 minus the population standard deviation of the salience scores across all \n    specified moral dimensions.\n\n    Formula: 1 - stddev_p(Dimension_1, Dimension_2, ..., Dimension_N)\n\n    Args:\n        data (pd.Series): A single row of data as a pandas Series, containing dimension scores.\n        **kwargs: Must include 'dimension_columns', a list of column names representing the moral dimensions.\n\n    Returns:\n        float: Calculated cohesion index, or None if insufficient data or configuration.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # The calculation requires a list of dimension columns to be specified in kwargs.\n        # This approach avoids hardcoding column names not present in the base data structure,\n        # providing flexibility for the research framework.\n        dimension_cols = kwargs.get('dimension_columns')\n        \n        # We need at least two dimensions to measure cohesion.\n        if not dimension_cols or not isinstance(dimension_cols, list) or len(dimension_cols) < 2:\n            return None\n\n        # Ensure all specified dimension columns are present in the data Series.\n        if not all(col in data.index for col in dimension_cols):\n            return None\n\n        # Extract scores, coercing non-numeric values to NaN, and drop any missing values.\n        scores = pd.to_numeric(data[dimension_cols], errors='coerce').dropna()\n\n        # We need at least two valid numeric data points to calculate standard deviation.\n        if len(scores) < 2:\n            return None\n\n        # Calculate the population standard deviation of the valid scores.\n        # This assumes scores are normalized (e.g., 0-1 range) for a meaningful index.\n        std_dev = np.std(scores)  # ddof=0 is default for population std dev\n        \n        cohesion_index = 1.0 - std_dev\n\n        # Clip the result to ensure it's within the logical [0, 1] range.\n        return float(np.clip(cohesion_index, 0.0, 1.0))\n\n    except Exception:\n        # Catch any unexpected errors during processing and return None for robustness.\n        return None\n\ndef calculate_all_derived_metrics(data: pd.DataFrame) -> Dict[str, Optional[float]]:\n    \"\"\"\n    Calculate all derived metrics for the given dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        Dictionary mapping metric names to calculated values\n    \"\"\"\n    results = {}\n    \n    # Get all calculation functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith('calculate_') and \n            name not in ['calculate_all_derived_metrics', 'calculate_derived_metrics']):\n            try:\n                results[name.replace('calculate_', '')] = obj(data)\n            except Exception as e:\n                results[name.replace('calculate_', '')] = None\n                \n    return results\n\n\ndef calculate_derived_metrics(data: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Template-compatible wrapper function for derived metrics calculation.\n    \n    This function is called by the universal notebook template and returns\n    the original data with additional derived metric columns.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        DataFrame with original data plus derived metric columns\n    \"\"\"\n    # Calculate all derived metrics\n    derived_metrics = calculate_all_derived_metrics(data)\n    \n    # Create a copy of the original data\n    result = data.copy()\n    \n    # Add derived metrics as new columns\n    for metric_name, metric_value in derived_metrics.items():\n        if metric_value is not None:\n            # For scalar metrics, broadcast to all rows\n            result[metric_name] = metric_value\n        else:\n            # For failed calculations, use NaN\n            result[metric_name] = np.nan\n    \n    return result\n",
  "cached_with_code": true
}