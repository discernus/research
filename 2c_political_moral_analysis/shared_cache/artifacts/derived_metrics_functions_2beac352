{
  "status": "success",
  "functions_generated": 6,
  "output_file": "automatedderivedmetricsagent_functions.py",
  "module_size": 14288,
  "function_code_content": "\"\"\"\nAutomated Derived Metrics Functions\n===================================\n\nGenerated by AutomatedDerivedMetricsAgent for experiment: Test Experiment\nDescription: Test experiment for derived metrics\nGenerated: 2025-08-29T12:28:38.373482+00:00\n\nThis module contains automatically generated calculation functions for derived metrics\nas specified in the framework's natural language descriptions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom typing import Optional, Dict, Any\n\n\ndef calculate_identity_tension(data, **kwargs):\n    \"\"\"\n    Calculate identity_tension: Conflict between tribal dominance and individual dignity dimensions.\n    \n    This tension is calculated as the absolute difference between the average score of the \n    'binding' foundations (tribal dominance) and the 'individualizing' foundations \n    (individual dignity). The scores are expected to be in a JSON object within the\n    'raw_analysis_response' column.\n\n    Formula: |mean(loyalty, authority, sanctity) - mean(care, fairness, liberty)|\n\n    Args:\n        data (pd.Series): A single row of data as a pandas Series.\n        **kwargs: Additional parameters (unused).\n        \n    Returns:\n        float: Calculated result or None if insufficient data.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    import json\n\n    try:\n        # The required scores are assumed to be in a JSON string/dict in this column.\n        raw_response = data.get('raw_analysis_response')\n\n        # 1. Handle missing raw response data\n        if pd.isna(raw_response):\n            return None\n        \n        # 2. Parse the JSON data\n        scores = {}\n        if isinstance(raw_response, dict):\n            scores = raw_response\n        elif isinstance(raw_response, str):\n            try:\n                scores = json.loads(raw_response)\n            except json.JSONDecodeError:\n                return None  # Invalid JSON format\n        else:\n            return None # Unsupported data type\n\n        if not isinstance(scores, dict):\n            return None # Parsed JSON is not a dictionary\n\n        # 3. Define foundation groups based on Moral Foundations Theory\n        individual_dignity_foundations = ['care', 'fairness', 'liberty']\n        tribal_dominance_foundations = ['loyalty', 'authority', 'sanctity']\n        \n        # 4. Extract scores for each group, handling missing keys and non-numeric values\n        dignity_scores = [\n            s for s in [scores.get(f) for f in individual_dignity_foundations] \n            if isinstance(s, (int, float))\n        ]\n        dominance_scores = [\n            s for s in [scores.get(f) for f in tribal_dominance_foundations] \n            if isinstance(s, (int, float))\n        ]\n\n        # 5. Ensure at least one valid score exists for each dimension to calculate tension\n        if not dignity_scores or not dominance_scores:\n            return None\n            \n        # 6. Calculate the mean score for each dimension\n        avg_dignity = np.mean(dignity_scores)\n        avg_dominance = np.mean(dominance_scores)\n        \n        # 7. Calculate tension as the absolute difference between the two dimensions\n        tension = np.abs(avg_dominance - avg_dignity)\n        \n        return float(tension)\n\n    except Exception:\n        # Broad exception for any other unforeseen errors during execution\n        return None\n\ndef calculate_emotional_balance(data, **kwargs):\n    \"\"\"\n    Calculate emotional_balance: Difference between hope and fear scores\n\n    Args:\n        data (pd.Series): A single row of data containing the necessary scores.\n        **kwargs: Additional parameters (unused).\n\n    Returns:\n        float: The calculated emotional balance, or None if input data is missing or invalid.\n    \n    Formula:\n        emotional_balance = hope - fear\n    \"\"\"\n    import pandas as pd\n\n    try:\n        hope_score = data['hope']\n        fear_score = data['fear']\n\n        # Check for missing data (NaN, None)\n        if pd.isna(hope_score) or pd.isna(fear_score):\n            return None\n\n        # Ensure scores are numeric before calculation\n        result = float(hope_score) - float(fear_score)\n        \n        return result\n\n    except (KeyError, TypeError, ValueError):\n        # Handles cases where columns are missing, data is not numeric,\n        # or other conversion errors.\n        return None\n\ndef calculate_success_climate(data, **kwargs):\n    \"\"\"\n    Calculate success_climate: Difference between compersion and envy scores.\n\n    Formula: success_climate = compersion - envy\n\n    Args:\n        data (pd.Series): A single row of data, expected to contain 'compersion'\n                          and 'envy' scores.\n        **kwargs: Additional keyword arguments (not used).\n\n    Returns:\n        float: The calculated result, or None if 'compersion' or 'envy' scores\n               are missing or non-numeric.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # The calculation requires 'compersion' and 'envy' scores.\n        # We use .get() to safely access these keys, returning None if they don't exist.\n        # This prevents KeyErrors, fulfilling the requirement to handle data where\n        # these specific columns might be missing.\n        compersion_score = data.get('compersion')\n        envy_score = data.get('envy')\n\n        # Convert to numeric, coercing any non-numeric values (including None) to NaN.\n        compersion_numeric = pd.to_numeric(compersion_score, errors='coerce')\n        envy_numeric = pd.to_numeric(envy_score, errors='coerce')\n\n        # If either score is missing or could not be converted to a number,\n        # the calculation is not possible.\n        if pd.isna(compersion_numeric) or pd.isna(envy_numeric):\n            return None\n\n        # Perform the specified calculation.\n        result = float(compersion_numeric - envy_numeric)\n        \n        return result\n\n    except Exception:\n        # A broad exception handler to ensure the function is robust and\n        # returns None in case of any unexpected errors during processing.\n        return None\n\ndef calculate_relational_climate(data, **kwargs):\n    \"\"\"\n    Calculate relational_climate: Difference between amity and enmity scores.\n\n    Formula: relational_climate = amity - enmity\n\n    Args:\n        data (pd.Series): A single row of data containing the necessary columns.\n        **kwargs: Additional parameters (unused).\n\n    Returns:\n        float: The calculated relational climate score, or None if input data is\n               missing or invalid.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # The calculation requires 'amity' and 'enmity' scores.\n        # We use .get() to safely access these values from the data Series.\n        # pd.to_numeric handles conversion and sets non-numeric values to NaN.\n        amity_score = pd.to_numeric(data.get('amity'), errors='coerce')\n        enmity_score = pd.to_numeric(data.get('enmity'), errors='coerce')\n\n        # If either value is missing (is None) or could not be converted to a\n        # number (is NaN), we cannot perform the calculation.\n        if pd.isna(amity_score) or pd.isna(enmity_score):\n            return None\n\n        # Perform the calculation as per the description.\n        result = amity_score - enmity_score\n\n        # Ensure the output is a standard Python float.\n        return float(result)\n\n    except Exception:\n        # A general exception handler to catch any unexpected errors during\n        # execution, ensuring the function always returns a value.\n        return None\n\ndef calculate_goal_orientation(data, **kwargs):\n    \"\"\"\n    Calculate goal_orientation: Difference between cohesive goals and fragmentative goals.\n\n    Formula: cohesive_goals - fragmentative_goals\n\n    Args:\n        data (pd.Series): A single row of data from a pandas DataFrame.\n        **kwargs: Additional parameters (not used in this calculation).\n\n    Returns:\n        float: The calculated score, or None if the necessary 'cohesive_goals'\n               or 'fragmentative_goals' columns are missing or contain\n               non-numeric/null data.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # This calculation requires 'cohesive_goals' and 'fragmentative_goals' columns.\n        # The function attempts to access these conceptual columns. If they do not\n        # exist in the input data, a KeyError will be raised and caught by the\n        # exception handler, which correctly returns None.\n        cohesive_score = data['cohesive_goals']\n        fragmentative_score = data['fragmentative_goals']\n\n        # Check for missing values (NaN, None) in the required columns.\n        if pd.isna(cohesive_score) or pd.isna(fragmentative_score):\n            return None\n\n        # Ensure values are numeric and perform the calculation.\n        result = float(cohesive_score) - float(fragmentative_score)\n\n        return result\n\n    except Exception:\n        # This generic exception will catch KeyErrors if the columns are missing,\n        # or ValueErrors/TypeErrors if the data is not convertible to float.\n        # In any such case, it signifies insufficient data for the calculation.\n        return None\n\ndef calculate_overall_cohesion_index(data, **kwargs):\n    \"\"\"\n    Calculate overall_cohesion_index: Comprehensive measure combining all dimensions.\n\n    This index measures the internal consistency of a moral argument by quantifying\n    the uniformity of expression across the six moral foundations. It is calculated\n    based on the statistical dispersion (standard deviation) of the foundation scores.\n    A low standard deviation signifies high cohesion, as all foundations are utilized\n    at similar levels. A high standard deviation signifies low cohesion, indicating a\n    focus on specific foundations to the exclusion of others.\n\n    Formula: 1 / (1 + standard_deviation(foundation_scores))\n\n    Args:\n        data (pd.Series): A single row of data as a pandas Series, expected to\n                          contain scores for the six moral foundations.\n        **kwargs: Additional keyword arguments (unused).\n\n    Returns:\n        float: The calculated overall cohesion index (between 0 and 1), or None\n               if the required foundation score columns are missing or contain\n               non-numeric/NaN values.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # Per the Moral Foundations Theory Framework context, cohesion is a function\n        # of the six core foundation scores.\n        foundation_cols = [\n            'care_score',\n            'fairness_score',\n            'loyalty_score',\n            'authority_score',\n            'sanctity_score',\n            'liberty_score'\n        ]\n\n        # Extract scores into a list. This will raise a KeyError if any column is missing,\n        # which is handled by the except block below. This is the expected behavior\n        # when the input `data` adheres to the restrictive structure in the prompt.\n        scores = [data[col] for col in foundation_cols]\n\n        # Convert to a numeric series, coercing errors to NaN\n        scores_series = pd.to_numeric(pd.Series(scores), errors='coerce')\n\n        # If any score is missing or could not be converted to a number,\n        # the calculation is not possible.\n        if scores_series.isnull().any():\n            return None\n\n        # Calculate the population standard deviation of the scores.\n        # A low std dev means high cohesion (scores are close together).\n        # ddof=0 for population std dev, as the 6 foundations are the full set.\n        std_dev = np.std(scores_series)\n\n        # The cohesion index is the inverse of the standard deviation, normalized\n        # to a 0-1 scale. Adding 1 to the denominator prevents division by zero\n        # and ensures that perfect cohesion (std_dev=0) results in an index of 1.\n        cohesion_index = 1 / (1 + std_dev)\n\n        return float(cohesion_index)\n\n    except KeyError:\n        # This is the primary expected failure path if the input `data` does not\n        # contain the required moral foundation score columns.\n        return None\n    except (ValueError, TypeError):\n        # Catches errors from data being in an unexpected format.\n        return None\n    except Exception:\n        # A final catch-all for any other unexpected issues.\n        return None\n\ndef calculate_all_derived_metrics(data: pd.DataFrame) -> Dict[str, Optional[float]]:\n    \"\"\"\n    Calculate all derived metrics for the given dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        Dictionary mapping metric names to calculated values\n    \"\"\"\n    results = {}\n    \n    # Get all calculation functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith('calculate_') and \n            name not in ['calculate_all_derived_metrics', 'calculate_derived_metrics']):\n            try:\n                results[name.replace('calculate_', '')] = obj(data)\n            except Exception as e:\n                results[name.replace('calculate_', '')] = None\n                \n    return results\n\n\ndef calculate_derived_metrics(data: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Template-compatible wrapper function for derived metrics calculation.\n    \n    This function is called by the universal notebook template and returns\n    the original data with additional derived metric columns.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        DataFrame with original data plus derived metric columns\n    \"\"\"\n    # Calculate all derived metrics\n    derived_metrics = calculate_all_derived_metrics(data)\n    \n    # Create a copy of the original data\n    result = data.copy()\n    \n    # Add derived metrics as new columns\n    for metric_name, metric_value in derived_metrics.items():\n        if metric_value is not None:\n            # For scalar metrics, broadcast to all rows\n            result[metric_name] = metric_value\n        else:\n            # For failed calculations, use NaN\n            result[metric_name] = np.nan\n    \n    return result\n",
  "cached_with_code": true
}