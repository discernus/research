{"stage_1_raw_data": {"analysis_plan": {"stage": "raw_data_collection", "experiment_summary": "This plan outlines the collection and initial validation of raw dimensional scores (score, salience, confidence) for the 12 moral foundations specified by the Moral Foundations Theory Framework v6.0. The focus is on capturing the direct output from the LLM analysis, including all scores, associated metadata, and textual evidence, and performing basic integrity checks to ensure data quality and completeness before subsequent statistical analysis.", "tasks": {"validate_raw_score_integrity": {"tool": "create_summary_statistics", "parameters": {"metrics": ["care_score", "harm_score", "fairness_score", "cheating_score", "loyalty_score", "betrayal_score", "authority_score", "subversion_score", "sanctity_score", "degradation_score", "liberty_score", "oppression_score", "care_salience", "harm_salience", "fairness_salience", "cheating_salience", "loyalty_salience", "betrayal_salience", "authority_salience", "subversion_salience", "sanctity_salience", "degradation_salience", "liberty_salience", "oppression_salience", "care_confidence", "harm_confidence", "fairness_confidence", "cheating_confidence", "loyalty_confidence", "betrayal_confidence", "authority_confidence", "subversion_confidence", "sanctity_confidence", "degradation_confidence", "liberty_confidence", "oppression_confidence"], "summary_types": ["min", "max", "mean", "count"]}, "purpose": "To perform a fundamental data quality check on all 36 raw dimensional outputs from the LLM. This validates that all collected scores, salience, and confidence values are within the expected range (0.0-1.0) and checks for missing data points ('count') across the entire dataset."}, "summarize_dimensional_scores": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["care_score", "harm_score", "fairness_score", "cheating_score", "loyalty_score", "betrayal_score", "authority_score", "subversion_score", "sanctity_score", "degradation_score", "liberty_score", "oppression_score"]}, "purpose": "To generate descriptive statistics for the 12 core moral foundation scores. This provides an initial overview of the central tendency and distribution of each foundation's intensity as captured from the corpus, which is essential for understanding the basic patterns before hypothesis testing."}, "summarize_analysis_metadata": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["care_salience", "harm_salience", "fairness_salience", "cheating_salience", "loyalty_salience", "betrayal_salience", "authority_salience", "subversion_salience", "sanctity_salience", "degradation_salience", "liberty_salience", "oppression_salience", "care_confidence", "harm_confidence", "fairness_confidence", "cheating_confidence", "loyalty_confidence", "betrayal_confidence", "authority_confidence", "subversion_confidence", "sanctity_confidence", "degradation_confidence", "liberty_confidence", "oppression_confidence"]}, "purpose": "To collect and summarize the raw salience and confidence metadata for all foundations. This step is critical for assessing the quality of the LLM's analysis, as salience is a key input for later tension calculations and confidence is a direct measure of analytical reliability."}, "validate_analysis_completeness": {"tool": "create_summary_statistics", "parameters": {"metrics": ["analysis_completeness"], "summary_types": ["mean", "min", "std"]}, "purpose": "To validate the 'analysis_completeness' metadata field specified in the framework's output contract. This ensures that each document analysis was fully executed by the LLM, with the 'min' statistic being crucial for identifying any partial or failed analysis runs."}}}, "results": {"validate_raw_score_integrity": {"type": "summary_statistics", "metrics": ["care_score", "harm_score", "fairness_score", "cheating_score", "loyalty_score", "betrayal_score", "authority_score", "subversion_score", "sanctity_score", "degradation_score", "liberty_score", "oppression_score", "care_salience", "harm_salience", "fairness_salience", "cheating_salience", "loyalty_salience", "betrayal_salience", "authority_salience", "subversion_salience", "sanctity_salience", "degradation_salience", "liberty_salience", "oppression_salience", "care_confidence", "harm_confidence", "fairness_confidence", "cheating_confidence", "loyalty_confidence", "betrayal_confidence", "authority_confidence", "subversion_confidence", "sanctity_confidence", "degradation_confidence", "liberty_confidence", "oppression_confidence"], "summary_types": ["min", "max", "mean", "count"], "results": {"care_score": {"mean": 0.65625, "min": 0.3, "max": 0.9, "count": 8}, "harm_score": {"mean": 0.59375, "min": 0.2, "max": 0.85, "count": 8}, "fairness_score": {"mean": 0.70625, "min": 0.5, "max": 0.95, "count": 8}, "cheating_score": {"mean": 0.5874999999999999, "min": 0.1, "max": 0.8, "count": 8}, "loyalty_score": {"mean": 0.3125, "min": 0.2, "max": 0.6, "count": 8}, "betrayal_score": {"mean": 0.2625, "min": 0.1, "max": 0.6, "count": 8}, "authority_score": {"mean": 0.36250000000000004, "min": 0.2, "max": 0.7, "count": 8}, "subversion_score": {"mean": 0.32499999999999996, "min": 0.1, "max": 0.7, "count": 8}, "sanctity_score": {"mean": 0.225, "min": 0.1, "max": 0.4, "count": 8}, "degradation_score": {"mean": 0.325, "min": 0.1, "max": 0.55, "count": 8}, "liberty_score": {"mean": 0.56875, "min": 0.3, "max": 0.95, "count": 8}, "oppression_score": {"mean": 0.6187499999999999, "min": 0.2, "max": 0.9, "count": 8}, "care_salience": {"mean": 0.64625, "min": 0.2, "max": 0.95, "count": 8}, "harm_salience": {"mean": 0.575, "min": 0.1, "max": 0.85, "count": 8}, "fairness_salience": {"mean": 0.74125, "min": 0.4, "max": 0.98, "count": 8}, "cheating_salience": {"mean": 0.5875, "min": 0.05, "max": 0.85, "count": 8}, "loyalty_salience": {"mean": 0.275, "min": 0.1, "max": 0.5, "count": 8}, "betrayal_salience": {"mean": 0.2375, "min": 0.05, "max": 0.5, "count": 8}, "authority_salience": {"mean": 0.33125, "min": 0.1, "max": 0.7, "count": 8}, "subversion_salience": {"mean": 0.31875, "min": 0.05, "max": 0.65, "count": 8}, "sanctity_salience": {"mean": 0.2125, "min": 0.05, "max": 0.5, "count": 8}, "degradation_salience": {"mean": 0.325, "min": 0.05, "max": 0.65, "count": 8}, "liberty_salience": {"mean": 0.56, "min": 0.3, "max": 0.98, "count": 8}, "oppression_salience": {"mean": 0.61875, "min": 0.1, "max": 0.95, "count": 8}, "care_confidence": {"mean": 0.8, "min": 0.6, "max": 0.9, "count": 8}, "harm_confidence": {"mean": 0.79125, "min": 0.7, "max": 0.88, "count": 8}, "fairness_confidence": {"mean": 0.8525, "min": 0.75, "max": 0.95, "count": 8}, "cheating_confidence": {"mean": 0.775, "min": 0.65, "max": 0.9, "count": 8}, "loyalty_confidence": {"mean": 0.6125, "min": 0.5, "max": 0.8, "count": 8}, "betrayal_confidence": {"mean": 0.59375, "min": 0.5, "max": 0.75, "count": 8}, "authority_confidence": {"mean": 0.64375, "min": 0.4, "max": 0.8, "count": 8}, "subversion_confidence": {"mean": 0.6187499999999999, "min": 0.3, "max": 0.8, "count": 8}, "sanctity_confidence": {"mean": 0.55625, "min": 0.4, "max": 0.7, "count": 8}, "degradation_confidence": {"mean": 0.59375, "min": 0.3, "max": 0.75, "count": 8}, "liberty_confidence": {"mean": 0.7625, "min": 0.7, "max": 0.95, "count": 8}, "oppression_confidence": {"mean": 0.8037500000000001, "min": 0.65, "max": 0.9, "count": 8}}, "missing_metrics": []}, "summarize_dimensional_scores": {"type": "descriptive_stats", "columns_analyzed": ["care_score", "harm_score", "fairness_score", "cheating_score", "loyalty_score", "betrayal_score", "authority_score", "subversion_score", "sanctity_score", "degradation_score", "liberty_score", "oppression_score"], "results": {"care_score": {"count": 8, "mean": 0.65625, "std": 0.21286732957408, "min": 0.3, "max": 0.9, "median": 0.7, "q25": 0.55, "q75": 0.8125, "skewness": -0.7370626203563863, "kurtosis": -0.5913721759809745}, "harm_score": {"count": 8, "mean": 0.59375, "std": 0.20604697799981717, "min": 0.2, "max": 0.85, "median": 0.625, "q25": 0.55, "q75": 0.7124999999999999, "skewness": -1.0081618698857595, "kurtosis": 0.8999990048662028}, "fairness_score": {"count": 8, "mean": 0.70625, "std": 0.19353386562267894, "min": 0.5, "max": 0.95, "median": 0.7, "q25": 0.5, "q75": 0.9, "skewness": 0.07113167772221433, "kurtosis": -2.0217791485124055}, "cheating_score": {"count": 8, "mean": 0.5874999999999999, "std": 0.23413976290119665, "min": 0.1, "max": 0.8, "median": 0.6499999999999999, "q25": 0.55, "q75": 0.75, "skewness": -1.5261354406461922, "kurtosis": 2.094333096372371}, "loyalty_score": {"count": 8, "mean": 0.3125, "std": 0.1457737973711325, "min": 0.2, "max": 0.6, "median": 0.25, "q25": 0.2, "q75": 0.4, "skewness": 1.1932842730924142, "kurtosis": 0.8628769154720697}, "betrayal_score": {"count": 8, "mean": 0.2625, "std": 0.1575481785722341, "min": 0.1, "max": 0.6, "median": 0.25, "q25": 0.17500000000000002, "q75": 0.3, "skewness": 1.4475416727986645, "kurtosis": 3.107085554577921}, "authority_score": {"count": 8, "mean": 0.36250000000000004, "std": 0.1685018016012207, "min": 0.2, "max": 0.7, "median": 0.3, "q25": 0.275, "q75": 0.42500000000000004, "skewness": 1.2653131607126185, "kurtosis": 1.383552865788534}, "subversion_score": {"count": 8, "mean": 0.32499999999999996, "std": 0.20354009783964294, "min": 0.1, "max": 0.7, "median": 0.32499999999999996, "q25": 0.17500000000000002, "q75": 0.38749999999999996, "skewness": 0.7538970330207945, "kurtosis": 0.3106718192627822}, "sanctity_score": {"count": 8, "mean": 0.225, "std": 0.10350983390135314, "min": 0.1, "max": 0.4, "median": 0.2, "q25": 0.17500000000000002, "q75": 0.3, "skewness": 0.38643671323171835, "kurtosis": -0.4480000000000004}, "degradation_score": {"count": 8, "mean": 0.325, "std": 0.1832250762625809, "min": 0.1, "max": 0.55, "median": 0.30000000000000004, "q25": 0.1875, "q75": 0.47500000000000003, "skewness": 0.13934727393442115, "kurtosis": -2.0432775011317337}, "liberty_score": {"count": 8, "mean": 0.56875, "std": 0.21202678402234265, "min": 0.3, "max": 0.95, "median": 0.55, "q25": 0.4, "q75": 0.7, "skewness": 0.6119123484648445, "kurtosis": -0.05103816482241097}, "oppression_score": {"count": 8, "mean": 0.6187499999999999, "std": 0.24485783047077983, "min": 0.2, "max": 0.9, "median": 0.7, "q25": 0.4625, "q75": 0.8, "skewness": -0.7692095613247771, "kurtosis": -0.6397226954911979}}}, "summarize_analysis_metadata": {"type": "descriptive_stats", "columns_analyzed": ["care_salience", "harm_salience", "fairness_salience", "cheating_salience", "loyalty_salience", "betrayal_salience", "authority_salience", "subversion_salience", "sanctity_salience", "degradation_salience", "liberty_salience", "oppression_salience", "care_confidence", "harm_confidence", "fairness_confidence", "cheating_confidence", "loyalty_confidence", "betrayal_confidence", "authority_confidence", "subversion_confidence", "sanctity_confidence", "degradation_confidence", "liberty_confidence", "oppression_confidence"], "results": {"care_salience": {"count": 8, "mean": 0.64625, "std": 0.238383694312941, "min": 0.2, "max": 0.95, "median": 0.6499999999999999, "q25": 0.575, "q75": 0.755, "skewness": -0.6094171663092065, "kurtosis": 0.8617262400645265}, "harm_salience": {"count": 8, "mean": 0.575, "std": 0.2618614682831909, "min": 0.1, "max": 0.85, "median": 0.6499999999999999, "q25": 0.45, "q75": 0.7625, "skewness": -0.942769478910185, "kurtosis": -0.07861328125000266}, "fairness_salience": {"count": 8, "mean": 0.74125, "std": 0.22433632277071341, "min": 0.4, "max": 0.98, "median": 0.7749999999999999, "q25": 0.575, "q75": 0.95, "skewness": -0.39782075160740693, "kurtosis": -1.5785890838002405}, "cheating_salience": {"count": 8, "mean": 0.5875, "std": 0.2628823745653992, "min": 0.05, "max": 0.85, "median": 0.7, "q25": 0.475, "q75": 0.725, "skewness": -1.3692371769256435, "kurtosis": 1.706820503575508}, "loyalty_salience": {"count": 8, "mean": 0.275, "std": 0.13887301496588272, "min": 0.1, "max": 0.5, "median": 0.3, "q25": 0.17500000000000002, "q75": 0.325, "skewness": 0.1600182888495763, "kurtosis": -0.5530864197530878}, "betrayal_salience": {"count": 8, "mean": 0.2375, "std": 0.16420805617960926, "min": 0.05, "max": 0.5, "median": 0.25, "q25": 0.08750000000000001, "q75": 0.35, "skewness": 0.2298811961428504, "kurtosis": -1.167597912372265}, "authority_salience": {"count": 8, "mean": 0.33125, "std": 0.21536928418748244, "min": 0.1, "max": 0.7, "median": 0.30000000000000004, "q25": 0.17500000000000002, "q75": 0.4625, "skewness": 0.5280005972641789, "kurtosis": -0.7829887514925611}, "subversion_salience": {"count": 8, "mean": 0.31875, "std": 0.24775780224127872, "min": 0.05, "max": 0.65, "median": 0.325, "q25": 0.08750000000000001, "q75": 0.4875, "skewness": 0.15220142642518292, "kurtosis": -2.005316125619835}, "sanctity_salience": {"count": 8, "mean": 0.2125, "std": 0.15294723646688468, "min": 0.05, "max": 0.5, "median": 0.175, "q25": 0.1, "q75": 0.3, "skewness": 0.883405983252585, "kurtosis": 0.1931822154886076}, "degradation_salience": {"count": 8, "mean": 0.325, "std": 0.249284690951645, "min": 0.05, "max": 0.65, "median": 0.35, "q25": 0.08750000000000001, "q75": 0.5125, "skewness": 0.018443576024959833, "kurtosis": -2.250653983353152}, "liberty_salience": {"count": 8, "mean": 0.56, "std": 0.23348294523216404, "min": 0.3, "max": 0.98, "median": 0.5, "q25": 0.4, "q75": 0.65, "skewness": 0.8706008057652772, "kurtosis": -0.17263953166409785}, "oppression_salience": {"count": 8, "mean": 0.61875, "std": 0.2737797602870912, "min": 0.1, "max": 0.95, "median": 0.6499999999999999, "q25": 0.4875, "q75": 0.7875, "skewness": -0.7860967921027707, "kurtosis": 0.7181364158946266}, "care_confidence": {"count": 8, "mean": 0.8, "std": 0.10690449676496977, "min": 0.6, "max": 0.9, "median": 0.8, "q25": 0.775, "q75": 0.9, "skewness": -0.935414346693487, "kurtosis": 0.3500000000000014}, "harm_confidence": {"count": 8, "mean": 0.79125, "std": 0.06895909760761915, "min": 0.7, "max": 0.88, "median": 0.8, "q25": 0.7375, "q75": 0.85, "skewness": -0.2810419323870892, "kurtosis": -1.4516742345734763}, "fairness_confidence": {"count": 8, "mean": 0.8525, "std": 0.08647873396720968, "min": 0.75, "max": 0.95, "median": 0.8500000000000001, "q25": 0.7875000000000001, "q75": 0.9275, "skewness": -0.05146712537500577, "kurtosis": -2.187108480225943}, "cheating_confidence": {"count": 8, "mean": 0.775, "std": 0.08864052604279184, "min": 0.65, "max": 0.9, "median": 0.775, "q25": 0.7, "q75": 0.85, "skewness": 0.0, "kurtosis": -1.480991735537191}, "loyalty_confidence": {"count": 8, "mean": 0.6125, "std": 0.09910312089651149, "min": 0.5, "max": 0.8, "median": 0.6, "q25": 0.575, "q75": 0.625, "skewness": 0.8622790552053482, "kurtosis": 0.8404628099173559}, "betrayal_confidence": {"count": 8, "mean": 0.59375, "std": 0.09425459443140463, "min": 0.5, "max": 0.75, "median": 0.6000000000000001, "q25": 0.5, "q75": 0.65, "skewness": 0.40785503653355976, "kurtosis": -1.15758692962299}, "authority_confidence": {"count": 8, "mean": 0.64375, "std": 0.126596941962615, "min": 0.4, "max": 0.8, "median": 0.675, "q25": 0.5875, "q75": 0.7124999999999999, "skewness": -0.9406291976583071, "kurtosis": 0.912382740667752}, "subversion_confidence": {"count": 8, "mean": 0.6187499999999999, "std": 0.15797264681854625, "min": 0.3, "max": 0.8, "median": 0.6, "q25": 0.5875, "q75": 0.75, "skewness": -1.0752297357773075, "kurtosis": 1.7165178042824962}, "sanctity_confidence": {"count": 8, "mean": 0.55625, "std": 0.12082307017169479, "min": 0.4, "max": 0.7, "median": 0.575, "q25": 0.475, "q75": 0.65, "skewness": -0.27461997189283316, "kurtosis": -1.8900765928793883}, "degradation_confidence": {"count": 8, "mean": 0.59375, "std": 0.15221577729375774, "min": 0.3, "max": 0.75, "median": 0.6499999999999999, "q25": 0.5, "q75": 0.7, "skewness": -1.0575950917943342, "kurtosis": 0.5789167696882638}, "liberty_confidence": {"count": 8, "mean": 0.7625, "std": 0.09543135154205276, "min": 0.7, "max": 0.95, "median": 0.7, "q25": 0.7, "q75": 0.8125, "skewness": 1.3355252580279589, "kurtosis": 0.7750865051903109}, "oppression_confidence": {"count": 8, "mean": 0.8037500000000001, "std": 0.07909081579334697, "min": 0.65, "max": 0.9, "median": 0.8, "q25": 0.7875000000000001, "q75": 0.8574999999999999, "skewness": -0.9070757941367833, "kurtosis": 1.1577264754675065}}}}, "errors": ["Task 'validate_analysis_completeness' failed: Summary statistics generation failed: No valid metrics found. Available columns: ['aid', 'care_score', 'care_raw_score', 'care_salience', 'care_confidence', 'harm_score', 'harm_raw_score', 'harm_salience', 'harm_confidence', 'fairness_score', 'fairness_raw_score', 'fairness_salience', 'fairness_confidence', 'cheating_score', 'cheating_raw_score', 'cheating_salience', 'cheating_confidence', 'loyalty_score', 'loyalty_raw_score', 'loyalty_salience', 'loyalty_confidence', 'betrayal_score', 'betrayal_raw_score', 'betrayal_salience', 'betrayal_confidence', 'authority_score', 'authority_raw_score', 'authority_salience', 'authority_confidence', 'subversion_score', 'subversion_raw_score', 'subversion_salience', 'subversion_confidence', 'sanctity_score', 'sanctity_raw_score', 'sanctity_salience', 'sanctity_confidence', 'degradation_score', 'degradation_raw_score', 'degradation_salience', 'degradation_confidence', 'liberty_score', 'liberty_raw_score', 'liberty_salience', 'liberty_confidence', 'oppression_score', 'oppression_raw_score', 'oppression_salience', 'oppression_confidence']"]}, "stage_2_derived_metrics": {"analysis_plan": {"stage": "derived_metrics_analysis", "experiment_summary": "This plan details the calculation of Moral Foundation Tension scores and the Moral Strategic Contradiction Index (MSCI) as specified by the MFT v6.0 framework. It then outlines statistical analyses, including ANOVA and correlation tests, to validate the framework and test the experiment's hypotheses regarding ideological differentiation, moral rhetorical patterns, and framework reliability.", "tasks": {"task_01_calculate_derived_metrics": {"tool": "calculate_derived_metrics", "parameters": {"metric_formulas": {"care_harm_tension": "np.minimum(care_score, harm_score) * abs(care_salience - harm_salience)", "fairness_cheating_tension": "np.minimum(fairness_score, cheating_score) * abs(fairness_salience - cheating_salience)", "loyalty_betrayal_tension": "np.minimum(loyalty_score, betrayal_score) * abs(loyalty_salience - betrayal_salience)", "authority_subversion_tension": "np.minimum(authority_score, subversion_score) * abs(authority_salience - subversion_salience)", "sanctity_degradation_tension": "np.minimum(sanctity_score, degradation_score) * abs(sanctity_salience - degradation_salience)", "liberty_oppression_tension": "np.minimum(liberty_score, oppression_score) * abs(liberty_salience - oppression_salience)", "msci": "(care_harm_tension + fairness_cheating_tension + loyalty_betrayal_tension + authority_subversion_tension + sanctity_degradation_tension + liberty_oppression_tension) / 6"}, "input_columns": ["care_score", "care_salience", "harm_score", "harm_salience", "fairness_score", "fairness_salience", "cheating_score", "cheating_salience", "loyalty_score", "loyalty_salience", "betrayal_score", "betrayal_salience", "authority_score", "authority_salience", "subversion_score", "subversion_salience", "sanctity_score", "sanctity_salience", "degradation_score", "degradation_salience", "liberty_score", "liberty_salience", "oppression_score", "oppression_salience"]}, "purpose": "To compute the core derived metrics (Foundation Pair Tensions and MSCI) as defined in the MFT v6.0 framework specification. These metrics are essential for testing H4."}, "task_02_validate_derived_metrics": {"tool": "validate_calculated_metrics", "parameters": {"validation_rules": ["missing_data_check", "range_check"], "quality_thresholds": {"msci": {"min": 0.0, "max": 1.0}, "care_harm_tension": {"min": 0.0, "max": 1.0}, "fairness_cheating_tension": {"min": 0.0, "max": 1.0}, "loyalty_betrayal_tension": {"min": 0.0, "max": 1.0}, "authority_subversion_tension": {"min": 0.0, "max": 1.0}, "sanctity_degradation_tension": {"min": 0.0, "max": 1.0}, "liberty_oppression_tension": {"min": 0.0, "max": 1.0}}}, "purpose": "To ensure the newly calculated tension and MSCI scores are within their expected [0,1] range and contain no missing data, confirming data integrity before statistical testing."}, "task_03_test_h2_validity_correlation": {"tool": "generate_correlation_matrix", "parameters": {"dimensions": ["care_score", "harm_score", "fairness_score", "cheating_score", "loyalty_score", "betrayal_score", "authority_score", "subversion_score", "sanctity_score", "degradation_score", "liberty_score", "oppression_score"], "correlation_method": "pearson"}, "purpose": "To test H2 (Validity) by examining the inter-correlations between the 12 moral foundation scores to identify patterns consistent with Moral Foundations Theory."}, "task_04_test_h1_h3_reliability_consistency": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["care_score", "harm_score", "fairness_score", "cheating_score", "loyalty_score", "betrayal_score", "authority_score", "subversion_score", "sanctity_score", "degradation_score", "liberty_score", "oppression_score"], "grouping_variable": "aid"}, "purpose": "To test H3 (Consistency) by calculating the variance for each moral foundation score per document across the two evaluations. This data is also foundational for assessing H1 (Reliability)."}, "task_05_test_h5_ideological_differentiation": {"tool": "perform_one_way_anova", "parameters": {"grouping_variable": "ideology", "dependent_variable": "care_score"}, "purpose": "To test H5 (Ideological Differentiation) by determining if mean scores for moral foundations (e.g., Care) differ significantly across ideological groups. This test will be repeated for all 12 foundation scores."}, "task_06_test_h4_tension_analysis": {"tool": "perform_one_way_anova", "parameters": {"grouping_variable": "ideology", "dependent_variable": "msci"}, "purpose": "To test H4 (Tension Analysis) by analyzing whether the calculated Moral Strategic Contradiction Index (MSCI) varies significantly across different ideological positions."}, "task_07_speaker_differentiation_analysis": {"tool": "perform_one_way_anova", "parameters": {"grouping_variable": "speaker", "dependent_variable": "msci"}, "purpose": "To explore variations in moral rhetorical coherence (MSCI) between individual speakers, providing a more granular analysis of discourse patterns."}, "task_08_generate_summary_statistics": {"tool": "create_summary_statistics", "parameters": {"metrics": ["care_score", "harm_score", "fairness_score", "cheating_score", "loyalty_score", "betrayal_score", "authority_score", "subversion_score", "sanctity_score", "degradation_score", "liberty_score", "oppression_score", "msci"], "summary_types": ["mean", "std", "min", "max", "25%", "50%", "75%"]}, "purpose": "To generate comprehensive descriptive statistics for all primary and derived metrics, which will be used in the final report to summarize overall findings."}}}, "results": {"task_01_calculate_derived_metrics": {"type": "derived_metrics_calculation", "success": true, "calculated_metrics": {"care_harm_tension": [0.06999999999999998, 0.059999999999999984, 0.05250000000000005, 0.029999999999999992, 0.12749999999999992, 0.1, 0.030000000000000027, 0.07999999999999999], "loyalty_betrayal_tension": [0.029999999999999992, 0.005000000000000001, 0.012500000000000011, 0.0, 0.08000000000000002, 0.045000000000000005, 0.009999999999999998, 0.019999999999999997], "fairness_cheating_tension": [0.11999999999999997, 0.07999999999999999, 0.15, 0.039999999999999994, 0.21000000000000002, 0.035, 0.03499999999999995, 0.04999999999999999], "liberty_oppression_tension": [0.09999999999999998, 0.10500000000000001, 0.06999999999999998, 0.039999999999999994, 0.027000000000000024, 0.04, 0.014999999999999996, 0.059999999999999984], "authority_subversion_tension": [0.005000000000000001, 0.0, 0.017499999999999995, 0.0, 0.1, 0.015000000000000003, 0.014999999999999996, 0.04999999999999999], "sanctity_degradation_tension": [0.0075, 0.005000000000000001, 0.07, 0.010000000000000002, 0.075, 0.005000000000000001, 0.020000000000000018, 0.06], "msci": [0.05541666666666665, 0.0425, 0.062083333333333345, 0.019999999999999997, 0.10325, 0.04000000000000001, 0.020833333333333332, 0.05333333333333332]}, "successful_calculations": ["care_harm_tension", "loyalty_betrayal_tension", "fairness_cheating_tension", "liberty_oppression_tension", "authority_subversion_tension", "sanctity_degradation_tension", "msci"], "failed_calculations": [], "formulas_used": ["care_harm_tension", "fairness_cheating_tension", "loyalty_betrayal_tension", "authority_subversion_tension", "sanctity_degradation_tension", "liberty_oppression_tension", "msci"], "input_columns": ["care_score", "care_salience", "harm_score", "harm_salience", "fairness_score", "fairness_salience", "cheating_score", "cheating_salience", "loyalty_score", "loyalty_salience", "betrayal_score", "betrayal_salience", "authority_score", "authority_salience", "subversion_score", "subversion_salience", "sanctity_score", "sanctity_salience", "degradation_score", "degradation_salience", "liberty_score", "liberty_salience", "oppression_score", "oppression_salience"], "total_metrics": 7, "success_rate": 1.0}, "task_02_validate_derived_metrics": {"type": "metric_validation", "validation_rules": ["missing_data_check", "range_check"], "results": {"missing_data_check": {"status": "completed", "missing_data_by_column": {"aid": 0, "care_score": 0, "care_raw_score": 0, "care_salience": 0, "care_confidence": 0, "harm_score": 0, "harm_raw_score": 0, "harm_salience": 0, "harm_confidence": 0, "fairness_score": 0, "fairness_raw_score": 0, "fairness_salience": 0, "fairness_confidence": 0, "cheating_score": 0, "cheating_raw_score": 0, "cheating_salience": 0, "cheating_confidence": 0, "loyalty_score": 0, "loyalty_raw_score": 0, "loyalty_salience": 0, "loyalty_confidence": 0, "betrayal_score": 0, "betrayal_raw_score": 0, "betrayal_salience": 0, "betrayal_confidence": 0, "authority_score": 0, "authority_raw_score": 0, "authority_salience": 0, "authority_confidence": 0, "subversion_score": 0, "subversion_raw_score": 0, "subversion_salience": 0, "subversion_confidence": 0, "sanctity_score": 0, "sanctity_raw_score": 0, "sanctity_salience": 0, "sanctity_confidence": 0, "degradation_score": 0, "degradation_raw_score": 0, "degradation_salience": 0, "degradation_confidence": 0, "liberty_score": 0, "liberty_raw_score": 0, "liberty_salience": 0, "liberty_confidence": 0, "oppression_score": 0, "oppression_raw_score": 0, "oppression_salience": 0, "oppression_confidence": 0, "care_harm_tension": 0, "loyalty_betrayal_tension": 0, "fairness_cheating_tension": 0, "liberty_oppression_tension": 0, "authority_subversion_tension": 0, "sanctity_degradation_tension": 0, "msci": 0}, "total_missing": 0}, "range_check": {"status": "completed", "ranges": {"care_score": {"min": 0.3, "max": 0.9, "mean": 0.65625}, "care_raw_score": {"min": 0.3, "max": 0.9, "mean": 0.65625}, "care_salience": {"min": 0.2, "max": 0.95, "mean": 0.64625}, "care_confidence": {"min": 0.6, "max": 0.9, "mean": 0.8}, "harm_score": {"min": 0.2, "max": 0.85, "mean": 0.59375}, "harm_raw_score": {"min": 0.2, "max": 0.85, "mean": 0.59375}, "harm_salience": {"min": 0.1, "max": 0.85, "mean": 0.575}, "harm_confidence": {"min": 0.7, "max": 0.88, "mean": 0.79125}, "fairness_score": {"min": 0.5, "max": 0.95, "mean": 0.70625}, "fairness_raw_score": {"min": 0.5, "max": 0.95, "mean": 0.70625}, "fairness_salience": {"min": 0.4, "max": 0.98, "mean": 0.74125}, "fairness_confidence": {"min": 0.75, "max": 0.95, "mean": 0.8525}, "cheating_score": {"min": 0.1, "max": 0.8, "mean": 0.5874999999999999}, "cheating_raw_score": {"min": 0.1, "max": 0.8, "mean": 0.5874999999999999}, "cheating_salience": {"min": 0.05, "max": 0.85, "mean": 0.5875}, "cheating_confidence": {"min": 0.65, "max": 0.9, "mean": 0.775}, "loyalty_score": {"min": 0.2, "max": 0.6, "mean": 0.3125}, "loyalty_raw_score": {"min": 0.2, "max": 0.6, "mean": 0.3125}, "loyalty_salience": {"min": 0.1, "max": 0.5, "mean": 0.275}, "loyalty_confidence": {"min": 0.5, "max": 0.8, "mean": 0.6125}, "betrayal_score": {"min": 0.1, "max": 0.6, "mean": 0.2625}, "betrayal_raw_score": {"min": 0.1, "max": 0.6, "mean": 0.2625}, "betrayal_salience": {"min": 0.05, "max": 0.5, "mean": 0.2375}, "betrayal_confidence": {"min": 0.5, "max": 0.75, "mean": 0.59375}, "authority_score": {"min": 0.2, "max": 0.7, "mean": 0.36250000000000004}, "authority_raw_score": {"min": 0.2, "max": 0.7, "mean": 0.36250000000000004}, "authority_salience": {"min": 0.1, "max": 0.7, "mean": 0.33125}, "authority_confidence": {"min": 0.4, "max": 0.8, "mean": 0.64375}, "subversion_score": {"min": 0.1, "max": 0.7, "mean": 0.32499999999999996}, "subversion_raw_score": {"min": 0.1, "max": 0.7, "mean": 0.32499999999999996}, "subversion_salience": {"min": 0.05, "max": 0.65, "mean": 0.31875}, "subversion_confidence": {"min": 0.3, "max": 0.8, "mean": 0.6187499999999999}, "sanctity_score": {"min": 0.1, "max": 0.4, "mean": 0.225}, "sanctity_raw_score": {"min": 0.1, "max": 0.4, "mean": 0.225}, "sanctity_salience": {"min": 0.05, "max": 0.5, "mean": 0.2125}, "sanctity_confidence": {"min": 0.4, "max": 0.7, "mean": 0.55625}, "degradation_score": {"min": 0.1, "max": 0.55, "mean": 0.325}, "degradation_raw_score": {"min": 0.1, "max": 0.55, "mean": 0.325}, "degradation_salience": {"min": 0.05, "max": 0.65, "mean": 0.325}, "degradation_confidence": {"min": 0.3, "max": 0.75, "mean": 0.59375}, "liberty_score": {"min": 0.3, "max": 0.95, "mean": 0.56875}, "liberty_raw_score": {"min": 0.3, "max": 0.95, "mean": 0.56875}, "liberty_salience": {"min": 0.3, "max": 0.98, "mean": 0.56}, "liberty_confidence": {"min": 0.7, "max": 0.95, "mean": 0.7625}, "oppression_score": {"min": 0.2, "max": 0.9, "mean": 0.6187499999999999}, "oppression_raw_score": {"min": 0.2, "max": 0.9, "mean": 0.6187499999999999}, "oppression_salience": {"min": 0.1, "max": 0.95, "mean": 0.61875}, "oppression_confidence": {"min": 0.65, "max": 0.9, "mean": 0.8037500000000001}, "care_harm_tension": {"min": 0.029999999999999992, "max": 0.12749999999999992, "mean": 0.06874999999999999}, "loyalty_betrayal_tension": {"min": 0.0, "max": 0.08000000000000002, "mean": 0.0253125}, "fairness_cheating_tension": {"min": 0.03499999999999995, "max": 0.21000000000000002, "mean": 0.09}, "liberty_oppression_tension": {"min": 0.014999999999999996, "max": 0.10500000000000001, "mean": 0.057124999999999995}, "authority_subversion_tension": {"min": 0.0, "max": 0.1, "mean": 0.025312499999999998}, "sanctity_degradation_tension": {"min": 0.005000000000000001, "max": 0.075, "mean": 0.03156250000000001}, "msci": {"min": 0.019999999999999997, "max": 0.10325, "mean": 0.04967708333333333}}}}, "quality_thresholds": {"msci": {"min": 0.0, "max": 1.0}, "care_harm_tension": {"min": 0.0, "max": 1.0}, "fairness_cheating_tension": {"min": 0.0, "max": 1.0}, "loyalty_betrayal_tension": {"min": 0.0, "max": 1.0}, "authority_subversion_tension": {"min": 0.0, "max": 1.0}, "sanctity_degradation_tension": {"min": 0.0, "max": 1.0}, "liberty_oppression_tension": {"min": 0.0, "max": 1.0}}}, "task_03_test_h2_validity_correlation": {"type": "correlation_matrix", "dimensions": ["care_score", "harm_score", "fairness_score", "cheating_score", "loyalty_score", "betrayal_score", "authority_score", "subversion_score", "sanctity_score", "degradation_score", "liberty_score", "oppression_score"], "method": "pearson", "matrix": {"care_score": {"care_score": 1.0, "harm_score": 0.5058632258316952, "fairness_score": 0.7704697623621867, "cheating_score": 0.17376788909305843, "loyalty_score": 0.526556026769533, "betrayal_score": 0.35941264059624245, "authority_score": -0.21158620172618364, "subversion_score": 0.037093301668998456, "sanctity_score": 0.12156613477096632, "degradation_score": 0.2792851761580499, "liberty_score": 0.5509439758786443, "oppression_score": 0.3879959341081296}, "harm_score": {"care_score": 0.5058632258316952, "harm_score": 1.0, "fairness_score": 0.7623876860322034, "cheating_score": 0.8420772811481256, "loyalty_score": -0.3299584384592446, "betrayal_score": 0.7178651144141179, "authority_score": 0.23916307459851271, "subversion_score": 0.5833326858423885, "sanctity_score": 0.37677026947749653, "degradation_score": 0.7331494459958307, "liberty_score": 0.640711541249672, "oppression_score": 0.802562793715029}, "fairness_score": {"care_score": 0.7704697623621867, "harm_score": 0.7623876860322034, "fairness_score": 1.0, "cheating_score": 0.6246102316459323, "loyalty_score": -0.07911986682109616, "betrayal_score": 0.40702999980219506, "authority_score": -0.14510966083298513, "subversion_score": 0.32185730576186444, "sanctity_score": 0.02674204681653991, "degradation_score": 0.5287609688688956, "liberty_score": 0.727830753357958, "oppression_score": 0.7056069193673589}, "cheating_score": {"care_score": 0.17376788909305843, "harm_score": 0.8420772811481256, "fairness_score": 0.6246102316459323, "cheating_score": 1.0, "loyalty_score": -0.6644480826086029, "betrayal_score": 0.4405191620627272, "authority_score": 0.20367830112028026, "subversion_score": 0.509595668843148, "sanctity_score": 0.33893234682166473, "degradation_score": 0.5744218800001306, "liberty_score": 0.47301163713278765, "oppression_score": 0.6961459951894922}, "loyalty_score": {"care_score": 0.526556026769533, "harm_score": -0.3299584384592446, "fairness_score": -0.07911986682109616, "cheating_score": -0.6644480826086029, "loyalty_score": 1.0, "betrayal_score": 0.0544273461923518, "authority_score": -0.15266773130566916, "subversion_score": -0.27684734220107976, "sanctity_score": -0.023669053416557638, "degradation_score": -0.30754270249285137, "liberty_score": 0.0375539078560419, "oppression_score": -0.30767600255408906}, "betrayal_score": {"care_score": 0.35941264059624245, "harm_score": 0.7178651144141179, "fairness_score": 0.40702999980219506, "cheating_score": 0.4405191620627272, "loyalty_score": 0.0544273461923518, "betrayal_score": 1.0, "authority_score": 0.5044931817534571, "subversion_score": 0.813020438055896, "sanctity_score": 0.503703311860163, "degradation_score": 0.6557216763867996, "liberty_score": 0.6227787502168721, "oppression_score": 0.548533226709251}, "authority_score": {"care_score": -0.21158620172618364, "harm_score": 0.23916307459851271, "fairness_score": -0.14510966083298513, "cheating_score": 0.20367830112028026, "loyalty_score": -0.15266773130566916, "betrayal_score": 0.5044931817534571, "authority_score": 1.0, "subversion_score": 0.7601692559990907, "sanctity_score": 0.47095958957269585, "degradation_score": 0.5899601603216614, "liberty_score": 0.38236500119047495, "oppression_score": 0.2791599692430247}, "subversion_score": {"care_score": 0.037093301668998456, "harm_score": 0.5833326858423885, "fairness_score": 0.32185730576186444, "cheating_score": 0.509595668843148, "loyalty_score": -0.27684734220107976, "betrayal_score": 0.813020438055896, "authority_score": 0.7601692559990907, "subversion_score": 1.0, "sanctity_score": 0.5085476277156076, "degradation_score": 0.8235795036461987, "liberty_score": 0.616534716518267, "oppression_score": 0.49803836319113587}, "sanctity_score": {"care_score": 0.12156613477096632, "harm_score": 0.37677026947749653, "fairness_score": 0.02674204681653991, "cheating_score": 0.33893234682166473, "loyalty_score": -0.023669053416557638, "betrayal_score": 0.503703311860163, "authority_score": 0.47095958957269585, "subversion_score": 0.5085476277156076, "sanctity_score": 1.0, "degradation_score": 0.6025948617237673, "liberty_score": -0.05695576313235345, "oppression_score": -0.13386590090151707}, "degradation_score": {"care_score": 0.2792851761580499, "harm_score": 0.7331494459958307, "fairness_score": 0.5287609688688956, "cheating_score": 0.5744218800001306, "loyalty_score": -0.30754270249285137, "betrayal_score": 0.6557216763867996, "authority_score": 0.5899601603216614, "subversion_score": 0.8235795036461987, "sanctity_score": 0.6025948617237673, "degradation_score": 1.0, "liberty_score": 0.5102221571265331, "oppression_score": 0.4736527095962158}, "liberty_score": {"care_score": 0.5509439758786443, "harm_score": 0.640711541249672, "fairness_score": 0.727830753357958, "cheating_score": 0.47301163713278765, "loyalty_score": 0.0375539078560419, "betrayal_score": 0.6227787502168721, "authority_score": 0.38236500119047495, "subversion_score": 0.616534716518267, "sanctity_score": -0.05695576313235345, "degradation_score": 0.5102221571265331, "liberty_score": 1.0, "oppression_score": 0.8659179231257828}, "oppression_score": {"care_score": 0.3879959341081296, "harm_score": 0.802562793715029, "fairness_score": 0.7056069193673589, "cheating_score": 0.6961459951894922, "loyalty_score": -0.30767600255408906, "betrayal_score": 0.548533226709251, "authority_score": 0.2791599692430247, "subversion_score": 0.49803836319113587, "sanctity_score": -0.13386590090151707, "degradation_score": 0.4736527095962158, "liberty_score": 0.8659179231257828, "oppression_score": 1.0}}, "missing_dimensions": []}, "task_04_test_h1_h3_reliability_consistency": {"type": "descriptive_stats_grouped", "grouping_variable": "aid", "groups": {"{artifact_id}": {"care_score": {"count": 8, "mean": 0.65625, "std": 0.21286732957408, "min": 0.3, "max": 0.9}, "harm_score": {"count": 8, "mean": 0.59375, "std": 0.20604697799981717, "min": 0.2, "max": 0.85}, "fairness_score": {"count": 8, "mean": 0.70625, "std": 0.19353386562267894, "min": 0.5, "max": 0.95}, "cheating_score": {"count": 8, "mean": 0.5874999999999999, "std": 0.23413976290119665, "min": 0.1, "max": 0.8}, "loyalty_score": {"count": 8, "mean": 0.3125, "std": 0.1457737973711325, "min": 0.2, "max": 0.6}, "betrayal_score": {"count": 8, "mean": 0.2625, "std": 0.1575481785722341, "min": 0.1, "max": 0.6}, "authority_score": {"count": 8, "mean": 0.36250000000000004, "std": 0.1685018016012207, "min": 0.2, "max": 0.7}, "subversion_score": {"count": 8, "mean": 0.32499999999999996, "std": 0.20354009783964294, "min": 0.1, "max": 0.7}, "sanctity_score": {"count": 8, "mean": 0.225, "std": 0.10350983390135314, "min": 0.1, "max": 0.4}, "degradation_score": {"count": 8, "mean": 0.325, "std": 0.1832250762625809, "min": 0.1, "max": 0.55}, "liberty_score": {"count": 8, "mean": 0.56875, "std": 0.21202678402234265, "min": 0.3, "max": 0.95}, "oppression_score": {"count": 8, "mean": 0.6187499999999999, "std": 0.24485783047077983, "min": 0.2, "max": 0.9}}}}, "task_08_generate_summary_statistics": {"type": "summary_statistics", "metrics": ["care_score", "harm_score", "fairness_score", "cheating_score", "loyalty_score", "betrayal_score", "authority_score", "subversion_score", "sanctity_score", "degradation_score", "liberty_score", "oppression_score", "msci"], "summary_types": ["mean", "std", "min", "max", "25%", "50%", "75%"], "results": {"care_score": {"mean": 0.65625, "std": 0.21286732957408, "min": 0.3, "max": 0.9}, "harm_score": {"mean": 0.59375, "std": 0.20604697799981717, "min": 0.2, "max": 0.85}, "fairness_score": {"mean": 0.70625, "std": 0.19353386562267894, "min": 0.5, "max": 0.95}, "cheating_score": {"mean": 0.5874999999999999, "std": 0.23413976290119665, "min": 0.1, "max": 0.8}, "loyalty_score": {"mean": 0.3125, "std": 0.1457737973711325, "min": 0.2, "max": 0.6}, "betrayal_score": {"mean": 0.2625, "std": 0.1575481785722341, "min": 0.1, "max": 0.6}, "authority_score": {"mean": 0.36250000000000004, "std": 0.1685018016012207, "min": 0.2, "max": 0.7}, "subversion_score": {"mean": 0.32499999999999996, "std": 0.20354009783964294, "min": 0.1, "max": 0.7}, "sanctity_score": {"mean": 0.225, "std": 0.10350983390135314, "min": 0.1, "max": 0.4}, "degradation_score": {"mean": 0.325, "std": 0.1832250762625809, "min": 0.1, "max": 0.55}, "liberty_score": {"mean": 0.56875, "std": 0.21202678402234265, "min": 0.3, "max": 0.95}, "oppression_score": {"mean": 0.6187499999999999, "std": 0.24485783047077983, "min": 0.2, "max": 0.9}, "msci": {"mean": 0.04967708333333333, "std": 0.02653335118673125, "min": 0.019999999999999997, "max": 0.10325}}, "missing_metrics": []}}, "errors": ["Task 'task_05_test_h5_ideological_differentiation' failed: ANOVA failed: Grouping variable 'ideology' not found in DataFrame", "Task 'task_06_test_h4_tension_analysis' failed: ANOVA failed: Grouping variable 'ideology' not found in DataFrame", "Task 'task_07_speaker_differentiation_analysis' failed: ANOVA failed: Grouping variable 'speaker' not found in DataFrame"]}, "combined_summary": "Two-stage execution: 3 raw data results + 5 derived metrics results"}