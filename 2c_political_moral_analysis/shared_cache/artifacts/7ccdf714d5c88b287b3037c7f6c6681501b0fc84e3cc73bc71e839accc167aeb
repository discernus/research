{"stage_1_raw_data": {"analysis_plan": {"stage": "raw_data_collection", "experiment_summary": "Collect raw dimensional scores, salience, confidence, and supporting evidence for each moral foundation from the LLM analysis of political speeches, adhering to the Moral Foundations Theory v7.0 framework and the Intelligent Extractor Schema.", "tasks": {"collect_dimensional_scores": {"tool": "collect_data", "parameters": {"columns": ["care_score", "harm_score", "fairness_score", "cheating_score", "loyalty_score", "betrayal_score", "authority_score", "subversion_score", "sanctity_score", "degradation_score", "liberty_score", "oppression_score"], "identifier": "aid"}, "purpose": "To capture the raw intensity scores for each of the 12 moral foundations as specified by the framework."}, "collect_salience_scores": {"tool": "collect_data", "parameters": {"columns": ["care_salience", "harm_salience", "fairness_salience", "cheating_salience", "loyalty_salience", "betrayal_salience", "authority_salience", "subversion_salience", "sanctity_salience", "degradation_salience", "liberty_salience", "oppression_salience"], "identifier": "aid"}, "purpose": "To capture the rhetorical prominence (salience) for each of the 12 moral foundations, as required by the framework for salience-weighted calculations."}, "collect_confidence_scores": {"tool": "collect_data", "parameters": {"columns": ["care_confidence", "harm_confidence", "fairness_confidence", "cheating_confidence", "loyalty_confidence", "betrayal_confidence", "authority_confidence", "subversion_confidence", "sanctity_confidence", "degradation_confidence", "liberty_confidence", "oppression_confidence"], "identifier": "aid"}, "purpose": "To capture the analytical confidence for each of the 12 moral foundations, as required by the framework for assessing data quality."}, "collect_evidence": {"tool": "collect_data", "parameters": {"columns": ["care_evidence", "harm_evidence", "fairness_evidence", "cheating_evidence", "loyalty_evidence", "betrayal_evidence", "authority_evidence", "subversion_evidence", "sanctity_evidence", "degradation_evidence", "liberty_evidence", "oppression_evidence"], "identifier": "aid"}, "purpose": "To capture the supporting textual evidence (quotes and context) for each moral foundation, as mandated by the framework for audit and replication."}, "validate_score_range": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["care_score", "harm_score", "fairness_score", "cheating_score", "loyalty_score", "betrayal_score", "authority_score", "subversion_score", "sanctity_score", "degradation_score", "liberty_score", "oppression_score"]}, "purpose": "To validate that all collected raw dimensional scores are within the expected range of 0.0 to 1.0, ensuring data integrity."}, "validate_salience_range": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["care_salience", "harm_salience", "fairness_salience", "cheating_salience", "loyalty_salience", "betrayal_salience", "authority_salience", "subversion_salience", "sanctity_salience", "degradation_salience", "liberty_salience", "oppression_salience"]}, "purpose": "To validate that all collected salience scores are within the expected range of 0.0 to 1.0, ensuring data integrity."}, "validate_confidence_range": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["care_confidence", "harm_confidence", "fairness_confidence", "cheating_confidence", "loyalty_confidence", "betrayal_confidence", "authority_confidence", "subversion_confidence", "sanctity_confidence", "degradation_confidence", "liberty_confidence", "oppression_confidence"]}, "purpose": "To validate that all collected confidence scores are within the expected range of 0.0 to 1.0, ensuring data integrity."}, "validate_evidence_completeness": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["care_evidence", "harm_evidence", "fairness_evidence", "cheating_evidence", "loyalty_evidence", "betrayal_evidence", "authority_evidence", "subversion_evidence", "sanctity_evidence", "degradation_evidence", "liberty_evidence", "oppression_evidence"]}, "purpose": "To check for the presence of evidence for each moral foundation, ensuring that the LLM analysis provided the required supporting data."}}}, "results": {"validate_score_range": {"type": "descriptive_stats", "columns_analyzed": ["care_score", "harm_score", "fairness_score", "cheating_score", "loyalty_score", "betrayal_score", "authority_score", "subversion_score", "sanctity_score", "degradation_score", "liberty_score", "oppression_score"], "results": {"care_score": {"count": 8, "mean": 0.58125, "std": 0.2202879608927499, "min": 0.3, "max": 0.85, "median": 0.6499999999999999, "q25": 0.375, "q75": 0.725, "skewness": -0.3067407627465046, "kurtosis": -1.7700274804095226}, "harm_score": {"count": 8, "mean": 0.65, "std": 0.20873770280289228, "min": 0.2, "max": 0.85, "median": 0.675, "q25": 0.6, "q75": 0.8, "skewness": -1.5864289801843032, "kurtosis": 2.99884439666756}, "fairness_score": {"count": 8, "mean": 0.75625, "std": 0.15454426088156292, "min": 0.5, "max": 0.9, "median": 0.7749999999999999, "q25": 0.6749999999999999, "q75": 0.9, "skewness": -0.5811479740485406, "kurtosis": -1.121819547558741}, "cheating_score": {"count": 8, "mean": 0.6499999999999999, "std": 0.249284690951645, "min": 0.1, "max": 0.95, "median": 0.7, "q25": 0.6, "q75": 0.7625, "skewness": -1.659921842246386, "kurtosis": 3.9994054696789476}, "loyalty_score": {"count": 8, "mean": 0.33125, "std": 0.16677080080157916, "min": 0.1, "max": 0.55, "median": 0.35, "q25": 0.25, "q75": 0.42500000000000004, "skewness": -0.3642988690657245, "kurtosis": -0.9699496816779987}, "betrayal_score": {"count": 8, "mean": 0.33749999999999997, "std": 0.1787855858683404, "min": 0.1, "max": 0.6, "median": 0.35, "q25": 0.1875, "q75": 0.4625, "skewness": 0.04687116261334157, "kurtosis": -1.4107924222090453}, "authority_score": {"count": 8, "mean": 0.35625, "std": 0.14985111658862318, "min": 0.2, "max": 0.6, "median": 0.375, "q25": 0.2, "q75": 0.42500000000000004, "skewness": 0.34958488850305275, "kurtosis": -0.9886193771763065}, "subversion_score": {"count": 8, "mean": 0.25625, "std": 0.1498511165886232, "min": 0.1, "max": 0.5, "median": 0.275, "q25": 0.1, "q75": 0.325, "skewness": 0.34958488850305375, "kurtosis": -0.9886193771763052}, "sanctity_score": {"count": 8, "mean": 0.225, "std": 0.09258200997725514, "min": 0.1, "max": 0.35, "median": 0.225, "q25": 0.17500000000000002, "q75": 0.3, "skewness": -0.27003086243366137, "kurtosis": -1.1812500000000008}, "degradation_score": {"count": 8, "mean": 0.33749999999999997, "std": 0.19775525999867324, "min": 0.1, "max": 0.7, "median": 0.32499999999999996, "q25": 0.1875, "q75": 0.42500000000000004, "skewness": 0.7273415455008438, "kurtosis": 0.2017639331957204}, "liberty_score": {"count": 8, "mean": 0.54375, "std": 0.14500615750472706, "min": 0.4, "max": 0.8, "median": 0.5, "q25": 0.4375, "q75": 0.625, "skewness": 0.867523010806272, "kurtosis": -0.3585054160412149}, "oppression_score": {"count": 8, "mean": 0.59375, "std": 0.21619683491802424, "min": 0.2, "max": 0.9, "median": 0.625, "q25": 0.5125000000000001, "q75": 0.7124999999999999, "skewness": -0.6500761801658211, "kurtosis": 0.589512401376016}}}, "validate_salience_range": {"type": "descriptive_stats", "columns_analyzed": ["care_salience", "harm_salience", "fairness_salience", "cheating_salience", "loyalty_salience", "betrayal_salience", "authority_salience", "subversion_salience", "sanctity_salience", "degradation_salience", "liberty_salience", "oppression_salience"], "results": {"care_salience": {"count": 8, "mean": 0.6437499999999999, "std": 0.18791620472966136, "min": 0.4, "max": 0.9, "median": 0.7, "q25": 0.475, "q75": 0.7625, "skewness": -0.2795312148938343, "kurtosis": -1.4514616873454695}, "harm_salience": {"count": 8, "mean": 0.69375, "std": 0.252752702401831, "min": 0.1, "max": 0.9, "median": 0.725, "q25": 0.7, "q75": 0.85, "skewness": -2.2736376657096535, "kurtosis": 5.794067569408737}, "fairness_salience": {"count": 8, "mean": 0.8125, "std": 0.12464234547582247, "min": 0.6, "max": 0.95, "median": 0.825, "q25": 0.7375, "q75": 0.9125, "skewness": -0.525641916711357, "kurtosis": -0.6525564803804977}, "cheating_salience": {"count": 8, "mean": 0.6625, "std": 0.257390753524675, "min": 0.1, "max": 0.9, "median": 0.725, "q25": 0.6499999999999999, "q75": 0.8125, "skewness": -1.775018368404919, "kurtosis": 3.3528149315974165}, "loyalty_salience": {"count": 8, "mean": 0.2875, "std": 0.1552647508520297, "min": 0.1, "max": 0.6, "median": 0.25, "q25": 0.2, "q75": 0.325, "skewness": 1.1879350814160234, "kurtosis": 1.6537283950617292}, "betrayal_salience": {"count": 8, "mean": 0.31875, "std": 0.17100020885534448, "min": 0.0, "max": 0.55, "median": 0.3, "q25": 0.25, "q75": 0.42500000000000004, "skewness": -0.5406002057564955, "kurtosis": 0.8542569780315823}, "authority_salience": {"count": 8, "mean": 0.34375, "std": 0.19167960618848168, "min": 0.1, "max": 0.7, "median": 0.3, "q25": 0.2625, "q75": 0.42500000000000004, "skewness": 0.7356468863419132, "kurtosis": 0.6022077897151874}, "subversion_salience": {"count": 8, "mean": 0.24374999999999997, "std": 0.18407587721216642, "min": 0.0, "max": 0.45, "median": 0.3, "q25": 0.05, "q75": 0.4, "skewness": -0.34892811586510464, "kurtosis": -2.0697839366339106}, "sanctity_salience": {"count": 8, "mean": 0.1875, "std": 0.14078859531733587, "min": 0.05, "max": 0.45, "median": 0.125, "q25": 0.1, "q75": 0.2375, "skewness": 1.209403857510497, "kurtosis": 0.319065010956904}, "degradation_salience": {"count": 8, "mean": 0.325, "std": 0.24201534780139167, "min": 0.0, "max": 0.7, "median": 0.3, "q25": 0.1375, "q75": 0.5125, "skewness": 0.24691036375930164, "kurtosis": -1.1088191552647242}, "liberty_salience": {"count": 8, "mean": 0.5375, "std": 0.16636878141217307, "min": 0.3, "max": 0.85, "median": 0.55, "q25": 0.4375, "q75": 0.6, "skewness": 0.6010743070375288, "kurtosis": 0.9994921956295526}, "oppression_salience": {"count": 8, "mean": 0.6000000000000001, "std": 0.22990681342044403, "min": 0.1, "max": 0.9, "median": 0.65, "q25": 0.6125, "q75": 0.6625, "skewness": -1.5282337488137636, "kurtosis": 3.791453615777945}}}, "validate_confidence_range": {"type": "descriptive_stats", "columns_analyzed": ["care_confidence", "harm_confidence", "fairness_confidence", "cheating_confidence", "loyalty_confidence", "betrayal_confidence", "authority_confidence", "subversion_confidence", "sanctity_confidence", "degradation_confidence", "liberty_confidence", "oppression_confidence"], "results": {"care_confidence": {"count": 8, "mean": 0.8187500000000001, "std": 0.0923405962417707, "min": 0.7, "max": 0.95, "median": 0.8, "q25": 0.775, "q75": 0.9, "skewness": -0.008504821780448217, "kurtosis": -1.212379046627012}, "harm_confidence": {"count": 8, "mean": 0.8400000000000001, "std": 0.07230886134196438, "min": 0.7, "max": 0.92, "median": 0.85, "q25": 0.8, "q75": 0.9, "skewness": -0.9703365967057523, "kurtosis": 0.8211502284332264}, "fairness_confidence": {"count": 8, "mean": 0.88125, "std": 0.07529703086538575, "min": 0.75, "max": 0.95, "median": 0.9, "q25": 0.8375, "q75": 0.95, "skewness": -0.820895896048697, "kurtosis": -0.5423274846549706}, "cheating_confidence": {"count": 8, "mean": 0.80375, "std": 0.1163661094501807, "min": 0.6, "max": 0.98, "median": 0.8, "q25": 0.775, "q75": 0.8625, "skewness": -0.37591615838573317, "kurtosis": 0.5125798910710548}, "loyalty_confidence": {"count": 8, "mean": 0.66875, "std": 0.059386746958271036, "min": 0.6, "max": 0.75, "median": 0.7, "q25": 0.6, "q75": 0.7, "skewness": -0.287751198208317, "kurtosis": -1.746130427816055}, "betrayal_confidence": {"count": 8, "mean": 0.675, "std": 0.07559289460184543, "min": 0.55, "max": 0.75, "median": 0.675, "q25": 0.6375, "q75": 0.75, "skewness": -0.4960783708246124, "kurtosis": -0.9953124999999994}, "authority_confidence": {"count": 8, "mean": 0.6625000000000001, "std": 0.09543135154205276, "min": 0.5, "max": 0.8, "median": 0.675, "q25": 0.6, "q75": 0.7124999999999999, "skewness": -0.30819813646799393, "kurtosis": -0.15501730103805667}, "subversion_confidence": {"count": 8, "mean": 0.60625, "std": 0.10155048005794948, "min": 0.4, "max": 0.7, "median": 0.6, "q25": 0.5875, "q75": 0.7, "skewness": -1.1786942772566402, "kurtosis": 1.7133412042502956}, "sanctity_confidence": {"count": 8, "mean": 0.5562499999999999, "std": 0.07288689868556623, "min": 0.5, "max": 0.7, "median": 0.525, "q25": 0.5, "q75": 0.6, "skewness": 1.1932842730924185, "kurtosis": 0.8628769154720803}, "degradation_confidence": {"count": 8, "mean": 0.6599999999999999, "std": 0.1011364001167306, "min": 0.55, "max": 0.85, "median": 0.625, "q25": 0.595, "q75": 0.7124999999999999, "skewness": 0.9898684521895952, "kurtosis": 0.2930776193002762}, "liberty_confidence": {"count": 8, "mean": 0.7437499999999999, "std": 0.09797047660246576, "min": 0.6, "max": 0.9, "median": 0.7, "q25": 0.7, "q75": 0.8125, "skewness": 0.3821749343635861, "kurtosis": -0.5265029745808549}, "oppression_confidence": {"count": 8, "mean": 0.79125, "std": 0.10575409482109224, "min": 0.6, "max": 0.95, "median": 0.775, "q25": 0.75, "q75": 0.8574999999999999, "skewness": -0.37082281043186327, "kurtosis": 0.7346240369289418}}}}, "errors": ["Unknown tool: collect_data", "Unknown tool: collect_data", "Unknown tool: collect_data", "Unknown tool: collect_data", "Task 'validate_evidence_completeness' failed: Descriptive stats calculation failed: Column 'care_evidence' not found in DataFrame. Available columns: ['aid', 'speaker', 'ideology', 'date', 'context', 'category', 'care_score', 'harm_score', 'fairness_score', 'cheating_score', 'loyalty_score', 'betrayal_score', 'authority_score', 'subversion_score', 'sanctity_score', 'degradation_score', 'liberty_score', 'oppression_score', 'care_salience', 'harm_salience', 'fairness_salience', 'cheating_salience', 'loyalty_salience', 'betrayal_salience', 'authority_salience', 'subversion_salience', 'sanctity_salience', 'degradation_salience', 'liberty_salience', 'oppression_salience', 'care_confidence', 'harm_confidence', 'fairness_confidence', 'cheating_confidence', 'loyalty_confidence', 'betrayal_confidence', 'authority_confidence', 'subversion_confidence', 'sanctity_confidence', 'degradation_confidence', 'liberty_confidence', 'oppression_confidence', 'gasket_version', 'extraction_time_seconds']"]}, "stage_2_derived_metrics": {"analysis_plan": {"stage": "derived_metrics_analysis", "experiment_summary": "This plan outlines the calculation of derived metrics based on the Moral Foundations Theory v7.0 framework and subsequent statistical analysis to test the experiment's hypotheses. It includes calculating foundation pair tensions and the Moral Strategic Contradiction Index (MSCI), followed by ANOVA tests to examine differences across ideological groups and correlation analysis to understand relationships between moral foundations.", "tasks": {"calculate_foundation_pair_tensions": {"tool": "calculate_derived_metrics", "parameters": {"metric_formulas": {"care_harm_tension": "np.minimum(care_score, harm_score) * np.abs(care_salience - harm_salience)", "fairness_cheating_tension": "np.minimum(fairness_score, cheating_score) * np.abs(fairness_salience - cheating_salience)", "loyalty_betrayal_tension": "np.minimum(loyalty_score, betrayal_score) * np.abs(loyalty_salience - betrayal_salience)", "authority_subversion_tension": "np.minimum(authority_score, subversion_score) * np.abs(authority_salience - subversion_salience)", "sanctity_degradation_tension": "np.minimum(sanctity_score, degradation_score) * np.abs(sanctity_salience - degradation_salience)", "liberty_oppression_tension": "np.minimum(liberty_score, oppression_score) * np.abs(liberty_salience - oppression_salience)"}, "input_columns": ["care_score", "harm_score", "fairness_score", "cheating_score", "loyalty_score", "betrayal_score", "authority_score", "subversion_score", "sanctity_score", "degradation_score", "liberty_score", "oppression_score", "care_salience", "harm_salience", "fairness_salience", "cheating_salience", "loyalty_salience", "betrayal_salience", "authority_salience", "subversion_salience", "sanctity_salience", "degradation_salience", "liberty_salience", "oppression_salience"]}, "purpose": "Calculate the tension scores for each of the six moral foundation pairs as defined in the framework."}, "calculate_msci": {"tool": "calculate_derived_metrics", "parameters": {"metric_formulas": {"moral_strategic_contradiction_index": "(care_harm_tension + fairness_cheating_tension + loyalty_betrayal_tension + authority_subversion_tension + sanctity_degradation_tension + liberty_oppression_tension) / 6"}, "input_columns": ["care_harm_tension", "fairness_cheating_tension", "loyalty_betrayal_tension", "authority_subversion_tension", "sanctity_degradation_tension", "liberty_oppression_tension"]}, "purpose": "Calculate the Moral Strategic Contradiction Index (MSCI) by averaging the foundation pair tensions."}, "validate_derived_metrics": {"tool": "validate_calculated_metrics", "parameters": {"validation_rules": ["missing_data_check", "range_check", "consistency_check"], "quality_thresholds": {"missing_data_check": {"max_missing_percentage": 0.05}, "range_check": {"care_harm_tension": [0.0, 1.0], "fairness_cheating_tension": [0.0, 1.0], "loyalty_betrayal_tension": [0.0, 1.0], "authority_subversion_tension": [0.0, 1.0], "sanctity_degradation_tension": [0.0, 1.0], "liberty_oppression_tension": [0.0, 1.0], "moral_strategic_contradiction_index": [0.0, 1.0]}, "consistency_check": {"moral_strategic_contradiction_index": "calculated_value >= 0 and calculated_value <= 1"}}}, "purpose": "Validate the calculated derived metrics (tensions and MSCI) for data integrity and adherence to expected ranges."}, "analyze_ideological_variation_care_harm": {"tool": "perform_one_way_anova", "parameters": {"grouping_variable": "ideology", "dependent_variable": "care_harm_tension"}, "purpose": "Test Hypothesis H5: Examine if there are significant differences in Care/Harm tension across different ideologies."}, "analyze_ideological_variation_fairness_cheating": {"tool": "perform_one_way_anova", "parameters": {"grouping_variable": "ideology", "dependent_variable": "fairness_cheating_tension"}, "purpose": "Test Hypothesis H5: Examine if there are significant differences in Fairness/Cheating tension across different ideologies."}, "analyze_ideological_variation_loyalty_betrayal": {"tool": "perform_one_way_anova", "parameters": {"grouping_variable": "ideology", "dependent_variable": "loyalty_betrayal_tension"}, "purpose": "Test Hypothesis H5: Examine if there are significant differences in Loyalty/Betrayal tension across different ideologies."}, "analyze_ideological_variation_authority_subversion": {"tool": "perform_one_way_anova", "parameters": {"grouping_variable": "ideology", "dependent_variable": "authority_subversion_tension"}, "purpose": "Test Hypothesis H5: Examine if there are significant differences in Authority/Subversion tension across different ideologies."}, "analyze_ideological_variation_sanctity_degradation": {"tool": "perform_one_way_anova", "parameters": {"grouping_variable": "ideology", "dependent_variable": "sanctity_degradation_tension"}, "purpose": "Test Hypothesis H5: Examine if there are significant differences in Sanctity/Degradation tension across different ideologies."}, "analyze_ideological_variation_liberty_oppression": {"tool": "perform_one_way_anova", "parameters": {"grouping_variable": "ideology", "dependent_variable": "liberty_oppression_tension"}, "purpose": "Test Hypothesis H5: Examine if there are significant differences in Liberty/Oppression tension across different ideologies."}, "analyze_ideological_variation_msci": {"tool": "perform_one_way_anova", "parameters": {"grouping_variable": "ideology", "dependent_variable": "moral_strategic_contradiction_index"}, "purpose": "Test Hypothesis H4 and H5: Examine if there are significant differences in overall moral tension (MSCI) across different ideologies."}, "analyze_speaker_variation_care": {"tool": "perform_one_way_anova", "parameters": {"grouping_variable": "speaker", "dependent_variable": "care_score"}, "purpose": "Test Hypothesis H5: Examine if there are significant differences in Care scores across different speakers."}, "analyze_speaker_variation_fairness": {"tool": "perform_one_way_anova", "parameters": {"grouping_variable": "speaker", "dependent_variable": "fairness_score"}, "purpose": "Test Hypothesis H5: Examine if there are significant differences in Fairness scores across different speakers."}, "analyze_speaker_variation_authority": {"tool": "perform_one_way_anova", "parameters": {"grouping_variable": "speaker", "dependent_variable": "authority_score"}, "purpose": "Test Hypothesis H5: Examine if there are significant differences in Authority scores across different speakers."}, "analyze_speaker_variation_liberty": {"tool": "perform_one_way_anova", "parameters": {"grouping_variable": "speaker", "dependent_variable": "liberty_score"}, "purpose": "Test Hypothesis H5: Examine if there are significant differences in Liberty scores across different speakers."}, "analyze_speaker_variation_msci": {"tool": "perform_one_way_anova", "parameters": {"grouping_variable": "speaker", "dependent_variable": "moral_strategic_contradiction_index"}, "purpose": "Test Hypothesis H4: Examine if there are significant differences in overall moral tension (MSCI) across different speakers."}, "correlate_moral_foundations": {"tool": "generate_correlation_matrix", "parameters": {"dimensions": ["care_score", "harm_score", "fairness_score", "cheating_score", "loyalty_score", "betrayal_score", "authority_score", "subversion_score", "sanctity_score", "degradation_score", "liberty_score", "oppression_score"], "correlation_method": "pearson"}, "purpose": "Test Hypothesis H2: Examine correlational patterns between moral foundations to validate theoretical expectations."}, "correlate_tensions_with_msci": {"tool": "generate_correlation_matrix", "parameters": {"dimensions": ["care_harm_tension", "fairness_cheating_tension", "loyalty_betrayal_tension", "authority_subversion_tension", "sanctity_degradation_tension", "liberty_oppression_tension", "moral_strategic_contradiction_index"], "correlation_method": "pearson"}, "purpose": "Explore relationships between individual foundation pair tensions and the overall MSCI, supporting tension analysis validation."}, "summarize_all_metrics": {"tool": "create_summary_statistics", "parameters": {"metrics": ["care_score", "harm_score", "fairness_score", "cheating_score", "loyalty_score", "betrayal_score", "authority_score", "subversion_score", "sanctity_score", "degradation_score", "liberty_score", "oppression_score", "care_harm_tension", "fairness_cheating_tension", "loyalty_betrayal_tension", "authority_subversion_tension", "sanctity_degradation_tension", "liberty_oppression_tension", "moral_strategic_contradiction_index"], "summary_types": ["mean", "std", "min", "max"]}, "purpose": "Provide descriptive statistics for all raw dimensional scores and calculated derived metrics."}}}, "results": {"calculate_foundation_pair_tensions": {"type": "derived_metrics_calculation", "success": true, "calculated_metrics": {"care_harm_tension": [0.040000000000000036, 0.06999999999999998, 0.03750000000000003, 0.07999999999999999, 0.12000000000000004, 0.14, 0.08999999999999998, 0.08999999999999998], "loyalty_betrayal_tension": [0.040000000000000015, 0.029999999999999992, 0.014999999999999996, 0.02249999999999997, 0.04999999999999999, 0.020000000000000004, 0.004999999999999999, 0.02], "fairness_cheating_tension": [0.04500000000000004, 0.040000000000000036, 0.26999999999999996, 0.07500000000000001, 0.175, 0.06, 0.03500000000000003, 0.06000000000000005], "liberty_oppression_tension": [0.03500000000000003, 0.09000000000000001, 0.13499999999999998, 0.08000000000000002, 0.040000000000000036, 0.04, 0.025000000000000022, 0.039999999999999994], "authority_subversion_tension": [0.01, 0.005000000000000001, 0.014999999999999996, 0.09999999999999998, 0.040000000000000015, 0.04000000000000001, 0.009999999999999998, 0.029999999999999992], "sanctity_degradation_tension": [0.005000000000000001, 0.009999999999999998, 0.0375, 0.06000000000000002, 0.14999999999999997, 0.010000000000000002, 0.017499999999999995, 0.02]}, "successful_calculations": ["care_harm_tension", "loyalty_betrayal_tension", "fairness_cheating_tension", "liberty_oppression_tension", "authority_subversion_tension", "sanctity_degradation_tension"], "failed_calculations": [], "formulas_used": ["care_harm_tension", "fairness_cheating_tension", "loyalty_betrayal_tension", "authority_subversion_tension", "sanctity_degradation_tension", "liberty_oppression_tension"], "input_columns": ["care_score", "harm_score", "fairness_score", "cheating_score", "loyalty_score", "betrayal_score", "authority_score", "subversion_score", "sanctity_score", "degradation_score", "liberty_score", "oppression_score", "care_salience", "harm_salience", "fairness_salience", "cheating_salience", "loyalty_salience", "betrayal_salience", "authority_salience", "subversion_salience", "sanctity_salience", "degradation_salience", "liberty_salience", "oppression_salience"], "total_metrics": 6, "success_rate": 1.0}, "calculate_msci": {"type": "derived_metrics_calculation", "success": true, "calculated_metrics": {"moral_strategic_contradiction_index": [0.029166666666666688, 0.04083333333333334, 0.085, 0.06958333333333333, 0.09583333333333334, 0.051666666666666666, 0.03041666666666667, 0.043333333333333335]}, "successful_calculations": ["moral_strategic_contradiction_index"], "failed_calculations": [], "formulas_used": ["moral_strategic_contradiction_index"], "input_columns": ["care_harm_tension", "fairness_cheating_tension", "loyalty_betrayal_tension", "authority_subversion_tension", "sanctity_degradation_tension", "liberty_oppression_tension"], "total_metrics": 1, "success_rate": 1.0}, "validate_derived_metrics": {"type": "metric_validation", "validation_rules": ["missing_data_check", "range_check", "consistency_check"], "results": {"missing_data_check": {"status": "completed", "missing_data_by_column": {"aid": 0, "speaker": 0, "ideology": 0, "date": 0, "context": 0, "category": 0, "care_score": 0, "harm_score": 0, "fairness_score": 0, "cheating_score": 0, "loyalty_score": 0, "betrayal_score": 0, "authority_score": 0, "subversion_score": 0, "sanctity_score": 0, "degradation_score": 0, "liberty_score": 0, "oppression_score": 0, "care_salience": 0, "harm_salience": 0, "fairness_salience": 0, "cheating_salience": 0, "loyalty_salience": 0, "betrayal_salience": 0, "authority_salience": 0, "subversion_salience": 0, "sanctity_salience": 0, "degradation_salience": 0, "liberty_salience": 0, "oppression_salience": 0, "care_confidence": 0, "harm_confidence": 0, "fairness_confidence": 0, "cheating_confidence": 0, "loyalty_confidence": 0, "betrayal_confidence": 0, "authority_confidence": 0, "subversion_confidence": 0, "sanctity_confidence": 0, "degradation_confidence": 0, "liberty_confidence": 0, "oppression_confidence": 0, "gasket_version": 0, "extraction_time_seconds": 0, "care_harm_tension": 0, "loyalty_betrayal_tension": 0, "fairness_cheating_tension": 0, "liberty_oppression_tension": 0, "authority_subversion_tension": 0, "sanctity_degradation_tension": 0, "moral_strategic_contradiction_index": 0}, "total_missing": 0}, "range_check": {"status": "completed", "ranges": {"care_score": {"min": 0.3, "max": 0.85, "mean": 0.58125}, "harm_score": {"min": 0.2, "max": 0.85, "mean": 0.65}, "fairness_score": {"min": 0.5, "max": 0.9, "mean": 0.75625}, "cheating_score": {"min": 0.1, "max": 0.95, "mean": 0.6499999999999999}, "loyalty_score": {"min": 0.1, "max": 0.55, "mean": 0.33125}, "betrayal_score": {"min": 0.1, "max": 0.6, "mean": 0.33749999999999997}, "authority_score": {"min": 0.2, "max": 0.6, "mean": 0.35625}, "subversion_score": {"min": 0.1, "max": 0.5, "mean": 0.25625}, "sanctity_score": {"min": 0.1, "max": 0.35, "mean": 0.225}, "degradation_score": {"min": 0.1, "max": 0.7, "mean": 0.33749999999999997}, "liberty_score": {"min": 0.4, "max": 0.8, "mean": 0.54375}, "oppression_score": {"min": 0.2, "max": 0.9, "mean": 0.59375}, "care_salience": {"min": 0.4, "max": 0.9, "mean": 0.6437499999999999}, "harm_salience": {"min": 0.1, "max": 0.9, "mean": 0.69375}, "fairness_salience": {"min": 0.6, "max": 0.95, "mean": 0.8125}, "cheating_salience": {"min": 0.1, "max": 0.9, "mean": 0.6625}, "loyalty_salience": {"min": 0.1, "max": 0.6, "mean": 0.2875}, "betrayal_salience": {"min": 0.0, "max": 0.55, "mean": 0.31875}, "authority_salience": {"min": 0.1, "max": 0.7, "mean": 0.34375}, "subversion_salience": {"min": 0.0, "max": 0.45, "mean": 0.24374999999999997}, "sanctity_salience": {"min": 0.05, "max": 0.45, "mean": 0.1875}, "degradation_salience": {"min": 0.0, "max": 0.7, "mean": 0.325}, "liberty_salience": {"min": 0.3, "max": 0.85, "mean": 0.5375}, "oppression_salience": {"min": 0.1, "max": 0.9, "mean": 0.6000000000000001}, "care_confidence": {"min": 0.7, "max": 0.95, "mean": 0.8187500000000001}, "harm_confidence": {"min": 0.7, "max": 0.92, "mean": 0.8400000000000001}, "fairness_confidence": {"min": 0.75, "max": 0.95, "mean": 0.88125}, "cheating_confidence": {"min": 0.6, "max": 0.98, "mean": 0.80375}, "loyalty_confidence": {"min": 0.6, "max": 0.75, "mean": 0.66875}, "betrayal_confidence": {"min": 0.55, "max": 0.75, "mean": 0.675}, "authority_confidence": {"min": 0.5, "max": 0.8, "mean": 0.6625000000000001}, "subversion_confidence": {"min": 0.4, "max": 0.7, "mean": 0.60625}, "sanctity_confidence": {"min": 0.5, "max": 0.7, "mean": 0.5562499999999999}, "degradation_confidence": {"min": 0.55, "max": 0.85, "mean": 0.6599999999999999}, "liberty_confidence": {"min": 0.6, "max": 0.9, "mean": 0.7437499999999999}, "oppression_confidence": {"min": 0.6, "max": 0.95, "mean": 0.79125}, "extraction_time_seconds": {"min": 1.256606101989746, "max": 1.603365182876587, "mean": 1.4070389568805695}, "care_harm_tension": {"min": 0.03750000000000003, "max": 0.14, "mean": 0.08343750000000001}, "loyalty_betrayal_tension": {"min": 0.004999999999999999, "max": 0.04999999999999999, "mean": 0.025312499999999995}, "fairness_cheating_tension": {"min": 0.03500000000000003, "max": 0.26999999999999996, "mean": 0.09500000000000001}, "liberty_oppression_tension": {"min": 0.025000000000000022, "max": 0.13499999999999998, "mean": 0.06062500000000002}, "authority_subversion_tension": {"min": 0.005000000000000001, "max": 0.09999999999999998, "mean": 0.03125}, "sanctity_degradation_tension": {"min": 0.005000000000000001, "max": 0.14999999999999997, "mean": 0.03874999999999999}, "moral_strategic_contradiction_index": {"min": 0.029166666666666688, "max": 0.09583333333333334, "mean": 0.05572916666666668}}}, "consistency_check": {"status": "completed", "notes": "Basic consistency check completed"}}, "quality_thresholds": {"missing_data_check": {"max_missing_percentage": 0.05}, "range_check": {"care_harm_tension": [0.0, 1.0], "fairness_cheating_tension": [0.0, 1.0], "loyalty_betrayal_tension": [0.0, 1.0], "authority_subversion_tension": [0.0, 1.0], "sanctity_degradation_tension": [0.0, 1.0], "liberty_oppression_tension": [0.0, 1.0], "moral_strategic_contradiction_index": [0.0, 1.0]}, "consistency_check": {"moral_strategic_contradiction_index": "calculated_value >= 0 and calculated_value <= 1"}}}, "analyze_ideological_variation_care_harm": {"type": "one_way_anova", "grouping_variable": "ideology", "dependent_variable": "care_harm_tension", "groups": {"Civil Rights Activist": {"n": 1, "mean": 0.12000000000000004, "std": 0.0}, "Conservative": {"n": 2, "mean": 0.11499999999999999, "std": 0.025000000000000015}, "Hardline Conservative": {"n": 1, "mean": 0.08999999999999998, "std": 0.0}, "Liberal": {"n": 1, "mean": 0.03750000000000003, "std": 0.0}, "National Conservative": {"n": 1, "mean": 0.07999999999999999, "std": 0.0}, "Progressive": {"n": 2, "mean": 0.05500000000000001, "std": 0.014999999999999972}}, "f_statistic": 1.6733455882352954, "p_value": 0.414826210813833, "significant": "False"}, "analyze_ideological_variation_fairness_cheating": {"type": "one_way_anova", "grouping_variable": "ideology", "dependent_variable": "fairness_cheating_tension", "groups": {"Civil Rights Activist": {"n": 1, "mean": 0.175, "std": 0.0}, "Conservative": {"n": 2, "mean": 0.047500000000000014, "std": 0.012499999999999983}, "Hardline Conservative": {"n": 1, "mean": 0.06000000000000005, "std": 0.0}, "Liberal": {"n": 1, "mean": 0.26999999999999996, "std": 0.0}, "National Conservative": {"n": 1, "mean": 0.07500000000000001, "std": 0.0}, "Progressive": {"n": 2, "mean": 0.04250000000000004, "std": 0.0025000000000000022}}, "f_statistic": 59.90769230769118, "p_value": 0.016499238748955373, "significant": "True"}, "analyze_ideological_variation_loyalty_betrayal": {"type": "one_way_anova", "grouping_variable": "ideology", "dependent_variable": "loyalty_betrayal_tension", "groups": {"Civil Rights Activist": {"n": 1, "mean": 0.04999999999999999, "std": 0.0}, "Conservative": {"n": 2, "mean": 0.0125, "std": 0.007500000000000002}, "Hardline Conservative": {"n": 1, "mean": 0.02, "std": 0.0}, "Liberal": {"n": 1, "mean": 0.014999999999999996, "std": 0.0}, "National Conservative": {"n": 1, "mean": 0.02249999999999997, "std": 0.0}, "Progressive": {"n": 2, "mean": 0.035, "std": 0.005000000000000011}}, "f_statistic": 3.1211538461538395, "p_value": 0.2602662411794169, "significant": "False"}, "analyze_ideological_variation_authority_subversion": {"type": "one_way_anova", "grouping_variable": "ideology", "dependent_variable": "authority_subversion_tension", "groups": {"Civil Rights Activist": {"n": 1, "mean": 0.040000000000000015, "std": 0.0}, "Conservative": {"n": 2, "mean": 0.025, "std": 0.015000000000000005}, "Hardline Conservative": {"n": 1, "mean": 0.029999999999999992, "std": 0.0}, "Liberal": {"n": 1, "mean": 0.014999999999999996, "std": 0.0}, "National Conservative": {"n": 1, "mean": 0.09999999999999998, "std": 0.0}, "Progressive": {"n": 2, "mean": 0.007500000000000001, "std": 0.0024999999999999996}}, "f_statistic": 5.427027027027033, "p_value": 0.16288065165560706, "significant": "False"}, "analyze_ideological_variation_sanctity_degradation": {"type": "one_way_anova", "grouping_variable": "ideology", "dependent_variable": "sanctity_degradation_tension", "groups": {"Civil Rights Activist": {"n": 1, "mean": 0.14999999999999997, "std": 0.0}, "Conservative": {"n": 2, "mean": 0.013749999999999998, "std": 0.0037499999999999964}, "Hardline Conservative": {"n": 1, "mean": 0.02, "std": 0.0}, "Liberal": {"n": 1, "mean": 0.0375, "std": 0.0}, "National Conservative": {"n": 1, "mean": 0.06000000000000002, "std": 0.0}, "Progressive": {"n": 2, "mean": 0.0075, "std": 0.0024999999999999988}}, "f_statistic": 161.32307692306708, "p_value": 0.006171943801016203, "significant": "True"}, "analyze_ideological_variation_liberty_oppression": {"type": "one_way_anova", "grouping_variable": "ideology", "dependent_variable": "liberty_oppression_tension", "groups": {"Civil Rights Activist": {"n": 1, "mean": 0.040000000000000036, "std": 0.0}, "Conservative": {"n": 2, "mean": 0.032500000000000015, "std": 0.007499999999999989}, "Hardline Conservative": {"n": 1, "mean": 0.039999999999999994, "std": 0.0}, "Liberal": {"n": 1, "mean": 0.13499999999999998, "std": 0.0}, "National Conservative": {"n": 1, "mean": 0.08000000000000002, "std": 0.0}, "Progressive": {"n": 2, "mean": 0.06250000000000003, "std": 0.02749999999999999}}, "f_statistic": 2.0546153846153836, "p_value": 0.3589857125015453, "significant": "False"}, "analyze_ideological_variation_msci": {"type": "one_way_anova", "grouping_variable": "ideology", "dependent_variable": "moral_strategic_contradiction_index", "groups": {"Civil Rights Activist": {"n": 1, "mean": 0.09583333333333334, "std": 0.0}, "Conservative": {"n": 2, "mean": 0.04104166666666667, "std": 0.010624999999999997}, "Hardline Conservative": {"n": 1, "mean": 0.043333333333333335, "std": 0.0}, "Liberal": {"n": 1, "mean": 0.085, "std": 0.0}, "National Conservative": {"n": 1, "mean": 0.06958333333333333, "std": 0.0}, "Progressive": {"n": 2, "mean": 0.03500000000000002, "std": 0.005833333333333326}}, "f_statistic": 5.583456425406213, "p_value": 0.15884216153415603, "significant": "False"}, "analyze_speaker_variation_care": {"type": "one_way_anova", "grouping_variable": "speaker", "dependent_variable": "care_score", "groups": {"Alexandria Ocasio-Cortez": {"n": 1, "mean": 0.8, "std": 0.0}, "Bernie Sanders": {"n": 1, "mean": 0.7, "std": 0.0}, "Cory Booker": {"n": 1, "mean": 0.85, "std": 0.0}, "J.D. Vance": {"n": 1, "mean": 0.4, "std": 0.0}, "John Lewis": {"n": 1, "mean": 0.6, "std": 0.0}, "John McCain": {"n": 1, "mean": 0.7, "std": 0.0}, "Mitt Romney": {"n": 1, "mean": 0.3, "std": 0.0}, "Steve King": {"n": 1, "mean": 0.3, "std": 0.0}}, "f_statistic": NaN, "p_value": NaN, "significant": "False"}, "analyze_speaker_variation_fairness": {"type": "one_way_anova", "grouping_variable": "speaker", "dependent_variable": "fairness_score", "groups": {"Alexandria Ocasio-Cortez": {"n": 1, "mean": 0.9, "std": 0.0}, "Bernie Sanders": {"n": 1, "mean": 0.85, "std": 0.0}, "Cory Booker": {"n": 1, "mean": 0.9, "std": 0.0}, "J.D. Vance": {"n": 1, "mean": 0.5, "std": 0.0}, "John Lewis": {"n": 1, "mean": 0.9, "std": 0.0}, "John McCain": {"n": 1, "mean": 0.6, "std": 0.0}, "Mitt Romney": {"n": 1, "mean": 0.7, "std": 0.0}, "Steve King": {"n": 1, "mean": 0.7, "std": 0.0}}, "f_statistic": NaN, "p_value": NaN, "significant": "False"}, "analyze_speaker_variation_authority": {"type": "one_way_anova", "grouping_variable": "speaker", "dependent_variable": "authority_score", "groups": {"Alexandria Ocasio-Cortez": {"n": 1, "mean": 0.2, "std": 0.0}, "Bernie Sanders": {"n": 1, "mean": 0.2, "std": 0.0}, "Cory Booker": {"n": 1, "mean": 0.35, "std": 0.0}, "J.D. Vance": {"n": 1, "mean": 0.6, "std": 0.0}, "John Lewis": {"n": 1, "mean": 0.4, "std": 0.0}, "John McCain": {"n": 1, "mean": 0.5, "std": 0.0}, "Mitt Romney": {"n": 1, "mean": 0.2, "std": 0.0}, "Steve King": {"n": 1, "mean": 0.4, "std": 0.0}}, "f_statistic": NaN, "p_value": NaN, "significant": "False"}, "analyze_speaker_variation_liberty": {"type": "one_way_anova", "grouping_variable": "speaker", "dependent_variable": "liberty_score", "groups": {"Alexandria Ocasio-Cortez": {"n": 1, "mean": 0.7, "std": 0.0}, "Bernie Sanders": {"n": 1, "mean": 0.6, "std": 0.0}, "Cory Booker": {"n": 1, "mean": 0.45, "std": 0.0}, "J.D. Vance": {"n": 1, "mean": 0.4, "std": 0.0}, "John Lewis": {"n": 1, "mean": 0.8, "std": 0.0}, "John McCain": {"n": 1, "mean": 0.4, "std": 0.0}, "Mitt Romney": {"n": 1, "mean": 0.5, "std": 0.0}, "Steve King": {"n": 1, "mean": 0.5, "std": 0.0}}, "f_statistic": NaN, "p_value": NaN, "significant": "False"}, "analyze_speaker_variation_msci": {"type": "one_way_anova", "grouping_variable": "speaker", "dependent_variable": "moral_strategic_contradiction_index", "groups": {"Alexandria Ocasio-Cortez": {"n": 1, "mean": 0.029166666666666688, "std": 0.0}, "Bernie Sanders": {"n": 1, "mean": 0.04083333333333334, "std": 0.0}, "Cory Booker": {"n": 1, "mean": 0.085, "std": 0.0}, "J.D. Vance": {"n": 1, "mean": 0.06958333333333333, "std": 0.0}, "John Lewis": {"n": 1, "mean": 0.09583333333333334, "std": 0.0}, "John McCain": {"n": 1, "mean": 0.051666666666666666, "std": 0.0}, "Mitt Romney": {"n": 1, "mean": 0.03041666666666667, "std": 0.0}, "Steve King": {"n": 1, "mean": 0.043333333333333335, "std": 0.0}}, "f_statistic": NaN, "p_value": NaN, "significant": "False"}, "correlate_moral_foundations": {"type": "correlation_matrix", "dimensions": ["care_score", "harm_score", "fairness_score", "cheating_score", "loyalty_score", "betrayal_score", "authority_score", "subversion_score", "sanctity_score", "degradation_score", "liberty_score", "oppression_score"], "method": "pearson", "matrix": {"care_score": {"care_score": 1.0, "harm_score": 0.23300839094505413, "fairness_score": 0.6018953975774185, "cheating_score": -0.04552538605799927, "loyalty_score": 0.46541457392214225, "betrayal_score": 0.2924478431815391, "authority_score": -0.21232488026017773, "subversion_score": -0.396249617300841, "sanctity_score": -0.27142903256261647, "degradation_score": -0.2357007752031238, "liberty_score": 0.241780280739929, "oppression_score": 0.25965199045422155}, "harm_score": {"care_score": 0.23300839094505413, "harm_score": 1.0, "fairness_score": 0.7417592824862987, "cheating_score": 0.8991181325291459, "loyalty_score": 0.2770032209411236, "betrayal_score": 0.7464542063808383, "authority_score": -0.5480527017022819, "subversion_score": 0.2169375277571534, "sanctity_score": -0.05544159532159278, "degradation_score": 0.39798880568780254, "liberty_score": 0.6843568492392639, "oppression_score": 0.9101009708952874}, "fairness_score": {"care_score": 0.6018953975774185, "harm_score": 0.7417592824862987, "fairness_score": 1.0, "cheating_score": 0.4727849620783072, "loyalty_score": 0.08833834564548647, "betrayal_score": 0.4556335613785239, "authority_score": -0.6804775815186571, "subversion_score": -0.06361405153007278, "sanctity_score": -0.2121687449272099, "degradation_score": 0.1080942955648734, "liberty_score": 0.7350874726695746, "oppression_score": 0.6747472858074648}, "cheating_score": {"care_score": -0.04552538605799927, "harm_score": 0.8991181325291459, "fairness_score": 0.4727849620783072, "cheating_score": 1.0, "loyalty_score": 0.12885984513779156, "betrayal_score": 0.6330542802144302, "authority_score": -0.5831982496116814, "subversion_score": 0.11472752451377337, "sanctity_score": -0.015474611514754284, "degradation_score": 0.3115206008654232, "liberty_score": 0.5631638528423621, "oppression_score": 0.7885767890421101}, "loyalty_score": {"care_score": 0.46541457392214225, "harm_score": 0.2770032209411236, "fairness_score": 0.08833834564548647, "cheating_score": 0.12885984513779156, "loyalty_score": 1.0, "betrayal_score": 0.7576174731270386, "authority_score": 0.43408847721740773, "subversion_score": 0.3769245625221115, "sanctity_score": 0.2197449759781319, "degradation_score": 0.47918938126261135, "liberty_score": 0.23075734638921033, "oppression_score": 0.5212724010554457}, "betrayal_score": {"care_score": 0.2924478431815391, "harm_score": 0.7464542063808383, "fairness_score": 0.4556335613785239, "cheating_score": 0.6330542802144302, "loyalty_score": 0.7576174731270386, "betrayal_score": 1.0, "authority_score": -0.036659131952753644, "subversion_score": 0.4032504514802885, "sanctity_score": 0.04315318520021028, "degradation_score": 0.5808303046149651, "liberty_score": 0.7266838128702222, "oppression_score": 0.8847058879792479}, "authority_score": {"care_score": -0.21232488026017773, "harm_score": -0.5480527017022819, "fairness_score": -0.6804775815186571, "cheating_score": -0.5831982496116814, "loyalty_score": 0.43408847721740773, "betrayal_score": -0.036659131952753644, "authority_score": 1.0, "subversion_score": 0.4751491053677933, "sanctity_score": 0.16732804492658393, "degradation_score": 0.19584266336293069, "liberty_score": -0.47458885341150986, "oppression_score": -0.37343236706841393}, "subversion_score": {"care_score": -0.396249617300841, "harm_score": 0.2169375277571534, "fairness_score": -0.06361405153007278, "cheating_score": 0.11472752451377337, "loyalty_score": 0.3769245625221115, "betrayal_score": 0.4032504514802885, "authority_score": 0.4751491053677933, "subversion_score": 1.0, "sanctity_score": 0.5277269109223036, "degradation_score": 0.858694754745158, "liberty_score": 0.1664142732741662, "oppression_score": 0.39823599292535683}, "sanctity_score": {"care_score": -0.27142903256261647, "harm_score": -0.05544159532159278, "fairness_score": -0.2121687449272099, "cheating_score": -0.015474611514754284, "loyalty_score": 0.2197449759781319, "betrayal_score": 0.04315318520021028, "authority_score": 0.16732804492658393, "subversion_score": 0.5277269109223036, "sanctity_score": 1.0, "degradation_score": 0.7412605989088268, "liberty_score": -0.11971303267014305, "oppression_score": 0.22303655315507898}, "degradation_score": {"care_score": -0.2357007752031238, "harm_score": 0.39798880568780254, "fairness_score": 0.1080942955648734, "cheating_score": 0.3115206008654232, "loyalty_score": 0.47918938126261135, "betrayal_score": 0.5808303046149651, "authority_score": 0.19584266336293069, "subversion_score": 0.858694754745158, "sanctity_score": 0.7412605989088268, "degradation_score": 1.0, "liberty_score": 0.37052238459709597, "oppression_score": 0.657832242008118}, "liberty_score": {"care_score": 0.241780280739929, "harm_score": 0.6843568492392639, "fairness_score": 0.7350874726695746, "cheating_score": 0.5631638528423621, "loyalty_score": 0.23075734638921033, "betrayal_score": 0.7266838128702222, "authority_score": -0.47458885341150986, "subversion_score": 0.1664142732741662, "sanctity_score": -0.11971303267014305, "degradation_score": 0.37052238459709597, "liberty_score": 1.0, "oppression_score": 0.7732430677732336}, "oppression_score": {"care_score": 0.25965199045422155, "harm_score": 0.9101009708952874, "fairness_score": 0.6747472858074648, "cheating_score": 0.7885767890421101, "loyalty_score": 0.5212724010554457, "betrayal_score": 0.8847058879792479, "authority_score": -0.37343236706841393, "subversion_score": 0.39823599292535683, "sanctity_score": 0.22303655315507898, "degradation_score": 0.657832242008118, "liberty_score": 0.7732430677732336, "oppression_score": 1.0}}, "missing_dimensions": []}, "correlate_tensions_with_msci": {"type": "correlation_matrix", "dimensions": ["care_harm_tension", "fairness_cheating_tension", "loyalty_betrayal_tension", "authority_subversion_tension", "sanctity_degradation_tension", "liberty_oppression_tension", "moral_strategic_contradiction_index"], "method": "pearson", "matrix": {"care_harm_tension": {"care_harm_tension": 1.0, "fairness_cheating_tension": -0.2279926620561428, "loyalty_betrayal_tension": 0.06095373163078376, "authority_subversion_tension": 0.31837574617332715, "sanctity_degradation_tension": 0.333787559920223, "liberty_oppression_tension": -0.5392319101854858, "moral_strategic_contradiction_index": 0.15277459020508527}, "fairness_cheating_tension": {"care_harm_tension": -0.2279926620561428, "fairness_cheating_tension": 1.0, "loyalty_betrayal_tension": 0.09854094463686693, "authority_subversion_tension": -2.3348640214350818e-17, "sanctity_degradation_tension": 0.5097915620229936, "liberty_oppression_tension": 0.6435255909985694, "moral_strategic_contradiction_index": 0.8378393626592336}, "loyalty_betrayal_tension": {"care_harm_tension": 0.06095373163078376, "fairness_cheating_tension": 0.09854094463686693, "loyalty_betrayal_tension": 1.0, "authority_subversion_tension": 0.04731069230447168, "sanctity_degradation_tension": 0.5679813212509076, "liberty_oppression_tension": -0.16589633756830952, "moral_strategic_contradiction_index": 0.3154098214813547}, "authority_subversion_tension": {"care_harm_tension": 0.31837574617332715, "fairness_cheating_tension": -2.3348640214350818e-17, "loyalty_betrayal_tension": 0.04731069230447168, "authority_subversion_tension": 1.0, "sanctity_degradation_tension": 0.3944991015808939, "liberty_oppression_tension": 0.038887711972026895, "moral_strategic_contradiction_index": 0.4228398656062898}, "sanctity_degradation_tension": {"care_harm_tension": 0.333787559920223, "fairness_cheating_tension": 0.5097915620229936, "loyalty_betrayal_tension": 0.5679813212509076, "authority_subversion_tension": 0.3944991015808939, "sanctity_degradation_tension": 1.0, "liberty_oppression_tension": -0.01709255396118161, "moral_strategic_contradiction_index": 0.8157549293324563}, "liberty_oppression_tension": {"care_harm_tension": -0.5392319101854858, "fairness_cheating_tension": 0.6435255909985694, "loyalty_betrayal_tension": -0.16589633756830952, "authority_subversion_tension": 0.038887711972026895, "sanctity_degradation_tension": -0.01709255396118161, "liberty_oppression_tension": 1.0, "moral_strategic_contradiction_index": 0.4686393919442529}, "moral_strategic_contradiction_index": {"care_harm_tension": 0.15277459020508527, "fairness_cheating_tension": 0.8378393626592336, "loyalty_betrayal_tension": 0.3154098214813547, "authority_subversion_tension": 0.4228398656062898, "sanctity_degradation_tension": 0.8157549293324563, "liberty_oppression_tension": 0.4686393919442529, "moral_strategic_contradiction_index": 1.0}}, "missing_dimensions": []}, "summarize_all_metrics": {"type": "summary_statistics", "metrics": ["care_score", "harm_score", "fairness_score", "cheating_score", "loyalty_score", "betrayal_score", "authority_score", "subversion_score", "sanctity_score", "degradation_score", "liberty_score", "oppression_score", "care_harm_tension", "fairness_cheating_tension", "loyalty_betrayal_tension", "authority_subversion_tension", "sanctity_degradation_tension", "liberty_oppression_tension", "moral_strategic_contradiction_index"], "summary_types": ["mean", "std", "min", "max"], "results": {"care_score": {"mean": 0.58125, "std": 0.2202879608927499, "min": 0.3, "max": 0.85}, "harm_score": {"mean": 0.65, "std": 0.20873770280289228, "min": 0.2, "max": 0.85}, "fairness_score": {"mean": 0.75625, "std": 0.15454426088156292, "min": 0.5, "max": 0.9}, "cheating_score": {"mean": 0.6499999999999999, "std": 0.249284690951645, "min": 0.1, "max": 0.95}, "loyalty_score": {"mean": 0.33125, "std": 0.16677080080157916, "min": 0.1, "max": 0.55}, "betrayal_score": {"mean": 0.33749999999999997, "std": 0.1787855858683404, "min": 0.1, "max": 0.6}, "authority_score": {"mean": 0.35625, "std": 0.14985111658862318, "min": 0.2, "max": 0.6}, "subversion_score": {"mean": 0.25625, "std": 0.1498511165886232, "min": 0.1, "max": 0.5}, "sanctity_score": {"mean": 0.225, "std": 0.09258200997725514, "min": 0.1, "max": 0.35}, "degradation_score": {"mean": 0.33749999999999997, "std": 0.19775525999867324, "min": 0.1, "max": 0.7}, "liberty_score": {"mean": 0.54375, "std": 0.14500615750472706, "min": 0.4, "max": 0.8}, "oppression_score": {"mean": 0.59375, "std": 0.21619683491802424, "min": 0.2, "max": 0.9}, "care_harm_tension": {"mean": 0.08343750000000001, "std": 0.0354798106574107, "min": 0.03750000000000003, "max": 0.14}, "fairness_cheating_tension": {"mean": 0.09500000000000001, "std": 0.08366600265340753, "min": 0.03500000000000003, "max": 0.26999999999999996}, "loyalty_betrayal_tension": {"mean": 0.025312499999999995, "std": 0.014295197745097079, "min": 0.004999999999999999, "max": 0.04999999999999999}, "authority_subversion_tension": {"mean": 0.03125, "std": 0.03102418411497714, "min": 0.005000000000000001, "max": 0.09999999999999998}, "sanctity_degradation_tension": {"mean": 0.03874999999999999, "std": 0.048439948094817054, "min": 0.005000000000000001, "max": 0.14999999999999997}, "liberty_oppression_tension": {"mean": 0.06062500000000002, "std": 0.03774325862228341, "min": 0.025000000000000022, "max": 0.13499999999999998}, "moral_strategic_contradiction_index": {"mean": 0.05572916666666668, "std": 0.02505821594822617, "min": 0.029166666666666688, "max": 0.09583333333333334}}, "missing_metrics": []}}, "errors": []}, "combined_summary": "Two-stage execution: 3 raw data results + 18 derived metrics results"}