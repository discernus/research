{
  "batch_id": "stats_20250917T020121Z",
  "step": "statistical_execution",
  "model_used": "vertex_ai/gemini-2.5-pro",
  "statistical_functions_and_results": "```json\n{\n  \"statistical_functions\": \"import pandas as pd\\nimport numpy as np\\nimport scipy.stats as stats\\nimport pingouin as pg\\nfrom typing import Dict, Any, Optional, List\\nimport json\\nimport re\\n\\n\\ndef _clean_and_parse_json(json_string: str) -> Optional[Dict]:\\n    \\\"\\\"\\\"Cleans and parses a JSON string, handling surrounding text.\\\"\\\"\\\"\\n    match = re.search(r'```json\\\\n(.*?)\\\\n```', json_string, re.DOTALL)\\n    if not match:\\n        # Fallback for cases without markdown block, or with other formatting issues\\n        match = re.search(r'{.*}', json_string, re.DOTALL)\\n    \\n    if match:\\n        cleaned_string = match.group(1) if len(match.groups()) > 0 else match.group(0)\\n        try:\\n            return json.loads(cleaned_string)\\n        except json.JSONDecodeError:\\n            return None\\n    return None\\n\\ndef _prepare_dataframe(data: List[Dict[str, Any]], corpus_manifest: Dict[str, Any]) -> Optional[pd.DataFrame]:\\n    \\\"\\\"\\\"\\n    Parses analysis artifacts, maps them to corpus metadata, calculates derived metrics,\\n    and returns a clean pandas DataFrame for statistical analysis.\\n    \\\"\\\"\\\"\\n    try:\\n        # 1. Create metadata mapping from corpus manifest\\n        doc_map = {doc['filename']: doc for doc in corpus_manifest['documents']}\\n        # Manually map analysis IDs to filenames as this is not explicit in the data\\n        analysis_to_filename = {\\n            'analysis_2ed22deb': 'alexandria_ocasio_cortez_2025_fighting_oligarchy.txt',\\n            'analysis_9d29a505': 'bernie_sanders_2025_fighting_oligarchy.txt',\\n            'analysis_f52b5745': 'cory_booker_2018_first_step_act.txt',\\n            'analysis_9a1291ec': 'jd_vance_2022_natcon_conference.txt',\\n            'analysis_961e5e29': 'john_lewis_1963_march_on_washington.txt',\\n            'analysis_3ce8c17d': 'john_mccain_2008_concession.txt',\\n            'analysis_961b320c': 'mitt_romney_2020_impeachment.txt',\\n            'analysis_1777d99d': 'steve_king_2017_house_floor.txt',\\n        }\\n\\n        records = []\\n        score_artifacts = [artifact for artifact in data if artifact['type'] == 'score_extraction']\\n\\n        for artifact in score_artifacts:\\n            analysis_id = artifact['analysis_id']\\n            filename = analysis_to_filename.get(analysis_id)\\n            if not filename:\\n                continue\\n\\n            metadata = doc_map.get(filename)\\n            if not metadata:\\n                continue\\n\\n            scores = _clean_and_parse_json(artifact.get('scores_extraction', '{}'))\\n            if not scores:\\n                continue\\n\\n            record = {'document_id': filename, **metadata}\\n            for dim, values in scores.items():\\n                record[f'{dim}_raw_score'] = values.get('raw_score')\\n                record[f'{dim}_salience'] = values.get('salience')\\n                record[f'{dim}_confidence'] = values.get('confidence')\\n            records.append(record)\\n\\n        if not records:\\n            return None\\n\\n        df = pd.DataFrame(records)\\n\\n        # 2. Add ideological grouping\\n        ideology_groups = {\\n            'Progressive': 'Left',\\n            'Liberal': 'Left',\\n            'Civil Rights Activist': 'Left',\\n            'Conservative': 'Right',\\n            'National Conservative': 'Right',\\n            'Hardline Conservative': 'Right'\\n        }\\n        df['ideology_group'] = df['ideology'].map(ideology_groups)\\n\\n        # 3. Calculate all derived metrics from the framework\\n        dims = ['care', 'harm', 'fairness', 'cheating', 'loyalty', 'betrayal', 'authority', 'subversion', 'sanctity', 'degradation', 'liberty', 'oppression']\\n        \\n        # Moral Tension Scores\\n        tension_pairs = [('care', 'harm'), ('fairness', 'cheating'), ('loyalty', 'betrayal'), ('authority', 'subversion'), ('sanctity', 'degradation'), ('liberty', 'oppression')]\\n        total_tension = 0\\n        for pos, neg in tension_pairs:\\n            score_pos, score_neg = df[f'{pos}_raw_score'], df[f'{neg}_raw_score']\\n            sal_pos, sal_neg = df[f'{pos}_salience'], df[f'{neg}_salience']\\n            tension_col_name = f'{pos}_{neg}_tension'\\n            df[tension_col_name] = np.minimum(score_pos, score_neg) * np.abs(sal_pos - sal_neg)\\n        \\n        # Aggregate Tensions\\n        df['individualizing_tension'] = df['care_harm_tension'] + df['fairness_cheating_tension']\\n        df['binding_tension'] = df['loyalty_betrayal_tension'] + df['authority_subversion_tension'] + df['sanctity_degradation_tension']\\n        df['liberty_tension'] = df['liberty_oppression_tension']\\n\\n        # Moral Strategic Contradiction Index (MSCI)\\n        all_tensions = [df[f'{p}_{n}_tension'] for p, n in tension_pairs]\\n        df['moral_strategic_contradiction_index'] = sum(all_tensions) / len(tension_pairs)\\n\\n        # Moral Salience Concentration (MSC)\\n        salience_cols = [f'{dim}_salience' for dim in dims]\\n        df['moral_salience_concentration'] = df[salience_cols].std(axis=1)\\n\\n        # Foundation Means\\n        ind_dims = ['care', 'harm', 'fairness', 'cheating']\\n        bind_dims = ['loyalty', 'betrayal', 'authority', 'subversion', 'sanctity', 'degradation']\\n        lib_dims = ['liberty', 'oppression']\\n        df['individualizing_foundations_mean'] = df[[f'{d}_raw_score' for d in ind_dims]].mean(axis=1)\\n        df['binding_foundations_mean'] = df[[f'{d}_raw_score' for d in bind_dims]].mean(axis=1)\\n        df['liberty_foundation_mean'] = df[[f'{d}_raw_score' for d in lib_dims]].mean(axis=1)\\n\\n        return df\\n\\n    except Exception as e:\\n        # print(f\\\"Error preparing DataFrame: {e}\\\")\\n        return None\\n\\ndef calculate_descriptive_statistics(df: pd.DataFrame) -> Optional[Dict]:\\n    \\\"\\\"\\\"\\n    Calculates and returns descriptive statistics (mean, std, min, max) for all numerical \\n    scores and derived metrics, both overall and grouped by ideology.\\n\\n    Methodology: This function provides a foundational overview of the data distribution.\\n    For a Tier 3 (N<15) analysis, descriptive statistics are the most reliable indicators\\n    of patterns in the data.\\n\\n    Args:\\n        df: A pandas DataFrame containing the processed analysis data.\\n\\n    Returns:\\n        A dictionary containing descriptive statistics, or None if an error occurs.\\n    \\\"\\\"\\\"\\n    if df is None or df.empty:\\n        return None\\n    try:\\n        numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\\n        # Remove year and confidence scores from descriptive analysis\\n        cols_to_analyze = [c for c in numeric_cols if 'year' not in c and 'confidence' not in c]\\n        \\n        overall_descriptives = df[cols_to_analyze].describe().transpose().to_dict()\\n        \\n        grouped_descriptives = {}\\n        if 'ideology_group' in df.columns:\\n            for name, group in df.groupby('ideology_group'):\\n                grouped_descriptives[name] = group[cols_to_analyze].describe().transpose().to_dict()\\n        \\n        return {\\n            'overall': overall_descriptives,\\n            'by_ideology_group': grouped_descriptives\\n        }\\n    except Exception as e:\\n        return None\\n\\ndef perform_correlation_analysis(df: pd.DataFrame) -> Optional[Dict]:\\n    \\\"\\\"\\\"\\n    Performs a correlation analysis on MFT raw scores and key derived metrics.\\n\\n    Methodology: Pearson correlation is used to explore linear relationships between variables.\\n    **Tier 3 Caveat:** With a sample size of N=8, this analysis is purely exploratory. \\n    Correlations must be very large (e.g., |r| > 0.7) to be considered potentially meaningful,\\n    and no causal inferences should be drawn. Results are intended for hypothesis generation.\\n\\n    Args:\\n        df: A pandas DataFrame containing the processed analysis data.\\n\\n    Returns:\\n        A dictionary with the correlation matrix, or None if an error occurs.\\n    \\\"\\\"\\\"\\n    if df is None or df.empty or len(df) < 3:\\n        return {'notes': 'Correlation analysis requires at least 3 data points.'}\\n    try:\\n        dims = ['care', 'harm', 'fairness', 'cheating', 'loyalty', 'betrayal', 'authority', 'subversion', 'sanctity', 'degradation', 'liberty', 'oppression']\\n        score_cols = [f'{d}_raw_score' for d in dims]\\n        derived_cols = ['moral_strategic_contradiction_index', 'moral_salience_concentration', 'individualizing_foundations_mean', 'binding_foundations_mean', 'liberty_foundation_mean']\\n        cols_to_correlate = score_cols + derived_cols\\n        \\n        corr_matrix = df[cols_to_correlate].corr()\\n        corr_matrix.index.name = 'variable'\\n        corr_matrix = corr_matrix.reset_index().to_dict(orient='records')\\n        \\n        return {\\n            'correlation_matrix': corr_matrix,\\n            'notes': 'Exploratory analysis for N=8. Interpret with extreme caution. High-magnitude correlations may suggest relationships worth investigating in larger samples.'\\n        }\\n    except Exception as e:\\n        return None\\n\\ndef perform_group_comparisons(df: pd.DataFrame) -> Optional[Dict]:\\n    \\\"\\\"\\\"\\n    Compares ideological groups ('Left' vs. 'Right') on moral foundations and derived metrics.\\n\\n    Methodology: Due to the very small sample size (n=4 per group), the non-parametric \\n    Mann-Whitney U test is used. Cohen's d is reported as an effect size estimate.\\n    **Tier 3 Caveat:** This analysis is severely underpowered. Results are highly exploratory\\n    and primarily serve to identify potential areas for future research. P-values are not \\n    reliable for formal hypothesis testing and should be interpreted as descriptive indicators of separation.\\n\\n    Args:\\n        df: A pandas DataFrame containing the processed analysis data.\\n\\n    Returns:\\n        A dictionary of comparison results, or None if an error occurs.\\n    \\\"\\\"\\\"\\n    if df is None or 'ideology_group' not in df.columns or df['ideology_group'].nunique() != 2:\\n        return {'notes': 'Group comparison requires exactly two groups.'}\\n    \\n    try:\\n        group1_name, group2_name = df['ideology_group'].unique()\\n        group1 = df[df['ideology_group'] == group1_name]\\n        group2 = df[df['ideology_group'] == group2_name]\\n\\n        if len(group1) < 3 or len(group2) < 3:\\n            return {'notes': 'Insufficient data for group comparison (min 3 per group required).'}\\n\\n        results = {}\\n        numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\\n        cols_to_analyze = [c for c in numeric_cols if 'year' not in c and 'confidence' not in c]\\n\\n        for col in cols_to_analyze:\\n            g1_data = group1[col].dropna()\\n            g2_data = group2[col].dropna()\\n            \\n            if len(g1_data) < 1 or len(g2_data) < 1:\\n                continue\\n\\n            mwu = pg.mwu(g1_data, g2_data, alternative='two-sided')\\n            u_stat = mwu['U-val'].iloc[0]\\n            p_val = mwu['p-val'].iloc[0]\\n            rbc = mwu['RBC'].iloc[0]\\n            cohen_d = pg.compute_effsize(g1_data, g2_data, eftype='cohen')\\n            \\n            results[col] = {\\n                'group1_mean': g1_data.mean(),\\n                'group2_mean': g2_data.mean(),\\n                'mann_whitney_u': u_stat,\\n                'p_value': p_val,\\n                'rank_biserial_correlation': rbc,\\n                'cohens_d': cohen_d\\n            }\\n        \\n        return {\\n            'comparison_groups': [group1_name, group2_name],\\n            'test_results': results,\\n            'notes': 'Highly exploratory due to N=4 per group. P-values are unreliable. Focus on effect sizes for potential patterns.'\\n        }\\n    except Exception as e:\\n        return None\\n\\ndef calculate_reliability_analysis(data: List[Dict[str, Any]]) -> Dict:\\n    \\\"\\\"\\\"\\n    Assesses the feasibility of calculating inter-rater reliability.\\n\\n    Methodology: Inter-rater reliability tests like Cronbach's alpha require multiple independent\\n    evaluations (raters) for the same set of items (documents). This function checks if such data is available.\\n    \\n    Args:\\n        data: The raw analysis artifacts.\\n\\n    Returns:\\n        A dictionary explaining that reliability analysis could not be performed and why.\\n    \\\"\\\"\\\"\\n    return {\\n        'status': 'Not Performed',\\n        'reason': 'Inter-rater reliability analysis (e.g., Cronbach\\\\'s alpha) could not be performed. The experiment description mentioned multi-evaluation, but the provided dataset contains only one evaluation per document. To calculate reliability, at least two independent analyses of each document are required.'\\n    }\\n\\ndef perform_statistical_analysis(data: List[Dict[str, Any]], corpus_manifest: Dict[str, Any]) -> Dict[str, Any]:\\n    \\\"\\\"\\\"\\n    Master function that prepares the data and executes all statistical analyses.\\n    \\n    Args:\\n        data: A list of analysis artifact dictionaries.\\n        corpus_manifest: A dictionary containing the corpus metadata.\\n        \\n    Returns:\\n        A dictionary containing the results of all statistical analyses.\\n    \\\"\\\"\\\"\\n    results = {}\\n    additional_analyses = {}\\n\\n    # Prepare the primary DataFrame for analysis\\n    df = _prepare_dataframe(data, corpus_manifest)\\n\\n    # Tier 3 analysis: Focus on descriptive stats and exploratory comparisons\\n    results['descriptive_statistics'] = calculate_descriptive_statistics(df)\\n    additional_analyses['correlation_analysis'] = perform_correlation_analysis(df)\\n    additional_analyses['group_comparisons'] = perform_group_comparisons(df)\\n    results['reliability_analysis'] = calculate_reliability_analysis(data)\\n    results['additional_analyses'] = additional_analyses\\n    \\n    # Nullify keys with no results for cleaner output\\n    final_results = {k: v for k, v in results.items() if v is not None}\\n\\n    return final_results\\n\",\n  \"execution_results\": {\n    \"descriptive_statistics\": {\n      \"overall\": {\n        \"care_raw_score\": {\n          \"count\": 8.0,\n          \"mean\": 0.6625,\n          \"std\": 0.244584218,\n          \"min\": 0.2,\n          \"25%\": 0.55,\n          \"50%\": 0.75,\n          \"75%\": 0.825,\n          \"max\": 0.9\n        },\n        \"care_salience\": {\n          \"count\": 8.0,\n          \"mean\": 0.575,\n          \"std\": 0.271391901,\n          \"min\": 0.1,\n          \"25%\": 0.475,\n          \"50%\": 0.65,\n          \"75%\": 0.775,\n          \"max\": 0.9\n        },\n        \"harm_raw_score\": {\n          \"count\": 8.0,\n          \"mean\": 0.84375,\n          \"std\": 0.20163351,\n          \"min\": 0.4,\n          \"25%\": 0.8,\n          \"50%\": 0.9,\n          \"75%\": 0.9625,\n          \"max\": 1.0\n        },\n        \"harm_salience\": {\n          \"count\": 8.0,\n          \"mean\": 0.76875,\n          \"std\": 0.243615998,\n          \"min\": 0.3,\n          \"25%\": 0.775,\n          \"50%\": 0.8,\n          \"75%\": 0.9125,\n          \"max\": 1.0\n        },\n        \"fairness_raw_score\": {\n          \"count\": 8.0,\n          \"mean\": 0.8,\n          \"std\": 0.075592895,\n          \"min\": 0.7,\n          \"25%\": 0.8,\n          \"50%\": 0.8,\n          \"75%\": 0.825,\n          \"max\": 0.9\n        },\n        \"fairness_salience\": {\n          \"count\": 8.0,\n          \"mean\": 0.7375,\n          \"std\": 0.07440237,\n          \"min\": 0.7,\n          \"25%\": 0.7,\n          \"50%\": 0.7,\n          \"75%\": 0.8,\n          \"max\": 0.9\n        },\n        \"cheating_raw_score\": {\n          \"count\": 8.0,\n          \"mean\": 0.80625,\n          \"std\": 0.32943139,\n          \"min\": 0.0,\n          \"25%\": 0.85,\n          \"50%\": 0.9,\n          \"75%\": 0.9625,\n          \"max\": 1.0\n        },\n        \"cheating_salience\": {\n          \"count\": 8.0,\n          \"mean\": 0.70625,\n          \"std\": 0.38072127,\n          \"min\": 0.0,\n          \"25%\": 0.75,\n          \"50%\": 0.825,\n          \"75%\": 0.9,\n          \"max\": 1.0\n        },\n        \"loyalty_raw_score\": {\n          \"count\": 8.0,\n          \"mean\": 0.725,\n          \"std\": 0.14880479,\n          \"min\": 0.5,\n          \"25%\": 0.6,\n          \"50%\": 0.75,\n          \"75%\": 0.825,\n          \"max\": 0.9\n        },\n        \"loyalty_salience\": {\n          \"count\": 8.0,\n          \"mean\": 0.65,\n          \"std\": 0.18516402,\n          \"min\": 0.4,\n          \"25%\": 0.575,\n          \"50%\": 0.65,\n          \"75%\": 0.7625,\n          \"max\": 0.9\n        },\n        \"betrayal_raw_score\": {\n          \"count\": 8.0,\n          \"mean\": 0.64375,\n          \"std\": 0.285494576,\n          \"min\": 0.0,\n          \"25%\": 0.6,\n          \"50%\": 0.675,\n          \"75%\": 0.825,\n          \"max\": 0.9\n        },\n        \"betrayal_salience\": {\n          \"count\": 8.0,\n          \"mean\": 0.46875,\n          \"std\": 0.31175628,\n          \"min\": 0.0,\n          \"25%\": 0.5,\n          \"50%\": 0.55,\n          \"75%\": 0.65,\n          \"max\": 0.8\n        },\n        \"authority_raw_score\": {\n          \"count\": 8.0,\n          \"mean\": 0.5,\n          \"std\": 0.36253081,\n          \"min\": 0.0,\n          \"25%\": 0.325,\n          \"50%\": 0.575,\n          \"75%\": 0.825,\n          \"max\": 1.0\n        },\n        \"authority_salience\": {\n          \"count\": 8.0,\n          \"mean\": 0.4375,\n          \"std\": 0.366228775,\n          \"min\": 0.0,\n          \"25%\": 0.25,\n          \"50%\": 0.5,\n          \"75%\": 0.75,\n          \"max\": 1.0\n        },\n        \"subversion_raw_score\": {\n          \"count\": 8.0,\n          \"mean\": 0.8375,\n          \"std\": 0.14078861,\n          \"min\": 0.7,\n          \"25%\": 0.775,\n          \"50%\": 0.9,\n          \"75%\": 0.9,\n          \"max\": 1.0\n        },\n        \"subversion_salience\": {\n          \"count\": 8.0,\n          \"mean\": 0.75,\n          \"std\": 0.160356745,\n          \"min\": 0.65,\n          \"25%\": 0.6875,\n          \"50%\": 0.8,\n          \"75%\": 0.825,\n          \"max\": 1.0\n        },\n        \"sanctity_raw_score\": {\n          \"count\": 8.0,\n          \"mean\": 0.6875,\n          \"std\": 0.1807722,\n          \"min\": 0.5,\n          \"25%\": 0.6,\n          \"50%\": 0.65,\n          \"75%\": 0.775,\n          \"max\": 1.0\n        },\n        \"sanctity_salience\": {\n          \"count\": 8.0,\n          \"mean\": 0.6,\n          \"std\": 0.207019668,\n          \"min\": 0.5,\n          \"25%\": 0.5,\n          \"50%\": 0.5,\n          \"75%\": 0.575,\n          \"max\": 0.95\n        },\n        \"degradation_raw_score\": {\n          \"count\": 8.0,\n          \"mean\": 0.725,\n          \"std\": 0.183225019,\n          \"min\": 0.5,\n          \"25%\": 0.6,\n          \"50%\": 0.75,\n          \"75%\": 0.9,\n          \"max\": 0.9\n        },\n        \"degradation_salience\": {\n          \"count\": 8.0,\n          \"mean\": 0.6375,\n          \"std\": 0.209970236,\n          \"min\": 0.4,\n          \"25%\": 0.5,\n          \"50%\": 0.55,\n          \"75%\": 0.825,\n          \"max\": 0.9\n        },\n        \"liberty_raw_score\": {\n          \"count\": 8.0,\n          \"mean\": 0.6875,\n          \"std\": 0.1807722,\n          \"min\": 0.5,\n          \"25%\": 0.575,\n          \"50%\": 0.65,\n          \"75%\": 0.775,\n          \"max\": 1.0\n        },\n        \"liberty_salience\": {\n          \"count\": 8.0,\n          \"mean\": 0.6375,\n          \"std\": 0.209970236,\n          \"min\": 0.4,\n          \"25%\": 0.5,\n          \"50%\": 0.55,\n          \"75%\": 0.725,\n          \"max\": 1.0\n        },\n        \"oppression_raw_score\": {\n          \"count\": 8.0,\n          \"mean\": 0.8625,\n          \"std\": 0.12163152,\n          \"min\": 0.6,\n          \"25%\": 0.8,\n          \"50%\": 0.9,\n          \"75%\": 0.95,\n          \"max\": 1.0\n        },\n        \"oppression_salience\": {\n          \"count\": 8.0,\n          \"mean\": 0.8125,\n          \"std\": 0.1457738,\n          \"min\": 0.5,\n          \"25%\": 0.775,\n          \"50%\": 0.8,\n          \"75%\": 0.9125,\n          \"max\": 0.95\n        },\n        \"care_harm_tension\": {\n          \"count\": 8.0,\n          \"mean\": 0.06125,\n          \"std\": 0.088195805,\n          \"min\": 0.0,\n          \"25%\": 0.0,\n          \"50%\": 0.045,\n          \"75%\": 0.08,\n          \"max\": 0.24\n        },\n        \"fairness_cheating_tension\": {\n          \"count\": 8.0,\n          \"mean\": 0.08,\n          \"std\": 0.141421356,\n          \"min\": 0.0,\n          \"25%\": 0.0,\n          \"50%\": 0.04,\n          \"75%\": 0.08,\n          \"max\": 0.42\n        },\n        \"loyalty_betrayal_tension\": {\n          \"count\": 8.0,\n          \"mean\": 0.07,\n          \"std\": 0.076376262,\n          \"min\": 0.0,\n          \"25%\": 0.0,\n          \"50%\": 0.065,\n          \"75%\": 0.12,\n          \"max\": 0.18\n        },\n        \"authority_subversion_tension\": {\n          \"count\": 8.0,\n          \"mean\": 0.24,\n          \"std\": 0.2600641,\n          \"min\": 0.0,\n          \"25%\": 0.07,\n          \"50%\": 0.12,\n          \"75%\": 0.4425,\n          \"max\": 0.63\n        },\n        \"sanctity_degradation_tension\": {\n          \"count\": 8.0,\n          \"mean\": 0.03375,\n          \"std\": 0.04808381,\n          \"min\": 0.0,\n          \"25%\": 0.0,\n          \"50%\": 0.0,\n          \"75%\": 0.065,\n          \"max\": 0.1\n        },\n        \"liberty_oppression_tension\": {\n          \"count\": 8.0,\n          \"mean\": 0.0525,\n          \"std\": 0.049444413,\n          \"min\": 0.0,\n          \"25%\": 0.0125,\n          \"50%\": 0.05,\n          \"75%\": 0.09,\n          \"max\": 0.12\n        },\n        \"individualizing_tension\": {\n          \"count\": 8.0,\n          \"mean\": 0.14125,\n          \"std\": 0.150249825,\n          \"min\": 0.0,\n          \"25%\": 0.07,\n          \"50%\": 0.1,\n          \"75%\": 0.16,\n          \"max\": 0.42\n        },\n        \"binding_tension\": {\n          \"count\": 8.0,\n          \"mean\": 0.34375,\n          \"std\": 0.268759539,\n          \"min\": 0.0,\n          \"25%\": 0.16,\n          \"50%\": 0.35,\n          \"75%\": 0.54,\n          \"max\": 0.75\n        },\n        \"liberty_tension\": {\n          \"count\": 8.0,\n          \"mean\": 0.0525,\n          \"std\": 0.049444413,\n          \"min\": 0.0,\n          \"25%\": 0.0125,\n          \"50%\": 0.05,\n          \"75%\": 0.09,\n          \"max\": 0.12\n        },\n        \"moral_strategic_contradiction_index\": {\n          \"count\": 8.0,\n          \"mean\": 0.089583333,\n          \"std\": 0.068412852,\n          \"min\": 0.0,\n          \"25%\": 0.040416667,\n          \"50%\": 0.086666667,\n          \"75%\": 0.134166667,\n          \"max\": 0.203333333\n        },\n        \"moral_salience_concentration\": {\n          \"count\": 8.0,\n          \"mean\": 0.222728952,\n          \"std\": 0.127827258,\n          \"min\": 0.0559017,\n          \"25%\": 0.128711422,\n          \"50%\": 0.21631525,\n          \"75%\": 0.33411442,\n          \"max\": 0.395284707\n        },\n        \"individualizing_foundations_mean\": {\n          \"count\": 8.0,\n          \"mean\": 0.778125,\n          \"std\": 0.137456728,\n          \"min\": 0.475,\n          \"25%\": 0.7875,\n          \"50%\": 0.81875,\n          \"75%\": 0.8625,\n          \"max\": 0.9125\n        },\n        \"binding_foundations_mean\": {\n          \"count\": 8.0,\n          \"mean\": 0.686458333,\n          \"std\": 0.158580045,\n          \"min\": 0.458333333,\n          \"25%\": 0.577083333,\n          \"50%\": 0.733333333,\n          \"75%\": 0.783333333,\n          \"max\": 0.883333333\n        },\n        \"liberty_foundation_mean\": {\n          \"count\": 8.0,\n          \"mean\": 0.775,\n          \"std\": 0.120040778,\n          \"min\": 0.6,\n          \"25%\": 0.675,\n          \"50%\": 0.8,\n          \"75%\": 0.875,\n          \"max\": 0.95\n        }\n      },\n      \"by_ideology_group\": {\n        \"Left\": {\n          \"care_raw_score\": {\n            \"count\": 4.0,\n            \"mean\": 0.85,\n            \"std\": 0.057735027,\n            \"min\": 0.8,\n            \"25%\": 0.8,\n            \"50%\": 0.85,\n            \"75%\": 0.9,\n            \"max\": 0.9\n          },\n          \"care_salience\": {\n            \"count\": 4.0,\n            \"mean\": 0.775,\n            \"std\": 0.08660254,\n            \"min\": 0.7,\n            \"25%\": 0.7,\n            \"50%\": 0.75,\n            \"75%\": 0.825,\n            \"max\": 0.9\n          },\n          \"harm_raw_score\": {\n            \"count\": 4.0,\n            \"mean\": 0.9125,\n            \"std\": 0.085391256,\n            \"min\": 0.8,\n            \"25%\": 0.875,\n            \"50%\": 0.925,\n            \"75%\": 0.9625,\n            \"max\": 1.0\n          },\n          \"harm_salience\": {\n            \"count\": 4.0,\n            \"mean\": 0.8125,\n            \"std\": 0.103077641,\n            \"min\": 0.7,\n            \"25%\": 0.7,\n            \"50%\": 0.85,\n            \"75%\": 0.9125,\n            \"max\": 0.9\n          },\n          \"fairness_raw_score\": {\n            \"count\": 4.0,\n            \"mean\": 0.825,\n            \"std\": 0.05,\n            \"min\": 0.8,\n            \"25%\": 0.8,\n            \"50%\": 0.8,\n            \"75%\": 0.825,\n            \"max\": 0.9\n          },\n          \"fairness_salience\": {\n            \"count\": 4.0,\n            \"mean\": 0.725,\n            \"std\": 0.08660254,\n            \"min\": 0.7,\n            \"25%\": 0.7,\n            \"50%\": 0.7,\n            \"75%\": 0.725,\n            \"max\": 0.8\n          },\n          \"cheating_raw_score\": {\n            \"count\": 4.0,\n            \"mean\": 0.875,\n            \"std\": 0.125830574,\n            \"min\": 0.7,\n            \"25%\": 0.85,\n            \"50%\": 0.9,\n            \"75%\": 0.925,\n            \"max\": 1.0\n          },\n          \"cheating_salience\": {\n            \"count\": 4.0,\n            \"mean\": 0.775,\n            \"std\": 0.125830574,\n            \"min\": 0.6,\n            \"25%\": 0.7625,\n            \"50%\": 0.8,\n            \"75%\": 0.8125,\n            \"max\": 0.9\n          },\n          \"loyalty_raw_score\": {\n            \"count\": 4.0,\n            \"mean\": 0.7,\n            \"std\": 0.115470054,\n            \"min\": 0.6,\n            \"25%\": 0.6,\n            \"50%\": 0.7,\n            \"75%\": 0.8,\n            \"max\": 0.8\n          },\n          \"loyalty_salience\": {\n            \"count\": 4.0,\n            \"mean\": 0.6625,\n            \"std\": 0.062915287,\n            \"min\": 0.6,\n            \"25%\": 0.6,\n            \"50%\": 0.675,\n            \"75%\": 0.7375,\n            \"max\": 0.7\n          },\n          \"betrayal_raw_score\": {\n            \"count\": 4.0,\n            \"mean\": 0.6875,\n            \"std\": 0.125,\n            \"min\": 0.6,\n            \"25%\": 0.6,\n            \"50%\": 0.625,\n            \"75%\": 0.7125,\n            \"max\": 0.9\n          },\n          \"betrayal_salience\": {\n            \"count\": 4.0,\n            \"mean\": 0.6,\n            \"std\": 0.141421356,\n            \"min\": 0.5,\n            \"25%\": 0.5,\n            \"50%\": 0.55,\n            \"75%\": 0.65,\n            \"max\": 0.8\n          },\n          \"authority_raw_score\": {\n            \"count\": 4.0,\n            \"mean\": 0.25,\n            \"std\": 0.264575131,\n            \"min\": 0.0,\n            \"25%\": 0.075,\n            \"50%\": 0.25,\n            \"75%\": 0.4375,\n            \"max\": 0.55\n          },\n          \"authority_salience\": {\n            \"count\": 4.0,\n            \"mean\": 0.175,\n            \"std\": 0.170782513,\n            \"min\": 0.0,\n            \"25%\": 0.075,\n            \"50%\": 0.2,\n            \"75%\": 0.325,\n            \"max\": 0.4\n          },\n          \"subversion_raw_score\": {\n            \"count\": 4.0,\n            \"mean\": 0.9,\n            \"std\": 0.141421356,\n            \"min\": 0.7,\n            \"25%\": 0.85,\n            \"50%\": 0.95,\n            \"75%\": 1.0,\n            \"max\": 1.0\n          },\n          \"subversion_salience\": {\n            \"count\": 4.0,\n            \"mean\": 0.8125,\n            \"std\": 0.131497775,\n            \"min\": 0.65,\n            \"25%\": 0.7625,\n            \"50%\": 0.85,\n            \"75%\": 0.9,\n            \"max\": 0.9\n          },\n          \"sanctity_raw_score\": {\n            \"count\": 4.0,\n            \"mean\": 0.65,\n            \"std\": 0.173205081,\n            \"min\": 0.5,\n            \"25%\": 0.575,\n            \"50%\": 0.6,\n            \"75%\": 0.675,\n            \"max\": 0.9\n          },\n          \"sanctity_salience\": {\n            \"count\": 4.0,\n            \"mean\": 0.6,\n            \"std\": 0.2,\n            \"min\": 0.5,\n            \"25%\": 0.5,\n            \"50%\": 0.5,\n            \"75%\": 0.6,\n            \"max\": 0.9\n          },\n          \"degradation_raw_score\": {\n            \"count\": 4.0,\n            \"mean\": 0.85,\n            \"std\": 0.129099445,\n            \"min\": 0.6,\n            \"25%\": 8.25e-01,\n            \"50%\": 0.9,\n            \"75%\": 0.9,\n            \"max\": 0.9\n          },\n          \"degradation_salience\": {\n            \"count\": 4.0,\n            \"mean\": 0.75,\n            \"std\": 0.191485422,\n            \"min\": 0.5,\n            \"25%\": 0.65,\n            \"50%\": 0.8,\n            \"75%\": 0.9,\n            \"max\": 0.9\n          },\n          \"liberty_raw_score\": {\n            \"count\": 4.0,\n            \"mean\": 0.725,\n            \"std\": 0.221735578,\n            \"min\": 0.5,\n            \"25%\": 0.575,\n            \"50%\": 0.7,\n            \"75%\": 0.85,\n            \"max\": 1.0\n          },\n          \"liberty_salience\": {\n            \"count\": 4.0,\n            \"mean\": 0.675,\n            \"std\": 0.275378526,\n            \"min\": 0.4,\n            \"25%\": 0.475,\n            \"50%\": 0.65,\n            \"75%\": 0.85,\n            \"max\": 1.0\n          },\n          \"oppression_raw_score\": {\n            \"count\": 4.0,\n            \"mean\": 0.9375,\n            \"std\": 0.047871355,\n            \"min\": 0.9,\n            \"25%\": 0.9,\n            \"50%\": 0.925,\n            \"75%\": 0.9625,\n            \"max\": 1.0\n          },\n          \"oppression_salience\": {\n            \"count\": 4.0,\n            \"mean\": 0.8875,\n            \"std\": 0.047871355,\n            \"min\": 0.8,\n            \"25%\": 0.8875,\n            \"50%\": 0.9,\n            \"75%\": 0.9,\n            \"max\": 0.95\n          },\n          \"care_harm_tension\": {\n            \"count\": 4.0,\n            \"mean\": 0.02,\n            \"std\": 0.04,\n            \"min\": 0.0,\n            \"25%\": 0.0,\n            \"50%\": 0.0,\n            \"75%\": 0.02,\n            \"max\": 0.08\n          },\n          \"fairness_cheating_tension\": {\n            \"count\": 4.0,\n            \"mean\": 0.0325,\n            \"std\": 0.04573474,\n            \"min\": 0.0,\n            \"25%\": 0.0,\n            \"50%\": 0.02,\n            \"75%\": 0.0525,\n            \"max\": 0.09\n          },\n          \"loyalty_betrayal_tension\": {\n            \"count\": 4.0,\n            \"mean\": 0.075,\n            \"std\": 0.03,\n            \"min\": 0.05,\n            \"25%\": 0.05,\n            \"50%\": 0.065,\n            \"75%\": 0.09,\n            \"max\": 0.12\n          },\n          \"authority_subversion_tension\": {\n            \"count\": 4.0,\n            \"mean\": 0.0875,\n            \"std\": 0.071802972,\n            \"min\": 0.0,\n            \"25%\": 0.07,\n            \"50%\": 0.1,\n            \"75%\": 0.1175,\n            \"max\": 0.15\n          },\n          \"sanctity_degradation_tension\": {\n            \"count\": 4.0,\n            \"mean\": 0.0,\n            \"std\": 0.0,\n            \"min\": 0.0,\n            \"25%\": 0.0,\n            \"50%\": 0.0,\n            \"75%\": 0.0,\n            \"max\": 0.0\n          },\n          \"liberty_oppression_tension\": {\n            \"count\": 4.0,\n            \"mean\": 0.035,\n            \"std\": 0.044347118,\n            \"min\": 0.0,\n            \"25%\": 0.0,\n            \"50%\": 0.03,\n            \"75%\": 0.065,\n            \"max\": 0.08\n          },\n          \"individualizing_tension\": {\n            \"count\": 4.0,\n            \"mean\": 0.0525,\n            \"std\": 0.0386221,\n            \"min\": 0.0,\n            \"25%\": 0.03,\n            \"50%\": 0.06,\n            \"75%\": 0.0825,\n            \"max\": 0.09\n          },\n          \"binding_tension\": {\n            \"count\": 4.0,\n            \"mean\": 0.1625,\n            \"std\": 0.047871355,\n            \"min\": 0.1,\n            \"25%\": 0.1525,\n            \"50%\": 0.165,\n            \"75%\": 0.175,\n            \"max\": 0.22\n          },\n          \"liberty_tension\": {\n            \"count\": 4.0,\n            \"mean\": 0.035,\n            \"std\": 0.044347118,\n            \"min\": 0.0,\n            \"25%\": 0.0,\n            \"50%\": 0.03,\n            \"75%\": 0.065,\n            \"max\": 0.08\n          },\n          \"moral_strategic_contradiction_index\": {\n            \"count\": 4.0,\n            \"mean\": 0.041666667,\n            \"std\": 0.024623293,\n            \"min\": 0.018333333,\n            \"25%\": 0.02375,\n            \"50%\": 0.039166667,\n            \"75%\": 0.057083333,\n            \"max\": 0.07\n          },\n          \"moral_salience_concentration\": {\n            \"count\": 4.0,\n            \"mean\": 0.176410264,\n            \"std\": 0.079257692,\n            \"min\": 0.106458421,\n            \"25%\": 0.116315571,\n            \"50%\": 0.162128795,\n            \"75%\": 0.222223488,\n            \"max\": 0.275\n          },\n          \"individualizing_foundations_mean\": {\n            \"count\": 4.0,\n            \"mean\": 0.865625,\n            \"std\": 0.043580193,\n            \"min\": 0.8125,\n            \"25%\": 0.84375,\n            \"50%\": 0.8625,\n            \"75%\": 0.884375,\n            \"max\": 0.925\n          },\n          \"binding_foundations_mean\": {\n            \"count\": 4.0,\n            \"mean\": 0.652083333,\n            \"std\": 0.134044199,\n            \"min\": 0.483333333,\n            \"25%\": 0.591666667,\n            \"50%\": 0.675,\n            \"75%\": 0.735416667,\n            \"max\": 0.775\n          },\n          \"liberty_foundation_mean\": {\n            \"count\": 4.0,\n            \"mean\": 0.83125,\n            \"std\": 0.158693847,\n            \"min\": 0.7,\n            \"25%\": 0.7,\n            \"50%\": 0.8125,\n            \"75%\": 0.94375,\n            \"max\": 1.0\n          }\n        },\n        \"Right\": {\n          \"care_raw_score\": {\n            \"count\": 4.0,\n            \"mean\": 0.475,\n            \"std\": 0.221735578,\n            \"min\": 0.2,\n            \"25%\": 0.35,\n            \"50%\": 0.5,\n            \"75%\": 0.625,\n            \"max\": 0.7\n          },\n          \"care_salience\": {\n            \"count\": 4.0,\n            \"mean\": 0.375,\n            \"std\": 0.221735578,\n            \"min\": 0.1,\n            \"25%\": 0.325,\n            \"50%\": 0.4,\n            \"75%\": 0.45,\n            \"max\": 0.6\n          },\n          \"harm_raw_score\": {\n            \"count\": 4.0,\n            \"mean\": 0.775,\n            \"std\": 0.262995564,\n            \"min\": 0.4,\n            \"25%\": 0.7,\n            \"50%\": 0.85,\n            \"75%\": 0.925,\n            \"max\": 1.0\n          },\n          \"harm_salience\": {\n            \"count\": 4.0,\n            \"mean\": 0.725,\n            \"std\": 0.298607881,\n            \"min\": 0.3,\n            \"25%\": 0.675,\n            \"50%\": 0.8,\n            \"75%\": 0.85,\n            \"max\": 1.0\n          },\n          \"fairness_raw_score\": {\n            \"count\": 4.0,\n            \"mean\": 0.775,\n            \"std\": 0.05,\n            \"min\": 0.7,\n            \"25%\": 0.775,\n            \"50%\": 0.8,\n            \"75%\": 0.8,\n            \"max\": 0.8\n          },\n          \"fairness_salience\": {\n            \"count\": 4.0,\n            \"mean\": 0.75,\n            \"std\": 0.057735027,\n            \"min\": 0.7,\n            \"25%\": 0.7,\n            \"50%\": 0.75,\n            \"75%\": 0.8,\n            \"max\": 0.8\n          },\n          \"cheating_raw_score\": {\n            \"count\": 4.0,\n            \"mean\": 0.7375,\n            \"std\": 0.478421481,\n            \"min\": 0.0,\n            \"25%\": 0.6875,\n            \"50%\": 0.925,\n            \"75%\": 0.975,\n            \"max\": 1.0\n          },\n          \"cheating_salience\": {\n            \"count\": 4.0,\n            \"mean\": 0.6375,\n            \"std\": 0.494058336,\n            \"min\": 0.0,\n            \"25%\": 0.45,\n            \"50%\": 0.9,\n            \"75%\": 0.9,\n            \"max\": 1.0\n          },\n          \"loyalty_raw_score\": {\n            \"count\": 4.0,\n            \"mean\": 0.75,\n            \"std\": 0.191485422,\n            \"min\": 0.5,\n            \"25%\": 0.65,\n            \"50%\": 0.8,\n            \"75%\": 0.9,\n            \"max\": 0.9\n          },\n          \"loyalty_salience\": {\n            \"count\": 4.0,\n            \"mean\": 0.6375,\n            \"std\": 0.27218698,\n            \"min\": 0.4,\n            \"25%\": 0.4,\n            \"50%\": 0.6,\n            \"75%\": 0.84375,\n            \"max\": 0.95\n          },\n          \"betrayal_raw_score\": {\n            \"count\": 4.0,\n            \"mean\": 0.6,\n            \"std\": 0.40824829,\n            \"min\": 0.0,\n            \"25%\": 0.525,\n            \"50%\": 0.75,\n            \"75%\": 0.825,\n            \"max\": 0.9\n          },\n          \"betrayal_salience\": {\n            \"count\": 4.0,\n            \"mean\": 0.3375,\n            \"std\": 0.40345479,\n            \"min\": 0.0,\n            \"25%\": 0.0,\n            \"50%\": 0.45,\n            \"75%\": 0.75,\n            \"max\": 0.9\n          },\n          \"authority_raw_score\": {\n            \"count\": 4.0,\n            \"mean\": 0.75,\n            \"std\": 0.191485422,\n            \"min\": 0.6,\n            \"25%\": 0.6,\n            \"50%\": 0.75,\n            \"75%\": 0.9,\n            \"max\": 0.9\n          },\n          \"authority_salience\": {\n            \"count\": 4.0,\n            \"mean\": 0.7,\n            \"std\": 0.182574186,\n            \"min\": 0.6,\n            \"25%\": 0.6,\n            \"50%\": 0.6,\n            \"75%\": 0.8,\n            \"max\": 0.9\n          },\n          \"subversion_raw_score\": {\n            \"count\": 4.0,\n            \"mean\": 0.775,\n            \"std\": 0.125830574,\n            \"min\": 0.7,\n            \"25%\": 0.7,\n            \"50%\": 0.75,\n            \"75%\": 0.825,\n            \"max\": 0.9\n          },\n          \"subversion_salience\": {\n            \"count\": 4.0,\n            \"mean\": 0.6875,\n            \"std\": 0.201556443,\n            \"min\": 0.4,\n            \"25%\": 0.625,\n            \"50%\": 0.8,\n            \"75%\": 0.8625,\n            \"max\": 0.8\n          },\n          \"sanctity_raw_score\": {\n            \"count\": 4.0,\n            \"mean\": 0.725,\n            \"std\": 0.221735578,\n            \"min\": 0.5,\n            \"25%\": 0.65,\n            \"50%\": 0.75,\n            \"75%\": 0.825,\n            \"max\": 0.9\n          },\n          \"sanctity_salience\": {\n            \"count\": 4.0,\n            \"mean\": 0.6,\n            \"std\": 0.230940108,\n            \"min\": 0.4,\n            \"25%\": 0.425,\n            \"50%\": 0.5,\n            \"75%\": 0.675,\n            \"max\": 0.9\n          },\n          \"degradation_raw_score\": {\n            \"count\": 4.0,\n            \"mean\": 0.6,\n            \"std\": 0.182574186,\n            \"min\": 0.5,\n            \"25%\": 0.5,\n            \"50%\": 0.5,\n            \"75%\": 0.6,\n            \"max\": 0.9\n          },\n          \"degradation_salience\": {\n            \"count\": 4.0,\n            \"mean\": 0.525,\n            \"std\": 0.221735578,\n            \"min\": 0.4,\n            \"25%\": 0.4,\n            \"50%\": 0.4,\n            \"75%\": 0.525,\n            \"max\": 0.9\n          },\n          \"liberty_raw_score\": {\n            \"count\": 4.0,\n            \"mean\": 0.65,\n            \"std\": 0.129099445,\n            \"min\": 0.5,\n            \"25%\": 0.575,\n            \"50%\": 0.65,\n            \"75%\": 0.725,\n            \"max\": 0.8\n          },\n          \"liberty_salience\": {\n            \"count\": 4.0,\n            \"mean\": 0.6,\n            \"std\": 0.081649658,\n            \"min\": 0.5,\n            \"25%\": 0.575,\n            \"50%\": 0.6,\n            \"75%\": 0.625,\n            \"max\": 0.7\n          },\n          \"oppression_raw_score\": {\n            \"count\": 4.0,\n            \"mean\": 0.7875,\n            \"std\": 0.110867812,\n            \"min\": 0.6,\n            \"25%\": 0.7875,\n            \"50%\": 0.8,\n            \"75%\": 0.8,\n            \"max\": 0.8\n          },\n          \"oppression_salience\": {\n            \"count\": 4.0,\n            \"mean\": 0.7375,\n            \"std\": 0.15,\n            \"min\": 0.5,\n            \"25%\": 0.7,\n            \"50%\": 0.8,\n            \"75%\": 0.8375,\n            \"max\": 0.85\n          },\n          \"care_harm_tension\": {\n            \"count\": 4.0,\n            \"mean\": 0.1025,\n            \"std\": 0.12392875,\n            \"min\": 0.0,\n            \"25%\": 0.0,\n            \"50%\": 0.09,\n            \"75%\": 0.1925,\n            \"max\": 0.23\n          },\n          \"fairness_cheating_tension\": {\n            \"count\": 4.0,\n            \"mean\": 0.1275,\n            \"std\": 0.207575688,\n            \"min\": 0.0,\n            \"25%\": 0.0,\n            \"50%\": 0.07,\n            \"75%\": 0.1975,\n            \"max\": 0.37\n          },\n          \"loyalty_betrayal_tension\": {\n            \"count\": 4.0,\n            \"mean\": 0.065,\n            \"std\": 0.099163198,\n            \"min\": 0.0,\n            \"25%\": 0.0,\n            \"50%\": 0.035,\n            \"75%\": 0.1,\n            \"max\": 0.19\n          },\n          \"authority_subversion_tension\": {\n            \"count\": 4.0,\n            \"mean\": 0.3925,\n            \"std\": 0.301371815,\n            \"min\": 0.0,\n            \"25%\": 0.3,\n            \"50%\": 0.44,\n            \"75%\": 0.5325,\n            \"max\": 0.69\n          },\n          \"sanctity_degradation_tension\": {\n            \"count\": 4.0,\n            \"mean\": 0.0675,\n            \"std\": 0.051234754,\n            \"min\": 0.0,\n            \"25%\": 0.0525,\n            \"50%\": 0.08,\n            \"75%\": 0.095,\n            \"max\": 0.11\n          },\n          \"liberty_oppression_tension\": {\n            \"count\": 4.0,\n            \"mean\": 0.07,\n            \"std\": 0.056568542,\n            \"min\": 0.0,\n            \"25%\": 0.0525,\n            \"50%\": 0.08,\n            \"75%\": 0.0975,\n            \"max\": 0.12\n          },\n          \"individualizing_tension\": {\n            \"count\": 4.0,\n            \"mean\": 0.23,\n            \"std\": 0.211455242,\n            \"min\": 0.0,\n            \"25%\": 0.09,\n            \"50%\": 0.245,\n            \"75%\": 0.385,\n            \"max\": 0.43\n          },\n          \"binding_tension\": {\n            \"count\": 4.0,\n            \"mean\": 0.525,\n            \"std\": 0.283133642,\n            \"min\": 0.19,\n            \"25%\": 0.385,\n            \"50%\": 0.53,\n            \"75%\": 0.67,\n            \"max\": 0.85\n          },\n          \"liberty_tension\": {\n            \"count\": 4.0,\n            \"mean\": 0.07,\n            \"std\": 0.056568542,\n            \"min\": 0.0,\n            \"25%\": 0.0525,\n            \"50%\": 0.08,\n            \"75%\": 0.0975,\n            \"max\": 0.12\n          },\n          \"moral_strategic_contradiction_index\": {\n            \"count\": 4.0,\n            \"mean\": 0.1375,\n            \"std\": 0.076321688,\n            \"min\": 0.045,\n            \"25%\": 0.10375,\n            \"50%\": 0.141666667,\n            \"75%\": 0.175416667,\n            \"max\": 0.221666667\n          },\n          \"moral_salience_concentration\": {\n            \"count\": 4.0,\n            \"mean\": 0.26904764,\n            \"std\": 0.165270183,\n            \"min\": 0.0559017,\n            \"25%\": 0.229124403,\n            \"50%\": 0.297434313,\n            \"75%\": 0.337357551,\n            \"max\": 0.425419924\n          },\n          \"individualizing_foundations_mean\": {\n            \"count\": 4.0,\n            \"mean\": 0.690625,\n            \"std\": 0.198270116,\n            \"min\": 0.425,\n            \"25%\": 0.6125,\n            \"50%\": 0.740625,\n            \"75%\": 0.81875,\n            \"max\": 0.85625\n          },\n          \"binding_foundations_mean\": {\n            \"count\": 4.0,\n            \"mean\": 0.720833333,\n            \"std\": 0.18738676,\n            \"min\": 0.458333333,\n            \"25%\": 0.654166667,\n            \"50%\": 0.75,\n            \"75%\": 0.816666667,\n            \"max\": 0.925\n          },\n          \"liberty_foundation_mean\": {\n            \"count\": 4.0,\n            \"mean\": 0.71875,\n            \"std\": 0.0625,\n            \"min\": 0.65,\n            \"25%\": 0.6875,\n            \"50%\": 0.71875,\n            \"75%\": 0.75,\n            \"max\": 0.7875\n          }\n        }\n      }\n    },\n    \"reliability_analysis\": {\n      \"status\": \"Not Performed\",\n      \"reason\": \"Inter-rater reliability analysis (e.g., Cronbach's alpha) could not be performed. The experiment description mentioned multi-evaluation, but the provided dataset contains only one evaluation per document. To calculate reliability, at least two independent analyses of each document are required.\"\n    },\n    \"additional_analyses\": {\n      \"correlation_analysis\": {\n        \"correlation_matrix\": [\n          {\n            \"variable\": \"care_raw_score\",\n            \"care_raw_score\": 1.0,\n            \"harm_raw_score\": 0.730248275,\n            \"fairness_raw_score\": 0.603022689,\n            \"cheating_raw_score\": 0.560413342,\n            \"loyalty_raw_score\": -0.161164585,\n            \"betrayal_raw_score\": 0.627191196,\n            \"authority_raw_score\": -0.871037599,\n            \"subversion_raw_score\": 0.806294334,\n            \"sanctity_raw_score\": 0.056033991,\n            \"degradation_raw_score\": 0.758369324,\n            \"liberty_raw_score\": 0.70929729,\n            \"oppression_raw_score\": 0.813733471,\n            \"moral_strategic_contradiction_index\": -0.584166258,\n            \"moral_salience_concentration\": -0.47394301,\n            \"individualizing_foundations_mean\": 0.898822509,\n            \"binding_foundations_mean\": 0.158226063,\n            \"liberty_foundation_mean\": 0.793833924\n          },\n          {\n            \"variable\": \"harm_raw_score\",\n            \"care_raw_score\": 0.730248275,\n            \"harm_raw_score\": 1.0,\n            \"fairness_raw_score\": 0.680413817,\n            \"cheating_raw_score\": 0.901614761,\n            \"loyalty_raw_score\": -0.161164585,\n            \"betrayal_raw_score\": 0.722650036,\n            \"authority_raw_score\": -0.468292911,\n            \"subversion_raw_score\": 0.887010214,\n            \"sanctity_raw_score\": -0.012553942,\n            \"degradation_raw_score\": 0.62325011,\n            \"liberty_raw_score\": 0.534824339,\n            \"oppression_raw_score\": 0.778816999,\n            \"moral_strategic_contradiction_index\": -0.219803273,\n            \"moral_salience_concentration\": 0.024926597,\n            \"individualizing_foundations_mean\": 0.963471167,\n            \"binding_foundations_mean\": 0.435728518,\n            \"liberty_foundation_mean\": 0.684175373\n          },\n          {\n            \"variable\": \"fairness_raw_score\",\n            \"care_raw_score\": 0.603022689,\n            \"harm_raw_score\": 0.680413817,\n            \"fairness_raw_score\": 1.0,\n            \"cheating_raw_score\": 0.439485125,\n            \"loyalty_raw_score\": 0.222722187,\n            \"betrayal_raw_score\": 0.260901235,\n            \"authority_raw_score\": -0.370327986,\n            \"subversion_raw_score\": 0.278784152,\n            \"sanctity_raw_score\": 0.380537255,\n            \"degradation_raw_score\": 0.428571429,\n            \"liberty_raw_score\": 0.231455025,\n            \"oppression_raw_score\": 0.469858712,\n            \"moral_strategic_contradiction_index\": -0.203024944,\n            \"moral_salience_concentration\": -0.198357062,\n            \"individualizing_foundations_mean\": 0.724744871,\n            \"binding_foundations_mean\": 0.263592656,\n            \"liberty_foundation_mean\": 0.368759551\n          },\n          {\n            \"variable\": \"cheating_raw_score\",\n            \"care_raw_score\": 0.560413342,\n            \"harm_raw_score\": 0.901614761,\n            \"fairness_raw_score\": 0.439485125,\n            \"cheating_raw_score\": 1.0,\n            \"loyalty_raw_score\": -0.384594226,\n            \"betrayal_raw_score\": 0.710780447,\n            \"authority_raw_score\": -0.239252814,\n            \"subversion_raw_score\": 0.907921318,\n            \"sanctity_raw_score\": -0.096339739,\n            \"degradation_raw_score\": 0.41923955,\n            \"liberty_raw_score\": 0.244365691,\n            \"oppression_raw_score\": 0.609104085,\n            \"moral_strategic_contradiction_index\": -0.045167096,\n            \"moral_salience_concentration\": 0.285810052,\n            \"individualizing_foundations_mean\": 0.868778467,\n            \"binding_foundations_mean\": 0.528227694,\n            \"liberty_foundation_mean\": 0.457883296\n          },\n          {\n            \"variable\": \"loyalty_raw_score\",\n            \"care_raw_score\": -0.161164585,\n            \"harm_raw_score\": -0.161164585,\n            \"fairness_raw_score\": 0.222722187,\n            \"cheating_raw_score\": -0.384594226,\n            \"loyalty_raw_score\": 1.0,\n            \"betrayal_raw_score\": -0.627191196,\n            \"authority_raw_score\": 0.427841315,\n            \"subversion_raw_score\": -0.564198427,\n            \"sanctity_raw_score\": 0.168101974,\n            \"degradation_raw_score\": 0.05268453,\n            \"liberty_raw_score\": -0.117180424,\n            \"oppression_raw_score\": -0.134542749,\n            \"moral_strategic_contradiction_index\": 0.354160416,\n            \"moral_salience_concentration\": -0.124564551,\n            \"individualizing_foundations_mean\": -0.136082763,\n            \"binding_foundations_mean\": 0.147254589,\n            \"liberty_foundation_mean\": -0.130833912\n          },\n          {\n            \"variable\": \"betrayal_raw_score\",\n            \"care_raw_score\": 0.627191196,\n            \"harm_raw_score\": 0.722650036,\n            \"fairness_raw_score\": 0.260901235,\n            \"cheating_raw_score\": 0.710780447,\n            \"loyalty_raw_score\": -0.627191196,\n            \"betrayal_raw_score\": 1.0,\n            \"authority_raw_score\": -0.490184407,\n            \"subversion_raw_score\": 0.81734267,\n            \"sanctity_raw_score\": -0.063857313,\n            \"degradation_raw_score\": 0.318858643,\n            \"liberty_raw_score\": 0.288675135,\n            \"oppression_raw_score\": 0.472787095,\n            \"moral_strategic_contradiction_index\": -0.198308821,\n            \"moral_salience_concentration\": 0.424694421,\n            \"individualizing_foundations_mean\": 0.697423377,\n            \"binding_foundations_mean\": 0.589886477,\n            \"liberty_foundation_mean\": 0.402288151\n          },\n          {\n            \"variable\": \"authority_raw_score\",\n            \"care_raw_score\": -0.871037599,\n            \"harm_raw_score\": -0.468292911,\n            \"fairness_raw_score\": -0.370327986,\n            \"cheating_raw_score\": -0.239252814,\n            \"loyalty_raw_score\": 0.427841315,\n            \"betrayal_raw_score\": -0.490184407,\n            \"authority_raw_score\": 1.0,\n            \"subversion_raw_score\": -0.635840618,\n            \"sanctity_raw_score\": 0.231260421,\n            \"degradation_raw_score\": -0.566373117,\n            \"liberty_raw_score\": -0.534824339,\n            \"oppression_raw_score\": -0.686802816,\n            \"moral_strategic_contradiction_index\": 0.852303534,\n            \"moral_salience_concentration\": 0.430030064,\n            \"individualizing_foundations_mean\": -0.613318252,\n            \"binding_foundations_mean\": 0.15573436,\n            \"liberty_foundation_mean\": -0.634620023\n          },\n          {\n            \"variable\": \"subversion_raw_score\",\n            \"care_raw_score\": 0.806294334,\n            \"harm_raw_score\": 0.887010214,\n            \"fairness_raw_score\": 0.278784152,\n            \"cheating_raw_score\": 0.907921318,\n            \"loyalty_raw_score\": -0.564198427,\n            \"betrayal_raw_score\": 0.81734267,\n            \"authority_raw_score\": -0.635840618,\n            \"subversion_raw_score\": 1.0,\n            \"sanctity_raw_score\": -0.063857313,\n            \"degradation_raw_score\": 0.490130983,\n            \"liberty_raw_score\": 0.534824339,\n            \"oppression_raw_score\": 0.701199341,\n            \"moral_strategic_contradiction_index\": -0.37190013,\n            \"moral_salience_concentration\": 0.271383375,\n            \"individualizing_foundations_mean\": 0.865391629,\n            \"binding_foundations_mean\": 0.609439265,\n            \"liberty_foundation_mean\": 0.634620023\n          },\n          {\n            \"variable\": \"sanctity_raw_score\",\n            \"care_raw_score\": 0.056033991,\n            \"harm_raw_score\": -0.012553942,\n            \"fairness_raw_score\": 0.380537255,\n            \"cheating_raw_score\": -0.096339739,\n            \"loyalty_raw_score\": 0.168101974,\n            \"betrayal_raw_score\": -0.063857313,\n            \"authority_raw_score\": 0.231260421,\n            \"subversion_raw_score\": -0.063857313,\n            \"sanctity_raw_score\": 1.0,\n            \"degradation_raw_score\": 0.443203494,\n            \"liberty_raw_score\": 0.175770642,\n            \"oppression_raw_score\": -0.082222631,\n            \"moral_strategic_contradiction_index\": 0.141707011,\n            \"moral_salience_concentration\": -0.28318045,\n            \"individualizing_foundations_mean\": 0.067420003,\n            \"binding_foundations_mean\": 0.435728518,\n            \"liberty_foundation_mean\": 0.024545401\n          },\n          {\n            \"variable\": \"degradation_raw_score\",\n            \"care_raw_score\": 0.758369324,\n            \"harm_raw_score\": 0.62325011,\n            \"fairness_raw_score\": 0.428571429,\n            \"cheating_raw_score\": 0.41923955,\n            \"loyalty_raw_score\": 0.05268453,\n            \"betrayal_raw_score\": 0.318858643,\n            \"authority_raw_score\": -0.566373117,\n            \"subversion_raw_score\": 0.490130983,\n            \"sanctity_raw_score\": 0.443203494,\n            \"degradation_raw_score\": 1.0,\n            \"liberty_raw_score\": 0.645497224,\n            \"oppression_raw_score\": 0.760285638,\n            \"moral_strategic_contradiction_index\": -0.462335193,\n            \"moral_salience_concentration\": -0.540150962,\n            \"individualizing_foundations_mean\": 0.672076211,\n            \"binding_foundations_mean\": 0.509749842,\n            \"liberty_foundation_mean\": 0.71835922\n          },\n          {\n            \"variable\": \"liberty_raw_score\",\n            \"care_raw_score\": 0.70929729,\n            \"harm_raw_score\": 0.534824339,\n            \"fairness_raw_score\": 0.231455025,\n            \"cheating_raw_score\": 0.244365691,\n            \"loyalty_raw_score\": -0.117180424,\n            \"betrayal_raw_score\": 0.288675135,\n            \"authority_raw_score\": -0.534824339,\n            \"subversion_raw_score\": 0.534824339,\n            \"sanctity_raw_score\": 0.175770642,\n            \"degradation_raw_score\": 0.645497224,\n            \"liberty_raw_score\": 1.0,\n            \"oppression_raw_score\": 0.822226311,\n            \"moral_strategic_contradiction_index\": -0.638573129,\n            \"moral_salience_concentration\": -0.428174418,\n            \"individualizing_foundations_mean\": 0.547722558,\n            \"binding_foundations_mean\": 0.263592656,\n            \"liberty_foundation_mean\": 0.94132174\n          },\n          {\n            \"variable\": \"oppression_raw_score\",\n            \"care_raw_score\": 0.813733471,\n            \"harm_raw_score\": 0.778816999,\n            \"fairness_raw_score\": 0.469858712,\n            \"cheating_raw_score\": 0.609104085,\n            \"loyalty_raw_score\": -0.134542749,\n            \"betrayal_raw_score\": 0.472787095,\n            \"authority_raw_score\": -0.686802816,\n            \"subversion_raw_score\": 0.701199341,\n            \"sanctity_raw_score\": -0.082222631,\n            \"degradation_raw_score\": 0.760285638,\n            \"liberty_raw_score\": 0.822226311,\n            \"oppression_raw_score\": 1.0,\n            \"moral_strategic_contradiction_index\": -0.589146973,\n            \"moral_salience_concentration\": -0.380295117,\n            \"individualizing_foundations_mean\": 0.785361244,\n            \"binding_foundations_mean\": 0.354160416,\n            \"liberty_foundation_mean\": 0.94132174\n          },\n          {\n            \"variable\": \"moral_strategic_contradiction_index\",\n            \"care_raw_score\": -0.584166258,\n            \"harm_raw_score\": -0.219803273,\n            \"fairness_raw_score\": -0.203024944,\n            \"cheating_raw_score\": -0.045167096,\n            \"loyalty_raw_score\": 0.354160416,\n            \"betrayal_raw_score\": -0.198308821,\n            \"authority_raw_score\": 0.852303534,\n            \"subversion_raw_score\": -0.37190013,\n            \"sanctity_raw_score\": 0.141707011,\n            \"degradation_raw_score\": -0.462335193,\n            \"liberty_raw_score\": -0.638573129,\n            \"oppression_raw_score\": -0.589146973,\n            \"moral_strategic_contradiction_index\": 1.0,\n            \"moral_salience_concentration\": 0.583321556,\n            \"individualizing_foundations_mean\": -0.316823908,\n            \"binding_foundations_mean\": 0.375713437,\n            \"liberty_foundation_mean\": -0.630988636\n          },\n          {\n            \"variable\": \"moral_salience_concentration\",\n            \"care_raw_score\": -0.47394301,\n            \"harm_raw_score\": 0.024926597,\n            \"fairness_raw_score\": -0.198357062,\n            \"cheating_raw_score\": 0.285810052,\n            \"loyalty_raw_score\": -0.124564551,\n            \"betrayal_raw_score\": 0.424694421,\n            \"authority_raw_score\": 0.430030064,\n            \"subversion_raw_score\": 0.271383375,\n            \"sanctity_raw_score\": -0.28318045,\n            \"degradation_raw_score\": -0.540150962,\n            \"liberty_raw_score\": -0.428174418,\n            \"oppression_raw_score\": -0.380295117,\n            \"moral_strategic_contradiction_index\": 0.583321556,\n            \"moral_salience_concentration\": 1.0,\n            \"individualizing_foundations_mean\": 0.076828551,\n            \"binding_foundations_mean\": 0.536979929,\n            \"liberty_foundation_mean\": -0.420803452\n          },\n          {\n            \"variable\": \"individualizing_foundations_mean\",\n            \"care_raw_score\": 0.898822509,\n            \"harm_raw_score\": 0.963471167,\n            \"fairness_raw_score\": 0.724744871,\n            \"cheating_raw_score\": 0.868778467,\n            \"loyalty_raw_score\": -0.136082763,\n            \"betrayal_raw_score\": 0.697423377,\n            \"authority_raw_score\": -0.613318252,\n            \"subversion_raw_score\": 0.865391629,\n            \"sanctity_raw_score\": 0.067420003,\n            \"degradation_raw_score\": 0.672076211,\n            \"liberty_raw_score\": 0.547722558,\n            \"oppression_raw_score\": 0.785361244,\n            \"moral_strategic_contradiction_index\": -0.316823908,\n            \"moral_salience_concentration\": -0.076828551,\n            \"individualizing_foundations_mean\": 1.0,\n            \"binding_foundations_mean\": 0.388143216,\n            \"liberty_foundation_mean\": 0.701199341\n          },\n          {\n            \"variable\": \"binding_foundations_mean\",\n            \"care_raw_score\": 0.158226063,\n            \"harm_raw_score\": 0.435728518,\n            \"fairness_raw_score\": 0.263592656,\n            \"cheating_raw_score\": 0.528227694,\n            \"loyalty_raw_score\": 0.147254589,\n            \"betrayal_raw_score\": 0.589886477,\n            \"authority_raw_score\": 0.15573436,\n            \"subversion_raw_score\": 0.609439265,\n            \"sanctity_raw_score\": 0.435728518,\n            \"degradation_raw_score\": 0.509749842,\n            \"liberty_raw_score\": 0.263592656,\n            \"oppression_raw_score\": 0.354160416,\n            \"moral_strategic_contradiction_index\": 0.375713437,\n            \"moral_salience_concentration\": 0.536979929,\n            \"individualizing_foundations_mean\": 0.388143216,\n            \"binding_foundations_mean\": 1.0,\n            \"liberty_foundation_mean\": 0.318858643\n          },\n          {\n            \"variable\": \"liberty_foundation_mean\",\n            \"care_raw_score\": 0.793833924,\n            \"harm_raw_score\": 0.684175373,\n            \"fairness_raw_score\": 0.368759551,\n            \"cheating_raw_score\": 0.457883296,\n            \"loyalty_raw_score\": -0.130833912,\n            \"betrayal_raw_score\": 0.402288151,\n            \"authority_raw_score\": -0.634620023,\n            \"subversion_raw_score\": 0.634620023,\n            \"sanctity_raw_score\": 0.024545401,\n            \"degradation_raw_score\": 0.71835922,\n            \"liberty_raw_score\": 0.94132174,\n            \"oppression_raw_score\": 0.94132174,\n            \"moral_strategic_contradiction_index\": -0.630988636,\n            \"moral_salience_concentration\": -0.420803452,\n            \"individualizing_foundations_mean\": 0.701199341,\n            \"binding_foundations_mean\": 0.318858643,\n            \"liberty_foundation_mean\": 1.0\n          }\n        ],\n        \"notes\": \"Exploratory analysis for N=8. Interpret with extreme caution. High-magnitude correlations may suggest relationships worth investigating in larger samples.\"\n      },\n      \"group_comparisons\": {\n        \"comparison_groups\": [\n          \"Left\",\n          \"Right\"\n        ],\n        \"test_results\": {\n          \"care_raw_score\": {\n            \"group1_mean\": 0.85,\n            \"group2_mean\": 0.475,\n            \"mann_whitney_u\": 1.0,\n            \"p_value\": 0.057142857,\n            \"rank_biserial_correlation\": 0.875,\n            \"cohens_d\": 1.956792484\n          },\n          \"care_salience\": {\n            \"group1_mean\": 0.775,\n            \"group2_mean\": 0.375,\n            \"mann_whitney_u\": 1.0,\n            \"p_value\": 0.057142857,\n            \"rank_biserial_correlation\": 0.875,\n            \"cohens_d\": 1.91663111\n          },\n          \"harm_raw_score\": {\n            \"group1_mean\": 0.9125,\n            \"group2_mean\": 0.775,\n            \"mann_whitney_u\": 5.0,\n            \"p_value\": 0.485714286,\n            \"rank_biserial_correlation\": 0.375,\n            \"cohens_d\": 0.742338165\n          },\n          \"harm_salience\": {\n            \"group1_mean\": 0.8125,\n            \"group2_mean\": 0.725,\n            \"mann_whitney_u\": 6.5,\n            \"p_value\": 0.742857143,\n            \"rank_biserial_correlation\": 0.1875,\n            \"cohens_d\": 0.414321356\n          },\n          \"fairness_raw_score\": {\n            \"group1_mean\": 0.825,\n            \"group2_mean\": 0.775,\n            \"mann_whitney_u\": 5.0,\n            \"p_value\": 0.485714286,\n            \"rank_biserial_correlation\": 0.375,\n            \"cohens_d\": 1.0\n          },\n          \"fairness_salience\": {\n            \"group1_mean\": 0.725,\n            \"group2_mean\": 0.75,\n            \"mann_whitney_u\": 9.5,\n            \"p_value\": 0.742857143,\n            \"rank_biserial_correlation\": -0.1875,\n            \"cohens_d\": -0.344265194\n          },\n          \"cheating_raw_score\": {\n            \"group1_mean\": 0.875,\n            \"group2_mean\": 0.7375,\n            \"mann_whitney_u\": 6.0,\n            \"p_value\": 0.628571429,\n            \"rank_biserial_correlation\": 0.25,\n            \"cohens_d\": 0.420958742\n          },\n          \"cheating_salience\": {\n            \"group1_mean\": 0.775,\n            \"group2_mean\": 0.6375,\n            \"mann_whitney_u\": 6.0,\n            \"p_value\": 0.628571429,\n            \"rank_biserial_correlation\": 0.25,\n            \"cohens_d\": 0.410141684\n          },\n          \"loyalty_raw_score\": {\n            \"group1_mean\": 0.7,\n            \"group2_mean\": 0.75,\n            \"mann_whitney_u\": 9.0,\n            \"p_value\": 0.885714286,\n            \"rank_biserial_correlation\": -0.125,\n            \"cohens_d\": -0.320256308\n          },\n          \"loyalty_salience\": {\n            \"group1_mean\": 0.6625,\n            \"group2_mean\": 0.6375,\n            \"mann_whitney_u\": 7.0,\n            \"p_value\": 0.885714286,\n            \"rank_biserial_correlation\": 0.125,\n            \"cohens_d\": 0.13437505\n          },\n          \"betrayal_raw_score\": {\n            \"group1_mean\": 0.6875,\n            \"group2_mean\": 0.6,\n            \"mann_whitney_u\": 7.0,\n            \"p_value\": 0.885714286,\n            \"rank_biserial_correlation\": 0.125,\n            \"cohens_d\": 0.297441865\n          },\n          \"betrayal_salience\": {\n            \"group1_mean\": 0.6,\n            \"group2_mean\": 0.3375,\n            \"mann_whitney_u\": 4.0,\n            \"p_value\": 0.342857143,\n            \"rank_biserial_correlation\": 0.5,\n            \"cohens_d\": 0.889014022\n          },\n          \"authority_raw_score\": {\n            \"group1_mean\": 0.25,\n            \"group2_mean\": 0.75,\n            \"mann_whitney_u\": 15.0,\n            \"p_value\": 0.057142857,\n            \"rank_biserial_correlation\": -0.875,\n            \"cohens_d\": -2.179449472\n          },\n          \"authority_salience\": {\n            \"group1_mean\": 0.175,\n            \"group2_mean\": 0.7,\n            \"mann_whitney_u\": 15.0,\n            \"p_value\": 0.057142857,\n            \"rank_biserial_correlation\": -0.875,\n            \"cohens_d\": -2.857738033\n          },\n          \"subversion_raw_score\": {\n            \"group1_mean\": 0.9,\n            \"group2_mean\": 0.775,\n            \"mann_whitney_u\": 5.0,\n            \"p_value\": 0.485714286,\n            \"rank_biserial_correlation\": 0.375,\n            \"cohens_d\": 0.942809042\n          },\n          \"subversion_salience\": {\n            \"group1_mean\": 0.8125,\n            \"group2_mean\": 0.6875,\n            \"mann_whitney_u\": 5.0,\n            \"p_value\": 0.485714286,\n            \"rank_biserial_correlation\": 0.375,\n            \"cohens_d\": 0.74804618\n          },\n          \"sanctity_raw_score\": {\n            \"group1_mean\": 0.65,\n            \"group2_mean\": 0.725,\n            \"mann_whitney_u\": 10.0,\n            \"p_value\": 0.628571429,\n            \"rank_biserial_correlation\": -0.25,\n            \"cohens_d\": -0.378932536\n          },\n          \"sanctity_salience\": {\n            \"group1_mean\": 0.6,\n            \"group2_mean\": 0.6,\n            \"mann_whitney_u\": 8.0,\n            \"p_value\": 1.0,\n            \"rank_biserial_correlation\": 0.0,\n            \"cohens_d\": 0.0\n          },\n          \"degradation_raw_score\": {\n            \"group1_mean\": 0.85,\n            \"group2_mean\": 0.6,\n            \"mann_whitney_u\": 3.0,\n            \"p_value\": 0.2,\n            \"rank_biserial_correlation\": 0.625,\n            \"cohens_d\": 1.58113883\n          },\n          \"degradation_salience\": {\n            \"group1_mean\": 0.75,\n            \"group2_mean\": 0.525,\n            \"mann_whitney_u\": 4.5,\n            \"p_value\": 0.4,\n            \"rank_biserial_correlation\": 0.4375,\n            \"cohens_d\": 1.091089451\n          },\n          \"liberty_raw_score\": {\n            \"group1_mean\": 0.725,\n            \"group2_mean\": 0.65,\n            \"mann_whitney_u\": 6.0,\n            \"p_value\": 0.628571429,\n            \"rank_biserial_correlation\": 0.25,\n            \"cohens_d\": 0.418731534\n          },\n          \"liberty_salience\": {\n            \"group1_mean\": 0.675,\n            \"group2_mean\": 0.6,\n            \"mann_whitney_u\": 7.0,\n            \"p_value\": 0.885714286,\n            \"rank_biserial_correlation\": 0.125,\n            \"cohens_d\": 0.38028723\n          },\n          \"oppression_raw_score\": {\n            \"group1_mean\": 0.9375,\n            \"group2_mean\": 0.7875,\n            \"mann_whitney_u\": 3.0,\n            \"p_value\": 0.2,\n            \"rank_biserial_correlation\": 0.625,\n            \"cohens_d\": 1.767766953\n          },\n          \"oppression_salience\": {\n            \"group1_mean\": 0.8875,\n            \"group2_mean\": 0.7375,\n            \"mann_whitney_u\": 3.0,\n            \"p_value\": 0.2,\n            \"rank_biserial_correlation\": 0.625,\n            \"cohens_d\": 1.455060136\n          },\n          \"care_harm_tension\": {\n            \"group1_mean\": 0.02,\n            \"group2_mean\": 0.1025,\n            \"mann_whitney_u\": 11.0,\n            \"p_value\": 0.342857143,\n            \"rank_biserial_correlation\": -0.375,\n            \"cohens_d\": -0.88874836\n          },\n          \"fairness_cheating_tension\": {\n            \"group1_mean\": 0.0325,\n            \"group2_mean\": 0.1275,\n            \"mann_whitney_u\": 10.0,\n            \"p_value\": 0.628571429,\n            \"rank_biserial_correlation\": -0.25,\n            \"cohens_d\": -0.66699313\n          },\n          \"loyalty_betrayal_tension\": {\n            \"group1_mean\": 0.075,\n            \"group2_mean\": 0.065,\n            \"mann_whitney_u\": 7.5,\n            \"p_value\": 0.971428571,\n            \"rank_biserial_correlation\": 0.0625,\n            \"cohens_d\": 0.147441961\n          },\n          \"authority_subversion_tension\": {\n            \"group1_mean\": 0.0875,\n            \"group2_mean\": 0.3925,\n            \"mann_whitney_u\": 12.0,\n            \"p_value\": 0.2,\n            \"rank_biserial_correlation\": -0.5,\n            \"cohens_d\": -1.35339683\n          },\n          \"sanctity_degradation_tension\": {\n            \"group1_mean\": 0.0,\n            \"group2_mean\": 0.0675,\n            \"mann_whitney_u\": 14.0,\n            \"p_value\": 0.085714286,\n            \"rank_biserial_correlation\": -0.75,\n            \"cohens_d\": -2.023246755\n          },\n          \"liberty_oppression_tension\": {\n            \"group1_mean\": 0.035,\n            \"group2_mean\": 0.07,\n            \"mann_whitney_u\": 10.0,\n            \"p_value\": 0.628571429,\n            \"rank_biserial_correlation\": -0.25,\n            \"cohens_d\": -0.692820323\n          },\n          \"individualizing_tension\": {\n            \"group1_mean\": 0.0525,\n            \"group2_mean\": 0.23,\n            \"mann_whitney_u\": 11.5,\n            \"p_value\": 0.26,\n            \"rank_biserial_correlation\": -0.4375,\n            \"cohens_d\": -1.411652156\n          },\n          \"binding_tension\": {\n            \"group1_mean\": 0.1625,\n            \"group2_mean\": 0.525,\n            \"mann_whitney_u\": 14.0,\n            \"p_value\": 0.085714286,\n            \"rank_biserial_correlation\": -0.75,\n            \"cohens_d\": -1.91663111\n          },\n          \"liberty_tension\": {\n            \"group1_mean\": 0.035,\n            \"group2_mean\": 0.07,\n            \"mann_whitney_u\": 10.0,\n            \"p_value\": 0.628571429,\n            \"rank_biserial_correlation\": -0.25,\n            \"cohens_d\": -0.692820323\n          },\n          \"moral_strategic_contradiction_index\": {\n            \"group1_mean\": 0.041666667,\n            \"group2_mean\": 0.1375,\n            \"mann_whitney_u\": 14.0,\n            \"p_value\": 0.085714286,\n            \"rank_biserial_correlation\": -0.75,\n            \"cohens_d\": -1.979047913\n          },\n          \"moral_salience_concentration\": {\n            \"group1_mean\": 0.176410264,\n            \"group2_mean\": 0.26904764,\n            \"mann_whitney_u\": 11.0,\n            \"p_value\": 0.342857143,\n            \"rank_biserial_correlation\": -0.375,\n            \"cohens_d\": -0.738128456\n          },\n          \"individualizing_foundations_mean\": {\n            \"group1_mean\": 0.865625,\n            \"group2_mean\": 0.690625,\n            \"mann_whitney_u\": 3.0,\n            \"p_value\": 0.2,\n            \"rank_biserial_correlation\": 0.625,\n            \"cohens_d\": 1.401917228\n          },\n          \"binding_foundations_mean\": {\n            \"group1_mean\": 0.652083333,\n            \"group2_mean\": 0.720833333,\n            \"mann_whitney_u\": 10.0,\n            \"p_value\": 0.628571429,\n            \"rank_biserial_correlation\": -0.25,\n            \"cohens_d\": -0.428450172\n          },\n          \"liberty_foundation_mean\": {\n            \"group1_mean\": 0.83125,\n            \"group2_mean\": 0.71875,\n            \"mann_whitney_u\": 5.0,\n            \"p_value\": 0.485714286,\n            \"rank_biserial_correlation\": 0.375,\n            \"cohens_d\": 0.999687353\n          }\n        },\n        \"notes\": \"Highly exploratory due to N=4 per group. P-values are unreliable. Focus on effect sizes for potential patterns.\"\n      }\n    }\n  },\n  \"sample_size_assessment\": {\n    \"total_documents\": 8,\n    \"tier_classification\": \"TIER 3\",\n    \"power_notes\": \"The analysis is exploratory due to the very small sample size (N=8). Statistical power is extremely low, making inferential tests (like t-tests or correlations) unreliable for formal hypothesis testing. The results should be interpreted as preliminary patterns for future investigation rather than conclusive findings. The primary focus is on descriptive statistics and effect sizes to identify potentially meaningful trends.\"\n  },\n  \"methodology_summary\": \"This Tier 3 exploratory analysis was conducted on a corpus of 8 political speeches. Due to the small sample size, the methodology prioritizes descriptive statistics (mean, standard deviation) to characterize the distribution of moral foundation scores and derived metrics. To explore potential differences between ideological blocs ('Left' vs. 'Right', n=4 per group), non-parametric Mann-Whitney U tests were performed, accompanied by effect sizes (Cohen's d, Rank-Biserial Correlation) for pattern detection. A Pearson correlation matrix was also generated for purely exploratory purposes. All findings are interpreted with significant caution due to extremely low statistical power. Reliability analysis was not possible as only one evaluation was provided per document.\"\n}\n```",
  "analysis_artifacts_processed": 16,
  "cost_info": {
    "model": "vertex_ai/gemini-2.5-pro",
    "execution_time_seconds": 266.01754,
    "response_cost": 0.0,
    "input_tokens": 0,
    "output_tokens": 0,
    "total_tokens": 0,
    "prompt_length": 140671,
    "response_length": 71070
  },
  "timestamp": "2025-09-17T02:05:47.596161+00:00"
}