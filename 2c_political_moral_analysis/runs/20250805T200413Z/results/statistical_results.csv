test_name,test_type,statistic_name,statistic_value,p_value,effect_size,degrees_of_freedom,sample_size,dependent_variable,grouping_variable,significance_level,interpretation,notes
calculate_individualizing_tension,derived_metrics_calculation,result_value,"{'type': 'derived_metrics_calculation', 'success': True, 'calculated_metrics': {'individualizing_tension': [0.28500000000000003, 0.14499999999999996, 0.3075, 0.04500000000000003, 0.22000000000000003, 0.17250000000000001, 0.07000000000000006, 0.21999999999999997]}, 'successful_calculations': ['individualizing_tension'], 'failed_calculations': [], 'formulas_used': ['individualizing_tension'], 'input_columns': ['care_score', 'care_salience', 'harm_score', 'harm_salience', 'fairness_score', 'fairness_salience', 'cheating_score', 'cheating_salience'], 'total_metrics': 1, 'success_rate': 1.0}",,,,,,,,Generic derived_metrics_calculation result,
calculate_binding_tension,derived_metrics_calculation,result_value,"{'type': 'derived_metrics_calculation', 'success': True, 'calculated_metrics': {'binding_tension': [0.04499999999999995, 0.0825, 0.04, 0.08000000000000006, 0.18, 0.15750000000000003, 0.16999999999999998, 0.17000000000000004]}, 'successful_calculations': ['binding_tension'], 'failed_calculations': [], 'formulas_used': ['binding_tension'], 'input_columns': ['loyalty_score', 'loyalty_salience', 'betrayal_score', 'betrayal_salience', 'authority_score', 'authority_salience', 'subversion_score', 'subversion_salience', 'sanctity_score', 'sanctity_salience', 'degradation_score', 'degradation_salience'], 'total_metrics': 1, 'success_rate': 1.0}",,,,,,,,Generic derived_metrics_calculation result,
calculate_foundation_tension,derived_metrics_calculation,result_value,"{'type': 'derived_metrics_calculation', 'success': False, 'calculated_metrics': {}, 'successful_calculations': [], 'failed_calculations': [{'metric': 'foundation_tension', 'formula': 'np.abs(individualizing_foundations_mean - binding_foundations_mean) * np.abs(individualizing_salience_mean - binding_salience_mean)', 'error': ""name 'individualizing_foundations_mean' is not defined""}], 'formulas_used': ['foundation_tension'], 'input_columns': ['care_score', 'harm_score', 'fairness_score', 'cheating_score', 'care_salience', 'harm_salience', 'fairness_salience', 'cheating_salience', 'loyalty_score', 'betrayal_score', 'authority_score', 'subversion_score', 'sanctity_score', 'degradation_score', 'loyalty_salience', 'betrayal_salience', 'authority_salience', 'subversion_salience', 'sanctity_salience', 'degradation_salience'], 'total_metrics': 1, 'success_rate': 0.0}",,,,,,,,Generic derived_metrics_calculation result,
calculate_msci,derived_metrics_calculation,result_value,"{'type': 'derived_metrics_calculation', 'success': False, 'error': ""Missing required columns: ['foundation_tension']"", 'available_columns': ['aid', 'speaker', 'ideology', 'date', 'context', 'category', 'care_score', 'care_salience', 'care_confidence', 'harm_score', 'harm_salience', 'harm_confidence', 'fairness_score', 'fairness_salience', 'fairness_confidence', 'cheating_score', 'cheating_salience', 'cheating_confidence', 'loyalty_score', 'loyalty_salience', 'loyalty_confidence', 'betrayal_score', 'betrayal_salience', 'betrayal_confidence', 'authority_score', 'authority_salience', 'authority_confidence', 'subversion_score', 'subversion_salience', 'subversion_confidence', 'sanctity_score', 'sanctity_salience', 'sanctity_confidence', 'degradation_score', 'degradation_salience', 'degradation_confidence', 'gasket_version', 'extraction_time_seconds', 'individualizing_tension', 'binding_tension'], 'calculated_metrics': {}, 'formulas_used': ['moral_strategic_contradiction_index']}",,,,,,,,Generic derived_metrics_calculation result,
classify_moral_patterns,derived_metrics_calculation,result_value,"{'type': 'derived_metrics_calculation', 'success': False, 'error': ""Missing required columns: ['moral_strategic_contradiction_index']"", 'available_columns': ['aid', 'speaker', 'ideology', 'date', 'context', 'category', 'care_score', 'care_salience', 'care_confidence', 'harm_score', 'harm_salience', 'harm_confidence', 'fairness_score', 'fairness_salience', 'fairness_confidence', 'cheating_score', 'cheating_salience', 'cheating_confidence', 'loyalty_score', 'loyalty_salience', 'loyalty_confidence', 'betrayal_score', 'betrayal_salience', 'betrayal_confidence', 'authority_score', 'authority_salience', 'authority_confidence', 'subversion_score', 'subversion_salience', 'subversion_confidence', 'sanctity_score', 'sanctity_salience', 'sanctity_confidence', 'degradation_score', 'degradation_salience', 'degradation_confidence', 'gasket_version', 'extraction_time_seconds', 'individualizing_tension', 'binding_tension'], 'calculated_metrics': {}, 'formulas_used': ['moral_pattern']}",,,,,,,,Generic derived_metrics_calculation result,
validate_derived_metrics_range,metric_validation,result_value,"{'type': 'metric_validation', 'validation_rules': [""{'metric_name': 'individualizing_tension', 'rule': 'range_check', 'parameters': {'min_value': 0.0, 'max_value': 1.0}}"", ""{'metric_name': 'binding_tension', 'rule': 'range_check', 'parameters': {'min_value': 0.0, 'max_value': 1.0}}"", ""{'metric_name': 'foundation_tension', 'rule': 'range_check', 'parameters': {'min_value': 0.0, 'max_value': 1.0}}"", ""{'metric_name': 'moral_strategic_contradiction_index', 'rule': 'range_check', 'parameters': {'min_value': 0.0, 'max_value': 1.0}}""], 'results': {'unknown_rule': {'status': 'not_found', 'message': ""Metric 'unknown_rule' not found in dataframe"", 'available_columns': ['aid', 'speaker', 'ideology', 'date', 'context', 'category', 'care_score', 'care_salience', 'care_confidence', 'harm_score', 'harm_salience', 'harm_confidence', 'fairness_score', 'fairness_salience', 'fairness_confidence', 'cheating_score', 'cheating_salience', 'cheating_confidence', 'loyalty_score', 'loyalty_salience', 'loyalty_confidence', 'betrayal_score', 'betrayal_salience', 'betrayal_confidence', 'authority_score', 'authority_salience', 'authority_confidence', 'subversion_score', 'subversion_salience', 'subversion_confidence', 'sanctity_score', 'sanctity_salience', 'sanctity_confidence', 'degradation_score', 'degradation_salience', 'degradation_confidence', 'gasket_version', 'extraction_time_seconds', 'individualizing_tension', 'binding_tension'], 'note': 'This is a framework-agnostic validation - LLMs determine validation logic'}}, 'quality_thresholds': {'range_check': 0.95}}",,,,,,,,Generic metric_validation result,
validate_derived_metrics_missing_data,metric_validation,result_value,"{'type': 'metric_validation', 'validation_rules': [""{'metric_name': 'individualizing_tension', 'rule': 'missing_data_check'}"", ""{'metric_name': 'binding_tension', 'rule': 'missing_data_check'}"", ""{'metric_name': 'foundation_tension', 'rule': 'missing_data_check'}"", ""{'metric_name': 'moral_strategic_contradiction_index', 'rule': 'missing_data_check'}"", ""{'metric_name': 'moral_pattern', 'rule': 'missing_data_check'}""], 'results': {'unknown_rule': {'status': 'not_found', 'message': ""Metric 'unknown_rule' not found in dataframe"", 'available_columns': ['aid', 'speaker', 'ideology', 'date', 'context', 'category', 'care_score', 'care_salience', 'care_confidence', 'harm_score', 'harm_salience', 'harm_confidence', 'fairness_score', 'fairness_salience', 'fairness_confidence', 'cheating_score', 'cheating_salience', 'cheating_confidence', 'loyalty_score', 'loyalty_salience', 'loyalty_confidence', 'betrayal_score', 'betrayal_salience', 'betrayal_confidence', 'authority_score', 'authority_salience', 'authority_confidence', 'subversion_score', 'subversion_salience', 'subversion_confidence', 'sanctity_score', 'sanctity_salience', 'sanctity_confidence', 'degradation_score', 'degradation_salience', 'degradation_confidence', 'gasket_version', 'extraction_time_seconds', 'individualizing_tension', 'binding_tension'], 'note': 'This is a framework-agnostic validation - LLMs determine validation logic'}}, 'quality_thresholds': {'missing_data_check': 0.0}}",,,,,,,,Generic metric_validation result,
calculate_descriptive_stats_all_metrics,summary_statistics,result_value,"{'type': 'summary_statistics', 'metrics': ['care_score', 'harm_score', 'fairness_score', 'cheating_score', 'loyalty_score', 'betrayal_score', 'authority_score', 'subversion_score', 'sanctity_score', 'degradation_score', 'care_salience', 'harm_salience', 'fairness_salience', 'cheating_salience', 'loyalty_salience', 'betrayal_salience', 'authority_salience', 'subversion_salience', 'sanctity_salience', 'degradation_salience', 'individualizing_tension', 'binding_tension'], 'summary_types': ['mean', 'std', 'min', 'max', 'count'], 'results': {'care_score': {'mean': 0.6625000000000001, 'std': 0.24311960607310729, 'min': 0.2, 'max': 0.9, 'count': 8}, 'harm_score': {'mean': 0.5874999999999999, 'std': 0.28125992045995973, 'min': 0.1, 'max': 0.85, 'count': 8}, 'fairness_score': {'mean': 0.8, 'std': 0.09636241116594318, 'min': 0.7, 'max': 0.9, 'count': 8}, 'cheating_score': {'mean': 0.625, 'std': 0.20354009783964294, 'min': 0.15, 'max': 0.8, 'count': 8}, 'loyalty_score': {'mean': 0.48750000000000004, 'std': 0.2150581316760657, 'min': 0.2, 'max': 0.75, 'count': 8}, 'betrayal_score': {'mean': 0.40625, 'std': 0.23820384427748312, 'min': 0.05, 'max': 0.7, 'count': 8}, 'authority_score': {'mean': 0.3375, 'std': 0.19226098333849673, 'min': 0.1, 'max': 0.7, 'count': 8}, 'subversion_score': {'mean': 0.4125, 'std': 0.2356601669474803, 'min': 0.1, 'max': 0.7, 'count': 8}, 'sanctity_score': {'mean': 0.325, 'std': 0.2104417123236605, 'min': 0.1, 'max': 0.6, 'count': 8}, 'degradation_score': {'mean': 0.30625, 'std': 0.23518609652783473, 'min': 0.0, 'max': 0.7, 'count': 8}, 'care_salience': {'mean': 0.68125, 'std': 0.26449075058091753, 'min': 0.25, 'max': 0.95, 'count': 8}, 'harm_salience': {'mean': 0.6375, 'std': 0.26423744732991306, 'min': 0.15, 'max': 0.85, 'count': 8}, 'fairness_salience': {'mean': 0.8375, 'std': 0.10264362759428511, 'min': 0.7, 'max': 0.95, 'count': 8}, 'cheating_salience': {'mean': 0.625, 'std': 0.1851640199545103, 'min': 0.25, 'max': 0.8, 'count': 8}, 'loyalty_salience': {'mean': 0.46875, 'std': 0.2617762130413795, 'min': 0.15, 'max': 0.85, 'count': 8}, 'betrayal_salience': {'mean': 0.4125, 'std': 0.2401636346922061, 'min': 0.1, 'max': 0.7, 'count': 8}, 'authority_salience': {'mean': 0.35625, 'std': 0.24118383622693887, 'min': 0.1, 'max': 0.8, 'count': 8}, 'subversion_salience': {'mean': 0.43125, 'std': 0.2576507880279596, 'min': 0.15, 'max': 0.7, 'count': 8}, 'sanctity_salience': {'mean': 0.3125, 'std': 0.26423744732991306, 'min': 0.05, 'max': 0.65, 'count': 8}, 'degradation_salience': {'mean': 0.30625, 'std': 0.24703600084660882, 'min': 0.0, 'max': 0.7, 'count': 8}, 'individualizing_tension': {'mean': 0.183125, 'std': 0.09411950989490511, 'min': 0.04500000000000003, 'max': 0.3075, 'count': 8}, 'binding_tension': {'mean': 0.115625, 'std': 0.0596230719963817, 'min': 0.04, 'max': 0.18, 'count': 8}}, 'missing_metrics': ['foundation_tension', 'moral_strategic_contradiction_index']}",,,,,,,,Generic summary_statistics result,
anova_ideological_variation_care,one_way_anova,F_statistic,131.99999999999108,0.007535764957107702,,,,care_score,ideology,p < 0.05,,
anova_ideological_variation_harm,one_way_anova,F_statistic,1.2256880733944961,0.5064207980296925,,,,harm_score,ideology,p >= 0.05,,
anova_ideological_variation_fairness,one_way_anova,F_statistic,20.399999999999764,0.04738573378165481,,,,fairness_score,ideology,p < 0.05,,
anova_ideological_variation_cheating,one_way_anova,F_statistic,0.14588235294117632,0.963080206648251,,,,cheating_score,ideology,p >= 0.05,,
anova_ideological_variation_loyalty,one_way_anova,F_statistic,0.11287128712871286,0.9772784617933281,,,,loyalty_score,ideology,p >= 0.05,,
anova_ideological_variation_betrayal,one_way_anova,F_statistic,0.7247787610619469,0.6666918922697392,,,,betrayal_score,ideology,p >= 0.05,,
anova_ideological_variation_authority,one_way_anova,F_statistic,1.1923076923076916,0.5148194507701438,,,,authority_score,ideology,p >= 0.05,,
anova_ideological_variation_subversion,one_way_anova,F_statistic,0.35853658536585364,0.8463995937632024,,,,subversion_score,ideology,p >= 0.05,,
anova_ideological_variation_sanctity,one_way_anova,F_statistic,49.199999999998866,0.020039511102233974,,,,sanctity_score,ideology,p < 0.05,,
anova_ideological_variation_degradation,one_way_anova,F_statistic,0.8773195876288662,0.6090280194802749,,,,degradation_score,ideology,p >= 0.05,,
validate_reliability_extraction_success,metric_validation,result_value,"{'type': 'metric_validation', 'validation_rules': [""{'metric_name': 'care_score', 'rule': 'missing_data_check'}"", ""{'metric_name': 'harm_score', 'rule': 'missing_data_check'}"", ""{'metric_name': 'fairness_score', 'rule': 'missing_data_check'}"", ""{'metric_name': 'cheating_score', 'rule': 'missing_data_check'}"", ""{'metric_name': 'loyalty_score', 'rule': 'missing_data_check'}"", ""{'metric_name': 'betrayal_score', 'rule': 'missing_data_check'}"", ""{'metric_name': 'authority_score', 'rule': 'missing_data_check'}"", ""{'metric_name': 'subversion_score', 'rule': 'missing_data_check'}"", ""{'metric_name': 'sanctity_score', 'rule': 'missing_data_check'}"", ""{'metric_name': 'degradation_score', 'rule': 'missing_data_check'}""], 'results': {'unknown_rule': {'status': 'not_found', 'message': ""Metric 'unknown_rule' not found in dataframe"", 'available_columns': ['aid', 'speaker', 'ideology', 'date', 'context', 'category', 'care_score', 'care_salience', 'care_confidence', 'harm_score', 'harm_salience', 'harm_confidence', 'fairness_score', 'fairness_salience', 'fairness_confidence', 'cheating_score', 'cheating_salience', 'cheating_confidence', 'loyalty_score', 'loyalty_salience', 'loyalty_confidence', 'betrayal_score', 'betrayal_salience', 'betrayal_confidence', 'authority_score', 'authority_salience', 'authority_confidence', 'subversion_score', 'subversion_salience', 'subversion_confidence', 'sanctity_score', 'sanctity_salience', 'sanctity_confidence', 'degradation_score', 'degradation_salience', 'degradation_confidence', 'gasket_version', 'extraction_time_seconds', 'individualizing_tension', 'binding_tension'], 'note': 'This is a framework-agnostic validation - LLMs determine validation logic'}}, 'quality_thresholds': {'missing_data_check': 0.0}}",,,,,,,,Generic metric_validation result,
