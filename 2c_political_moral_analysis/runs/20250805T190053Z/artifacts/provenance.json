{
  "run_metadata": {
    "experiment_name": "political_moral_analysis",
    "run_timestamp": "20250805T190053Z",
    "framework_version": "../../frameworks/seed/political/moral_foundations_theory_v7.3.md",
    "model_used": "vertex_ai/gemini-2.5-flash-lite",
    "total_artifacts": 24,
    "organized_artifacts": 15
  },
  "directory_structure": {
    "data/": "CSV files for external statistical analysis",
    "artifacts/analysis_plans/": "What the LLM planned to analyze",
    "artifacts/analysis_results/": "Raw analysis outputs from LLM",
    "artifacts/statistical_results/": "Mathematical computations and metrics",
    "artifacts/evidence/": "Curated quotes and supporting data",
    "artifacts/reports/": "Final synthesis outputs and reports",
    "artifacts/inputs/": "Framework, corpus, and experiment configuration",
    "technical/": "System logs and model interaction records"
  },
  "pipeline_stages": {
    "inputs_and_system": {
      "artifacts": 11,
      "total_size_mb": 0.13605499267578125
    },
    "analysis": {
      "artifacts": 9,
      "total_size_mb": 0.046820640563964844
    },
    "evidence_curation": {
      "artifacts": 1,
      "total_size_mb": 0.0051250457763671875
    },
    "synthesis": {
      "artifacts": 2,
      "total_size_mb": 0.04806995391845703
    },
    "statistical_computation": {
      "artifacts": 1,
      "total_size_mb": 0.020685195922851562
    }
  },
  "artifact_descriptions": {
    "raw_analysis_response_v6_27db43a8": "Raw analysis response from LLM with scores and reasoning",
    "raw_analysis_response_v6_5cc7883b": "Raw analysis response from LLM with scores and reasoning",
    "raw_analysis_response_v6_60cacb30": "Raw analysis response from LLM with scores and reasoning",
    "raw_analysis_response_v6_770ac54c": "Raw analysis response from LLM with scores and reasoning",
    "raw_analysis_response_v6_7a4eadab": "Raw analysis response from LLM with scores and reasoning",
    "raw_analysis_response_v6_8ea9411c": "Raw analysis response from LLM with scores and reasoning",
    "raw_analysis_response_v6_95f793eb": "Raw analysis response from LLM with scores and reasoning",
    "raw_analysis_response_v6_e5f1e44a": "Raw analysis response from LLM with scores and reasoning",
    "analysis_response_386ebddc.json": "Artifact of type analysis_json_v6",
    "curated_evidence_7620d43e.json": "Highest-confidence evidence supporting findings",
    "moral_foundations_theory_v7.3_7a5f8f24.md": "Analytical framework used for evaluation",
    "final_report_2025-08-05_8647ab90.md": "Final research report with findings and implications",
    "analysis_plan_989b3288.md": "Analysis plan generated by LLM for systematic evaluation",
    "statistical_results_c28e1cb0.json": "Statistical computations and significance tests",
    "synthesis_report_2025-08-05_c8a352fc.md": "Synthesis report combining multiple analyses"
  },
  "navigation_guide": {
    "primary_researcher": [
      "FINAL_REPORT.md",
      "data/scores.csv",
      "data/evidence.csv"
    ],
    "internal_reviewer": [
      "METHODOLOGY_SUMMARY.md",
      "STATISTICAL_SUMMARY.md"
    ],
    "replication_researcher": [
      "artifacts/",
      "technical/manifest.json",
      "README.md"
    ],
    "fraud_auditor": [
      "technical/manifest.json",
      "technical/logs/",
      "provenance.json"
    ],
    "llm_skeptic": [
      "technical/model_interactions/",
      "data/reliability_metrics.csv"
    ]
  }
}