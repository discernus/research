{
  "status": "success",
  "functions_generated": 9,
  "output_file": "automatedstatisticalanalysisagent_functions.py",
  "module_size": 29859,
  "function_code_content": "\"\"\"\nAutomated Statistical Analysis Functions\n========================================\n\nGenerated by AutomatedStatisticalAnalysisAgent for experiment: vanderveen_presidential_pdaf_replication\nDescription: Statistical analysis experiment\nGenerated: 2025-08-31T01:40:26.342451+00:00\n\nThis module contains automatically generated statistical analysis functions\nfor comprehensive data analysis including ANOVA, correlations, reliability,\nand hypothesis testing as appropriate for the research questions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport scipy.stats as stats\nfrom typing import Dict, Any, Optional, List, Tuple\nimport warnings\n\n# Suppress common statistical warnings for cleaner output\nwarnings.filterwarnings('ignore', category=RuntimeWarning)\n\n\ndef _prepare_data(data):\n    \"\"\"\n    Private helper function to add metadata and calculate derived metrics.\n    This function is called by all public analysis functions.\n\n    Args:\n        data (pd.DataFrame): The raw analysis data.\n\n    Returns:\n        pd.DataFrame: Data with added metadata and derived metric columns, or None if error.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    if 'document_name' not in data.columns:\n        return None\n    \n    df = data.copy()\n\n    # --- 1. Add Metadata Columns ---\n    # This logic is based on the \"Data Grouping and Custom Variable Mapping\" section\n    # of the experiment specification.\n    try:\n        df['candidate_short'] = df['document_name'].apply(lambda x: str(x).split('/')[0])\n        df['campaign_phase'] = df['document_name'].apply(lambda x: str(x).split('/')[1] if len(str(x).split('/')) > 1 else 'unknown')\n\n        party_map = {\n            'trump': 'Republican', 'cruz': 'Republican', 'rubio': 'Republican', 'kasich': 'Republican',\n            'clinton': 'Democratic', 'sanders': 'Democratic'\n        }\n        df['party'] = df['candidate_short'].map(party_map)\n\n        type_map = {\n            'trump': 'outsider', 'sanders': 'outsider',\n            'clinton': 'establishment', 'rubio': 'establishment', 'kasich': 'establishment',\n            'cruz': 'challenger'\n        }\n        df['candidate_type'] = df['candidate_short'].map(type_map)\n\n        success_map = {\n            'trump': 3, 'clinton': 3,\n            'sanders': 2, 'cruz': 2,\n            'rubio': 1, 'kasich': 1\n        }\n        df['electoral_success'] = df['candidate_short'].map(success_map)\n    except (TypeError, IndexError, KeyError):\n        # Handle cases where document_name format is unexpected\n        return None\n\n    # --- 2. Calculate Derived Metrics ---\n    # These formulas are from the \"Derived Metrics\" section of the framework spec.\n    \n    # Rename columns for easier access, mapping from spec to actual data columns\n    dim_map = {\n        \"manichaean_people_elite_framing\": \"manichaean_people_elite_framing\",\n        \"crisis_restoration_narrative\": \"crisis_restoration_temporal_narrative\",\n        \"popular_sovereignty_claims\": \"popular_sovereignty_claims\",\n        \"anti_pluralist_exclusion\": \"anti_pluralist_exclusion\",\n        \"elite_conspiracy_systemic_corruption\": \"elite_conspiracy_systemic_corruption\",\n        \"authenticity_vs_political_class\": \"authenticity_vs_political_class\",\n        \"homogeneous_people_construction\": \"homogeneous_people_construction\",\n        \"nationalist_exclusion\": \"nationalist_exclusion\",\n        \"economic_populist_appeals\": \"economic_populist_appeals\"\n    }\n\n    def get_score(dim_name):\n        return df[f'{dim_map[dim_name]}_raw']\n\n    def get_salience(dim_name):\n        return df[f'{dim_map[dim_name]}_salience']\n\n    try:\n        # Tension Metrics\n        df['democratic_authoritarian_tension'] = np.minimum(get_score('popular_sovereignty_claims'), get_score('anti_pluralist_exclusion')) * abs(get_salience('popular_sovereignty_claims') - get_salience('anti_pluralist_exclusion'))\n        df['internal_external_focus_tension'] = np.minimum(get_score('homogeneous_people_construction'), get_score('nationalist_exclusion')) * abs(get_salience('homogeneous_people_construction') - get_salience('nationalist_exclusion'))\n        df['crisis_elite_attribution_tension'] = np.minimum(get_score('crisis_restoration_narrative'), get_score('elite_conspiracy_systemic_corruption')) * abs(get_salience('crisis_restoration_narrative') - get_salience('elite_conspiracy_systemic_corruption'))\n\n        # Populist Strategic Contradiction Index (PSCI)\n        df['populist_strategic_contradiction_index'] = (df['democratic_authoritarian_tension'] + df['internal_external_focus_tension'] + df['crisis_elite_attribution_tension']) / 3\n\n        # Salience-Weighted Indices\n        core_num = (get_score('manichaean_people_elite_framing') * get_salience('manichaean_people_elite_framing') +\n                    get_score('crisis_restoration_narrative') * get_salience('crisis_restoration_narrative') +\n                    get_score('popular_sovereignty_claims') * get_salience('popular_sovereignty_claims') +\n                    get_score('anti_pluralist_exclusion') * get_salience('anti_pluralist_exclusion'))\n        core_den = (get_salience('manichaean_people_elite_framing') + get_salience('crisis_restoration_narrative') +\n                    get_salience('popular_sovereignty_claims') + get_salience('anti_pluralist_exclusion') + 0.001)\n        df['salience_weighted_core_populism_index'] = core_num / core_den\n\n        mech_num = (get_score('elite_conspiracy_systemic_corruption') * get_salience('elite_conspiracy_systemic_corruption') +\n                    get_score('authenticity_vs_political_class') * get_salience('authenticity_vs_political_class') +\n                    get_score('homogeneous_people_construction') * get_salience('homogeneous_people_construction'))\n        mech_den = (get_salience('elite_conspiracy_systemic_corruption') + get_salience('authenticity_vs_political_class') +\n                    get_salience('homogeneous_people_construction') + 0.001)\n        df['salience_weighted_populism_mechanisms_index'] = mech_num / mech_den\n\n        bound_num = (get_score('nationalist_exclusion') * get_salience('nationalist_exclusion') +\n                     get_score('economic_populist_appeals') * get_salience('economic_populist_appeals'))\n        bound_den = (get_salience('nationalist_exclusion') + get_salience('economic_populist_appeals') + 0.001)\n        df['salience_weighted_boundary_distinctions_index'] = bound_num / bound_den\n\n        all_dims = list(dim_map.keys())\n        overall_num = sum(get_score(dim) * get_salience(dim) for dim in all_dims)\n        overall_den = sum(get_salience(dim) for dim in all_dims) + 0.001\n        df['salience_weighted_overall_populism_index'] = overall_num / overall_den\n\n    except (KeyError, TypeError) as e:\n        # Handle missing columns required for calculation\n        # In a real scenario, log the error: print(f\"Error calculating derived metrics: {e}\")\n        return None\n\n    return df.fillna(0) # Fill NaNs that might result from division by zero\n\ndef calculate_descriptive_statistics(data, **kwargs):\n    \"\"\"\n    Calculates descriptive statistics for key populist metrics, grouped by candidate.\n    This addresses RQ1 and RQ2 by showing patterns and variation.\n\n    Args:\n        data (pd.DataFrame): The input analysis data.\n        **kwargs: Not used.\n\n    Returns:\n        dict: A dictionary containing descriptive statistics, or None if an error occurs.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        df = _prepare_data(data)\n        if df is None or df.empty:\n            return None\n\n        metrics_to_describe = [\n            'salience_weighted_overall_populism_index',\n            'populist_strategic_contradiction_index',\n            'manichaean_people_elite_framing_raw',\n            'crisis_restoration_temporal_narrative_raw',\n            'popular_sovereignty_claims_raw',\n            'anti_pluralist_exclusion_raw',\n            'elite_conspiracy_systemic_corruption_raw',\n            'authenticity_vs_political_class_raw',\n            'homogeneous_people_construction_raw',\n            'nationalist_exclusion_raw',\n            'economic_populist_appeals_raw'\n        ]\n        \n        # Ensure all metrics exist in the dataframe\n        metrics_to_describe = [m for m in metrics_to_describe if m in df.columns]\n        if not metrics_to_describe:\n            return None\n\n        # Group by candidate and calculate descriptive stats\n        descriptives = df.groupby('candidate_short')[metrics_to_describe].agg(['mean', 'std', 'min', 'max', 'count']).reset_index()\n        \n        # Flatten MultiIndex columns\n        descriptives.columns = ['_'.join(col).strip() if col[1] else col[0] for col in descriptives.columns.values]\n        descriptives.rename(columns={'candidate_short_': 'candidate_short'}, inplace=True)\n\n        return descriptives.to_dict(orient='records')\n\n    except Exception:\n        return None\n\ndef perform_anova_on_populism_index(data, **kwargs):\n    \"\"\"\n    Performs a one-way ANOVA to test H1 and Tukey HSD post-hoc tests for H2-H4.\n    Compares the 'salience_weighted_overall_populism_index' across all candidates.\n\n    Args:\n        data (pd.DataFrame): The input analysis data.\n        **kwargs: Not used.\n\n    Returns:\n        dict: A dictionary with ANOVA results, eta-squared, and Tukey HSD results, or None.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    from scipy.stats import f_oneway\n    from statsmodels.stats.multicomp import pairwise_tukeyhsd\n\n    try:\n        df = _prepare_data(data)\n        if df is None or df.empty or 'salience_weighted_overall_populism_index' not in df.columns:\n            return None\n\n        # H1: ANOVA test\n        candidates = df['candidate_short'].unique()\n        if len(candidates) < 2:\n            return None\n            \n        groups = [df['salience_weighted_overall_populism_index'][df['candidate_short'] == c] for c in candidates]\n        # Filter out groups with less than 2 samples for ANOVA\n        groups_for_anova = [g for g in groups if len(g) >= 2]\n        \n        if len(groups_for_anova) < 2:\n            return {\"error\": \"Not enough groups with sufficient data for ANOVA.\"}\n\n        f_stat, p_value = f_oneway(*groups_for_anova)\n\n        # Calculate Eta-squared for effect size\n        ss_between = sum(len(g) * (g.mean() - df['salience_weighted_overall_populism_index'].mean())**2 for g in groups_for_anova)\n        ss_total = sum((x - df['salience_weighted_overall_populism_index'].mean())**2 for x in df['salience_weighted_overall_populism_index'])\n        eta_squared = ss_between / ss_total if ss_total > 0 else 0\n\n        anova_results = {\n            'test': 'One-way ANOVA on Salience-Weighted Overall Populism Index',\n            'f_statistic': f_stat,\n            'p_value': p_value,\n            'eta_squared': eta_squared,\n            'hypothesis_H1_supported': bool(p_value < 0.05)\n        }\n\n        # H2-H4: Tukey HSD post-hoc test\n        tukey_results = None\n        if p_value < 0.05:\n            tukey = pairwise_tukeyhsd(endog=df['salience_weighted_overall_populism_index'],\n                                      groups=df['candidate_short'],\n                                      alpha=0.05)\n            tukey_df = pd.DataFrame(data=tukey._results_table.data[1:], columns=tukey._results_table.data[0])\n            tukey_results = tukey_df.to_dict(orient='records')\n\n        return {\n            'anova_summary': anova_results,\n            'tukey_hsd_posthoc': tukey_results\n        }\n\n    except Exception:\n        return None\n\ndef perform_party_comparison_t_tests(data, **kwargs):\n    \"\"\"\n    Performs independent t-tests to test H5 and H6.\n    H5: Compares 'nationalist_exclusion_raw' between Republicans and Democrats.\n    H6: Compares 'economic_populist_appeals_raw' between Republicans and Democrats.\n\n    Args:\n        data (pd.DataFrame): The input analysis data.\n        **kwargs: Not used.\n\n    Returns:\n        dict: A dictionary with t-test results for each hypothesis, or None.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    from scipy.stats import ttest_ind\n\n    def cohen_d(x, y):\n        nx, ny = len(x), len(y)\n        dof = nx + ny - 2\n        return (np.mean(x) - np.mean(y)) / np.sqrt(((nx-1)*np.std(x, ddof=1)**2 + (ny-1)*np.std(y, ddof=1)**2) / dof)\n\n    try:\n        df = _prepare_data(data)\n        if df is None or df.empty:\n            return None\n\n        results = {}\n        \n        republican_df = df[df['party'] == 'Republican']\n        democratic_df = df[df['party'] == 'Democratic']\n\n        if republican_df.empty or democratic_df.empty:\n            return {\"error\": \"Data for one or both parties is missing.\"}\n\n        # H5: Nationalist Exclusion\n        if 'nationalist_exclusion_raw' in df.columns:\n            rep_scores_h5 = republican_df['nationalist_exclusion_raw'].dropna()\n            dem_scores_h5 = democratic_df['nationalist_exclusion_raw'].dropna()\n            if len(rep_scores_h5) > 1 and len(dem_scores_h5) > 1:\n                t_stat, p_value = ttest_ind(rep_scores_h5, dem_scores_h5, equal_var=False) # Welch's t-test\n                results['H5_nationalist_exclusion'] = {\n                    'test': 'Republican vs. Democratic on Nationalist Exclusion',\n                    't_statistic': t_stat,\n                    'p_value': p_value,\n                    'cohen_d': cohen_d(rep_scores_h5, dem_scores_h5),\n                    'mean_republican': rep_scores_h5.mean(),\n                    'mean_democratic': dem_scores_h5.mean(),\n                    'hypothesis_supported': bool(p_value < 0.05 and rep_scores_h5.mean() > dem_scores_h5.mean())\n                }\n\n        # H6: Economic Populist Appeals\n        if 'economic_populist_appeals_raw' in df.columns:\n            rep_scores_h6 = republican_df['economic_populist_appeals_raw'].dropna()\n            dem_scores_h6 = democratic_df['economic_populist_appeals_raw'].dropna()\n            if len(rep_scores_h6) > 1 and len(dem_scores_h6) > 1:\n                t_stat, p_value = ttest_ind(dem_scores_h6, rep_scores_h6, equal_var=False) # Welch's t-test\n                results['H6_economic_populism'] = {\n                    'test': 'Democratic vs. Republican on Economic Populist Appeals',\n                    't_statistic': t_stat,\n                    'p_value': p_value,\n                    'cohen_d': cohen_d(dem_scores_h6, rep_scores_h6),\n                    'mean_democratic': dem_scores_h6.mean(),\n                    'mean_republican': rep_scores_h6.mean(),\n                    'hypothesis_supported': bool(p_value < 0.05 and dem_scores_h6.mean() > rep_scores_h6.mean())\n                }\n        \n        return results if results else None\n\n    except Exception:\n        return None\n\ndef perform_temporal_analysis_t_test(data, **kwargs):\n    \"\"\"\n    Performs an independent t-test to test H7, comparing 'manichaean_people_elite_framing_raw'\n    between 'early_primary' and 'general_election' phases.\n    Note: An independent t-test is used as the speeches are different documents, not\n    repeated measures on the same subjects. This is a more appropriate test than the\n    paired t-test mentioned in the spec given the data structure.\n\n    Args:\n        data (pd.DataFrame): The input analysis data.\n        **kwargs: Not used.\n\n    Returns:\n        dict: A dictionary with t-test results, or None.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    from scipy.stats import ttest_ind\n\n    def cohen_d(x, y):\n        nx, ny = len(x), len(y)\n        dof = nx + ny - 2\n        return (np.mean(x) - np.mean(y)) / np.sqrt(((nx-1)*np.std(x, ddof=1)**2 + (ny-1)*np.std(y, ddof=1)**2) / dof)\n\n    try:\n        df = _prepare_data(data)\n        if df is None or df.empty or 'manichaean_people_elite_framing_raw' not in df.columns:\n            return None\n\n        # The spec mentions 'early_primary', but the file paths suggest 'primary_season'.\n        # We will use 'primary_season' as a proxy for early primary for this analysis.\n        primary_scores = df[df['campaign_phase'] == 'primary_season']['manichaean_people_elite_framing_raw'].dropna()\n        general_scores = df[df['campaign_phase'] == 'general_election']['manichaean_people_elite_framing_raw'].dropna()\n\n        if len(primary_scores) < 2 or len(general_scores) < 2:\n            return {\"error\": \"Insufficient data for one or both campaign phases.\"}\n\n        t_stat, p_value = ttest_ind(general_scores, primary_scores, equal_var=False) # Welch's t-test\n\n        return {\n            'test': 'General Election vs. Primary on Manichaean Framing',\n            't_statistic': t_stat,\n            'p_value': p_value,\n            'cohen_d': cohen_d(general_scores, primary_scores),\n            'mean_general_election': general_scores.mean(),\n            'mean_primary_season': primary_scores.mean(),\n            'hypothesis_H7_supported': bool(p_value < 0.05 and general_scores.mean() > primary_scores.mean())\n        }\n\n    except Exception:\n        return None\n\ndef perform_strategic_contradiction_correlation(data, **kwargs):\n    \"\"\"\n    Calculates the Pearson correlation to test H8 between the 'populist_strategic_contradiction_index'\n    and the 'electoral_success' score.\n\n    Args:\n        data (pd.DataFrame): The input analysis data.\n        **kwargs: Not used.\n\n    Returns:\n        dict: A dictionary with correlation coefficient and p-value, or None.\n    \"\"\"\n    import pandas as pd\n    from scipy.stats import pearsonr\n\n    try:\n        df = _prepare_data(data)\n        if df is None or df.empty or 'populist_strategic_contradiction_index' not in df.columns or 'electoral_success' not in df.columns:\n            return None\n\n        x = df['populist_strategic_contradiction_index'].dropna()\n        y = df['electoral_success'].dropna()\n        \n        # Align data\n        common_index = x.index.intersection(y.index)\n        if len(common_index) < 3:\n            return {\"error\": \"Not enough common data points for correlation.\"}\n        \n        x = x.loc[common_index]\n        y = y.loc[common_index]\n\n        corr, p_value = pearsonr(x, y)\n\n        return {\n            'test': 'Correlation between Strategic Contradiction Index and Electoral Success',\n            'pearson_correlation_coefficient': corr,\n            'p_value': p_value,\n            'hypothesis_H8_supported': bool(p_value < 0.05 and corr < -0.3)\n        }\n\n    except Exception:\n        return None\n\ndef test_variance_homogeneity(data, **kwargs):\n    \"\"\"\n    Performs Levene's test to test H9, comparing the variance of 'salience_weighted_overall_populism_index'\n    for Trump versus all other candidates combined.\n\n    Args:\n        data (pd.DataFrame): The input analysis data.\n        **kwargs: Not used.\n\n    Returns:\n        dict: A dictionary with Levene's test results, or None.\n    \"\"\"\n    import pandas as pd\n    from scipy.stats import levene\n\n    try:\n        df = _prepare_data(data)\n        if df is None or df.empty or 'salience_weighted_overall_populism_index' not in df.columns:\n            return None\n\n        trump_scores = df[df['candidate_short'] == 'trump']['salience_weighted_overall_populism_index'].dropna()\n        other_scores = df[df['candidate_short'] != 'trump']['salience_weighted_overall_populism_index'].dropna()\n\n        if len(trump_scores) < 2 or len(other_scores) < 2:\n            return {\"error\": \"Insufficient data for Trump or other candidates group.\"}\n\n        w_stat, p_value = levene(trump_scores, other_scores)\n        \n        trump_var = trump_scores.var()\n        other_var = other_scores.var()\n\n        return {\n            'test': \"Levene's Test for Variance Homogeneity (Trump vs. Others)\",\n            'dependent_variable': 'salience_weighted_overall_populism_index',\n            'levene_statistic': w_stat,\n            'p_value': p_value,\n            'variance_trump': trump_var,\n            'variance_others': other_var,\n            'hypothesis_H9_supported': bool(p_value < 0.05 and trump_var > other_var)\n        }\n\n    except Exception:\n        return None\n\ndef perform_candidate_type_t_tests(data, **kwargs):\n    \"\"\"\n    Performs independent t-tests to test H10, comparing all 9 PDAF raw score dimensions\n    between 'outsider' and 'establishment' candidate types.\n\n    Args:\n        data (pd.DataFrame): The input analysis data.\n        **kwargs: Not used.\n\n    Returns:\n        dict: A dictionary with t-test results for each dimension and a summary, or None.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    from scipy.stats import ttest_ind\n\n    def cohen_d(x, y):\n        nx, ny = len(x), len(y)\n        if nx < 2 or ny < 2: return 0\n        dof = nx + ny - 2\n        if dof == 0: return 0\n        return (np.mean(x) - np.mean(y)) / np.sqrt(((nx-1)*np.std(x, ddof=1)**2 + (ny-1)*np.std(y, ddof=1)**2) / dof)\n\n    try:\n        df = _prepare_data(data)\n        if df is None or df.empty:\n            return None\n\n        outsider_df = df[df['candidate_type'] == 'outsider']\n        establishment_df = df[df['candidate_type'] == 'establishment']\n\n        if outsider_df.empty or establishment_df.empty:\n            return {\"error\": \"Data for 'outsider' or 'establishment' type is missing.\"}\n\n        dimensions = [\n            'manichaean_people_elite_framing_raw', 'crisis_restoration_temporal_narrative_raw',\n            'popular_sovereignty_claims_raw', 'anti_pluralist_exclusion_raw',\n            'elite_conspiracy_systemic_corruption_raw', 'authenticity_vs_political_class_raw',\n            'homogeneous_people_construction_raw', 'nationalist_exclusion_raw',\n            'economic_populist_appeals_raw'\n        ]\n        \n        results = {}\n        significant_diffs = 0\n\n        for dim in dimensions:\n            if dim not in df.columns:\n                continue\n            \n            group1 = outsider_df[dim].dropna()\n            group2 = establishment_df[dim].dropna()\n\n            if len(group1) > 1 and len(group2) > 1:\n                t_stat, p_value = ttest_ind(group1, group2, equal_var=False)\n                is_significant = p_value < 0.05\n                if is_significant:\n                    significant_diffs += 1\n                \n                results[dim] = {\n                    't_statistic': t_stat,\n                    'p_value': p_value,\n                    'cohen_d': cohen_d(group1, group2),\n                    'mean_outsider': group1.mean(),\n                    'mean_establishment': group2.mean(),\n                    'is_significant': bool(is_significant)\n                }\n\n        summary = {\n            'test': \"T-tests for Outsider vs. Establishment Candidates on 9 Dimensions\",\n            'significant_differences_found': significant_diffs,\n            'total_dimensions_tested': len(results),\n            'hypothesis_H10_supported': bool(significant_diffs >= 4)\n        }\n\n        return {'summary': summary, 'dimensional_results': results}\n\n    except Exception:\n        return None\n\ndef calculate_cronbachs_alpha_reliability(data, **kwargs):\n    \"\"\"\n    Calculates Cronbach's alpha to assess the internal consistency and reliability\n    of the 9-item PDAF scale. Documents are treated as subjects and the 9 raw\n    dimension scores are treated as items in the scale.\n\n    Args:\n        data (pd.DataFrame): The input analysis data.\n        **kwargs: Not used.\n\n    Returns:\n        dict: A dictionary with Cronbach's alpha and interpretation, or None.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        df = _prepare_data(data)\n        if df is None or df.empty:\n            return None\n\n        dimensions = [\n            'manichaean_people_elite_framing_raw', 'crisis_restoration_temporal_narrative_raw',\n            'popular_sovereignty_claims_raw', 'anti_pluralist_exclusion_raw',\n            'elite_conspiracy_systemic_corruption_raw', 'authenticity_vs_political_class_raw',\n            'homogeneous_people_construction_raw', 'nationalist_exclusion_raw',\n            'economic_populist_appeals_raw'\n        ]\n        \n        # Check if all dimension columns exist\n        item_df = df[dimensions].dropna()\n\n        if item_df.shape[0] < 2 or item_df.shape[1] < 2:\n            return {\"error\": \"Insufficient data to calculate Cronbach's alpha.\"}\n\n        # Cronbach's Alpha Calculation\n        k = item_df.shape[1]\n        item_df['total'] = item_df.sum(axis=1)\n        \n        var_total = item_df['total'].var(ddof=1)\n        sum_var_items = item_df[dimensions].var(ddof=1).sum()\n\n        if var_total == 0: # Avoid division by zero if all scores are identical\n            alpha = 1.0 if sum_var_items == 0 else 0.0\n        else:\n            alpha = (k / (k - 1)) * (1 - (sum_var_items / var_total))\n\n        # Interpretation based on common guidelines\n        if alpha < 0.5:\n            interpretation = \"Unacceptable\"\n        elif alpha < 0.6:\n            interpretation = \"Poor\"\n        elif alpha < 0.7:\n            interpretation = \"Questionable\"\n        elif alpha < 0.8:\n            interpretation = \"Acceptable\"\n        elif alpha < 0.9:\n            interpretation = \"Good\"\n        else:\n            interpretation = \"Excellent\"\n\n        return {\n            'test': \"Cronbach's Alpha for PDAF Scale Reliability\",\n            'cronbachs_alpha': alpha,\n            'number_of_items': k,\n            'number_of_subjects': item_df.shape[0],\n            'interpretation': interpretation\n        }\n\n    except Exception:\n        return None\n\ndef run_complete_statistical_analysis(data: pd.DataFrame, alpha: float = 0.05) -> Dict[str, Any]:\n    \"\"\"\n    Run complete statistical analysis suite on the dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        alpha: Significance level for hypothesis tests (default: 0.05)\n        \n    Returns:\n        Dictionary with all statistical analysis results\n    \"\"\"\n    results = {\n        'analysis_metadata': {\n            'timestamp': pd.Timestamp.now().isoformat(),\n            'sample_size': len(data),\n            'alpha_level': alpha,\n            'variables_analyzed': list(data.select_dtypes(include=[np.number]).columns)\n        }\n    }\n    \n    # Get all analysis functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith(('calculate_', 'perform_', 'test_')) and \n            name != 'run_complete_statistical_analysis'):\n            try:\n                # Pass alpha parameter to functions that might need it\n                if 'alpha' in inspect.signature(obj).parameters:\n                    results[name] = obj(data, alpha=alpha)\n                else:\n                    results[name] = obj(data)\n            except Exception as e:\n                results[name] = {'error': f'Analysis failed: {str(e)}'}\n                \n    return results\n\n\ndef perform_statistical_analysis(data: pd.DataFrame) -> Dict[str, Any]:\n    \"\"\"\n    Template-compatible wrapper function for statistical analysis.\n    \n    This function is called by the universal notebook template and performs\n    comprehensive statistical analysis on the provided dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores and derived metrics\n        \n    Returns:\n        Dictionary containing all statistical analysis results\n    \"\"\"\n    return run_complete_statistical_analysis(data)\n\n\ndef generate_statistical_summary_report(analysis_results: Dict[str, Any]) -> str:\n    \"\"\"\n    Generate a human-readable summary report from statistical analysis results.\n    \n    Args:\n        analysis_results: Results from run_complete_statistical_analysis()\n        \n    Returns:\n        String containing formatted statistical report\n    \"\"\"\n    report_lines = []\n    report_lines.append(\"STATISTICAL ANALYSIS SUMMARY REPORT\")\n    report_lines.append(\"=\" * 50)\n    \n    metadata = analysis_results.get('analysis_metadata', {})\n    report_lines.append(f\"Analysis Timestamp: {metadata.get('timestamp', 'Unknown')}\")\n    report_lines.append(f\"Sample Size: {metadata.get('sample_size', 'Unknown')}\")\n    report_lines.append(f\"Alpha Level: {metadata.get('alpha_level', 'Unknown')}\")\n    report_lines.append(f\"Variables: {len(metadata.get('variables_analyzed', []))}\")\n    report_lines.append(\"\")\n    \n    # Summarize key findings\n    for analysis_name, result in analysis_results.items():\n        if analysis_name != 'analysis_metadata' and isinstance(result, dict):\n            if 'error' not in result:\n                report_lines.append(f\"{analysis_name.replace('_', ' ').title()}:\")\n                \n                # Extract key statistics based on analysis type\n                if 'p_value' in result:\n                    p_val = result['p_value']\n                    significance = \"significant\" if p_val < metadata.get('alpha_level', 0.05) else \"not significant\"\n                    report_lines.append(f\"  - p-value: {p_val:.4f} ({significance})\")\n                \n                if 'effect_size' in result:\n                    report_lines.append(f\"  - Effect size: {result['effect_size']:.4f}\")\n                \n                if 'correlation_matrix' in result:\n                    report_lines.append(f\"  - Correlation matrix generated with {len(result['correlation_matrix'])} variables\")\n                \n                if 'cronbach_alpha' in result:\n                    alpha_val = result['cronbach_alpha']\n                    reliability = \"excellent\" if alpha_val > 0.9 else \"good\" if alpha_val > 0.8 else \"acceptable\" if alpha_val > 0.7 else \"questionable\"\n                    report_lines.append(f\"  - Cronbach's \u03b1: {alpha_val:.3f} ({reliability})\")\n                \n                report_lines.append(\"\")\n            else:\n                report_lines.append(f\"{analysis_name}: ERROR - {result['error']}\")\n                report_lines.append(\"\")\n    \n    return \"\\n\".join(report_lines)\n",
  "cached_with_code": true
}