{
  "status": "success",
  "functions_generated": 9,
  "output_file": "automatedstatisticalanalysisagent_functions.py",
  "module_size": 32836,
  "function_code_content": "\"\"\"\nAutomated Statistical Analysis Functions\n========================================\n\nGenerated by AutomatedStatisticalAnalysisAgent for experiment: vanderveen_presidential_pdaf_replication\nDescription: Statistical analysis experiment\nGenerated: 2025-08-31T01:10:30.290469+00:00\n\nThis module contains automatically generated statistical analysis functions\nfor comprehensive data analysis including ANOVA, correlations, reliability,\nand hypothesis testing as appropriate for the research questions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport scipy.stats as stats\nfrom typing import Dict, Any, Optional, List, Tuple\nimport warnings\n\n# Suppress common statistical warnings for cleaner output\nwarnings.filterwarnings('ignore', category=RuntimeWarning)\n\n\ndef _add_metadata_and_derived_metrics(data):\n    \"\"\"\n    Internal helper function to preprocess the data. It calculates all derived \n    metrics specified in the framework and adds metadata columns for grouping.\n    This function is essential for all subsequent statistical analyses.\n\n    Methodology:\n    1.  Calculates 8 derived metrics based on the formulas in the PDAF v10.0 spec.\n        - Tension scores are calculated using min(score_A, score_B) * abs(salience_A - salience_B).\n        - Salience-weighted indices are calculated as the weighted average of raw scores,\n          using salience as the weight. A small epsilon (0.001) is added to the\n          denominator to prevent division by zero.\n    2.  Adds metadata columns (`candidate_short`, `party`, `candidate_type`, \n        `electoral_success`, `campaign_phase`) to the DataFrame.\n    3.  Metadata is mapped from the `document_name` based on the explicit groupings\n        defined in the experiment specification.\n    4.  `campaign_phase` is inferred from the date in the filename, with 'early_primary'\n        defined as before 2016-03-15 and 'general_election' as after 2016-07-26.\n\n    Args:\n        data (pd.DataFrame): The raw analysis data.\n\n    Returns:\n        pd.DataFrame: The DataFrame with added derived metrics and metadata, or None if error.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    if data is None or data.empty:\n        return None\n    \n    df = data.copy()\n\n    try:\n        # Define dimension names for easier access\n        dims = [\n            \"manichaean_people_elite_framing\", \"crisis_restoration_narrative\",\n            \"popular_sovereignty_claims\", \"anti_pluralist_exclusion\",\n            \"elite_conspiracy_systemic_corruption\", \"authenticity_vs_political_class\",\n            \"homogeneous_people_construction\", \"nationalist_exclusion\",\n            \"economic_populist_appeals\"\n        ]\n        \n        core_dims = dims[:4]\n        mech_dims = dims[4:7]\n        bound_dims = dims[7:]\n\n        # --- 1. Calculate Derived Metrics ---\n        # Tension Indices\n        df['democratic_authoritarian_tension'] = np.minimum(df['popular_sovereignty_claims_raw'], df['anti_pluralist_exclusion_raw']) * np.abs(df['popular_sovereignty_claims_salience'] - df['anti_pluralist_exclusion_salience'])\n        df['internal_external_focus_tension'] = np.minimum(df['homogeneous_people_construction_raw'], df['nationalist_exclusion_raw']) * np.abs(df['homogeneous_people_construction_salience'] - df['nationalist_exclusion_salience'])\n        df['crisis_elite_attribution_tension'] = np.minimum(df['crisis_restoration_narrative_raw'], df['elite_conspiracy_systemic_corruption_raw']) * np.abs(df['crisis_restoration_narrative_salience'] - df['elite_conspiracy_systemic_corruption_salience'])\n\n        # Populist Strategic Contradiction Index (PSCI)\n        df['populist_strategic_contradiction_index'] = (df['democratic_authoritarian_tension'] + df['internal_external_focus_tension'] + df['crisis_elite_attribution_tension']) / 3\n\n        # Salience-Weighted Indices\n        def weighted_index(sub_dims):\n            numerator = sum(df[f'{dim}_raw'] * df[f'{dim}_salience'] for dim in sub_dims)\n            denominator = sum(df[f'{dim}_salience'] for dim in sub_dims) + 0.001\n            return numerator / denominator\n\n        df['salience_weighted_core_populism_index'] = weighted_index(core_dims)\n        df['salience_weighted_populism_mechanisms_index'] = weighted_index(mech_dims)\n        df['salience_weighted_boundary_distinctions_index'] = weighted_index(bound_dims)\n        df['salience_weighted_overall_populism_index'] = weighted_index(dims)\n\n        # --- 2. Add Metadata ---\n        df['candidate_short'] = df['document_name'].str.split('_').str[0]\n\n        # Mappings from experiment spec\n        party_map = {'trump': 'Republican', 'clinton': 'Democratic', 'sanders': 'Democratic', 'cruz': 'Republican', 'rubio': 'Republican', 'kasich': 'Republican'}\n        type_map = {'trump': 'outsider', 'clinton': 'establishment', 'sanders': 'outsider', 'cruz': 'challenger', 'rubio': 'establishment', 'kasich': 'establishment'}\n        success_map = {'trump': 3, 'clinton': 3, 'sanders': 2, 'cruz': 2, 'rubio': 1, 'kasich': 1}\n\n        df['party'] = df['candidate_short'].map(party_map)\n        df['candidate_type'] = df['candidate_short'].map(type_map)\n        df['electoral_success'] = df['candidate_short'].map(success_map)\n\n        # Infer campaign phase from date in filename\n        date_str = df['document_name'].str.split('_').str[1:4].str.join('-')\n        df['date'] = pd.to_datetime(date_str, errors='coerce')\n        \n        def get_phase(date):\n            if pd.isna(date):\n                return 'unknown'\n            if date < pd.Timestamp('2016-03-15'):\n                return 'early_primary'\n            elif date <= pd.Timestamp('2016-07-26'):\n                return 'late_primary'\n            else:\n                return 'general_election'\n        \n        df['campaign_phase'] = df['date'].apply(get_phase)\n\n        return df.dropna(subset=['candidate_short', 'party', 'candidate_type', 'electoral_success'])\n\n    except (KeyError, AttributeError) as e:\n        # This might happen if column names are unexpected or data is malformed\n        print(f\"Error during data preparation: {e}\")\n        return None\n\ndef calculate_descriptive_statistics(data, **kwargs):\n    \"\"\"\n    Calculates descriptive statistics for key populist metrics, grouped by candidate.\n    This addresses RQ1 and RQ2 by providing a foundational overview of the data.\n\n    Methodology:\n    - The function first prepares the data by adding metadata and derived metrics.\n    - It then calculates the mean, standard deviation, min, max, and count for the\n      'salience_weighted_overall_populism_index' and the nine raw dimension scores.\n    - Statistics are grouped by the 'candidate_short' field.\n    \n    Args:\n        data (pd.DataFrame): The raw analysis data.\n        **kwargs: Not used.\n        \n    Returns:\n        dict: A dictionary containing a table of descriptive statistics, or None if an error occurs.\n    \"\"\"\n    import pandas as pd\n    \n    try:\n        processed_data = _add_metadata_and_derived_metrics(data)\n        if processed_data is None or processed_data.empty:\n            return None\n\n        metrics_to_describe = [\n            'salience_weighted_overall_populism_index',\n            'manichaean_people_elite_framing_raw',\n            'crisis_restoration_narrative_raw',\n            'popular_sovereignty_claims_raw',\n            'anti_pluralist_exclusion_raw',\n            'elite_conspiracy_systemic_corruption_raw',\n            'authenticity_vs_political_class_raw',\n            'homogeneous_people_construction_raw',\n            'nationalist_exclusion_raw',\n            'economic_populist_appeals_raw'\n        ]\n        \n        # Ensure all metrics exist in the dataframe\n        metrics_to_describe = [m for m in metrics_to_describe if m in processed_data.columns]\n        if not metrics_to_describe:\n            return None\n\n        descriptives = processed_data.groupby('candidate_short')[metrics_to_describe].agg(['mean', 'std', 'min', 'max', 'count'])\n        \n        return {\n            \"description\": \"Descriptive statistics for key metrics by candidate.\",\n            \"results_table\": descriptives.to_dict()\n        }\n\n    except Exception as e:\n        print(f\"Error in calculate_descriptive_statistics: {e}\")\n        return None\n\ndef test_hypothesis_H1_H4_anova(data, **kwargs):\n    \"\"\"\n    Tests hypotheses H1-H4 regarding differences in populist rhetoric among candidates.\n\n    Methodology:\n    - H1: A one-way ANOVA is performed to test for significant differences in the mean\n      'salience_weighted_overall_populism_index' across the 6 candidates.\n      Effect size (eta-squared) is calculated.\n    - H2-H4: If the ANOVA is significant, a Tukey HSD post-hoc test is conducted\n      to identify which specific candidate pairs differ significantly. This tests\n      the directional hypotheses about Trump vs. Clinton, Sanders vs. Clinton, and\n      Trump vs. establishment Republicans.\n\n    Args:\n        data (pd.DataFrame): The raw analysis data.\n        **kwargs: Not used.\n        \n    Returns:\n        dict: A dictionary with ANOVA results and Tukey HSD pairwise comparisons, or None.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    from scipy.stats import f_oneway\n    from statsmodels.stats.multicomp import pairwise_tukeyhsd\n    \n    try:\n        processed_data = _add_metadata_and_derived_metrics(data)\n        if processed_data is None or processed_data.empty:\n            return None\n\n        target_metric = 'salience_weighted_overall_populism_index'\n        groups = processed_data.groupby('candidate_short')[target_metric].apply(list)\n        \n        # Ensure there are at least 2 groups with sufficient data\n        groups = groups[groups.apply(len) > 1]\n        if len(groups) < 2:\n            return {\"status\": \"error\", \"message\": \"Insufficient groups for ANOVA.\"}\n\n        # H1: One-way ANOVA\n        f_stat, p_value = f_oneway(*groups)\n        \n        # Calculate Eta-squared for effect size\n        ss_between = sum(len(g) * (np.mean(g) - processed_data[target_metric].mean())**2 for g in groups)\n        ss_total = sum((x - processed_data[target_metric].mean())**2 for x in processed_data[target_metric])\n        eta_squared = ss_between / ss_total if ss_total > 0 else 0\n\n        results = {\n            \"hypothesis_H1\": {\n                \"test\": \"One-way ANOVA on Salience-Weighted Overall Populism Index\",\n                \"f_statistic\": f_stat,\n                \"p_value\": p_value,\n                \"eta_squared\": eta_squared,\n                \"significant\": p_value < 0.05,\n                \"conclusion\": \"Reject H\u2080: At least one candidate's mean populism score is different.\" if p_value < 0.05 else \"Fail to reject H\u2080: No significant difference found.\"\n            },\n            \"hypotheses_H2_H4\": {}\n        }\n\n        # H2-H4: Tukey HSD post-hoc test\n        if p_value < 0.05:\n            tukey_results = pairwise_tukeyhsd(endog=processed_data[target_metric], groups=processed_data['candidate_short'], alpha=0.05)\n            results[\"hypotheses_H2_H4\"] = {\n                \"test\": \"Tukey HSD for pairwise comparisons\",\n                \"results_table\": str(tukey_results),\n                \"summary_df\": pd.DataFrame(tukey_results._results_table.data[1:], columns=tukey_results._results_table.data[0]).to_dict('records')\n            }\n        else:\n            results[\"hypotheses_H2_H4\"][\"message\"] = \"ANOVA was not significant, so post-hoc tests were not performed.\"\n\n        return results\n\n    except Exception as e:\n        print(f\"Error in test_hypothesis_H1_H4_anova: {e}\")\n        return None\n\ndef test_hypothesis_H5_H6_party_diff(data, **kwargs):\n    \"\"\"\n    Tests hypotheses H5 and H6 regarding party differences on specific populist dimensions.\n\n    Methodology:\n    - H5: An independent samples t-test compares the mean 'nationalist_exclusion_raw'\n      scores between Republican and Democratic candidates.\n    - H6: An independent samples t-test compares the mean 'economic_populist_appeals_raw'\n      scores between Democratic and Republican candidates.\n    - Cohen's d is calculated for effect size for each significant comparison.\n\n    Args:\n        data (pd.DataFrame): The raw analysis data.\n        **kwargs: Not used.\n        \n    Returns:\n        dict: A dictionary with t-test results for both hypotheses, or None.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    from scipy.stats import ttest_ind\n\n    def cohen_d(x, y):\n        nx, ny = len(x), len(y)\n        dof = nx + ny - 2\n        return (np.mean(x) - np.mean(y)) / np.sqrt(((nx-1)*np.std(x, ddof=1)**2 + (ny-1)*np.std(y, ddof=1)**2) / dof)\n\n    try:\n        processed_data = _add_metadata_and_derived_metrics(data)\n        if processed_data is None or processed_data.empty:\n            return None\n\n        results = {}\n        \n        # H5: Republicans > Democrats on Nationalist Exclusion\n        republican_ne = processed_data[processed_data['party'] == 'Republican']['nationalist_exclusion_raw'].dropna()\n        democratic_ne = processed_data[processed_data['party'] == 'Democratic']['nationalist_exclusion_raw'].dropna()\n        \n        if len(republican_ne) > 1 and len(democratic_ne) > 1:\n            t_stat_h5, p_value_h5 = ttest_ind(republican_ne, democratic_ne, equal_var=False, alternative='greater')\n            results['hypothesis_H5'] = {\n                \"test\": \"Independent t-test: Republican vs. Democratic on Nationalist Exclusion\",\n                \"t_statistic\": t_stat_h5,\n                \"p_value\": p_value_h5,\n                \"significant\": p_value_h5 < 0.05,\n                \"cohen_d\": cohen_d(republican_ne, democratic_ne) if p_value_h5 < 0.05 else None,\n                \"means\": {\"republican\": republican_ne.mean(), \"democratic\": democratic_ne.mean()}\n            }\n        else:\n            results['hypothesis_H5'] = {\"status\": \"error\", \"message\": \"Insufficient data for H5.\"}\n\n        # H6: Democrats > Republicans on Economic Populist Appeals\n        democratic_epa = processed_data[processed_data['party'] == 'Democratic']['economic_populist_appeals_raw'].dropna()\n        republican_epa = processed_data[processed_data['party'] == 'Republican']['economic_populist_appeals_raw'].dropna()\n\n        if len(democratic_epa) > 1 and len(republican_epa) > 1:\n            t_stat_h6, p_value_h6 = ttest_ind(democratic_epa, republican_epa, equal_var=False, alternative='greater')\n            results['hypothesis_H6'] = {\n                \"test\": \"Independent t-test: Democratic vs. Republican on Economic Populist Appeals\",\n                \"t_statistic\": t_stat_h6,\n                \"p_value\": p_value_h6,\n                \"significant\": p_value_h6 < 0.05,\n                \"cohen_d\": cohen_d(democratic_epa, republican_epa) if p_value_h6 < 0.05 else None,\n                \"means\": {\"democratic\": democratic_epa.mean(), \"republican\": republican_epa.mean()}\n            }\n        else:\n            results['hypothesis_H6'] = {\"status\": \"error\", \"message\": \"Insufficient data for H6.\"}\n            \n        return results\n\n    except Exception as e:\n        print(f\"Error in test_hypothesis_H5_H6_party_diff: {e}\")\n        return None\n\ndef test_hypothesis_H7_temporal_diff(data, **kwargs):\n    \"\"\"\n    Tests hypothesis H7 regarding the intensification of populist rhetoric over time.\n\n    Methodology:\n    - An independent samples t-test compares the mean 'manichaean_people_elite_framing_raw'\n      scores between the 'early_primary' and 'general_election' campaign phases.\n    - Note: The experiment spec mentions a \"paired t-test,\" which is inappropriate for\n      comparing independent groups of speeches. This function implements the more\n      statistically sound independent t-test.\n    - Cohen's d is calculated for effect size if the result is significant.\n\n    Args:\n        data (pd.DataFrame): The raw analysis data.\n        **kwargs: Not used.\n        \n    Returns:\n        dict: A dictionary with the t-test results, or None if an error occurs.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    from scipy.stats import ttest_ind\n\n    def cohen_d(x, y):\n        nx, ny = len(x), len(y)\n        dof = nx + ny - 2\n        return (np.mean(x) - np.mean(y)) / np.sqrt(((nx-1)*np.std(x, ddof=1)**2 + (ny-1)*np.std(y, ddof=1)**2) / dof)\n\n    try:\n        processed_data = _add_metadata_and_derived_metrics(data)\n        if processed_data is None or processed_data.empty:\n            return None\n\n        early_primary = processed_data[processed_data['campaign_phase'] == 'early_primary']['manichaean_people_elite_framing_raw'].dropna()\n        general_election = processed_data[processed_data['campaign_phase'] == 'general_election']['manichaean_people_elite_framing_raw'].dropna()\n\n        if len(early_primary) < 2 or len(general_election) < 2:\n            return {\"status\": \"error\", \"message\": \"Insufficient data for one or both campaign phases.\"}\n\n        # H7: General Election > Early Primary on Manichaean Framing\n        t_stat, p_value = ttest_ind(general_election, early_primary, equal_var=False, alternative='greater')\n        \n        return {\n            \"hypothesis_H7\": {\n                \"test\": \"Independent t-test: General Election vs. Early Primary on Manichaean People-Elite Framing\",\n                \"note\": \"Using independent t-test as speeches are independent samples, not paired.\",\n                \"t_statistic\": t_stat,\n                \"p_value\": p_value,\n                \"significant\": p_value < 0.05,\n                \"cohen_d\": cohen_d(general_election, early_primary) if p_value < 0.05 else None,\n                \"means\": {\"general_election\": general_election.mean(), \"early_primary\": early_primary.mean()}\n            }\n        }\n\n    except Exception as e:\n        print(f\"Error in test_hypothesis_H7_temporal_diff: {e}\")\n        return None\n\ndef test_hypothesis_H8_strategic_correlation(data, **kwargs):\n    \"\"\"\n    Tests hypothesis H8, which posits a negative correlation between rhetorical\n    contradiction and electoral success.\n\n    Methodology:\n    - A Pearson correlation is calculated between the 'populist_strategic_contradiction_index' (PSCI)\n      and the 'electoral_success' score.\n    - The hypothesis (H8) predicts a negative correlation (r < -0.3, p < 0.05).\n\n    Args:\n        data (pd.DataFrame): The raw analysis data.\n        **kwargs: Not used.\n        \n    Returns:\n        dict: A dictionary with the Pearson correlation coefficient and p-value, or None.\n    \"\"\"\n    import pandas as pd\n    from scipy.stats import pearsonr\n    \n    try:\n        processed_data = _add_metadata_and_derived_metrics(data)\n        if processed_data is None or processed_data.empty:\n            return None\n\n        df_corr = processed_data[['populist_strategic_contradiction_index', 'electoral_success']].dropna()\n        \n        if len(df_corr) < 3:\n            return {\"status\": \"error\", \"message\": \"Insufficient data for correlation analysis.\"}\n\n        corr, p_value = pearsonr(df_corr['populist_strategic_contradiction_index'], df_corr['electoral_success'])\n        \n        return {\n            \"hypothesis_H8\": {\n                \"test\": \"Pearson correlation between Populist Strategic Contradiction Index and Electoral Success\",\n                \"correlation_coefficient\": corr,\n                \"p_value\": p_value,\n                \"significant\": p_value < 0.05 and corr < -0.3,\n                \"conclusion\": \"Hypothesis supported: a significant negative correlation was found.\" if p_value < 0.05 and corr < -0.3 else \"Hypothesis not supported.\"\n            }\n        }\n\n    except Exception as e:\n        print(f\"Error in test_hypothesis_H8_strategic_correlation: {e}\")\n        return None\n\ndef test_hypothesis_H9_variance(data, **kwargs):\n    \"\"\"\n    Tests hypothesis H9, which predicts that Trump's populist rhetoric is more\n    variable than that of other candidates.\n\n    Methodology:\n    - A Levene's test for homogeneity of variances is performed.\n    - It compares the variance of the 'salience_weighted_overall_populism_index' for\n      Trump's speeches against the combined group of all other candidates' speeches.\n\n    Args:\n        data (pd.DataFrame): The raw analysis data.\n        **kwargs: Not used.\n        \n    Returns:\n        dict: A dictionary with the Levene's test statistic and p-value, or None.\n    \"\"\"\n    import pandas as pd\n    from scipy.stats import levene\n    \n    try:\n        processed_data = _add_metadata_and_derived_metrics(data)\n        if processed_data is None or processed_data.empty:\n            return None\n\n        target_metric = 'salience_weighted_overall_populism_index'\n        trump_scores = processed_data[processed_data['candidate_short'] == 'trump'][target_metric].dropna()\n        other_scores = processed_data[processed_data['candidate_short'] != 'trump'][target_metric].dropna()\n\n        if len(trump_scores) < 2 or len(other_scores) < 2:\n            return {\"status\": \"error\", \"message\": \"Insufficient data for one or both groups for Levene's test.\"}\n\n        w_stat, p_value = levene(trump_scores, other_scores)\n        \n        return {\n            \"hypothesis_H9\": {\n                \"test\": \"Levene's test for variance of Salience-Weighted Overall Populism Index (Trump vs. Others)\",\n                \"w_statistic\": w_stat,\n                \"p_value\": p_value,\n                \"significant\": p_value < 0.05,\n                \"conclusion\": \"Hypothesis supported: Trump's scores show significantly different variance.\" if p_value < 0.05 else \"Hypothesis not supported: No significant difference in variance found.\",\n                \"variances\": {\"trump\": trump_scores.var(), \"others\": other_scores.var()}\n            }\n        }\n\n    except Exception as e:\n        print(f\"Error in test_hypothesis_H9_variance: {e}\")\n        return None\n\ndef test_hypothesis_H10_candidate_type_diff(data, **kwargs):\n    \"\"\"\n    Tests hypothesis H10, which predicts significant differences between 'outsider'\n    and 'establishment' candidates on at least 4 of the 9 PDAF dimensions.\n\n    Methodology:\n    - For each of the 9 raw PDAF dimension scores, an independent samples t-test\n      is performed to compare the means of the 'outsider' group (Trump, Sanders)\n      and the 'establishment' group (Clinton, Rubio, Kasich).\n    - Cohen's d is calculated for effect size for each significant comparison.\n    - The function counts the number of dimensions with significant differences.\n\n    Args:\n        data (pd.DataFrame): The raw analysis data.\n        **kwargs: Not used.\n        \n    Returns:\n        dict: A dictionary summarizing the t-test results for all 9 dimensions and\n              the overall conclusion for H10, or None if an error occurs.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    from scipy.stats import ttest_ind\n\n    def cohen_d(x, y):\n        nx, ny = len(x), len(y)\n        dof = nx + ny - 2\n        return (np.mean(x) - np.mean(y)) / np.sqrt(((nx-1)*np.std(x, ddof=1)**2 + (ny-1)*np.std(y, ddof=1)**2) / dof)\n\n    try:\n        processed_data = _add_metadata_and_derived_metrics(data)\n        if processed_data is None or processed_data.empty:\n            return None\n\n        dims = [\n            \"manichaean_people_elite_framing\", \"crisis_restoration_narrative\",\n            \"popular_sovereignty_claims\", \"anti_pluralist_exclusion\",\n            \"elite_conspiracy_systemic_corruption\", \"authenticity_vs_political_class\",\n            \"homogeneous_people_construction\", \"nationalist_exclusion\",\n            \"economic_populist_appeals\"\n        ]\n        \n        outsider_data = processed_data[processed_data['candidate_type'] == 'outsider']\n        establishment_data = processed_data[processed_data['candidate_type'] == 'establishment']\n\n        if outsider_data.empty or establishment_data.empty:\n            return {\"status\": \"error\", \"message\": \"Insufficient data for 'outsider' or 'establishment' groups.\"}\n\n        results = {}\n        significant_diffs = 0\n        for dim in dims:\n            dim_raw = f\"{dim}_raw\"\n            group1 = outsider_data[dim_raw].dropna()\n            group2 = establishment_data[dim_raw].dropna()\n\n            if len(group1) > 1 and len(group2) > 1:\n                t_stat, p_value = ttest_ind(group1, group2, equal_var=False)\n                is_sig = p_value < 0.05\n                if is_sig:\n                    significant_diffs += 1\n                \n                results[dim] = {\n                    \"t_statistic\": t_stat,\n                    \"p_value\": p_value,\n                    \"significant\": is_sig,\n                    \"cohen_d\": cohen_d(group1, group2) if is_sig else None,\n                    \"means\": {\"outsider\": group1.mean(), \"establishment\": group2.mean()}\n                }\n            else:\n                results[dim] = {\"status\": \"error\", \"message\": \"Insufficient data for this dimension.\"}\n\n        return {\n            \"hypothesis_H10\": {\n                \"test\": \"Independent t-tests: 'outsider' vs. 'establishment' on 9 PDAF dimensions\",\n                \"significant_dimensions_count\": significant_diffs,\n                \"hypothesis_supported\": significant_diffs >= 4,\n                \"conclusion\": f\"Hypothesis supported: {significant_diffs} dimensions showed significant differences.\" if significant_diffs >= 4 else f\"Hypothesis not supported: Only {significant_diffs} dimensions showed significant differences.\",\n                \"dimensional_results\": results\n            }\n        }\n\n    except Exception as e:\n        print(f\"Error in test_hypothesis_H10_candidate_type_diff: {e}\")\n        return None\n\ndef calculate_internal_consistency(data, **kwargs):\n    \"\"\"\n    Calculates the internal consistency (reliability) of the PDAF scales.\n\n    Methodology:\n    - Cronbach's alpha is calculated to measure the internal consistency of a set of\n      scale items (the PDAF dimensions). A higher value indicates that the items\n      measure a single underlying latent construct.\n    - Alpha is calculated for:\n      1. The overall 9-dimension populism scale.\n      2. The 4-dimension 'Core Populism' sub-scale.\n      3. The 3-dimension 'Populism Mechanisms' sub-scale.\n      4. The 2-dimension 'Boundary Distinctions' sub-scale.\n    - Note: The experiment spec incorrectly requests alpha \"for each dimension.\" This\n      function implements the correct statistical application of Cronbach's alpha,\n      which is to assess a scale composed of multiple items.\n\n    Args:\n        data (pd.DataFrame): The raw analysis data.\n        **kwargs: Not used.\n        \n    Returns:\n        dict: A dictionary containing Cronbach's alpha for the overall scale and sub-scales.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    def cronbach_alpha(df):\n        if df.shape[1] < 2:\n            return np.nan\n        df_clean = df.dropna()\n        if df_clean.shape[0] < 2:\n            return np.nan\n        \n        k = df_clean.shape[1]\n        item_vars = df_clean.var(axis=0, ddof=1).sum()\n        total_var = df_clean.sum(axis=1).var(ddof=1)\n        \n        return (k / (k - 1)) * (1 - item_vars / total_var)\n\n    try:\n        processed_data = _add_metadata_and_derived_metrics(data)\n        if processed_data is None or processed_data.empty:\n            return None\n\n        dims = [f\"{d}_raw\" for d in [\n            \"manichaean_people_elite_framing\", \"crisis_restoration_narrative\",\n            \"popular_sovereignty_claims\", \"anti_pluralist_exclusion\",\n            \"elite_conspiracy_systemic_corruption\", \"authenticity_vs_political_class\",\n            \"homogeneous_people_construction\", \"nationalist_exclusion\",\n            \"economic_populist_appeals\"\n        ]]\n        \n        core_dims = dims[:4]\n        mech_dims = dims[4:7]\n        bound_dims = dims[7:]\n\n        results = {\n            \"overall_scale_alpha\": cronbach_alpha(processed_data[dims]),\n            \"core_populism_subscale_alpha\": cronbach_alpha(processed_data[core_dims]),\n            \"populism_mechanisms_subscale_alpha\": cronbach_alpha(processed_data[mech_dims]),\n            \"boundary_distinctions_subscale_alpha\": cronbach_alpha(processed_data[bound_dims]),\n        }\n        \n        return {\n            \"test\": \"Cronbach's Alpha for Internal Consistency of PDAF Scales\",\n            \"note\": \"Alpha is calculated for scales (sets of dimensions), not individual dimensions.\",\n            \"results\": results\n        }\n\n    except Exception as e:\n        print(f\"Error in calculate_internal_consistency: {e}\")\n        return None\n\ndef run_complete_statistical_analysis(data: pd.DataFrame, alpha: float = 0.05) -> Dict[str, Any]:\n    \"\"\"\n    Run complete statistical analysis suite on the dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        alpha: Significance level for hypothesis tests (default: 0.05)\n        \n    Returns:\n        Dictionary with all statistical analysis results\n    \"\"\"\n    results = {\n        'analysis_metadata': {\n            'timestamp': pd.Timestamp.now().isoformat(),\n            'sample_size': len(data),\n            'alpha_level': alpha,\n            'variables_analyzed': list(data.select_dtypes(include=[np.number]).columns)\n        }\n    }\n    \n    # Get all analysis functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith(('calculate_', 'perform_', 'test_')) and \n            name != 'run_complete_statistical_analysis'):\n            try:\n                # Pass alpha parameter to functions that might need it\n                if 'alpha' in inspect.signature(obj).parameters:\n                    results[name] = obj(data, alpha=alpha)\n                else:\n                    results[name] = obj(data)\n            except Exception as e:\n                results[name] = {'error': f'Analysis failed: {str(e)}'}\n                \n    return results\n\n\ndef perform_statistical_analysis(data: pd.DataFrame) -> Dict[str, Any]:\n    \"\"\"\n    Template-compatible wrapper function for statistical analysis.\n    \n    This function is called by the universal notebook template and performs\n    comprehensive statistical analysis on the provided dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores and derived metrics\n        \n    Returns:\n        Dictionary containing all statistical analysis results\n    \"\"\"\n    return run_complete_statistical_analysis(data)\n\n\ndef generate_statistical_summary_report(analysis_results: Dict[str, Any]) -> str:\n    \"\"\"\n    Generate a human-readable summary report from statistical analysis results.\n    \n    Args:\n        analysis_results: Results from run_complete_statistical_analysis()\n        \n    Returns:\n        String containing formatted statistical report\n    \"\"\"\n    report_lines = []\n    report_lines.append(\"STATISTICAL ANALYSIS SUMMARY REPORT\")\n    report_lines.append(\"=\" * 50)\n    \n    metadata = analysis_results.get('analysis_metadata', {})\n    report_lines.append(f\"Analysis Timestamp: {metadata.get('timestamp', 'Unknown')}\")\n    report_lines.append(f\"Sample Size: {metadata.get('sample_size', 'Unknown')}\")\n    report_lines.append(f\"Alpha Level: {metadata.get('alpha_level', 'Unknown')}\")\n    report_lines.append(f\"Variables: {len(metadata.get('variables_analyzed', []))}\")\n    report_lines.append(\"\")\n    \n    # Summarize key findings\n    for analysis_name, result in analysis_results.items():\n        if analysis_name != 'analysis_metadata' and isinstance(result, dict):\n            if 'error' not in result:\n                report_lines.append(f\"{analysis_name.replace('_', ' ').title()}:\")\n                \n                # Extract key statistics based on analysis type\n                if 'p_value' in result:\n                    p_val = result['p_value']\n                    significance = \"significant\" if p_val < metadata.get('alpha_level', 0.05) else \"not significant\"\n                    report_lines.append(f\"  - p-value: {p_val:.4f} ({significance})\")\n                \n                if 'effect_size' in result:\n                    report_lines.append(f\"  - Effect size: {result['effect_size']:.4f}\")\n                \n                if 'correlation_matrix' in result:\n                    report_lines.append(f\"  - Correlation matrix generated with {len(result['correlation_matrix'])} variables\")\n                \n                if 'cronbach_alpha' in result:\n                    alpha_val = result['cronbach_alpha']\n                    reliability = \"excellent\" if alpha_val > 0.9 else \"good\" if alpha_val > 0.8 else \"acceptable\" if alpha_val > 0.7 else \"questionable\"\n                    report_lines.append(f\"  - Cronbach's \u03b1: {alpha_val:.3f} ({reliability})\")\n                \n                report_lines.append(\"\")\n            else:\n                report_lines.append(f\"{analysis_name}: ERROR - {result['error']}\")\n                report_lines.append(\"\")\n    \n    return \"\\n\".join(report_lines)\n",
  "cached_with_code": true
}