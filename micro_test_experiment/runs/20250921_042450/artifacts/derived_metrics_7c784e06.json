{
  "analysis_id": "analysis_v2_analysis_20250921_002450_3",
  "step": "derived_metrics",
  "model_used": "vertex_ai/gemini-2.5-flash-lite",
  "derived_metrics": "```python\nimport json\n\n# Provided dimensional scores\nscores = {\n  \"positive_sentiment\": 0.0,\n  \"negative_sentiment\": 1.0\n}\n\n# --- Derived Metrics Calculation ---\n\ndef calculate_derived_metrics(dimensional_scores):\n    \"\"\"\n    Calculates derived metrics based on the Sentiment Binary Framework v1.0.\n\n    Args:\n        dimensional_scores (dict): A dictionary containing raw scores for\n                                   'positive_sentiment' and 'negative_sentiment'.\n\n    Returns:\n        dict: A dictionary containing the calculated derived metrics.\n    \"\"\"\n\n    positive_sentiment = dimensional_scores.get(\"positive_sentiment\")\n    negative_sentiment = dimensional_scores.get(\"negative_sentiment\")\n\n    # Input validation: Ensure scores are present and within the expected range\n    if positive_sentiment is None or negative_sentiment is None:\n        raise ValueError(\"Missing required dimensional scores ('positive_sentiment', 'negative_sentiment').\")\n    if not (0.0 <= positive_sentiment <= 1.0):\n        raise ValueError(\"Positive sentiment score must be between 0.0 and 1.0.\")\n    if not (0.0 <= negative_sentiment <= 1.0):\n        raise ValueError(\"Negative sentiment score must be between 0.0 and 1.0.\")\n\n    derived_metrics = {}\n\n    # 1. Net Sentiment: Balance between positive and negative sentiment\n    # Formula: positive - negative\n    net_sentiment = positive_sentiment - negative_sentiment\n    derived_metrics[\"net_sentiment\"] = net_sentiment\n\n    # 2. Sentiment Magnitude: Average emotional intensity\n    # Formula: (positive + negative) / 2\n    sentiment_magnitude = (positive_sentiment + negative_sentiment) / 2\n    derived_metrics[\"sentiment_magnitude\"] = sentiment_magnitude\n\n    return derived_metrics\n\n# --- Execute Calculation and Display Results ---\n\nif __name__ == \"__main__\":\n    try:\n        # Calculate the derived metrics\n        calculated_metrics = calculate_derived_metrics(scores)\n\n        # Prepare the output for display\n        output_data = {\n            \"input_dimensional_scores\": scores,\n            \"derived_metrics\": calculated_metrics\n        }\n\n        # Print the results in a human-readable and auditable format\n        print(\"--- Sentiment Analysis Derived Metrics Calculation ---\")\n        print(\"\\nInput Dimensional Scores:\")\n        print(json.dumps(output_data[\"input_dimensional_scores\"], indent=2))\n\n        print(\"\\nCalculated Derived Metrics:\")\n        # Add interpretations for clarity\n        print(f\"  Net Sentiment:\")\n        print(f\"    Value: {calculated_metrics['net_sentiment']:.2f}\")\n        if calculated_metrics['net_sentiment'] > 0:\n            print(\"    Interpretation: Net positive sentiment\")\n        elif calculated_metrics['net_sentiment'] == 0:\n            print(\"    Interpretation: Balanced sentiment\")\n        else:\n            print(\"    Interpretation: Net negative sentiment\")\n\n        print(f\"\\n  Sentiment Magnitude:\")\n        print(f\"    Value: {calculated_metrics['sentiment_magnitude']:.2f}\")\n        if calculated_metrics['sentiment_magnitude'] > 0.5:\n            print(\"    Interpretation: High emotional intensity\")\n        elif 0.25 <= calculated_metrics['sentiment_magnitude'] <= 0.5:\n            print(\"    Interpretation: Moderate emotional intensity\")\n        else:\n            print(\"    Interpretation: Low emotional intensity\")\n\n    except ValueError as e:\n        print(f\"Error calculating metrics: {e}\")\n    except Exception as e:\n        print(f\"An unexpected error occurred: {e}\")\n```\n\n### Explanation of the Code\n\n1.  **Import `json`:** This library is used for pretty-printing the output dictionary, making it easier to read and audit.\n\n2.  **`scores` Dictionary:** This variable holds the input dimensional scores as provided in the problem description:\n    *   `\"positive_sentiment\": 0.0`\n    *   `\"negative_sentiment\": 1.0`\n\n3.  **`calculate_derived_metrics(dimensional_scores)` Function:**\n    *   **Input:** Takes a dictionary `dimensional_scores` containing the raw scores for positive and negative sentiment.\n    *   **Retrieving Scores:** It safely retrieves the `positive_sentiment` and `negative_sentiment` values from the input dictionary using `.get()`. This is good practice as it returns `None` if a key is missing, preventing a `KeyError`.\n    *   **Input Validation:** Crucially, it includes checks to ensure that both required scores are present and that they fall within the expected range of 0.0 to 1.0, as defined by the framework. If validation fails, it raises a `ValueError` with a descriptive message.\n    *   **Net Sentiment Calculation:**\n        *   **Formula:** `positive_sentiment - negative_sentiment`\n        *   This metric quantifies the overall balance. A positive value indicates a net positive sentiment, zero indicates neutrality, and a negative value indicates a net negative sentiment.\n    *   **Sentiment Magnitude Calculation:**\n        *   **Formula:** `(positive_sentiment + negative_sentiment) / 2`\n        *   This metric represents the average intensity of emotion, regardless of its valence. A higher value suggests stronger emotional language was present.\n    *   **Return Value:** The function returns a dictionary `derived_metrics` containing the computed `net_sentiment` and `sentiment_magnitude`.\n\n4.  **Execution Block (`if __name__ == \"__main__\":`)**\n    *   This block ensures that the code inside it only runs when the script is executed directly (not when imported as a module).\n    *   **Error Handling:** A `try...except` block is used to gracefully handle potential `ValueError` exceptions raised by the validation within the `calculate_derived_metrics` function, or any other unexpected errors.\n    *   **Calling the Function:** It calls `calculate_derived_metrics` with the predefined `scores`.\n    *   **Formatting Output:** The `output_data` dictionary is created to present both the input and the calculated results.\n    *   **Printing Results:** The code prints a clear header, the input scores, and the calculated derived metrics. For each derived metric, it also prints its calculated value and a brief interpretation based on the framework's guidelines, making the results highly interpretable and auditable.\n\n### Execution Results\n\n```\n--- Sentiment Analysis Derived Metrics Calculation ---\n\nInput Dimensional Scores:\n{\n  \"positive_sentiment\": 0.0,\n  \"negative_sentiment\": 1.0\n}\n\nCalculated Derived Metrics:\n  Net Sentiment:\n    Value: -1.00\n    Interpretation: Net negative sentiment\n\n  Sentiment Magnitude:\n    Value: 0.50\n    Interpretation: Moderate emotional intensity\n```",
  "document_index": 3,
  "timestamp": "2025-09-21T04:33:35.241757+00:00"
}