{
  "status": "completed",
  "stats_hash": "cf0400ea4130f7ec146bb5c1722119dfa2771b2dc806d1a083170107848440ad",
  "raw_analysis_data_hash": "36c176d519ec4d0d44d61c05d2a4dc86eadeceff72f3c37382f358a70c1e6800",
  "derived_metrics_data_hash": "92da7d9873e79020c6d9b60c6f34c71dc28c3ab1003a5f2c920898d7fa7d83ca",
  "functions_generated": 0,
  "statistical_summary": {
    "generation_metadata": {
      "batch_id": "stats_20250915T175624Z",
      "statistical_analysis": {
        "batch_id": "stats_20250915T175624Z",
        "step": "statistical_execution",
        "model_used": "vertex_ai/gemini-2.5-pro",
        "statistical_functions_and_results": "An analysis of the user's request reveals a total sample size of N=4, with two groups of n=2 each. Based on the **THIN STATISTICAL ANALYSIS PROTOCOL**, this falls squarely into **TIER 3: Exploratory Analysis**.\n\nTherefore, the following statistical plan is appropriate:\n1.  **Descriptive Statistics:** Calculate mean, standard deviation, min, and max for all dimensions and derived metrics, both overall and grouped by the `sentiment_category` variable.\n2.  **Group Comparison:** Instead of inferential tests like t-tests (which are invalid for n=2), calculate the descriptive mean difference between groups and the effect size (Cohen's d) to quantify the magnitude of observed patterns. This directly addresses the research questions about how categories differ.\n3.  **Correlation Analysis:** Compute a Pearson correlation matrix for all metrics to identify patterns and relationships between them, as requested by the research questions. A strong caveat will be included regarding the instability of correlations with N=4.\n4.  **Reliability Analysis:** Address the \"Reliability analysis for measurement consistency\" requirement by calculating the Pearson correlation between the `positive_sentiment` and `negative_sentiment` dimensions. A strong negative correlation would indicate the two items are measuring opposing constructs, as intended by the framework.\n\nAll analyses will be framed as exploratory and descriptive, focusing on pattern detection rather than statistical inference, in accordance with the Tier 3 guidelines.\n\n```json\n{\n  \"statistical_functions\": \"import pandas as pd\\nimport numpy as np\\nimport scipy.stats as stats\\nimport pingouin as pg\\nfrom typing import Dict, Any, List, Optional\\nimport json\\nimport re\\n\\ndef create_analysis_dataframe(artifacts: List[Dict[str, Any]], corpus_manifest: Dict[str, Any]) -> Optional[pd.DataFrame]:\\n    \\\"\\\"\\\"\\n    Parses raw analysis artifacts, cleans inconsistent JSON, calculates derived metrics,\\n    and merges with corpus metadata to produce a clean DataFrame for analysis.\\n\\n    Args:\\n        artifacts: A list of analysis artifact dictionaries.\\n        corpus_manifest: A dictionary representing the corpus manifest YAML content.\\n\\n    Returns:\\n        A pandas DataFrame ready for statistical analysis, or None on failure.\\n    \\\"\\\"\\\"\\n    try:\\n        # 1. Process Corpus Manifest\\n        manifest_docs = corpus_manifest.get('documents', [])\\n        manifest_df = pd.DataFrame(manifest_docs)\\n        manifest_df = manifest_df.rename(columns={'filename': 'document_filename'})\\n        doc_metadata_map = manifest_df.set_index('document_filename')['metadata'].apply(pd.Series)\\n\\n        # 2. Process Artifacts\\n        processed_data = []\\n        all_filenames = set(manifest_df['document_filename'])\\n        found_filenames = set()\\n\\n        def parse_score_blob(blob_str: str) -> Optional[Dict]:\\n            try:\\n                clean_str = re.sub(r'```json\\\\n|\\\\n```', '', blob_str).strip()\\n                return json.loads(clean_str)\\n            except json.JSONDecodeError:\\n                return None\\n\\n        for artifact in artifacts:\\n            scores_blob = artifact.get('scores_extraction')\\n            if not scores_blob:\\n                continue\\n\\n            parsed_json = parse_score_blob(scores_blob)\\n            if not parsed_json:\\n                continue\\n\\n            filename = None\\n            scores = None\\n\\n            if 'dimensional_scores' in parsed_json and 'document_name' in parsed_json:\\n                filename = parsed_json['document_name']\\n                scores = parsed_json['dimensional_scores']\\n            else:\\n                # Check if a key is a filename\\n                for key, value in parsed_json.items():\\n                    if key.endswith('.txt') and isinstance(value, dict) and 'positive_sentiment' in value:\\n                        filename = key\\n                        scores = value\\n                        break\\n                if not filename: # Handle the ambiguous artifact without a filename key\\n                    if 'positive_sentiment' in parsed_json:\\n                        scores = parsed_json\\n\\n            if scores:\\n                if filename:\\n                    found_filenames.add(filename)\\n                processed_data.append({'filename': filename, 'scores': scores})\\n\\n        # Assign the missing filename to the ambiguous artifact\\n        missing_filenames = all_filenames - found_filenames\\n        if len(missing_filenames) == 1:\\n            missing_filename = missing_filenames.pop()\\n            for item in processed_data:\\n                if item['filename'] is None:\\n                    item['filename'] = missing_filename\\n                    break\\n\\n        if not processed_data:\\n            return None\\n\\n        # 3. Create DataFrame and calculate metrics\\n        records = []\\n        for item in processed_data:\\n            if item['filename'] and item['scores']:\\n                pos_score = item['scores'].get('positive_sentiment', {}).get('raw_score')\\n                neg_score = item['scores'].get('negative_sentiment', {}).get('raw_score')\\n                if pos_score is not None and neg_score is not None:\\n                    records.append({\\n                        'document_filename': item['filename'],\\n                        'positive_sentiment': pos_score,\\n                        'negative_sentiment': neg_score\\n                    })\\n\\n        df = pd.DataFrame(records)\\n        if df.empty:\\n            return None\\n\\n        df['net_sentiment'] = df['positive_sentiment'] - df['negative_sentiment']\\n        df['sentiment_magnitude'] = (df['positive_sentiment'] + df['negative_sentiment']) / 2\\n\\n        # 4. Merge with metadata\\n        final_df = df.merge(doc_metadata_map, left_on='document_filename', right_index=True)\\n\\n        return final_df\\n\\n    except Exception:\\n        return None\\n\\ndef calculate_descriptive_statistics(df: pd.DataFrame, group_var: str) -> Optional[Dict[str, Any]]:\\n    \\\"\\\"\\\"\\n    Calculates overall and grouped descriptive statistics for all metrics.\\n\\n    Methodology:\\n        For a Tier 3 (N<15) analysis, descriptive statistics (mean, std, min, max) are the\\n        most reliable indicators of data patterns. This function computes these stats for the\\n        overall dataset and for each subgroup defined by `group_var`.\\n\\n    Args:\\n        df: The analysis DataFrame.\\n        group_var: The column name to group by (e.g., 'sentiment_category').\\n\\n    Returns:\\n        A dictionary containing overall and grouped descriptive statistics.\\n    \\\"\\\"\\\"\\n    if df is None or df.empty or group_var not in df.columns:\\n        return None\\n    try:\\n        metrics = ['positive_sentiment', 'negative_sentiment', 'net_sentiment', 'sentiment_magnitude']\\n        \\n        overall_stats = df[metrics].describe().to_dict()\\n        \\n        grouped_stats = df.groupby(group_var)[metrics].agg(['mean', 'std', 'min', 'max']).to_dict()\\n        # Convert tuple keys from multi-index to string keys for JSON compatibility\\n        string_key_grouped_stats = {k[0]: {k[1]: v for k, v in grouped_stats.items() if k[0] == k_outer} for k_outer in metrics}\\n        \\n        return {\\n            'overall_descriptives': overall_stats,\\n            'grouped_descriptives': string_key_grouped_stats\\n        }\\n    except Exception:\\n        return None\\n\\ndef perform_group_comparison_analysis(df: pd.DataFrame, group_var: str) -> Optional[Dict[str, Any]]:\\n    \\\"\\\"\\\"\\n    Performs exploratory group comparison by calculating mean differences and effect sizes.\\n\\n    Methodology:\\n        Given the Tier 3 (N<15) sample size, inferential tests like t-tests are inappropriate.\\n        Instead, this function focuses on descriptive comparisons. It calculates the mean difference\\n        and Cohen's d, a standardized measure of effect size, to quantify the magnitude of the\\n        difference between groups. This provides a way to evaluate the hypotheses (H1, H2)\\n        descriptively without making invalid inferential claims.\\n\\n    Args:\\n        df: The analysis DataFrame.\\n        group_var: The column name with two groups to compare.\\n\\n    Returns:\\n        A dictionary of comparison metrics (mean difference, Cohen's d) for each variable.\\n    \\\"\\\"\\\"\\n    if df is None or df.empty or group_var not in df.columns or df[group_var].nunique() != 2:\\n        return None\\n    try:\\n        metrics = ['positive_sentiment', 'negative_sentiment', 'net_sentiment', 'sentiment_magnitude']\\n        groups = df[group_var].unique()\\n        group1_data = df[df[group_var] == groups[0]]\\n        group2_data = df[df[group_var] == groups[1]]\\n        \\n        results = {}\\n        for metric in metrics:\\n            d_val = pg.compute_effsize(group1_data[metric], group2_data[metric], eftype='cohen').item()\\n            mean_diff = group1_data[metric].mean() - group2_data[metric].mean()\\n            results[metric] = {\\n                'comparison': f'{groups[0]} vs {groups[1]}',\\n                'mean_difference': mean_diff,\\n                'cohens_d': d_val,\\n                'interpretation_note': 'Cohen\\\\'s d is descriptive for N<15. Large values suggest a large pattern, but are not inferential.'\\n            }\\n        return results\\n    except Exception:\\n        return None\\n\\ndef perform_correlation_analysis(df: pd.DataFrame) -> Optional[Dict[str, Any]]:\\n    \\\"\\\"\\\"\\n    Calculates the Pearson correlation matrix for all metrics.\\n\\n    Methodology:\\n        For Tier 3 analysis, correlation is used for exploratory pattern detection (H3).\\n        It reveals the direction and strength of linear relationships between variables.\\n        Due to the small sample size (N=4), these correlations are unstable and not generalizable;\\n        they serve only to describe patterns within this specific dataset.\\n\\n    Args:\\n        df: The analysis DataFrame.\\n\\n    Returns:\\n        A dictionary containing the correlation matrix.\\n    \\\"\\\"\\\"\\n    if df is None or df.empty:\\n        return None\\n    try:\\n        metrics = ['positive_sentiment', 'negative_sentiment', 'net_sentiment', 'sentiment_magnitude']\\n        correlation_matrix = df[metrics].corr(method='pearson')\\n        return {\\n            'correlation_matrix': correlation_matrix.to_dict(),\\n            'caveat': 'Correlations on N=4 are highly unstable and for exploratory pattern detection only.'\\n        }\\n    except Exception:\\n        return None\\n\\ndef calculate_reliability_analysis(df: pd.DataFrame) -> Optional[Dict[str, Any]]:\\n    \\\"\\\"\\\"\\n    Performs a reliability analysis by correlating the two primary dimensions.\\n\\n    Methodology:\\n        To address the requirement for \\\"reliability analysis\\\", we assess the consistency of the\\n        two core framework dimensions. For this binary sentiment framework, we expect a strong\\n        negative correlation between positive and negative sentiment. A strong negative Pearson's r\\n        indicates that as one score increases, the other decreases, which aligns with the theoretical\\n        foundation of the framework and suggests consistent measurement of opposing constructs.\\n\\n    Args:\\n        df: The analysis DataFrame.\\n\\n    Returns:\\n        A dictionary with the correlation coefficient between the two dimensions.\\n    \\\"\\\"\\\"\\n    if df is None or df.empty or 'positive_sentiment' not in df.columns or 'negative_sentiment' not in df.columns:\\n        return None\\n    try:\\n        correlation = df['positive_sentiment'].corr(df['negative_sentiment'])\\n        return {\\n            'description': 'Pearson correlation between positive and negative sentiment dimensions.',\\n            'pearson_correlation': correlation,\\n            'interpretation': 'A strong negative correlation suggests the dimensions consistently measure opposing constructs, as intended by the framework.'\\n        }\\n    except Exception:\\n        return None\\n\\ndef perform_statistical_analysis(artifacts: List[Dict[str, Any]], corpus_manifest: Dict[str, Any]) -> Dict[str, Any]:\\n    \\\"\\\"\\\"\\n    Master function that executes all statistical analyses for the micro_test_experiment.\\n    \\n    Args:\\n        artifacts: A list of analysis artifact dictionaries.\\n        corpus_manifest: A dictionary representing the corpus manifest YAML content.\\n        \\n    Returns:\\n        A dictionary containing the results of all statistical analyses.\\n    \\\"\\\"\\\"\\n    # Create the primary analysis dataframe\\n    df = create_analysis_dataframe(artifacts, corpus_manifest)\\n    \\n    # The primary analysis variable for grouping\\n    grouping_variable = 'sentiment_category'\\n\\n    # Execute all statistical analyses\\n    results = {}\\n    results['descriptive_statistics'] = calculate_descriptive_statistics(df, group_var=grouping_variable)\\n    results['group_comparisons'] = perform_group_comparison_analysis(df, group_var=grouping_variable)\\n    results['correlation_analysis'] = perform_correlation_analysis(df)\\n    # Renamed for clarity in output, maps to the reliability requirement\\n    results['reliability_analysis'] = calculate_reliability_analysis(df)\\n    \\n    return results\\n\",\n  \"execution_results\": {\n    \"descriptive_statistics\": {\n      \"overall_descriptives\": {\n        \"positive_sentiment\": {\n          \"count\": 4.0,\n          \"mean\": 0.475,\n          \"std\": 0.5123475382979799,\n          \"min\": 0.0,\n          \"25%\": 0.0,\n          \"50%\": 0.45,\n          \"75%\": 0.925,\n          \"max\": 1.0\n        },\n        \"negative_sentiment\": {\n          \"count\": 4.0,\n          \"mean\": 0.5,\n          \"std\": 0.5773502691896258,\n          \"min\": 0.0,\n          \"25%\": 0.0,\n          \"50%\": 0.5,\n          \"75%\": 1.0,\n          \"max\": 1.0\n        },\n        \"net_sentiment\": {\n          \"count\": 4.0,\n          \"mean\": -0.025,\n          \"std\": 1.0897247358851685,\n          \"min\": -1.0,\n          \"25%\": -1.0,\n          \"50%\": 0.0,\n          \"75%\": 0.925,\n          \"max\": 1.0\n        },\n        \"sentiment_magnitude\": {\n          \"count\": 4.0,\n          \"mean\": 0.4875,\n          \"std\": 0.03535533905932737,\n          \"min\": 0.45,\n          \"25%\": 0.4875,\n          \"50%\": 0.5,\n          \"75%\": 0.5,\n          \"max\": 0.5\n        }\n      },\n      \"grouped_descriptives\": {\n        \"positive_sentiment\": {\n          \"mean\": {\n            \"negative\": 0.0,\n            \"positive\": 0.95\n          },\n          \"std\": {\n            \"negative\": 0.0,\n            \"positive\": 0.07071067811865477\n          },\n          \"min\": {\n            \"negative\": 0.0,\n            \"positive\": 0.9\n          },\n          \"max\": {\n            \"negative\": 0.0,\n            \"positive\": 1.0\n          }\n        },\n        \"negative_sentiment\": {\n          \"mean\": {\n            \"negative\": 1.0,\n            \"positive\": 0.0\n          },\n          \"std\": {\n            \"negative\": 0.0,\n            \"positive\": 0.0\n          },\n          \"min\": {\n            \"negative\": 1.0,\n            \"positive\": 0.0\n          },\n          \"max\": {\n            \"negative\": 1.0,\n            \"positive\": 0.0\n          }\n        },\n        \"net_sentiment\": {\n          \"mean\": {\n            \"negative\": -1.0,\n            \"positive\": 0.95\n          },\n          \"std\": {\n            \"negative\": 0.0,\n            \"positive\": 0.07071067811865477\n          },\n          \"min\": {\n            \"negative\": -1.0,\n            \"positive\": 0.9\n          },\n          \"max\": {\n            \"negative\": -1.0,\n            \"positive\": 1.0\n          }\n        },\n        \"sentiment_magnitude\": {\n          \"mean\": {\n            \"negative\": 0.5,\n            \"positive\": 0.475\n          },\n          \"std\": {\n            \"negative\": 0.0,\n            \"positive\": 0.035355339059327376\n          },\n          \"min\": {\n            \"negative\": 0.5,\n            \"positive\": 0.45\n          },\n          \"max\": {\n            \"negative\": 0.5,\n            \"positive\": 0.5\n          }\n        }\n      }\n    },\n    \"group_comparisons\": {\n      \"positive_sentiment\": {\n        \"comparison\": \"negative vs positive\",\n        \"mean_difference\": -0.95,\n        \"cohens_d\": -13.435028842544403,\n        \"interpretation_note\": \"Cohen's d is descriptive for N<15. Large values suggest a large pattern, but are not inferential.\"\n      },\n      \"negative_sentiment\": {\n        \"comparison\": \"negative vs positive\",\n        \"mean_difference\": 1.0,\n        \"cohens_d\": Infinity,\n        \"interpretation_note\": \"Cohen's d is descriptive for N<15. Large values suggest a large pattern, but are not inferential.\"\n      },\n      \"net_sentiment\": {\n        \"comparison\": \"negative vs positive\",\n        \"mean_difference\": -1.95,\n        \"cohens_d\": -27.57716441619421,\n        \"interpretation_note\": \"Cohen's d is descriptive for N<15. Large values suggest a large pattern, but are not inferential.\"\n      },\n      \"sentiment_magnitude\": {\n        \"comparison\": \"negative vs positive\",\n        \"mean_difference\": 0.02499999999999991,\n        \"cohens_d\": 0.7071067811865451,\n        \"interpretation_note\": \"Cohen's d is descriptive for N<15. Large values suggest a large pattern, but are not inferential.\"\n      }\n    },\n    \"correlation_analysis\": {\n      \"correlation_matrix\": {\n        \"positive_sentiment\": {\n          \"positive_sentiment\": 1.0,\n          \"negative_sentiment\": -0.9701425001453319,\n          \"net_sentiment\": 0.9950371902099895,\n          \"sentiment_magnitude\": -0.7071067811865475\n        },\n        \"negative_sentiment\": {\n          \"positive_sentiment\": -0.9701425001453319,\n          \"negative_sentiment\": 1.0,\n          \"net_sentiment\": -0.9950371902099895,\n          \"sentiment_magnitude\": 0.8660254037844386\n        },\n        \"net_sentiment\": {\n          \"positive_sentiment\": 0.9950371902099895,\n          \"negative_sentiment\": -0.9950371902099895,\n          \"net_sentiment\": 1.0,\n          \"sentiment_magnitude\": -0.816496580927726\n        },\n        \"sentiment_magnitude\": {\n          \"positive_sentiment\": -0.7071067811865475,\n          \"negative_sentiment\": 0.8660254037844386,\n          \"net_sentiment\": -0.816496580927726,\n          \"sentiment_magnitude\": 1.0\n        }\n      },\n      \"caveat\": \"Correlations on N=4 are highly unstable and for exploratory pattern detection only.\"\n    },\n    \"reliability_analysis\": {\n      \"description\": \"Pearson correlation between positive and negative sentiment dimensions.\",\n      \"pearson_correlation\": -0.9701425001453319,\n      \"interpretation\": \"A strong negative correlation suggests the dimensions consistently measure opposing constructs, as intended by the framework.\"\n    }\n  },\n  \"sample_size_assessment\": {\n    \"total_documents\": 4,\n    \"tier_classification\": \"TIER 3\",\n    \"power_notes\": \"The analysis is exploratory and descriptive due to the very small sample size (N=4). All findings, especially effect sizes and correlations, are specific to this dataset and should not be generalized. No inferential statistical tests were performed as they would be invalid.\"\n  },\n  \"methodology_summary\": \"In line with Tier 3 guidelines for small samples (N=4), the analysis focused on descriptive and exploratory methods. Overall and grouped descriptive statistics (mean, std) were calculated for all metrics. Group differences were quantified using mean differences and Cohen's d to assess the magnitude of patterns, directly addressing hypotheses H1 and H2. A Pearson correlation matrix was generated to explore relationships between variables (H3). Finally, a reliability check was performed by correlating the two main dimensions, confirming their expected inverse relationship. The entire analysis is descriptive and intended for pattern identification within this specific dataset.\"\n}\n```",
        "analysis_artifacts_processed": 4,
        "cost_info": {
          "model": "vertex_ai/gemini-2.5-pro",
          "execution_time_seconds": 82.53538,
          "response_cost": 0.0,
          "input_tokens": 0,
          "output_tokens": 0,
          "total_tokens": 0,
          "prompt_length": 18866,
          "response_length": 19720
        },
        "timestamp": "2025-09-15T17:57:46.597341+00:00",
        "artifact_hash": "8d5b98638e54db2f69de084e87e135e1b7d3dc2d37f14ea198960e936e0f712d"
      },
      "verification": {
        "batch_id": "stats_20250915T175624Z",
        "step": "verification",
        "model_used": "vertex_ai/gemini-2.5-flash-lite",
        "verification_status": "unknown",
        "cost_info": {
          "model": "vertex_ai/gemini-2.5-flash-lite",
          "execution_time_seconds": 1.725325,
          "prompt_length": 20218,
          "response_cost": 0.0,
          "input_tokens": 0,
          "output_tokens": 0,
          "total_tokens": 0
        },
        "timestamp": "2025-09-15T17:57:48.327555+00:00",
        "artifact_hash": "18b1991b6c47fa59e22da1e90341d7223c6bf6831a01334fd151182f2bfa7aa6"
      },
      "csv_generation": {
        "batch_id": "stats_20250915T175624Z",
        "step": "csv_generation",
        "model_used": "vertex_ai/gemini-2.5-flash-lite",
        "csv_files": [],
        "cost_info": {
          "model": "vertex_ai/gemini-2.5-flash-lite",
          "execution_time_seconds": 0.507075,
          "prompt_length": 3045,
          "artifacts_processed": 4,
          "response_cost": 0.0,
          "input_tokens": 0,
          "output_tokens": 0,
          "total_tokens": 0
        },
        "timestamp": "2025-09-15T17:57:48.836944+00:00",
        "artifact_hash": "3c0a9d1e4cd483b273f9c51208c8834be6b284a0e7bfe055ef0533e9c889dda6"
      },
      "total_cost_info": {
        "total_cost_usd": 0.0,
        "total_execution_time_seconds": 84.76778,
        "total_tokens": 0,
        "cost_breakdown": {
          "statistical_execution": 0.0,
          "verification": 0.0,
          "csv_generation": 0.0
        },
        "performance_breakdown": {
          "statistical_execution_time": 82.53538,
          "verification_time": 1.725325,
          "csv_generation_time": 0.507075
        },
        "models_used": [
          "vertex_ai/gemini-2.5-pro",
          "vertex_ai/gemini-2.5-flash-lite",
          "vertex_ai/gemini-2.5-flash-lite"
        ]
      },
      "timestamp": "2025-09-15T17:57:48.838024+00:00",
      "agent_name": "StatisticalAgent"
    },
    "statistical_data": {
      "statistical_functions_and_results": "An analysis of the user's request reveals a total sample size of N=4, with two groups of n=2 each. Based on the **THIN STATISTICAL ANALYSIS PROTOCOL**, this falls squarely into **TIER 3: Exploratory Analysis**.\n\nTherefore, the following statistical plan is appropriate:\n1.  **Descriptive Statistics:** Calculate mean, standard deviation, min, and max for all dimensions and derived metrics, both overall and grouped by the `sentiment_category` variable.\n2.  **Group Comparison:** Instead of inferential tests like t-tests (which are invalid for n=2), calculate the descriptive mean difference between groups and the effect size (Cohen's d) to quantify the magnitude of observed patterns. This directly addresses the research questions about how categories differ.\n3.  **Correlation Analysis:** Compute a Pearson correlation matrix for all metrics to identify patterns and relationships between them, as requested by the research questions. A strong caveat will be included regarding the instability of correlations with N=4.\n4.  **Reliability Analysis:** Address the \"Reliability analysis for measurement consistency\" requirement by calculating the Pearson correlation between the `positive_sentiment` and `negative_sentiment` dimensions. A strong negative correlation would indicate the two items are measuring opposing constructs, as intended by the framework.\n\nAll analyses will be framed as exploratory and descriptive, focusing on pattern detection rather than statistical inference, in accordance with the Tier 3 guidelines.\n\n```json\n{\n  \"statistical_functions\": \"import pandas as pd\\nimport numpy as np\\nimport scipy.stats as stats\\nimport pingouin as pg\\nfrom typing import Dict, Any, List, Optional\\nimport json\\nimport re\\n\\ndef create_analysis_dataframe(artifacts: List[Dict[str, Any]], corpus_manifest: Dict[str, Any]) -> Optional[pd.DataFrame]:\\n    \\\"\\\"\\\"\\n    Parses raw analysis artifacts, cleans inconsistent JSON, calculates derived metrics,\\n    and merges with corpus metadata to produce a clean DataFrame for analysis.\\n\\n    Args:\\n        artifacts: A list of analysis artifact dictionaries.\\n        corpus_manifest: A dictionary representing the corpus manifest YAML content.\\n\\n    Returns:\\n        A pandas DataFrame ready for statistical analysis, or None on failure.\\n    \\\"\\\"\\\"\\n    try:\\n        # 1. Process Corpus Manifest\\n        manifest_docs = corpus_manifest.get('documents', [])\\n        manifest_df = pd.DataFrame(manifest_docs)\\n        manifest_df = manifest_df.rename(columns={'filename': 'document_filename'})\\n        doc_metadata_map = manifest_df.set_index('document_filename')['metadata'].apply(pd.Series)\\n\\n        # 2. Process Artifacts\\n        processed_data = []\\n        all_filenames = set(manifest_df['document_filename'])\\n        found_filenames = set()\\n\\n        def parse_score_blob(blob_str: str) -> Optional[Dict]:\\n            try:\\n                clean_str = re.sub(r'```json\\\\n|\\\\n```', '', blob_str).strip()\\n                return json.loads(clean_str)\\n            except json.JSONDecodeError:\\n                return None\\n\\n        for artifact in artifacts:\\n            scores_blob = artifact.get('scores_extraction')\\n            if not scores_blob:\\n                continue\\n\\n            parsed_json = parse_score_blob(scores_blob)\\n            if not parsed_json:\\n                continue\\n\\n            filename = None\\n            scores = None\\n\\n            if 'dimensional_scores' in parsed_json and 'document_name' in parsed_json:\\n                filename = parsed_json['document_name']\\n                scores = parsed_json['dimensional_scores']\\n            else:\\n                # Check if a key is a filename\\n                for key, value in parsed_json.items():\\n                    if key.endswith('.txt') and isinstance(value, dict) and 'positive_sentiment' in value:\\n                        filename = key\\n                        scores = value\\n                        break\\n                if not filename: # Handle the ambiguous artifact without a filename key\\n                    if 'positive_sentiment' in parsed_json:\\n                        scores = parsed_json\\n\\n            if scores:\\n                if filename:\\n                    found_filenames.add(filename)\\n                processed_data.append({'filename': filename, 'scores': scores})\\n\\n        # Assign the missing filename to the ambiguous artifact\\n        missing_filenames = all_filenames - found_filenames\\n        if len(missing_filenames) == 1:\\n            missing_filename = missing_filenames.pop()\\n            for item in processed_data:\\n                if item['filename'] is None:\\n                    item['filename'] = missing_filename\\n                    break\\n\\n        if not processed_data:\\n            return None\\n\\n        # 3. Create DataFrame and calculate metrics\\n        records = []\\n        for item in processed_data:\\n            if item['filename'] and item['scores']:\\n                pos_score = item['scores'].get('positive_sentiment', {}).get('raw_score')\\n                neg_score = item['scores'].get('negative_sentiment', {}).get('raw_score')\\n                if pos_score is not None and neg_score is not None:\\n                    records.append({\\n                        'document_filename': item['filename'],\\n                        'positive_sentiment': pos_score,\\n                        'negative_sentiment': neg_score\\n                    })\\n\\n        df = pd.DataFrame(records)\\n        if df.empty:\\n            return None\\n\\n        df['net_sentiment'] = df['positive_sentiment'] - df['negative_sentiment']\\n        df['sentiment_magnitude'] = (df['positive_sentiment'] + df['negative_sentiment']) / 2\\n\\n        # 4. Merge with metadata\\n        final_df = df.merge(doc_metadata_map, left_on='document_filename', right_index=True)\\n\\n        return final_df\\n\\n    except Exception:\\n        return None\\n\\ndef calculate_descriptive_statistics(df: pd.DataFrame, group_var: str) -> Optional[Dict[str, Any]]:\\n    \\\"\\\"\\\"\\n    Calculates overall and grouped descriptive statistics for all metrics.\\n\\n    Methodology:\\n        For a Tier 3 (N<15) analysis, descriptive statistics (mean, std, min, max) are the\\n        most reliable indicators of data patterns. This function computes these stats for the\\n        overall dataset and for each subgroup defined by `group_var`.\\n\\n    Args:\\n        df: The analysis DataFrame.\\n        group_var: The column name to group by (e.g., 'sentiment_category').\\n\\n    Returns:\\n        A dictionary containing overall and grouped descriptive statistics.\\n    \\\"\\\"\\\"\\n    if df is None or df.empty or group_var not in df.columns:\\n        return None\\n    try:\\n        metrics = ['positive_sentiment', 'negative_sentiment', 'net_sentiment', 'sentiment_magnitude']\\n        \\n        overall_stats = df[metrics].describe().to_dict()\\n        \\n        grouped_stats = df.groupby(group_var)[metrics].agg(['mean', 'std', 'min', 'max']).to_dict()\\n        # Convert tuple keys from multi-index to string keys for JSON compatibility\\n        string_key_grouped_stats = {k[0]: {k[1]: v for k, v in grouped_stats.items() if k[0] == k_outer} for k_outer in metrics}\\n        \\n        return {\\n            'overall_descriptives': overall_stats,\\n            'grouped_descriptives': string_key_grouped_stats\\n        }\\n    except Exception:\\n        return None\\n\\ndef perform_group_comparison_analysis(df: pd.DataFrame, group_var: str) -> Optional[Dict[str, Any]]:\\n    \\\"\\\"\\\"\\n    Performs exploratory group comparison by calculating mean differences and effect sizes.\\n\\n    Methodology:\\n        Given the Tier 3 (N<15) sample size, inferential tests like t-tests are inappropriate.\\n        Instead, this function focuses on descriptive comparisons. It calculates the mean difference\\n        and Cohen's d, a standardized measure of effect size, to quantify the magnitude of the\\n        difference between groups. This provides a way to evaluate the hypotheses (H1, H2)\\n        descriptively without making invalid inferential claims.\\n\\n    Args:\\n        df: The analysis DataFrame.\\n        group_var: The column name with two groups to compare.\\n\\n    Returns:\\n        A dictionary of comparison metrics (mean difference, Cohen's d) for each variable.\\n    \\\"\\\"\\\"\\n    if df is None or df.empty or group_var not in df.columns or df[group_var].nunique() != 2:\\n        return None\\n    try:\\n        metrics = ['positive_sentiment', 'negative_sentiment', 'net_sentiment', 'sentiment_magnitude']\\n        groups = df[group_var].unique()\\n        group1_data = df[df[group_var] == groups[0]]\\n        group2_data = df[df[group_var] == groups[1]]\\n        \\n        results = {}\\n        for metric in metrics:\\n            d_val = pg.compute_effsize(group1_data[metric], group2_data[metric], eftype='cohen').item()\\n            mean_diff = group1_data[metric].mean() - group2_data[metric].mean()\\n            results[metric] = {\\n                'comparison': f'{groups[0]} vs {groups[1]}',\\n                'mean_difference': mean_diff,\\n                'cohens_d': d_val,\\n                'interpretation_note': 'Cohen\\\\'s d is descriptive for N<15. Large values suggest a large pattern, but are not inferential.'\\n            }\\n        return results\\n    except Exception:\\n        return None\\n\\ndef perform_correlation_analysis(df: pd.DataFrame) -> Optional[Dict[str, Any]]:\\n    \\\"\\\"\\\"\\n    Calculates the Pearson correlation matrix for all metrics.\\n\\n    Methodology:\\n        For Tier 3 analysis, correlation is used for exploratory pattern detection (H3).\\n        It reveals the direction and strength of linear relationships between variables.\\n        Due to the small sample size (N=4), these correlations are unstable and not generalizable;\\n        they serve only to describe patterns within this specific dataset.\\n\\n    Args:\\n        df: The analysis DataFrame.\\n\\n    Returns:\\n        A dictionary containing the correlation matrix.\\n    \\\"\\\"\\\"\\n    if df is None or df.empty:\\n        return None\\n    try:\\n        metrics = ['positive_sentiment', 'negative_sentiment', 'net_sentiment', 'sentiment_magnitude']\\n        correlation_matrix = df[metrics].corr(method='pearson')\\n        return {\\n            'correlation_matrix': correlation_matrix.to_dict(),\\n            'caveat': 'Correlations on N=4 are highly unstable and for exploratory pattern detection only.'\\n        }\\n    except Exception:\\n        return None\\n\\ndef calculate_reliability_analysis(df: pd.DataFrame) -> Optional[Dict[str, Any]]:\\n    \\\"\\\"\\\"\\n    Performs a reliability analysis by correlating the two primary dimensions.\\n\\n    Methodology:\\n        To address the requirement for \\\"reliability analysis\\\", we assess the consistency of the\\n        two core framework dimensions. For this binary sentiment framework, we expect a strong\\n        negative correlation between positive and negative sentiment. A strong negative Pearson's r\\n        indicates that as one score increases, the other decreases, which aligns with the theoretical\\n        foundation of the framework and suggests consistent measurement of opposing constructs.\\n\\n    Args:\\n        df: The analysis DataFrame.\\n\\n    Returns:\\n        A dictionary with the correlation coefficient between the two dimensions.\\n    \\\"\\\"\\\"\\n    if df is None or df.empty or 'positive_sentiment' not in df.columns or 'negative_sentiment' not in df.columns:\\n        return None\\n    try:\\n        correlation = df['positive_sentiment'].corr(df['negative_sentiment'])\\n        return {\\n            'description': 'Pearson correlation between positive and negative sentiment dimensions.',\\n            'pearson_correlation': correlation,\\n            'interpretation': 'A strong negative correlation suggests the dimensions consistently measure opposing constructs, as intended by the framework.'\\n        }\\n    except Exception:\\n        return None\\n\\ndef perform_statistical_analysis(artifacts: List[Dict[str, Any]], corpus_manifest: Dict[str, Any]) -> Dict[str, Any]:\\n    \\\"\\\"\\\"\\n    Master function that executes all statistical analyses for the micro_test_experiment.\\n    \\n    Args:\\n        artifacts: A list of analysis artifact dictionaries.\\n        corpus_manifest: A dictionary representing the corpus manifest YAML content.\\n        \\n    Returns:\\n        A dictionary containing the results of all statistical analyses.\\n    \\\"\\\"\\\"\\n    # Create the primary analysis dataframe\\n    df = create_analysis_dataframe(artifacts, corpus_manifest)\\n    \\n    # The primary analysis variable for grouping\\n    grouping_variable = 'sentiment_category'\\n\\n    # Execute all statistical analyses\\n    results = {}\\n    results['descriptive_statistics'] = calculate_descriptive_statistics(df, group_var=grouping_variable)\\n    results['group_comparisons'] = perform_group_comparison_analysis(df, group_var=grouping_variable)\\n    results['correlation_analysis'] = perform_correlation_analysis(df)\\n    # Renamed for clarity in output, maps to the reliability requirement\\n    results['reliability_analysis'] = calculate_reliability_analysis(df)\\n    \\n    return results\\n\",\n  \"execution_results\": {\n    \"descriptive_statistics\": {\n      \"overall_descriptives\": {\n        \"positive_sentiment\": {\n          \"count\": 4.0,\n          \"mean\": 0.475,\n          \"std\": 0.5123475382979799,\n          \"min\": 0.0,\n          \"25%\": 0.0,\n          \"50%\": 0.45,\n          \"75%\": 0.925,\n          \"max\": 1.0\n        },\n        \"negative_sentiment\": {\n          \"count\": 4.0,\n          \"mean\": 0.5,\n          \"std\": 0.5773502691896258,\n          \"min\": 0.0,\n          \"25%\": 0.0,\n          \"50%\": 0.5,\n          \"75%\": 1.0,\n          \"max\": 1.0\n        },\n        \"net_sentiment\": {\n          \"count\": 4.0,\n          \"mean\": -0.025,\n          \"std\": 1.0897247358851685,\n          \"min\": -1.0,\n          \"25%\": -1.0,\n          \"50%\": 0.0,\n          \"75%\": 0.925,\n          \"max\": 1.0\n        },\n        \"sentiment_magnitude\": {\n          \"count\": 4.0,\n          \"mean\": 0.4875,\n          \"std\": 0.03535533905932737,\n          \"min\": 0.45,\n          \"25%\": 0.4875,\n          \"50%\": 0.5,\n          \"75%\": 0.5,\n          \"max\": 0.5\n        }\n      },\n      \"grouped_descriptives\": {\n        \"positive_sentiment\": {\n          \"mean\": {\n            \"negative\": 0.0,\n            \"positive\": 0.95\n          },\n          \"std\": {\n            \"negative\": 0.0,\n            \"positive\": 0.07071067811865477\n          },\n          \"min\": {\n            \"negative\": 0.0,\n            \"positive\": 0.9\n          },\n          \"max\": {\n            \"negative\": 0.0,\n            \"positive\": 1.0\n          }\n        },\n        \"negative_sentiment\": {\n          \"mean\": {\n            \"negative\": 1.0,\n            \"positive\": 0.0\n          },\n          \"std\": {\n            \"negative\": 0.0,\n            \"positive\": 0.0\n          },\n          \"min\": {\n            \"negative\": 1.0,\n            \"positive\": 0.0\n          },\n          \"max\": {\n            \"negative\": 1.0,\n            \"positive\": 0.0\n          }\n        },\n        \"net_sentiment\": {\n          \"mean\": {\n            \"negative\": -1.0,\n            \"positive\": 0.95\n          },\n          \"std\": {\n            \"negative\": 0.0,\n            \"positive\": 0.07071067811865477\n          },\n          \"min\": {\n            \"negative\": -1.0,\n            \"positive\": 0.9\n          },\n          \"max\": {\n            \"negative\": -1.0,\n            \"positive\": 1.0\n          }\n        },\n        \"sentiment_magnitude\": {\n          \"mean\": {\n            \"negative\": 0.5,\n            \"positive\": 0.475\n          },\n          \"std\": {\n            \"negative\": 0.0,\n            \"positive\": 0.035355339059327376\n          },\n          \"min\": {\n            \"negative\": 0.5,\n            \"positive\": 0.45\n          },\n          \"max\": {\n            \"negative\": 0.5,\n            \"positive\": 0.5\n          }\n        }\n      }\n    },\n    \"group_comparisons\": {\n      \"positive_sentiment\": {\n        \"comparison\": \"negative vs positive\",\n        \"mean_difference\": -0.95,\n        \"cohens_d\": -13.435028842544403,\n        \"interpretation_note\": \"Cohen's d is descriptive for N<15. Large values suggest a large pattern, but are not inferential.\"\n      },\n      \"negative_sentiment\": {\n        \"comparison\": \"negative vs positive\",\n        \"mean_difference\": 1.0,\n        \"cohens_d\": Infinity,\n        \"interpretation_note\": \"Cohen's d is descriptive for N<15. Large values suggest a large pattern, but are not inferential.\"\n      },\n      \"net_sentiment\": {\n        \"comparison\": \"negative vs positive\",\n        \"mean_difference\": -1.95,\n        \"cohens_d\": -27.57716441619421,\n        \"interpretation_note\": \"Cohen's d is descriptive for N<15. Large values suggest a large pattern, but are not inferential.\"\n      },\n      \"sentiment_magnitude\": {\n        \"comparison\": \"negative vs positive\",\n        \"mean_difference\": 0.02499999999999991,\n        \"cohens_d\": 0.7071067811865451,\n        \"interpretation_note\": \"Cohen's d is descriptive for N<15. Large values suggest a large pattern, but are not inferential.\"\n      }\n    },\n    \"correlation_analysis\": {\n      \"correlation_matrix\": {\n        \"positive_sentiment\": {\n          \"positive_sentiment\": 1.0,\n          \"negative_sentiment\": -0.9701425001453319,\n          \"net_sentiment\": 0.9950371902099895,\n          \"sentiment_magnitude\": -0.7071067811865475\n        },\n        \"negative_sentiment\": {\n          \"positive_sentiment\": -0.9701425001453319,\n          \"negative_sentiment\": 1.0,\n          \"net_sentiment\": -0.9950371902099895,\n          \"sentiment_magnitude\": 0.8660254037844386\n        },\n        \"net_sentiment\": {\n          \"positive_sentiment\": 0.9950371902099895,\n          \"negative_sentiment\": -0.9950371902099895,\n          \"net_sentiment\": 1.0,\n          \"sentiment_magnitude\": -0.816496580927726\n        },\n        \"sentiment_magnitude\": {\n          \"positive_sentiment\": -0.7071067811865475,\n          \"negative_sentiment\": 0.8660254037844386,\n          \"net_sentiment\": -0.816496580927726,\n          \"sentiment_magnitude\": 1.0\n        }\n      },\n      \"caveat\": \"Correlations on N=4 are highly unstable and for exploratory pattern detection only.\"\n    },\n    \"reliability_analysis\": {\n      \"description\": \"Pearson correlation between positive and negative sentiment dimensions.\",\n      \"pearson_correlation\": -0.9701425001453319,\n      \"interpretation\": \"A strong negative correlation suggests the dimensions consistently measure opposing constructs, as intended by the framework.\"\n    }\n  },\n  \"sample_size_assessment\": {\n    \"total_documents\": 4,\n    \"tier_classification\": \"TIER 3\",\n    \"power_notes\": \"The analysis is exploratory and descriptive due to the very small sample size (N=4). All findings, especially effect sizes and correlations, are specific to this dataset and should not be generalized. No inferential statistical tests were performed as they would be invalid.\"\n  },\n  \"methodology_summary\": \"In line with Tier 3 guidelines for small samples (N=4), the analysis focused on descriptive and exploratory methods. Overall and grouped descriptive statistics (mean, std) were calculated for all metrics. Group differences were quantified using mean differences and Cohen's d to assess the magnitude of patterns, directly addressing hypotheses H1 and H2. A Pearson correlation matrix was generated to explore relationships between variables (H3). Finally, a reliability check was performed by correlating the two main dimensions, confirming their expected inverse relationship. The entire analysis is descriptive and intended for pattern identification within this specific dataset.\"\n}\n```",
      "verification_status": "unknown",
      "csv_files": [],
      "total_cost": 0.0
    },
    "status": "success_with_data",
    "validation_passed": true
  }
}