{
  "generation_metadata": {
    "status": "success",
    "functions_generated": 6,
    "output_file": "automatedderivedmetricsagent_functions.py",
    "module_size": 12761,
    "function_code_content": "\"\"\"\nAutomated Derived Metrics Functions\n===================================\n\nGenerated by AutomatedDerivedMetricsAgent for experiment: Test Experiment\nDescription: Test experiment for derived metrics\nGenerated: 2025-09-10T23:15:37.462046+00:00\n\nThis module contains automatically generated calculation functions for derived metrics\nas specified in the framework's natural language descriptions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom typing import Optional, Dict, Any\n\n\ndef calculate_identity_tension(data, **kwargs):\n    \"\"\"\n    Calculate identity_tension: Conflict between tribal dominance and individual dignity dimensions.\n\n    This metric quantifies the tension between collective identity (tribalism) and\n    individual rights/value (dignity). A higher score indicates a greater conflict\n    or disparity between these two dimensions. The calculation assumes that both\n    input dimensions are scaled from 0.0 to 1.0.\n\n    Formula: |tribal_dominance - individual_dignity|\n    \n    Args:\n        data (pd.Series): A single row of data from a pandas DataFrame\n                          containing the necessary dimension scores.\n        **kwargs: Additional parameters (unused).\n        \n    Returns:\n        float: The calculated identity tension score, or None if the\n               necessary data is missing or invalid.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # Based on the calculation description, we require these two dimensions.\n        # The function will fail gracefully if they are not in the input data.\n        tribal_col = 'tribal_dominance'\n        dignity_col = 'individual_dignity'\n\n        # Ensure the input is a pandas Series\n        if not isinstance(data, pd.Series):\n            return None\n\n        # Check for the existence of required columns in the Series index\n        if tribal_col not in data.index or dignity_col not in data.index:\n            return None\n\n        tribal_dominance = data[tribal_col]\n        individual_dignity = data[dignity_col]\n        \n        # Check for missing or non-numeric data\n        if pd.isna(tribal_dominance) or pd.isna(individual_dignity):\n            return None\n            \n        # Perform the calculation\n        tension = abs(float(tribal_dominance) - float(individual_dignity))\n        \n        return float(tension)\n\n    except (TypeError, ValueError, KeyError):\n        # Catch errors from invalid data types, failed conversions, or missing keys\n        return None\n    except Exception:\n        # Catch any other unexpected errors\n        return None\n\ndef calculate_emotional_balance(data, **kwargs):\n    \"\"\"\n    Calculate emotional_balance: Difference between hope and fear scores\n\n    Formula: hope - fear\n    \n    Args:\n        data: pandas DataFrame with dimension scores (treated as a single row/Series).\n        **kwargs: Additional parameters (unused).\n        \n    Returns:\n        float: Calculated result or None if insufficient data.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # This calculation requires 'hope' and 'fear' scores.\n        # Based on the provided data structure, these columns are not expected\n        # to be present. The function attempts the calculation and is\n        # designed to gracefully return None if the required columns are\n        # missing (KeyError) or if data is invalid.\n        hope_score = data['hope']\n        fear_score = data['fear']\n\n        # Ensure both values are present and numeric before calculation\n        if pd.isna(hope_score) or pd.isna(fear_score):\n            return None\n\n        # Perform the calculation\n        result = float(hope_score) - float(fear_score)\n\n        # Ensure the result is a valid finite number (not inf or -inf)\n        if not np.isfinite(result):\n            return None\n            \n        return result\n\n    except Exception:\n        # Catches missing columns (KeyError), non-numeric types (TypeError),\n        # or any other unexpected issue during execution.\n        return None\n\ndef calculate_success_climate(data, **kwargs):\n    \"\"\"\n    Calculate success_climate: Difference between compersion and envy scores.\n\n    Formula: compersion - envy\n\n    Args:\n        data (pd.Series): A row of data containing the necessary dimension scores.\n        **kwargs: Additional keyword arguments (not used).\n\n    Returns:\n        float: The calculated difference between 'compersion' and 'envy' scores,\n               or None if the necessary data is missing or invalid.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # The calculation requires 'compersion' and 'envy' scores.\n        # These column names are derived from the calculation's description.\n        compersion_score = data['compersion']\n        envy_score = data['envy']\n\n        # Handle cases where scores are present but are not valid numbers (e.g., NaN)\n        if pd.isna(compersion_score) or pd.isna(envy_score):\n            return None\n\n        # Perform the calculation, ensuring types are numeric\n        result = float(compersion_score) - float(envy_score)\n\n        # A final check to ensure the result is a finite number (not inf/-inf)\n        if not np.isfinite(result):\n            return None\n\n        return result\n\n    except (KeyError, TypeError, ValueError):\n        # Handles missing 'compersion' or 'envy' columns, or non-numeric data.\n        # This function will return None if the input DataFrame does not\n        # contain the required columns for the calculation.\n        return None\n\ndef calculate_relational_climate(data, **kwargs):\n    \"\"\"\n    Calculate relational_climate: Difference between amity and enmity scores\n\n    Formula: amity - enmity\n\n    Args:\n        data (pd.Series): A row of data containing 'amity' and 'enmity' scores.\n        **kwargs: Additional keyword arguments (unused).\n\n    Returns:\n        float: The calculated score, or None if data is missing or invalid.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # The calculation is defined as the difference between amity and enmity\n        amity_score = data['amity']\n        enmity_score = data['enmity']\n\n        # Handle cases where scores are missing (NaN, None)\n        if pd.isna(amity_score) or pd.isna(enmity_score):\n            return None\n\n        # Ensure scores are numeric and perform calculation\n        result = float(amity_score) - float(enmity_score)\n\n        # Return None if the result is not a finite number (e.g., infinity)\n        if not np.isfinite(result):\n            return None\n\n        return result\n\n    except (KeyError, TypeError, ValueError):\n        # KeyError: If 'amity' or 'enmity' columns are not present.\n        # TypeError: If scores are not numeric or cannot be cast to float.\n        # ValueError: If casting to float fails for a non-numeric string.\n        return None\n\ndef calculate_goal_orientation(data, **kwargs):\n    \"\"\"\n    Calculate goal_orientation: Difference between cohesive goals and fragmentative goals.\n\n    Formula: cohesive_goals - fragmentative_goals\n\n    Args:\n        data (pd.Series): A single row of data containing the dimension scores.\n        **kwargs: Additional keyword arguments (not used).\n\n    Returns:\n        float: The calculated goal orientation score, or None if the necessary\n               data ('cohesive_goals', 'fragmentative_goals') is missing or invalid.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n\n    try:\n        # The calculation is based on the semantic names from the description.\n        # This function assumes the input `data` Series/DataFrame has been\n        # pre-processed to include 'cohesive_goals' and 'fragmentative_goals' columns.\n        cohesive_goals = pd.to_numeric(data['cohesive_goals'], errors='coerce')\n        fragmentative_goals = pd.to_numeric(data['fragmentative_goals'], errors='coerce')\n\n        # Check for missing values after coercion\n        if pd.isna(cohesive_goals) or pd.isna(fragmentative_goals):\n            return None\n\n        # Perform the calculation\n        result = cohesive_goals - fragmentative_goals\n        \n        # Ensure the result is a standard float and not a numpy type\n        return float(result)\n\n    except (KeyError, TypeError, AttributeError, ValueError):\n        # KeyError: If 'cohesive_goals' or 'fragmentative_goals' columns are missing.\n        # TypeError/AttributeError/ValueError: If data is not in a convertible or accessible format.\n        return None\n    except Exception:\n        # Catch any other unexpected errors during calculation.\n        return None\n\ndef calculate_overall_cohesion_index(data, **kwargs):\n    \"\"\"\n    Calculate overall_cohesion_index: Comprehensive measure combining all dimensions.\n\n    This index measures the balance or cohesion between the positive and negative\n    sentiment dimensions. A value of 1.0 indicates perfect balance (e.g., positive\n    and negative scores are equal), while a value of 0.0 indicates maximum\n    imbalance (one score is high and the other is low).\n\n    Formula: 1.0 - abs(positive_sentiment - negative_sentiment)\n    \n    Args:\n        data (pd.Series): A single row of data as a pandas Series, expected to\n                          contain 'positive_sentiment' and 'negative_sentiment' columns.\n        **kwargs: Additional parameters (unused).\n        \n    Returns:\n        float: The calculated overall cohesion index, ranging from 0.0 to 1.0.\n               Returns None if the necessary data is missing, not numeric, or\n               outside the expected [0.0, 1.0] range.\n    \"\"\"\n    import pandas as pd\n    \n    try:\n        # The 'Dimensions' for this framework are 'Positive Sentiment' and 'Negative Sentiment'.\n        # We use the corresponding snake_case column names 'positive_sentiment' and\n        # 'negative_sentiment' for the calculation.\n        positive_score = data.get('positive_sentiment')\n        negative_score = data.get('negative_sentiment')\n\n        # Check for missing data (column absent, None, or NaN)\n        if pd.isna(positive_score) or pd.isna(negative_score):\n            return None\n        \n        # Convert to float and handle potential type errors\n        positive_score = float(positive_score)\n        negative_score = float(negative_score)\n\n        # Scores are expected to be in the 0.0 to 1.0 range as per the framework\n        if not (0.0 <= positive_score <= 1.0 and 0.0 <= negative_score <= 1.0):\n            return None\n            \n        # Calculate the cohesion index\n        cohesion_index = 1.0 - abs(positive_score - negative_score)\n        \n        return cohesion_index\n\n    except (ValueError, TypeError):\n        # Handles cases where scores are not convertible to float.\n        return None\n    except Exception:\n        # A general catch-all for any other unexpected errors.\n        return None\n\ndef calculate_all_derived_metrics(data: pd.DataFrame) -> Dict[str, Optional[float]]:\n    \"\"\"\n    Calculate all derived metrics for the given dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        Dictionary mapping metric names to calculated values\n    \"\"\"\n    results = {}\n    \n    # Get all calculation functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith('calculate_') and \n            name not in ['calculate_all_derived_metrics', 'calculate_derived_metrics']):\n            try:\n                results[name.replace('calculate_', '')] = obj(data)\n            except Exception as e:\n                results[name.replace('calculate_', '')] = None\n                \n    return results\n\n\ndef calculate_derived_metrics(data: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Template-compatible wrapper function for derived metrics calculation.\n    \n    This function is called by the universal notebook template and returns\n    the original data with additional derived metric columns.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        DataFrame with original data plus derived metric columns\n    \"\"\"\n    # Calculate all derived metrics\n    derived_metrics = calculate_all_derived_metrics(data)\n    \n    # Create a copy of the original data\n    result = data.copy()\n    \n    # Add derived metrics as new columns\n    for metric_name, metric_value in derived_metrics.items():\n        if metric_value is not None:\n            # For scalar metrics, broadcast to all rows\n            result[metric_name] = metric_value\n        else:\n            # For failed calculations, use NaN\n            result[metric_name] = np.nan\n    \n    return result\n",
    "cached_with_code": true
  },
  "derived_metrics_data": {
    "status": "success",
    "original_count": 4,
    "derived_count": 4,
    "derived_metrics": [
      {
        "analysis_id": "analysis_10abeb033cb9",
        "result_hash": "ec0269cd824fc3fe88c006ad359dd60d41010b54874bf88d32bb1f3e727cab9e",
        "result_content": {
          "analysis_id": "analysis_10abeb033cb9",
          "agent_name": "EnhancedAnalysisAgent",
          "agent_version": "enhanced_v2.1_raw_output",
          "experiment_name": "micro_test_experiment",
          "model_used": "vertex_ai/gemini-2.5-flash",
          "raw_analysis_response": "<<<DISCERNUS_ANALYSIS_JSON_v6>>>\n{\n  \"analysis_metadata\": {\n    \"framework_name\": \"sentiment_binary_v1\",\n    \"framework_version\": \"1.0.0\",\n    \"analyst_confidence\": 0.99,\n    \"analysis_notes\": \"Analysis conducted using three independent approaches (Evidence-First, Context-Weighted, Pattern-Based) with median aggregation. Document shows strong, unambiguous positive sentiment.\",\n    \"internal_consistency_approach\": \"3-run median aggregation\"\n  },\n  \"document_analyses\": [\n    {\n      \"document_id\": \"{{artifact_id}}\",\n      \"document_name\": \"positive_test_1.txt\",\n      \"dimensional_scores\": {\n        \"positive_sentiment\": {\n          \"raw_score\": 1.0,\n          \"salience\": 1.0,\n          \"confidence\": 1.0\n        },\n        \"negative_sentiment\": {\n          \"raw_score\": 0.0,\n          \"salience\": 0.0,\n          \"confidence\": 1.0\n        }\n      },\n      \"evidence\": [\n        {\n          \"dimension\": \"positive_sentiment\",\n          \"quote_text\": \"This is a wonderful day! Everything is going perfectly. I feel great about the future. Success is everywhere. The team did an excellent job. We're achieving amazing results. Optimism fills the air. What a fantastic opportunity! I'm thrilled with the progress. Everything looks bright and promising.\",\n          \"confidence\": 1.0,\n          \"context_type\": \"direct_statement\"\n        },\n        {\n          \"dimension\": \"negative_sentiment\",\n          \"quote_text\": \"\",\n          \"confidence\": 1.0,\n          \"context_type\": \"not_applicable\"\n        }\n      ]\n    }\n  ]\n}\n<<<END_DISCERNUS_ANALYSIS_JSON_v6>>>",
          "evidence_hash": "120c1e67e69d3d9748974ba259e90748a6a9ecfcc88d42ee4cc1a1a1921520ad",
          "execution_metadata": {
            "start_time": "2025-09-10T23:10:15.811122+00:00",
            "end_time": "2025-09-10T23:10:35.359404+00:00",
            "duration_seconds": 19.54826
          },
          "input_artifacts": {
            "framework_hash": "178020617d567968935db724ea6eeb1f4debda637043ba96a1cd8859fcf9dc22",
            "document_hashes": [
              "26c27e1e47385f483ab2ef36e82b95f807d9fa48154395bcf45f9489ef3ed1ba"
            ],
            "num_documents": 1
          },
          "provenance": {
            "security_boundary": {
              "experiment_name": "micro_test_experiment",
              "experiment_root": "/Volumes/code/discernus/projects/micro_test_experiment",
              "boundary_type": "filesystem",
              "security_level": "experiment_scoped"
            },
            "audit_session_id": "20250910T231015Z_b55af74d"
          }
        },
        "cached": true
      },
      {
        "analysis_id": "analysis_c59f132cd433",
        "result_hash": "8aa22dde922ddb5f9156ba2bab75178a55d68ddbf0c9aabc92fe65870eab3b1c",
        "result_content": {
          "analysis_id": "analysis_c59f132cd433",
          "agent_name": "EnhancedAnalysisAgent",
          "agent_version": "enhanced_v2.1_raw_output",
          "experiment_name": "micro_test_experiment",
          "model_used": "vertex_ai/gemini-2.5-flash",
          "raw_analysis_response": "<<<DISCERNUS_ANALYSIS_JSON_v6>>>\n{\n  \"analysis_metadata\": {\n    \"framework_name\": \"sentiment_binary_v1\",\n    \"framework_version\": \"1.0.0\",\n    \"analyst_confidence\": 1.0,\n    \"analysis_notes\": \"Applied three independent analytical approaches with median aggregation\",\n    \"internal_consistency_approach\": \"3-run median aggregation\"\n  },\n  \"document_analyses\": [\n    {\n      \"document_id\": \"{{artifact_id}}\",\n      \"document_name\": \"positive_test_2.txt\",\n      \"dimensional_scores\": {\n        \"positive_sentiment\": {\n          \"raw_score\": 0.9,\n          \"salience\": 1.0,\n          \"confidence\": 1.0\n        },\n        \"negative_sentiment\": {\n          \"raw_score\": 0.0,\n          \"salience\": 0.0,\n          \"confidence\": 1.0\n        }\n      },\n      \"evidence\": [\n        {\n          \"dimension\": \"positive_sentiment\",\n          \"quote_text\": \"What a superb morning! All systems are operating flawlessly. I'm excited about what's coming next. Achievement surrounds us. The group performed outstandingly. We're reaching incredible goals. Hopefulness permeates everything. Such a marvelous chance! I'm delighted by the advancement. Everything appears glowing and encouraging.\",\n          \"confidence\": 1.0,\n          \"context_type\": \"direct_statement\"\n        },\n        {\n          \"dimension\": \"negative_sentiment\",\n          \"quote_text\": \"\",\n          \"confidence\": 1.0,\n          \"context_type\": \"absence_of_evidence\"\n        }\n      ]\n    }\n  ]\n}\n<<<END_DISCERNUS_ANALYSIS_JSON_v6>>>",
          "evidence_hash": "27b61a108872158939f5ac6d2949d37a1e96611ba176affade72e879c671a753",
          "execution_metadata": {
            "start_time": "2025-09-10T23:10:35.360682+00:00",
            "end_time": "2025-09-10T23:10:58.471798+00:00",
            "duration_seconds": 23.111107
          },
          "input_artifacts": {
            "framework_hash": "178020617d567968935db724ea6eeb1f4debda637043ba96a1cd8859fcf9dc22",
            "document_hashes": [
              "3671de4a6c31fc2bb356ceed5589d1b4bb2288df674bf0d827dc973872b462a3"
            ],
            "num_documents": 1
          },
          "provenance": {
            "security_boundary": {
              "experiment_name": "micro_test_experiment",
              "experiment_root": "/Volumes/code/discernus/projects/micro_test_experiment",
              "boundary_type": "filesystem",
              "security_level": "experiment_scoped"
            },
            "audit_session_id": "20250910T231015Z_b55af74d"
          }
        },
        "cached": true
      },
      {
        "analysis_id": "analysis_ceae493876a6",
        "result_hash": "00416f0d9dc7ab13d1e92492833f33301b616b00ee8803d6a65442e5c53e7678",
        "result_content": {
          "analysis_id": "analysis_ceae493876a6",
          "agent_name": "EnhancedAnalysisAgent",
          "agent_version": "enhanced_v2.1_raw_output",
          "experiment_name": "micro_test_experiment",
          "model_used": "vertex_ai/gemini-2.5-flash",
          "raw_analysis_response": "<<<DISCERNUS_ANALYSIS_JSON_v6>>>\n{\n  \"analysis_metadata\": {\n    \"framework_name\": \"sentiment_binary_v1\",\n    \"framework_version\": \"1.0.0\",\n    \"analyst_confidence\": 1.0,\n    \"analysis_notes\": \"Applied three independent analytical approaches with median aggregation. Document is overtly negative, leading to high confidence in sentiment scores.\",\n    \"internal_consistency_approach\": \"3-run median aggregation\"\n  },\n  \"document_analyses\": [\n    {\n      \"document_id\": \"{{artifact_id}}\",\n      \"document_name\": \"negative_test_1.txt\",\n      \"dimensional_scores\": {\n        \"positive_sentiment\": {\n          \"raw_score\": 0.0,\n          \"salience\": 0.0,\n          \"confidence\": 1.0\n        },\n        \"negative_sentiment\": {\n          \"raw_score\": 1.0,\n          \"salience\": 0.9,\n          \"confidence\": 1.0\n        }\n      },\n      \"evidence\": [\n        {\n          \"dimension\": \"positive_sentiment\",\n          \"quote_text\": \"\",\n          \"confidence\": 1.0,\n          \"context_type\": \"absence\"\n        },\n        {\n          \"dimension\": \"negative_sentiment\",\n          \"quote_text\": \"Everything looks dark and hopeless.\",\n          \"confidence\": 1.0,\n          \"context_type\": \"direct_statement\"\n        }\n      ]\n    }\n  ]\n}\n<<<END_DISCERNUS_ANALYSIS_JSON_v6>>>",
          "evidence_hash": "5095c35631e46436076bbc7bb4368d7cb0e5233fb76762a2dd210b335ed116ae",
          "execution_metadata": {
            "start_time": "2025-09-10T23:10:58.472208+00:00",
            "end_time": "2025-09-10T23:11:40.633088+00:00",
            "duration_seconds": 42.160874
          },
          "input_artifacts": {
            "framework_hash": "178020617d567968935db724ea6eeb1f4debda637043ba96a1cd8859fcf9dc22",
            "document_hashes": [
              "123e5c9fe4425f26d19c815d8f4b304e6c211e38014847dc087f108396aa6134"
            ],
            "num_documents": 1
          },
          "provenance": {
            "security_boundary": {
              "experiment_name": "micro_test_experiment",
              "experiment_root": "/Volumes/code/discernus/projects/micro_test_experiment",
              "boundary_type": "filesystem",
              "security_level": "experiment_scoped"
            },
            "audit_session_id": "20250910T231015Z_b55af74d"
          }
        },
        "cached": true
      },
      {
        "analysis_id": "analysis_39d66267a094",
        "result_hash": "df44a73932e274b878e77790b54341bb2366ed6718c993ff864571e0c424c7bd",
        "result_content": {
          "analysis_id": "analysis_39d66267a094",
          "agent_name": "EnhancedAnalysisAgent",
          "agent_version": "enhanced_v2.1_raw_output",
          "experiment_name": "micro_test_experiment",
          "model_used": "vertex_ai/gemini-2.5-flash",
          "raw_analysis_response": "<<<DISCERNUS_ANALYSIS_JSON_v6>>>\n{\n  \"analysis_metadata\": {\n    \"framework_name\": \"sentiment_binary_v1\",\n    \"framework_version\": \"1.0.0\",\n    \"analyst_confidence\": 0.99,\n    \"analysis_notes\": \"Applied three independent analytical approaches with median aggregation. The document explicitly states its negative sentiment purpose.\",\n    \"internal_consistency_approach\": \"3-run median aggregation\"\n  },\n  \"document_analyses\": [\n    {\n      \"document_id\": \"[DOCUMENT_ID_PLACEHOLDER]\",\n      \"document_name\": \"negative_test_2.txt\",\n      \"dimensional_scores\": {\n        \"positive_sentiment\": {\n          \"raw_score\": 0.0,\n          \"salience\": 0.0,\n          \"confidence\": 1.0\n        },\n        \"negative_sentiment\": {\n          \"raw_score\": 1.0,\n          \"salience\": 1.0,\n          \"confidence\": 1.0\n        }\n      },\n      \"evidence\": [\n        {\n          \"dimension\": \"positive_sentiment\",\n          \"quote_text\": \"\",\n          \"confidence\": 1.0,\n          \"context_type\": \"absence_of_evidence\"\n        },\n        {\n          \"dimension\": \"negative_sentiment\",\n          \"quote_text\": \"What an awful predicament. All plans are failing miserably. I'm dreading what's to come. Defeat engulfs us. The group performed dreadfully. We're encountering catastrophe. Despair saturates everything. Such a calamitous result! I'm crushed by the setbacks. Everything appears bleak and discouraging.\",\n          \"confidence\": 1.0,\n          \"context_type\": \"direct_statement\"\n        }\n      ]\n    }\n  ]\n}\n<<<END_DISCERNUS_ANALYSIS_JSON_v6>>>",
          "evidence_hash": "c05472f18144f2f94c95a26ef0b70408f127d1552b1c5667cbbc8a571b43d6bb",
          "execution_metadata": {
            "start_time": "2025-09-10T23:11:40.633549+00:00",
            "end_time": "2025-09-10T23:11:57.115877+00:00",
            "duration_seconds": 16.482316
          },
          "input_artifacts": {
            "framework_hash": "178020617d567968935db724ea6eeb1f4debda637043ba96a1cd8859fcf9dc22",
            "document_hashes": [
              "68b092892a2216aa8ebd70a470a361c86d2bf3ceb23469275acd0fb85d9367a9"
            ],
            "num_documents": 1
          },
          "provenance": {
            "security_boundary": {
              "experiment_name": "micro_test_experiment",
              "experiment_root": "/Volumes/code/discernus/projects/micro_test_experiment",
              "boundary_type": "filesystem",
              "security_level": "experiment_scoped"
            },
            "audit_session_id": "20250910T231015Z_b55af74d"
          }
        },
        "cached": true
      }
    ],
    "columns_added": []
  },
  "status": "success_with_data",
  "validation_passed": true
}