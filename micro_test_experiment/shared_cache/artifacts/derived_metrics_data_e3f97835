{
  "status": "completed",
  "derived_metrics_hash": "151f3a3106f0708016bcb2f469bea968bac64f7b0b458e00551516084344e2d9",
  "functions_generated": 5,
  "derived_metrics_results": {
    "generation_metadata": {
      "status": "success",
      "functions_generated": 5,
      "output_file": "automatedderivedmetricsagent_functions.py",
      "module_size": 5899,
      "function_code_content": "import pandas as pd\nimport numpy as np\nimport json\nfrom typing import Optional, Dict, Any, List\n\ndef _extract_scores(row: pd.Series) -> Optional[Dict[str, Any]]:\n    \"\"\"Extracts dimensional scores from a DataFrame row.\n\n    This helper function navigates the nested data structure, parses the\n    JSON string from 'raw_analysis_response', and returns the\n    'dimensional_scores' dictionary.\n\n    It handles multiple possible JSON container formats, including proprietary\n    delimiters and markdown code fences.\n\n    Args:\n        row: A pandas Series representing a single row of the DataFrame.\n\n    Returns:\n        A dictionary containing the dimensional scores, or None if any part\n        of the extraction process fails.\n    \"\"\"\n    try:\n        raw_response = row['analysis_result']['result_content']['raw_analysis_response']\n\n        start_marker = '<<<DISCERNUS_ANALYSIS_JSON_v6>>>'\n        end_marker = '<<<END_DISCERNUS_ANALYSIS_JSON_v6>>>'\n        json_content = None\n\n        if start_marker in raw_response and end_marker in raw_response:\n            start_idx = raw_response.find(start_marker) + len(start_marker)\n            end_idx = raw_response.find(end_marker)\n            json_content = raw_response[start_idx:end_idx].strip()\n        elif raw_response.strip().startswith(\"```json\"):\n            json_content = raw_response.strip()[7:-3].strip()\n        elif raw_response.strip().startswith(\"{\"):\n             json_content = raw_response.strip()\n\n        if not json_content:\n            return None\n\n        analysis_data = json.loads(json_content)\n\n        if 'document_analyses' in analysis_data and isinstance(analysis_data['document_analyses'], list) and analysis_data['document_analyses']:\n            document_analysis = analysis_data['document_analyses'][0]\n            return document_analysis.get('dimensional_scores')\n        return None\n    except (KeyError, IndexError, TypeError, json.JSONDecodeError):\n        return None\n\ndef calculate_net_sentiment(row: pd.Series, **kwargs) -> Optional[float]:\n    \"\"\"\n    Calculates the net sentiment balance (positive - negative).\n\n    Formula:\n    net_sentiment = dimensions.positive_sentiment.raw_score - dimensions.negative_sentiment.raw_score\n\n    Args:\n        row: A pandas Series representing a single row of the DataFrame.\n        **kwargs: Additional parameters (unused).\n\n    Returns:\n        The calculated net sentiment as a float, or None if scores are unavailable.\n    \"\"\"\n    scores = _extract_scores(row)\n    if scores and 'positive_sentiment' in scores and 'negative_sentiment' in scores:\n        try:\n            positive_score = scores['positive_sentiment']['raw_score']\n            negative_score = scores['negative_sentiment']['raw_score']\n            if isinstance(positive_score, (int, float)) and isinstance(negative_score, (int, float)):\n                return float(positive_score - negative_score)\n        except (KeyError, TypeError):\n            return None\n    return None\n\ndef calculate_sentiment_magnitude(row: pd.Series, **kwargs) -> Optional[float]:\n    \"\"\"\n    Calculates the average emotional intensity (positive + negative) / 2.\n\n    Formula:\n    sentiment_magnitude = (dimensions.positive_sentiment.raw_score + dimensions.negative_sentiment.raw_score) / 2\n\n    Args:\n        row: A pandas Series representing a single row of the DataFrame.\n        **kwargs: Additional parameters (unused).\n\n    Returns:\n        The calculated sentiment magnitude as a float, or None if scores are unavailable.\n    \"\"\"\n    scores = _extract_scores(row)\n    if scores and 'positive_sentiment' in scores and 'negative_sentiment' in scores:\n        try:\n            positive_score = scores['positive_sentiment']['raw_score']\n            negative_score = scores['negative_sentiment']['raw_score']\n            if isinstance(positive_score, (int, float)) and isinstance(negative_score, (int, float)):\n                return float((positive_score + negative_score) / 2.0)\n        except (KeyError, TypeError):\n            return None\n    return None\n\ndef calculate_all_derived_metrics(row: pd.Series, **kwargs) -> Dict[str, Optional[float]]:\n    \"\"\"\n    Calculates all derived metrics for a single data row.\n\n    This function calls each individual derived metric calculation function\n    and returns the results in a dictionary. It does not use reflection\n    and calls each function directly by name.\n\n    Args:\n        row: A pandas Series representing a single row of the DataFrame.\n        **kwargs: Additional parameters to pass to calculation functions.\n\n    Returns:\n        A dictionary where keys are the metric names and values are the\n        calculated scores.\n    \"\"\"\n    results = {\n        \"net_sentiment\": calculate_net_sentiment(row, **kwargs),\n        \"sentiment_magnitude\": calculate_sentiment_magnitude(row, **kwargs),\n    }\n    return results\n\ndef calculate_derived_metrics(data: pd.DataFrame, **kwargs) -> pd.DataFrame:\n    \"\"\"\n    Applies all derived metric calculations to the DataFrame.\n\n    This wrapper function iterates through each row of the input DataFrame,\n    applies all defined derived metric calculations, and appends the results\n    as new columns. It creates a copy of the input data to avoid side effects.\n\n    Args:\n        data: The input pandas DataFrame with analysis data.\n        **kwargs: Additional parameters to pass to calculation functions.\n\n    Returns:\n        A new pandas DataFrame with the original data plus new columns for\n        each calculated derived metric. Missing values are represented as NaN.\n    \"\"\"\n    if not isinstance(data, pd.DataFrame):\n        raise TypeError(\"Input 'data' must be a pandas DataFrame.\")\n\n    df = data.copy()\n\n    derived_metrics_series = df.apply(\n        lambda row: pd.Series(calculate_all_derived_metrics(row, **kwargs)),\n        axis=1\n    )\n\n    result_df = df.join(derived_metrics_series)\n\n    return result_df\n",
      "cached_with_code": true,
      "cache_metadata": {
        "cache_key": "derived_metrics_a12843a9dda5",
        "cached_at": "2025-01-15T14:30:00Z",
        "agent_name": "DerivedMetricsPhase"
      }
    },
    "derived_metrics_data": {
      "status": "success",
      "original_count": 4,
      "derived_count": 4,
      "derived_metrics": [
        {
          "raw_analysis_response": "```json\n{\n  \"analysis_metadata\": {\n    \"framework_name\": \"sentiment_binary_v1\",\n    \"framework_version\": \"1.0.0\",\n    \"analyst_confidence\": 0.98,\n    \"analysis_notes\": \"Applied three independent analytical approaches with median aggregation. The document explicitly states its positive sentiment context, which was strongly corroborated by the textual evidence.\",\n    \"internal_consistency_approach\": \"3-run median aggregation\"\n  },\n  \"document_analyses\": [\n    {\n      \"document_id\": \"positive_test_1.txt\",\n      \"document_name\": \"Positive Test Document 1\",\n      \"dimensional_scores\": {\n        \"positive_sentiment\": {\n          \"raw_score\": 1.0,\n          \"salience\": 1.0,\n          \"confidence\": 1.0\n        },\n        \"negative_sentiment\": {\n          \"raw_score\": 0.0,\n          \"salience\": 0.0,\n          \"confidence\": 1.0\n        }\n      },\n      \"evidence_quotes\": {\n        \"positive_sentiment\": [\n          \"This is a wonderful day! Everything is going perfectly. I feel great about the future. Success is everywhere. The team did an excellent job.\",\n          \"We're achieving amazing results. Optimism fills the air. What a fantastic opportunity! I'm thrilled with the progress. Everything looks bright and promising.\"\n        ],\n        \"negative_sentiment\": []\n      },\n      \"marked_up_document\": \"# Document Analysis - Marked Up Text\\n\\n# Positive Test Document 1\\n\\n**Context**: Sample text with positive sentiment\\n\\nThis is a [positive_sentiment: \\\"wonderful\\\"] day! Everything is going [positive_sentiment: \\\"perfectly\\\"]. I feel [positive_sentiment: \\\"great\\\"] about the future. [positive_sentiment: \\\"Success\\\"] is everywhere. The team did an [positive_sentiment: \\\"excellent\\\"] job. We're achieving [positive_sentiment: \\\"amazing\\\"] results. [positive_sentiment: \\\"Optimism\\\"] fills the air. What a [positive_sentiment: \\\"fantastic\\\"] opportunity! I'm [positive_sentiment: \\\"thrilled\\\"] with the progress. Everything looks [positive_sentiment: \\\"bright\\\"] and [positive_sentiment: \\\"promising\\\"].\\n\"\n    }\n  ]\n}\n```",
          "net_sentiment": null,
          "sentiment_magnitude": null
        },
        {
          "raw_analysis_response": "```json\n{\n  \"analysis_metadata\": {\n    \"framework_name\": \"sentiment_binary_v1\",\n    \"framework_version\": \"1.0.0\",\n    \"analyst_confidence\": 0.95,\n    \"analysis_notes\": \"Applied three independent analytical approaches with median aggregation\",\n    \"internal_consistency_approach\": \"3-run median aggregation\"\n  },\n  \"document_analyses\": [\n    {\n      \"document_id\": \"positive_test_2.txt\",\n      \"document_name\": \"positive_test_2.txt\",\n      \"dimensional_scores\": {\n        \"positive_sentiment\": {\n          \"raw_score\": 1.0,\n          \"salience\": 1.0,\n          \"confidence\": 1.0\n        },\n        \"negative_sentiment\": {\n          \"raw_score\": 0.0,\n          \"salience\": 0.0,\n          \"confidence\": 1.0\n        }\n      },\n      \"evidence_quotes\": {\n        \"positive_sentiment\": [\n          \"What a superb morning! All systems are operating flawlessly.\",\n          \"Hopefulness permeates everything. Such a marvelous chance! I'm delighted by the advancement. Everything appears glowing and encouraging.\"\n        ],\n        \"negative_sentiment\": []\n      },\n      \"marked_up_document\": \"# Document Analysis - Marked Up Text\\n\\n# Positive Test Document 2\\n\\n**Context**: Sample text with positive sentiment\\n\\nWhat a [positive_sentiment: \\\"superb\\\"] morning! All systems are operating [positive_sentiment: \\\"flawlessly\\\"]. I'm [positive_sentiment: \\\"excited\\\"] about what's coming next. [positive_sentiment: \\\"Achievement surrounds us\\\"]. The group performed [positive_sentiment: \\\"outstandingly\\\"]. We're reaching [positive_sentiment: \\\"incredible goals\\\"]. [positive_sentiment: \\\"Hopefulness permeates everything\\\"]. Such a [positive_sentiment: \\\"marvelous\\\"] chance! I'm [positive_sentiment: \\\"delighted\\\"] by the [positive_sentiment: \\\"advancement\\\"]. Everything appears [positive_sentiment: \\\"glowing\\\"] and [positive_sentiment: \\\"encouraging\\\"].\"\n    }\n  ]\n}\n```",
          "net_sentiment": null,
          "sentiment_magnitude": null
        },
        {
          "raw_analysis_response": "```json\n{\n  \"analysis_metadata\": {\n    \"framework_name\": \"sentiment_binary_v1\",\n    \"framework_version\": \"1.0.0\",\n    \"analyst_confidence\": 0.98,\n    \"analysis_notes\": \"Applied three independent analytical approaches with median aggregation. The document explicitly aims for negative sentiment, making scoring straightforward.\",\n    \"internal_consistency_approach\": \"3-run median aggregation\"\n  },\n  \"document_analyses\": [\n    {\n      \"document_id\": \"negative_test_1.txt\",\n      \"document_name\": \"negative_test_1.txt\",\n      \"dimensional_scores\": {\n        \"positive_sentiment\": {\n          \"raw_score\": 0.0,\n          \"salience\": 0.0,\n          \"confidence\": 1.0\n        },\n        \"negative_sentiment\": {\n          \"raw_score\": 0.9,\n          \"salience\": 1.0,\n          \"confidence\": 1.0\n        }\n      },\n      \"evidence_quotes\": {\n        \"positive_sentiment\": [],\n        \"negative_sentiment\": [\n          \"This is a terrible situation.\",\n          \"Failure surrounds us.\",\n          \"The team did a horrible job. We're facing disaster.\",\n          \"Pessimism fills the air. What a disastrous outcome!\",\n          \"I'm devastated by the results. Everything looks dark and hopeless.\"\n        ]\n      },\n      \"marked_up_document\": \"# Document Analysis - Marked Up Text\\n\\n# Negative Test Document 1\\n\\n**Context**: Sample text with negative sentiment\\n\\nThis is a [NEGATIVE_SENTIMENT: \\\"terrible situation\\\"]. [NEGATIVE_SENTIMENT: \\\"Everything is going wrong\\\"]. I feel [NEGATIVE_SENTIMENT: \\\"awful about the future\\\"]. [NEGATIVE_SENTIMENT: \\\"Failure surrounds us\\\"]. The team did a [NEGATIVE_SENTIMENT: \\\"horrible job\\\"]. We're [NEGATIVE_SENTIMENT: \\\"facing disaster\\\"]. [NEGATIVE_SENTIMENT: \\\"Pessimism fills the air\\\"]. What a [NEGATIVE_SENTIMENT: \\\"disastrous outcome!\\\"] I'm [NEGATIVE_SENTIMENT: \\\"devastated by the results\\\"]. [NEGATIVE_SENTIMENT: \\\"Everything looks dark and hopeless\\\"].\"\n    }\n  ]\n}\n```",
          "net_sentiment": null,
          "sentiment_magnitude": null
        },
        {
          "raw_analysis_response": "```json\n{\n  \"analysis_metadata\": {\n    \"framework_name\": \"sentiment_binary_v1\",\n    \"framework_version\": \"1.0.0\",\n    \"analyst_confidence\": 0.98,\n    \"analysis_notes\": \"Applied three independent analytical approaches with median aggregation. The document exhibits exceptionally strong negative sentiment with a complete absence of positive sentiment.\",\n    \"internal_consistency_approach\": \"3-run median aggregation\"\n  },\n  \"document_analyses\": [\n    {\n      \"document_id\": \"negative_test_2.txt\",\n      \"document_name\": \"Negative Test Document 2\",\n      \"dimensional_scores\": {\n        \"positive_sentiment\": {\n          \"raw_score\": 0.0,\n          \"salience\": 0.0,\n          \"confidence\": 1.0\n        },\n        \"negative_sentiment\": {\n          \"raw_score\": 1.0,\n          \"salience\": 1.0,\n          \"confidence\": 1.0\n        }\n      },\n      \"evidence_quotes\": {\n        \"positive_sentiment\": [],\n        \"negative_sentiment\": [\n          \"What an awful predicament. All plans are failing miserably. I'm dreading what's to come. Defeat engulfs us. The group performed dreadfully.\",\n          \"We're encountering catastrophe. Despair saturates everything. Such a calamitous result! I'm crushed by the setbacks. Everything appears bleak and discouraging.\"\n        ]\n      },\n      \"marked_up_document\": \"# Document Analysis - Marked Up Text\\n\\n# Negative Test Document 2\\n\\n**Context**: Sample text with negative sentiment\\n\\n[NEGATIVE_SENTIMENT: \\\"What an awful predicament.\\\"] [NEGATIVE_SENTIMENT: \\\"All plans are failing miserably.\\\"] [NEGATIVE_SENTIMENT: \\\"I'm dreading what's to come.\\\"] [NEGATIVE_SENTIMENT: \\\"Defeat engulfs us.\\\"] [NEGATIVE_SENTIMENT: \\\"The group performed dreadfully.\\\"] [NEGATIVE_SENTIMENT: \\\"We're encountering catastrophe.\\\"] [NEGATIVE_SENTIMENT: \\\"Despair saturates everything.\\\"] [NEGATIVE_SENTIMENT: \\\"Such a calamitous result!\\\"] [NEGATIVE_SENTIMENT: \\\"I'm crushed by the setbacks.\\\"] [NEGATIVE_SENTIMENT: \\\"Everything appears bleak and discouraging.\\\"]\"\n    }\n  ]\n}\n```",
          "net_sentiment": null,
          "sentiment_magnitude": null
        }
      ],
      "columns_added": [
        "sentiment_magnitude",
        "net_sentiment"
      ]
    },
    "status": "success_with_data",
    "validation_passed": true
  }
}