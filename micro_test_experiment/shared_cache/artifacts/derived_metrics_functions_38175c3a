{
  "status": "success",
  "functions_generated": 5,
  "output_file": "automatedderivedmetricsagent_functions.py",
  "module_size": 5858,
  "function_code_content": "import pandas as pd\nimport numpy as np\nimport json\nfrom typing import Optional, Dict, Any\n\ndef _get_dimensional_scores(data_row: pd.Series) -> Optional[Dict[str, Any]]:\n    \"\"\"Parses the raw analysis response from a row to extract dimensional scores.\n\n    Args:\n        data_row (pd.Series): A single row from a DataFrame, expected to contain\n                              a 'raw_analysis_response' column.\n\n    Returns:\n        Optional[Dict[str, Any]]: A dictionary of dimensional scores or None if parsing fails.\n    \"\"\"\n    try:\n        if 'raw_analysis_response' not in data_row or not isinstance(data_row['raw_analysis_response'], str):\n            return None\n\n        raw_response = data_row['raw_analysis_response']\n\n        start_marker = '<<<DISCERNUS_ANALYSIS_JSON_v6>>>'\n        end_marker = '<<<END_DISCERNUS_ANALYSIS_JSON_v6>>>'\n        start_idx = raw_response.find(start_marker)\n        end_idx = raw_response.find(end_marker)\n\n        if start_idx != -1 and end_idx != -1:\n            json_content = raw_response[start_idx + len(start_marker):end_idx].strip()\n            analysis = json.loads(json_content)\n        else:\n            # Fallback for raw JSON string without markers\n            analysis = json.loads(raw_response)\n\n        if 'document_analyses' in analysis and isinstance(analysis['document_analyses'], list) and len(analysis['document_analyses']) > 0:\n            # Assuming one document analysis per row as per the problem description\n            return analysis['document_analyses'][0].get('dimensional_scores')\n        \n        return None\n\n    except (KeyError, IndexError, TypeError, json.JSONDecodeError, AttributeError):\n        return None\n\ndef calculate_net_sentiment(data: pd.Series, **kwargs) -> Optional[float]:\n    \"\"\"\n    Calculates the net sentiment balance (positive - negative).\n\n    Formula: dimensions.positive_sentiment.raw_score - dimensions.negative_sentiment.raw_score\n\n    Args:\n        data (pd.Series): A single row of a DataFrame containing the analysis data in 'raw_analysis_response'.\n        **kwargs: Additional parameters (unused).\n\n    Returns:\n        Optional[float]: The calculated net sentiment, or None if data is missing or invalid.\n    \"\"\"\n    scores = _get_dimensional_scores(data)\n    if scores:\n        try:\n            pos_score = scores.get('positive_sentiment', {}).get('raw_score')\n            neg_score = scores.get('negative_sentiment', {}).get('raw_score')\n            if pos_score is not None and neg_score is not None:\n                return float(pos_score) - float(neg_score)\n        except (TypeError, ValueError):\n            return None\n    return None\n\ndef calculate_sentiment_magnitude(data: pd.Series, **kwargs) -> Optional[float]:\n    \"\"\"\n    Calculates the average emotional intensity (positive + negative) / 2.\n\n    Formula: (dimensions.positive_sentiment.raw_score + dimensions.negative_sentiment.raw_score) / 2\n\n    Args:\n        data (pd.Series): A single row of a DataFrame containing the analysis data in 'raw_analysis_response'.\n        **kwargs: Additional parameters (unused).\n\n    Returns:\n        Optional[float]: The calculated sentiment magnitude, or None if data is missing or invalid.\n    \"\"\"\n    scores = _get_dimensional_scores(data)\n    if scores:\n        try:\n            pos_score = scores.get('positive_sentiment', {}).get('raw_score')\n            neg_score = scores.get('negative_sentiment', {}).get('raw_score')\n            if pos_score is not None and neg_score is not None:\n                return (float(pos_score) + float(neg_score)) / 2.0\n        except (TypeError, ValueError):\n            return None\n    return None\n\ndef calculate_all_derived_metrics(data: pd.Series, **kwargs) -> Dict[str, Optional[float]]:\n    \"\"\"\n    Calculates all derived metrics for a single row of data by calling each individual metric function.\n\n    This function is designed to be used with pandas `.apply()` on a row-by-row basis.\n\n    Args:\n        data (pd.Series): A single row of a DataFrame.\n        **kwargs: Additional parameters to pass to calculation functions.\n\n    Returns:\n        Dict[str, Optional[float]]: A dictionary mapping metric names to their calculated values.\n    \"\"\"\n    results = {\n        \"net_sentiment\": calculate_net_sentiment(data, **kwargs),\n        \"sentiment_magnitude\": calculate_sentiment_magnitude(data, **kwargs),\n    }\n    return results\n\ndef calculate_derived_metrics(data: pd.DataFrame, **kwargs) -> pd.DataFrame:\n    \"\"\"\n    Calculates all derived metrics and adds them as new columns to the DataFrame.\n\n    This wrapper function iterates through each row, applies all derived metric\n    calculations via `calculate_all_derived_metrics`, and appends the results as new columns.\n\n    Args:\n        data (pd.DataFrame): The input DataFrame with a 'raw_analysis_response' column.\n        **kwargs: Additional parameters to pass to calculation functions.\n\n    Returns:\n        pd.DataFrame: A new DataFrame with the original data plus columns for each derived metric.\n    \"\"\"\n    df = data.copy()\n\n    if 'raw_analysis_response' not in df.columns:\n        df['net_sentiment'] = np.nan\n        df['sentiment_magnitude'] = np.nan\n        return df\n\n    derived_metrics_series = df.apply(\n        lambda row: calculate_all_derived_metrics(row, **kwargs),\n        axis=1\n    )\n\n    derived_metrics_df = pd.json_normalize(derived_metrics_series)\n\n    expected_cols = [\"net_sentiment\", \"sentiment_magnitude\"]\n    for col in expected_cols:\n        if col not in derived_metrics_df.columns:\n            derived_metrics_df[col] = np.nan\n\n    # Join the new metrics, ensuring not to duplicate columns if they already exist\n    # and to only add the expected columns from this framework.\n    cols_to_add = [col for col in expected_cols if col not in df.columns]\n    df = df.join(derived_metrics_df[cols_to_add])\n\n    return df\n",
  "cached_with_code": true
}