{
  "status": "success",
  "functions_generated": 3,
  "output_file": "automatedstatisticalanalysisagent_functions.py",
  "module_size": 16692,
  "function_code_content": "\"\"\"\nAutomated Statistical Analysis Functions\n========================================\n\nGenerated by AutomatedStatisticalAnalysisAgent for experiment: micro_test_experiment\nDescription: Statistical analysis experiment\nGenerated: 2025-09-01T17:40:04.795244+00:00\n\nThis module contains automatically generated statistical analysis functions\nfor comprehensive data analysis including ANOVA, correlations, reliability,\nand hypothesis testing as appropriate for the research questions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport scipy.stats as stats\nfrom typing import Dict, Any, Optional, List, Tuple\nimport warnings\n\n# Suppress common statistical warnings for cleaner output\nwarnings.filterwarnings('ignore', category=RuntimeWarning)\n\n\ndef descriptive_statistics_by_sentiment_category(data, **kwargs):\n    \"\"\"\n    Calculate descriptive statistics for all dimensions and derived metrics by sentiment category.\n    \n    Args:\n        data: pandas DataFrame containing the analysis data\n        **kwargs: Additional parameters\n        \n    Returns:\n        dict: Descriptive statistics by sentiment category or None if insufficient data\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # Create sentiment category mapping based on document names\n        def get_sentiment_category(document_name):\n            if 'positive' in document_name.lower():\n                return 'positive'\n            elif 'negative' in document_name.lower():\n                return 'negative'\n            else:\n                return 'unknown'\n        \n        # Add sentiment category column\n        data_copy = data.copy()\n        data_copy['sentiment_category'] = data_copy['document_name'].apply(get_sentiment_category)\n        \n        # Calculate derived metrics\n        data_copy['net_sentiment'] = data_copy['positive_sentiment_raw'] - data_copy['negative_sentiment_raw']\n        data_copy['sentiment_magnitude'] = (data_copy['positive_sentiment_raw'] + data_copy['negative_sentiment_raw']) / 2\n        \n        # Define columns for analysis\n        analysis_columns = [\n            'positive_sentiment_raw', 'positive_sentiment_salience', 'positive_sentiment_confidence',\n            'negative_sentiment_raw', 'negative_sentiment_salience', 'negative_sentiment_confidence',\n            'net_sentiment', 'sentiment_magnitude'\n        ]\n        \n        results = {}\n        \n        # Calculate descriptive statistics by sentiment category\n        for category in data_copy['sentiment_category'].unique():\n            if category == 'unknown':\n                continue\n                \n            category_data = data_copy[data_copy['sentiment_category'] == category]\n            \n            if len(category_data) == 0:\n                continue\n                \n            category_stats = {}\n            \n            for column in analysis_columns:\n                if column in category_data.columns:\n                    stats = {\n                        'count': len(category_data),\n                        'mean': float(category_data[column].mean()),\n                        'std': float(category_data[column].std()) if len(category_data) > 1 else 0.0,\n                        'min': float(category_data[column].min()),\n                        'max': float(category_data[column].max()),\n                        'median': float(category_data[column].median()),\n                        'q25': float(category_data[column].quantile(0.25)),\n                        'q75': float(category_data[column].quantile(0.75))\n                    }\n                    category_stats[column] = stats\n            \n            results[category] = category_stats\n        \n        # Calculate overall statistics\n        overall_stats = {}\n        for column in analysis_columns:\n            if column in data_copy.columns:\n                stats = {\n                    'count': len(data_copy),\n                    'mean': float(data_copy[column].mean()),\n                    'std': float(data_copy[column].std()) if len(data_copy) > 1 else 0.0,\n                    'min': float(data_copy[column].min()),\n                    'max': float(data_copy[column].max()),\n                    'median': float(data_copy[column].median()),\n                    'q25': float(data_copy[column].quantile(0.25)),\n                    'q75': float(data_copy[column].quantile(0.75))\n                }\n                overall_stats[column] = stats\n        \n        results['overall'] = overall_stats\n        \n        return results\n        \n    except Exception:\n        return None\n\ndef anova_sentiment_category_comparison(data, **kwargs):\n    \"\"\"\n    Perform one-way ANOVA comparing sentiment dimensions between positive and negative sentiment categories.\n    \n    Args:\n        data: pandas DataFrame containing the analysis data\n        **kwargs: Additional parameters\n        \n    Returns:\n        dict: ANOVA results for each dimension or None if insufficient data\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    from scipy import stats\n    \n    try:\n        # Create sentiment category mapping\n        def get_sentiment_category(document_name):\n            if 'positive' in document_name.lower():\n                return 'positive'\n            elif 'negative' in document_name.lower():\n                return 'negative'\n            else:\n                return 'unknown'\n        \n        data_copy = data.copy()\n        data_copy['sentiment_category'] = data_copy['document_name'].apply(get_sentiment_category)\n        \n        # Calculate derived metrics\n        data_copy['net_sentiment'] = data_copy['positive_sentiment_raw'] - data_copy['negative_sentiment_raw']\n        data_copy['sentiment_magnitude'] = (data_copy['positive_sentiment_raw'] + data_copy['negative_sentiment_raw']) / 2\n        \n        # Filter out unknown categories\n        data_copy = data_copy[data_copy['sentiment_category'] != 'unknown']\n        \n        if len(data_copy) < 4:  # Need at least 2 per group\n            return None\n        \n        # Define dimensions to test\n        dimensions = [\n            'positive_sentiment_raw', 'positive_sentiment_salience', 'positive_sentiment_confidence',\n            'negative_sentiment_raw', 'negative_sentiment_salience', 'negative_sentiment_confidence',\n            'net_sentiment', 'sentiment_magnitude'\n        ]\n        \n        results = {}\n        \n        for dimension in dimensions:\n            if dimension not in data_copy.columns:\n                continue\n                \n            # Get groups\n            positive_group = data_copy[data_copy['sentiment_category'] == 'positive'][dimension]\n            negative_group = data_copy[data_copy['sentiment_category'] == 'negative'][dimension]\n            \n            if len(positive_group) < 2 or len(negative_group) < 2:\n                continue\n            \n            # Perform ANOVA\n            f_stat, p_value = stats.f_oneway(positive_group, negative_group)\n            \n            # Calculate effect size (eta squared)\n            ss_between = len(positive_group) * (positive_group.mean() - data_copy[dimension].mean())**2 + \\\n                        len(negative_group) * (negative_group.mean() - data_copy[dimension].mean())**2\n            ss_total = ((data_copy[dimension] - data_copy[dimension].mean())**2).sum()\n            eta_squared = ss_between / ss_total if ss_total > 0 else 0\n            \n            # Levene's test for homogeneity of variance\n            levene_stat, levene_p = stats.levene(positive_group, negative_group)\n            \n            results[dimension] = {\n                'f_statistic': float(f_stat),\n                'p_value': float(p_value),\n                'eta_squared': float(eta_squared),\n                'significant': p_value < 0.05,\n                'levene_statistic': float(levene_stat),\n                'levene_p_value': float(levene_p),\n                'homogeneity_assumption_met': levene_p > 0.05,\n                'positive_group_mean': float(positive_group.mean()),\n                'negative_group_mean': float(negative_group.mean()),\n                'positive_group_n': len(positive_group),\n                'negative_group_n': len(negative_group)\n            }\n        \n        return results\n        \n    except Exception:\n        return None\n\ndef correlation_analysis_sentiment_dimensions(data, **kwargs):\n    \"\"\"\n    Calculate correlation matrix for all sentiment dimensions and derived metrics.\n    \n    Args:\n        data: pandas DataFrame containing the analysis data\n        **kwargs: Additional parameters\n        \n    Returns:\n        dict: Correlation analysis results or None if insufficient data\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    from scipy import stats\n    \n    try:\n        data_copy = data.copy()\n        \n        # Calculate derived metrics\n        data_copy['net_sentiment'] = data_copy['positive_sentiment_raw'] - data_copy['negative_sentiment_raw']\n        data_copy['sentiment_magnitude'] = (data_copy['positive_sentiment_raw'] + data_copy['negative_sentiment_raw']) / 2\n        \n        # Define columns for correlation analysis\n        correlation_columns = [\n            'positive_sentiment_raw', 'positive_sentiment_salience', 'positive_sentiment_confidence',\n            'negative_sentiment_raw', 'negative_sentiment_salience', 'negative_sentiment_confidence',\n            'net_sentiment', 'sentiment_magnitude'\n        ]\n        \n        # Filter to only include available columns\n        available_columns = [col for col in correlation_columns if col in data_copy.columns]\n        \n        if len(available_columns) < 2 or len(data_copy) < 3:\n            return None\n        \n        correlation_data = data_copy[available_columns]\n        \n        # Calculate Pearson correlations\n        pearson_corr = correlation_data.corr()\n        \n        # Calculate Spearman correlations\n        spearman_corr = correlation_data.corr(method='spearman')\n        \n        # Calculate p-values for correlations\n        n = len(correlation_data)\n        pearson_p_values = {}\n        spearman_p_values = {}\n        \n        for i, col1 in enumerate(available_columns):\n            pearson_p_values[col1] = {}\n            spearman_p_values[col1] = {}\n            for j, col2 in enumerate(available_columns):\n                if i != j:\n                    # Pearson p-value\n                    pearson_r, pearson_p = stats.pearsonr(correlation_data[col1], correlation_data[col2])\n                    pearson_p_values[col1][col2] = float(pearson_p)\n                    \n                    # Spearman p-value\n                    spearman_r, spearman_p = stats.spearmanr(correlation_data[col1], correlation_data[col2])\n                    spearman_p_values[col1][col2] = float(spearman_p)\n                else:\n                    pearson_p_values[col1][col2] = 0.0\n                    spearman_p_values[col1][col2] = 0.0\n        \n        results = {\n            'pearson_correlations': pearson_corr.to_dict(),\n            'spearman_correlations': spearman_corr.to_dict(),\n            'pearson_p_values': pearson_p_values,\n            'spearman_p_values': spearman_p_values,\n            'sample_size': n,\n            'variables_analyzed': available_columns\n        }\n        \n        # Identify significant correlations\n        significant_correlations = []\n        for col1 in available_columns:\n            for col2 in available_columns:\n                if col1 != col2:\n                    pearson_r = pearson_corr.loc[col1, col2]\n                    pearson_p = pearson_p_values[col1][col2]\n                    if pearson_p < 0.05:\n                        significant_correlations.append({\n                            'variable_1': col1,\n                            'variable_2': col2,\n                            'pearson_r': float(pearson_r),\n                            'pearson_p': pearson_p,\n                            'strength': 'strong' if abs(pearson_r) > 0.7 else 'moderate' if abs(pearson_r) > 0.3 else 'weak'\n                        })\n        \n        results['significant_correlations'] = significant_correlations\n        \n        return results\n        \n    except Exception:\n        return None\n\ndef run_complete_statistical_analysis(data: pd.DataFrame, alpha: float = 0.05) -> Dict[str, Any]:\n    \"\"\"\n    Run complete statistical analysis suite on the dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        alpha: Significance level for hypothesis tests (default: 0.05)\n        \n    Returns:\n        Dictionary with all statistical analysis results\n    \"\"\"\n    results = {\n        'analysis_metadata': {\n            'timestamp': pd.Timestamp.now().isoformat(),\n            'sample_size': len(data),\n            'alpha_level': alpha,\n            'variables_analyzed': list(data.select_dtypes(include=[np.number]).columns)\n        }\n    }\n    \n    # Get all analysis functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith(('calculate_', 'perform_', 'test_')) and \n            name != 'run_complete_statistical_analysis'):\n            try:\n                # Pass alpha parameter to functions that might need it\n                if 'alpha' in inspect.signature(obj).parameters:\n                    results[name] = obj(data, alpha=alpha)\n                else:\n                    results[name] = obj(data)\n            except Exception as e:\n                results[name] = {'error': f'Analysis failed: {str(e)}'}\n                \n    return results\n\n\ndef perform_statistical_analysis(data: pd.DataFrame) -> Dict[str, Any]:\n    \"\"\"\n    Template-compatible wrapper function for statistical analysis.\n    \n    This function is called by the universal notebook template and performs\n    comprehensive statistical analysis on the provided dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores and derived metrics\n        \n    Returns:\n        Dictionary containing all statistical analysis results\n    \"\"\"\n    return run_complete_statistical_analysis(data)\n\n\ndef generate_statistical_summary_report(analysis_results: Dict[str, Any]) -> str:\n    \"\"\"\n    Generate a human-readable summary report from statistical analysis results.\n    \n    Args:\n        analysis_results: Results from run_complete_statistical_analysis()\n        \n    Returns:\n        String containing formatted statistical report\n    \"\"\"\n    report_lines = []\n    report_lines.append(\"STATISTICAL ANALYSIS SUMMARY REPORT\")\n    report_lines.append(\"=\" * 50)\n    \n    metadata = analysis_results.get('analysis_metadata', {})\n    report_lines.append(f\"Analysis Timestamp: {metadata.get('timestamp', 'Unknown')}\")\n    report_lines.append(f\"Sample Size: {metadata.get('sample_size', 'Unknown')}\")\n    report_lines.append(f\"Alpha Level: {metadata.get('alpha_level', 'Unknown')}\")\n    report_lines.append(f\"Variables: {len(metadata.get('variables_analyzed', []))}\")\n    report_lines.append(\"\")\n    \n    # Summarize key findings\n    for analysis_name, result in analysis_results.items():\n        if analysis_name != 'analysis_metadata' and isinstance(result, dict):\n            if 'error' not in result:\n                report_lines.append(f\"{analysis_name.replace('_', ' ').title()}:\")\n                \n                # Extract key statistics based on analysis type\n                if 'p_value' in result:\n                    p_val = result['p_value']\n                    significance = \"significant\" if p_val < metadata.get('alpha_level', 0.05) else \"not significant\"\n                    report_lines.append(f\"  - p-value: {p_val:.4f} ({significance})\")\n                \n                if 'effect_size' in result:\n                    report_lines.append(f\"  - Effect size: {result['effect_size']:.4f}\")\n                \n                if 'correlation_matrix' in result:\n                    report_lines.append(f\"  - Correlation matrix generated with {len(result['correlation_matrix'])} variables\")\n                \n                if 'cronbach_alpha' in result:\n                    alpha_val = result['cronbach_alpha']\n                    reliability = \"excellent\" if alpha_val > 0.9 else \"good\" if alpha_val > 0.8 else \"acceptable\" if alpha_val > 0.7 else \"questionable\"\n                    report_lines.append(f\"  - Cronbach's \u03b1: {alpha_val:.3f} ({reliability})\")\n                \n                report_lines.append(\"\")\n            else:\n                report_lines.append(f\"{analysis_name}: ERROR - {result['error']}\")\n                report_lines.append(\"\")\n    \n    return \"\\n\".join(report_lines)\n",
  "cached_with_code": true
}