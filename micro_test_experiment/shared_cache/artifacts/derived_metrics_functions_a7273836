{
  "status": "success",
  "functions_generated": 6,
  "output_file": "automatedderivedmetricsagent_functions.py",
  "module_size": 12048,
  "function_code_content": "\"\"\"\nAutomated Derived Metrics Functions\n===================================\n\nGenerated by AutomatedDerivedMetricsAgent for experiment: Test Experiment\nDescription: Test experiment for derived metrics\nGenerated: 2025-09-09T17:54:16.135053+00:00\n\nThis module contains automatically generated calculation functions for derived metrics\nas specified in the framework's natural language descriptions.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom typing import Optional, Dict, Any\n\n\ndef calculate_identity_tension(data, **kwargs):\n    \"\"\"\n    Calculate identity_tension: Conflict between tribal dominance and individual dignity dimensions\n    \n    Formula: abs(tribal_dominance - individual_dignity)\n    \n    Args:\n        data (pd.Series): A single row of data containing dimension scores.\n        **kwargs: Additional keyword arguments (not used).\n        \n    Returns:\n        float: The calculated identity tension, or None if input data is missing or invalid.\n    \"\"\"\n    import pandas as pd\n    \n    try:\n        # The calculation requires 'tribal_dominance' and 'individual_dignity' dimensions.\n        # These are not present in the provided \"ACTUAL DATA STRUCTURE\" sample,\n        # so this function is designed to fail gracefully by returning None.\n        tribal_dominance = data.get('tribal_dominance')\n        individual_dignity = data.get('individual_dignity')\n\n        # Check if the necessary columns exist and have non-null values\n        if tribal_dominance is None or individual_dignity is None or pd.isna(tribal_dominance) or pd.isna(individual_dignity):\n            return None\n\n        # Ensure values are floats for calculation\n        tribal_dominance = float(tribal_dominance)\n        individual_dignity = float(individual_dignity)\n\n        # The formula calculates the absolute difference, representing the 'tension' or 'conflict'.\n        # A higher value indicates greater divergence between the two dimensions.\n        tension = abs(tribal_dominance - individual_dignity)\n        \n        return tension\n\n    except (TypeError, ValueError):\n        # This handles cases where data might not be numeric\n        return None\n    except Exception:\n        # A general catch-all for any other unexpected errors\n        return None\n\ndef calculate_emotional_balance(data, **kwargs):\n    \"\"\"\n    Calculate emotional_balance: Difference between hope and fear scores\n\n    Formula: hope - fear\n    \n    Args:\n        data (pd.Series): A row of data from a pandas DataFrame.\n        **kwargs: Additional parameters (unused).\n        \n    Returns:\n        float: Calculated result or None if insufficient data.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # This calculation requires 'hope' and 'fear' scores.\n        hope_score = data['hope']\n        fear_score = data['fear']\n        \n        # Check for missing data in the required columns.\n        if pd.isna(hope_score) or pd.isna(fear_score):\n            return None\n            \n        # Calculate the difference and ensure the result is a standard float.\n        return float(hope_score) - float(fear_score)\n\n    except (KeyError, TypeError, ValueError):\n        # Handles cases where columns are missing or data is not numeric.\n        return None\n\ndef calculate_success_climate(data, **kwargs):\n    \"\"\"\n    Calculate success_climate: Difference between compersion and envy scores\n\n    Formula: success_climate = compersion - envy\n    \n    Args:\n        data: pandas DataFrame with dimension scores (expected as a Series for a single row).\n        **kwargs: Additional parameters (unused).\n        \n    Returns:\n        float: Calculated result or None if insufficient data.\n    \"\"\"\n    import pandas as pd\n    \n    try:\n        # The calculation is explicitly defined as the difference between 'compersion' and 'envy'.\n        # We use pd.to_numeric to safely convert values, coercing errors to Not a Number (NaN).\n        # The .get() method safely handles cases where the keys might be missing from the data.\n        compersion_score = pd.to_numeric(data.get('compersion'), errors='coerce')\n        envy_score = pd.to_numeric(data.get('envy'), errors='coerce')\n\n        # Check if either score is NaN (which occurs if key was missing, value was None,\n        # or value was non-numeric). If so, we cannot calculate and return None.\n        if pd.isna(compersion_score) or pd.isna(envy_score):\n            return None\n        \n        # If both scores are valid numbers, perform the calculation and return as a float.\n        return float(compersion_score - envy_score)\n\n    except Exception:\n        # Broad exception handler to ensure stability in production, returning None on any error.\n        return None\n\ndef calculate_relational_climate(data, **kwargs):\n    \"\"\"\n    Calculate relational_climate: Difference between amity and enmity scores\n\n    Formula: amity - enmity\n    \n    Args:\n        data: pandas DataFrame with dimension scores (passed as a single row or Series)\n        **kwargs: Additional parameters\n        \n    Returns:\n        float: Calculated result or None if insufficient data\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # The calculation is \"Difference between amity and enmity scores\".\n        # We therefore require 'amity' and 'enmity' columns. This function design\n        # prioritizes the explicit calculation description.\n        amity_col = 'amity'\n        enmity_col = 'enmity'\n\n        # Use .get() for safe access to columns that might be missing.\n        amity_score = data.get(amity_col)\n        enmity_score = data.get(enmity_col)\n        \n        # Check for missing data (None, NaN, etc.) before calculation.\n        if pd.isna(amity_score) or pd.isna(enmity_score):\n            return None\n            \n        # Cast to float to ensure numeric operation and return the difference.\n        result = float(amity_score) - float(enmity_score)\n        \n        return result\n\n    except Exception:\n        # Catch all other errors during execution (e.g., non-numeric values\n        # that cause float conversion to fail) and return None for robustness.\n        return None\n\ndef calculate_goal_orientation(data, **kwargs):\n    \"\"\"\n    Calculate goal_orientation: Difference between cohesive goals and fragmentative goals\n\n    Formula: goal_orientation = cohesive_goals - fragmentative_goals\n    \n    Args:\n        data (pd.Series): A row of data from a DataFrame.\n        **kwargs: Additional parameters (unused).\n        \n    Returns:\n        float: Calculated result or None if insufficient data. The function\n               requires 'cohesive_goals' and 'fragmentative_goals' columns.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        cohesive_goals = data['cohesive_goals']\n        fragmentative_goals = data['fragmentative_goals']\n\n        # Check for missing values before calculation\n        if pd.isna(cohesive_goals) or pd.isna(fragmentative_goals):\n            return None\n\n        # Perform the calculation and ensure the result is a standard float\n        result = float(cohesive_goals) - float(fragmentative_goals)\n\n        # A final sanity check for NaN results from unusual float arithmetic\n        if np.isnan(result):\n            return None\n        \n        return result\n\n    except (KeyError, TypeError, ValueError):\n        # KeyError: If 'cohesive_goals' or 'fragmentative_goals' columns do not exist.\n        # TypeError: If data is not subscriptable or values are of an incorrect type for subtraction.\n        # ValueError: If values cannot be cast to float.\n        return None\n\ndef calculate_overall_cohesion_index(data, **kwargs):\n    \"\"\"\n    Calculate overall_cohesion_index: Comprehensive measure combining all dimensions.\n\n    This index measures the balance between positive and negative sentiment scores.\n    A value of 1.0 indicates perfect balance (e.g., positive=0.5, negative=0.5),\n    while a value of 0.0 indicates complete dominance by one sentiment\n    (e.g., positive=1.0, negative=0.0).\n\n    Formula: 1 - abs(positive_sentiment - negative_sentiment)\n    \n    Args:\n        data (pd.Series or pd.DataFrame): A single row of data containing the dimension scores.\n            It is expected to have 'positive_sentiment' and 'negative_sentiment' columns\n            as inferred from the framework's dimensions.\n        **kwargs: Additional parameters (not used).\n        \n    Returns:\n        float: The calculated overall cohesion index, or None if necessary data is missing or invalid.\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    \n    try:\n        # The framework dimensions are \"Positive Sentiment\" and \"Negative Sentiment\".\n        # We infer the required column names as 'positive_sentiment' and 'negative_sentiment'.\n        # The broad exception handling will return None if these columns do not exist\n        # or if data is otherwise invalid, fulfilling the requirements.\n\n        # Handle both pd.Series (single row) and pd.DataFrame (first row) input\n        if isinstance(data, pd.DataFrame):\n            if data.empty:\n                return None\n            row = data.iloc[0]\n        elif isinstance(data, pd.Series):\n            row = data\n        else:\n            return None # Invalid input type\n\n        positive_score = row['positive_sentiment']\n        negative_score = row['negative_sentiment']\n        \n        # Check for non-numeric or missing values which cannot be calculated\n        if pd.isna(positive_score) or pd.isna(negative_score):\n            return None\n\n        # Calculate the cohesion index based on the absolute difference\n        cohesion_index = 1.0 - abs(float(positive_score) - float(negative_score))\n        \n        # The dimension scores are specified to be between 0.0 and 1.0.\n        # The result of the formula will also be in this range.\n        # We clip for extra safety against potential floating point inaccuracies or invalid inputs.\n        return np.clip(cohesion_index, 0.0, 1.0)\n        \n    except Exception:\n        # Catch any exceptions from missing columns, invalid data types, etc.\n        return None\n\ndef calculate_all_derived_metrics(data: pd.DataFrame) -> Dict[str, Optional[float]]:\n    \"\"\"\n    Calculate all derived metrics for the given dataset.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        Dictionary mapping metric names to calculated values\n    \"\"\"\n    results = {}\n    \n    # Get all calculation functions from this module\n    import inspect\n    current_module = inspect.getmodule(inspect.currentframe())\n    \n    for name, obj in inspect.getmembers(current_module):\n        if (inspect.isfunction(obj) and \n            name.startswith('calculate_') and \n            name not in ['calculate_all_derived_metrics', 'calculate_derived_metrics']):\n            try:\n                results[name.replace('calculate_', '')] = obj(data)\n            except Exception as e:\n                results[name.replace('calculate_', '')] = None\n                \n    return results\n\n\ndef calculate_derived_metrics(data: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Template-compatible wrapper function for derived metrics calculation.\n    \n    This function is called by the universal notebook template and returns\n    the original data with additional derived metric columns.\n    \n    Args:\n        data: pandas DataFrame with dimension scores\n        \n    Returns:\n        DataFrame with original data plus derived metric columns\n    \"\"\"\n    # Calculate all derived metrics\n    derived_metrics = calculate_all_derived_metrics(data)\n    \n    # Create a copy of the original data\n    result = data.copy()\n    \n    # Add derived metrics as new columns\n    for metric_name, metric_value in derived_metrics.items():\n        if metric_value is not None:\n            # For scalar metrics, broadcast to all rows\n            result[metric_name] = metric_value\n        else:\n            # For failed calculations, use NaN\n            result[metric_name] = np.nan\n    \n    return result\n",
  "cached_with_code": true
}