"""
Automated Derived Metrics Functions
===================================

Generated by AutomatedDerivedMetricsAgent for experiment: simple_test
Description: No description
Generated: 2025-08-16T12:24:29.173806+00:00

This module contains automatically generated calculation functions for derived metrics
as specified in the framework's natural language descriptions.
"""

import pandas as pd
import numpy as np
from typing import Optional, Dict, Any


def calculate_identity_tension(data, **kwargs):
    """
    Calculate identity_tension: Conflict between tribal dominance and individual dignity dimensions.

    The formula for identity_tension is the absolute difference between
    the 'Tribal Dominance' score and the 'Individual Dignity' score.
    identity_tension = |Tribal Dominance - Individual Dignity|

    Scores for both 'Tribal Dominance' and 'Individual Dignity' are expected to be
    between 0.0 and 1.0. A higher tension score indicates greater conflict.

    Args:
        data (pandas.DataFrame): A DataFrame expected to contain 'Tribal Dominance'
                                 and 'Individual Dignity' columns. If multiple rows
                                 are present, the first non-null valid score from
                                 each respective column will be used for the calculation.
        **kwargs: Additional parameters (not used in this calculation but required by signature).

    Returns:
        float: The calculated identity_tension score (0.0 to 1.0).
               Returns None if:
               - 'data' is not a pandas DataFrame.
               - Required columns ('Tribal Dominance', 'Individual Dignity') are missing.
               - 'data' is empty or contains no valid (non-null) scores in the required columns.
               - Extracted scores are not numeric or are outside the 0.0-1.0 range.
    """
    import pandas as pd
    import numpy as np
    
    try:
        # Validate input is a pandas DataFrame
        if not isinstance(data, pd.DataFrame):
            return None

        # Define required columns
        required_cols = ['Tribal Dominance', 'Individual Dignity']

        # Check if all required columns exist in the DataFrame
        if not all(col in data.columns for col in required_cols):
            return None
        
        # Ensure the DataFrame is not empty
        if data.empty:
            return None

        # Attempt to extract the first valid (non-NaN) score for each dimension.
        # .dropna() removes NaN values, and .iloc[0] gets the first element.
        # If .dropna() results in an empty Series, the subsequent .iloc[0] would raise IndexError,
        # which is caught by the outer try-except, or handled explicitly below.
        
        tribal_dominance_series = data['Tribal Dominance'].dropna()
        individual_dignity_series = data['Individual Dignity'].dropna()

        # If no valid data is found in a column after dropping NaNs, return None
        if tribal_dominance_series.empty or individual_dignity_series.empty:
            return None
            
        tribal_dominance_score = tribal_dominance_series.iloc[0]
        individual_dignity_score = individual_dignity_series.iloc[0]

        # Validate that extracted scores are numeric (int or float)
        if not (isinstance(tribal_dominance_score, (int, float)) and
                isinstance(individual_dignity_score, (int, float))):
            return None

        # Validate that scores are within the expected range [0.0, 1.0]
        if not (0.0 <= tribal_dominance_score <= 1.0 and
                0.0 <= individual_dignity_score <= 1.0):
            return None

        # Calculate identity tension using the absolute difference
        tension = abs(tribal_dominance_score - individual_dignity_score)
        
        return tension

    except Exception:
        # Catch any unexpected errors during processing and return None gracefully
        return None

def calculate_emotional_balance(data, **kwargs):
    """
    Calculate emotional_balance: Difference between hope and fear scores.

    Formula: emotional_balance = average(hope_score) - average(fear_score)

    Args:
        data: pandas DataFrame with dimension scores. Expected to contain
              'hope_score' and 'fear_score' columns, typically ranging from 0.0 to 1.0.
        **kwargs: Additional parameters (not used in this calculation).

    Returns:
        float: Calculated emotional balance score. The result will be
               between -1.0 and 1.0 if input scores are between 0.0 and 1.0.
               Returns None if 'hope_score' or 'fear_score' columns are missing,
               the DataFrame is empty, or if calculation results in NaN due to insufficient valid data.
    """
    import pandas as pd
    import numpy as np

    try:
        # Ensure data is a pandas DataFrame and not empty
        if not isinstance(data, pd.DataFrame) or data.empty:
            return None

        # Define required columns for the calculation
        required_columns = ['hope_score', 'fear_score']

        # Check if all required columns exist in the DataFrame
        if not all(col in data.columns for col in required_columns):
            return None

        # Calculate the average of 'hope_score' and 'fear_score' from the DataFrame.
        # Using .mean() handles potential multiple rows and returns NaN if no valid numbers.
        avg_hope_score = data['hope_score'].mean()
        avg_fear_score = data['fear_score'].mean()

        # If either average is NaN (e.g., column exists but contains only NaNs),
        # it means there's insufficient data to perform the calculation.
        if pd.isna(avg_hope_score) or pd.isna(avg_fear_score):
            return None

        # Perform the core calculation
        emotional_balance_score = avg_hope_score - avg_fear_score

        # Final check for NaN in the result, though unlikely if previous checks pass
        if pd.isna(emotional_balance_score):
            return None

        return float(emotional_balance_score)

    except Exception:
        # Catch any unexpected errors (e.g., non-numeric data that can't be averaged)
        # and return None to indicate a failure in calculation.
        return None

def calculate_success_climate(data, **kwargs):
    """
    Calculate success_climate: Difference between compersion and envy scores.

    Formula: success_climate = compersion_score - envy_score

    Args:
        data (pandas.DataFrame): A pandas DataFrame expected to contain 'compersion'
                                 and 'envy' scores as columns. If multiple rows exist,
                                 the first valid score from each column will be used.
        **kwargs: Additional parameters (not used in this calculation but for framework compatibility).

    Returns:
        float: The calculated success_climate score (difference between compersion and envy),
               or None if 'compersion' or 'envy' scores are missing, not found,
               or contain non-numeric data in the DataFrame.
    """
    import pandas as pd
    import numpy as np
    
    try:
        # Check if the required columns exist in the DataFrame
        if 'compersion' not in data.columns or 'envy' not in data.columns:
            return None

        # Attempt to extract the first value from the 'compersion' column
        # and 'envy' column. Use .iloc[0] to safely get the first element
        # and handle cases where the Series might contain multiple rows.
        compersion_score = data['compersion'].iloc[0]
        envy_score = data['envy'].iloc[0]

        # Check if the extracted scores are NaN (Not a Number)
        if pd.isna(compersion_score) or pd.isna(envy_score):
            return None

        # Ensure the extracted scores are numeric types (int or float)
        if not (isinstance(compersion_score, (int, float)) and
                isinstance(envy_score, (int, float))):
            return None

        # Perform the calculation: difference between compersion and envy scores
        result = float(compersion_score - envy_score)

        return result

    except IndexError:
        # This exception occurs if .iloc[0] is called on a Series that is empty
        # (e.g., column exists but the DataFrame has no rows).
        return None
    except Exception:
        # Catch any other unexpected errors during data access or calculation
        return None

def calculate_relational_climate(data, **kwargs):
    """
    Calculate relational_climate: Difference between amity and enmity scores
    
    Formula: relational_climate = mean(amity_score) - mean(enmity_score)
    
    Args:
        data (pd.DataFrame): DataFrame expected to contain 'amity' and 'enmity'
                             columns. These columns should contain numerical scores
                             (e.g., 0.0-1.0). If multiple rows exist, the mean of the scores
                             for each dimension will be used for the overall calculation.
        **kwargs: Additional parameters (not directly used in this specific calculation,
                  but included for framework consistency).
        
    Returns:
        float: The calculated relational climate score. Assuming amity and enmity scores
               are within 0.0-1.0, this score typically ranges from -1.0 to 1.0.
               Returns None if:
               - 'data' is not a pandas DataFrame or is empty.
               - 'amity' or 'enmity' columns are missing from 'data'.
               - 'amity' or 'enmity' columns contain no valid (non-NaN after coercion)
                 numerical data.
    """
    import pandas as pd
    import numpy as np
    
    try:
        # Validate input DataFrame
        if not isinstance(data, pd.DataFrame) or data.empty:
            return None

        required_columns = ['amity', 'enmity']

        # Check if all required columns exist in the DataFrame
        if not all(col in data.columns for col in required_columns):
            return None

        # Extract and convert columns to numeric, coercing non-numeric values to NaN.
        # This ensures robustness against mixed or non-numerical data types.
        amity_scores = pd.to_numeric(data['amity'], errors='coerce')
        enmity_scores = pd.to_numeric(data['enmity'], errors='coerce')

        # Calculate the mean of valid (non-NaN) scores for each dimension.
        # If all values in a series are NaN, .mean() will return NaN.
        mean_amity = amity_scores.mean()
        mean_enmity = enmity_scores.mean()

        # Check if calculated means are valid numbers. If either mean is NaN, it implies
        # that there was no valid numerical data for that dimension, hence insufficient data.
        if pd.isna(mean_amity) or pd.isna(mean_enmity):
            return None

        # Calculate the relational climate score as the difference
        relational_climate_score = mean_amity - mean_enmity

        # Ensure the return type is float
        return float(relational_climate_score)

    except Exception:
        # Catch any unexpected errors during execution (e.g., issues with data processing)
        # and return None to indicate a failure or inability to compute.
        return None

def calculate_goal_orientation(data, **kwargs):
    """
    Calculate goal_orientation: Difference between cohesive goals and fragmentative goals.
    
    Formula: Average(Individual Dignity - Tribal Dominance)
    Score Range: -1.0 to 1.0 (since each dimension 'Individual Dignity' and 'Tribal Dominance' is scored 0.0-1.0)

    Args:
        data: pandas DataFrame expected to contain 'Individual Dignity' and 'Tribal Dominance' columns.
              Each row represents an observation where these dimensions have been scored.
        **kwargs: Additional parameters (not used in this calculation but included for framework consistency).
        
    Returns:
        float: Calculated average goal_orientation across all valid observations in the DataFrame,
               or None if insufficient data (e.g., missing required columns, all values are NaN or non-numeric).
    """
    import pandas as pd
    import numpy as np
    
    # Define the column names for cohesive and fragmentative goals
    cohesive_col = 'Individual Dignity'
    fragmentative_col = 'Tribal Dominance'

    try:
        # 1. Check if the required columns exist in the DataFrame
        if cohesive_col not in data.columns or fragmentative_col not in data.columns:
            return None
        
        # 2. Extract relevant columns and ensure numeric types, coercing invalid parsing to NaN
        cohesive_scores = pd.to_numeric(data[cohesive_col], errors='coerce')
        fragmentative_scores = pd.to_numeric(data[fragmentative_col], errors='coerce')
        
        # 3. Calculate the raw difference for each row
        differences = cohesive_scores - fragmentative_scores
        
        # 4. Remove any rows where the difference is NaN (due to missing input or non-numeric values)
        valid_differences = differences.dropna()
        
        # 5. If no valid differences remain after dropping NaNs, return None
        if valid_differences.empty:
            return None
            
        # 6. Calculate the average of the valid differences to get the final goal_orientation score
        goal_orientation_score = valid_differences.mean()
        
        # Ensure the result is a standard Python float, not a numpy float type
        return float(goal_orientation_score)

    except Exception:
        # Catch any unexpected errors that might occur during the process
        return None

def calculate_overall_cohesion_index(data, **kwargs):
    """
    Calculate overall_cohesion_index: Comprehensive measure combining all dimensions.

    Formula: The overall cohesion index is calculated as the average of five dimension scores,
    where 'Tribal Dominance' is inverted to reflect its negative contribution to cohesion,
    and other dimensions are assumed to contribute positively.
    Specifically:
    `overall_cohesion_index = ( (1 - tribal_dominance_score) + individual_dignity_score + dimension_3_score + dimension_4_score + dimension_5_score ) / 5`
    All dimension scores are expected to be between 0.0 and 1.0.

    Args:
        data (pd.DataFrame): pandas DataFrame with dimension scores.
                             Expected columns (case-sensitive):
                             - 'tribal_dominance_score'
                             - 'individual_dignity_score'
                             - 'dimension_3_score' (placeholder for 3rd dimension, assumed positive contribution)
                             - 'dimension_4_score' (placeholder for 4th dimension, assumed positive contribution)
                             - 'dimension_5_score' (placeholder for 5th dimension, assumed positive contribution)
                             Note: The 'dimension_X_score' column names should be replaced with actual
                             dimension names from the framework once defined (e.g., 'intergroup_empathy_score').
        **kwargs: Additional parameters (not used in this calculation but included for framework compatibility).

    Returns:
        float: The calculated overall cohesion index (0.0-1.0), or None if insufficient/invalid data.
    """
    import pandas as pd
    import numpy as np

    try:
        if not isinstance(data, pd.DataFrame):
            return None

        # Define the expected dimension columns.
        # These are placeholders for dimension 3, 4, and 5 as they were not explicitly named in the prompt.
        # Users should replace 'dimension_X_score' with actual column names if available.
        dimension_columns = [
            'tribal_dominance_score',
            'individual_dignity_score',
            'dimension_3_score',
            'dimension_4_score',
            'dimension_5_score'
        ]

        # Check if all required columns exist in the DataFrame
        if not all(col in data.columns for col in dimension_columns):
            return None

        # Create a temporary DataFrame for calculation to avoid modifying original and handle data types
        df_scores = data[dimension_columns].copy()

        # Convert relevant columns to numeric, coercing non-numeric values to NaN.
        # This handles potential string or object types and ensures arithmetic operations are valid.
        for col in dimension_columns:
            df_scores[col] = pd.to_numeric(df_scores[col], errors='coerce')

        # Drop rows where all specified dimension scores are NaN, as they cannot contribute to the calculation.
        df_scores.dropna(how='all', subset=dimension_columns, inplace=True)

        if df_scores.empty:
            # No valid data left for calculation after cleaning
            return None

        # Apply transformations based on how each dimension contributes to cohesion.
        # 'Tribal Dominance' is assumed to negatively impact cohesion, so its score is inverted (1 - score).
        df_scores['tribal_dominance_adjusted'] = 1 - df_scores['tribal_dominance_score']

        # Other dimensions are assumed to positively impact cohesion, so their scores are used directly.
        df_scores['individual_dignity_adjusted'] = df_scores['individual_dignity_score']
        df_scores['dimension_3_adjusted'] = df_scores['dimension_3_score']
        df_scores['dimension_4_adjusted'] = df_scores['dimension_4_score']
        df_scores['dimension_5_adjusted'] = df_scores['dimension_5_score']

        # Define the columns that now hold the cohesion-adjusted scores.
        adjusted_cols = [
            'tribal_dominance_adjusted',
            'individual_dignity_adjusted',
            'dimension_3_adjusted',
            'dimension_4_adjusted',
            'dimension_5_adjusted'
        ]

        # Calculate the row-wise mean of the adjusted scores.
        # `.mean(axis=1)` calculates the mean for each row, ignoring NaN values in a row.
        # If all adjusted scores in a row are NaN, that row's result will be NaN.
        row_cohesion_indices = df_scores[adjusted_cols].mean(axis=1)

        # Calculate the overall mean from all valid row cohesion indices.
        # `.mean()` on a Series ignores NaN values. If all values are NaN, it returns NaN.
        overall_index = row_cohesion_indices.mean()

        # If the final overall_index is NaN (e.g., no valid data points across the entire dataset), return None.
        if pd.isna(overall_index):
            return None

        # Ensure the final result is within the 0.0-1.0 range, as per score range requirement.
        # .item() converts the numpy float to a standard Python float.
        return np.clip(overall_index, 0.0, 1.0).item()

    except Exception:
        # Catch any unexpected errors during the process (e.g., issues with pandas operations,
        # or underlying data problems not caught by explicit checks).
        return None

def calculate_all_derived_metrics(data: pd.DataFrame) -> Dict[str, Optional[float]]:
    """
    Calculate all derived metrics for the given dataset.
    
    Args:
        data: pandas DataFrame with dimension scores
        
    Returns:
        Dictionary mapping metric names to calculated values
    """
    results = {}
    
    # Get all calculation functions from this module
    import inspect
    current_module = inspect.getmodule(inspect.currentframe())
    
    for name, obj in inspect.getmembers(current_module):
        if (inspect.isfunction(obj) and 
            name.startswith('calculate_') and 
            name not in ['calculate_all_derived_metrics', 'calculate_derived_metrics']):
            try:
                results[name.replace('calculate_', '')] = obj(data)
            except Exception as e:
                results[name.replace('calculate_', '')] = None
                
    return results


def calculate_derived_metrics(data: pd.DataFrame) -> pd.DataFrame:
    """
    Template-compatible wrapper function for derived metrics calculation.
    
    This function is called by the universal notebook template and returns
    the original data with additional derived metric columns.
    
    Args:
        data: pandas DataFrame with dimension scores
        
    Returns:
        DataFrame with original data plus derived metric columns
    """
    # Calculate all derived metrics
    derived_metrics = calculate_all_derived_metrics(data)
    
    # Create a copy of the original data
    result = data.copy()
    
    # Add derived metrics as new columns
    for metric_name, metric_value in derived_metrics.items():
        if metric_value is not None:
            # For scalar metrics, broadcast to all rows
            result[metric_name] = metric_value
        else:
            # For failed calculations, use NaN
            result[metric_name] = np.nan
    
    return result
