{"stage_1_raw_data": {"analysis_plan": {"stage": "raw_data_collection", "experiment_summary": "This stage focuses on the collection and initial validation of raw analytical data generated by the LLM. The plan ensures the capture of all 30 specified data points (10 dimensional scores, 10 salience scores, 10 confidence scores) for each analysis run, as defined by the Civic Analysis Framework (CAF) v7.1. Validation tasks will verify data completeness, adherence to score ranges (0.0-1.0), and integrity across experimental groups.", "tasks": {"initial_data_overview": {"tool": "create_summary_statistics", "parameters": {"metrics": ["dignity_score", "tribalism_score", "truth_score", "manipulation_score", "justice_score", "resentment_score", "hope_score", "fear_score", "pragmatism_score", "fantasy_score", "dignity_salience", "tribalism_salience", "truth_salience", "manipulation_salience", "justice_salience", "resentment_salience", "hope_salience", "fear_salience", "pragmatism_salience", "fantasy_salience", "dignity_confidence", "tribalism_confidence", "truth_confidence", "manipulation_confidence", "justice_confidence", "resentment_confidence", "hope_confidence", "fear_confidence", "pragmatism_confidence", "fantasy_confidence"], "summary_types": ["count", "mean", "std", "min", "max"]}, "purpose": "To generate a comprehensive overview of all collected raw data points. This task verifies data completeness (via 'count') and checks that all scores and metadata fall within the expected 0.0-1.0 range (via 'min' and 'max'), as required by the framework's validation rules."}, "validate_dimensional_scores": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["dignity_score", "tribalism_score", "truth_score", "manipulation_score", "justice_score", "resentment_score", "hope_score", "fear_score", "pragmatism_score", "fantasy_score"]}, "purpose": "To specifically validate that all core dimensional scores from the LLM analysis fall within the required 0.0 to 1.0 range. This is a primary quality check on the raw extracted data."}, "validate_salience_metadata": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["dignity_salience", "tribalism_salience", "truth_salience", "manipulation_salience", "justice_salience", "resentment_salience", "hope_salience", "fear_salience", "pragmatism_salience", "fantasy_salience"]}, "purpose": "To validate that all collected salience metadata scores fall within the required 0.0 to 1.0 range, ensuring the integrity of the metadata required by the CAF v7.1 framework."}, "validate_confidence_metadata": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["dignity_confidence", "tribalism_confidence", "truth_confidence", "manipulation_confidence", "justice_confidence", "resentment_confidence", "hope_confidence", "fear_confidence", "pragmatism_confidence", "fantasy_confidence"]}, "purpose": "To validate that all collected confidence metadata scores fall within the required 0.0 to 1.0 range, confirming the quality of the analytical certainty metrics."}, "validate_data_integrity_by_group": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["dignity_score", "tribalism_score", "justice_score", "resentment_score", "hope_score"], "grouping_variable": "ideology"}, "purpose": "To ensure that raw data has been collected successfully for all key experimental groups ('conservative', 'progressive'). This task verifies that corpus metadata has been joined correctly and provides a preliminary check for systematic collection failures before formal analysis begins."}}}, "results": {"initial_data_overview": {"type": "summary_statistics", "metrics": ["dignity_score", "tribalism_score", "truth_score", "manipulation_score", "justice_score", "resentment_score", "hope_score", "fear_score", "pragmatism_score", "fantasy_score", "dignity_salience", "tribalism_salience", "truth_salience", "manipulation_salience", "justice_salience", "resentment_salience", "hope_salience", "fear_salience", "pragmatism_salience", "fantasy_salience", "dignity_confidence", "tribalism_confidence", "truth_confidence", "manipulation_confidence", "justice_confidence", "resentment_confidence", "hope_confidence", "fear_confidence", "pragmatism_confidence", "fantasy_confidence"], "summary_types": ["count", "mean", "std", "min", "max"], "results": {"dignity_score": {"mean": 0.775, "std": 0.03535533905932741, "min": 0.75, "max": 0.8, "count": 2}, "tribalism_score": {"mean": 0.44999999999999996, "std": 0.35355339059327373, "min": 0.2, "max": 0.7, "count": 2}, "truth_score": {"mean": 0.7, "std": 0.07071067811865474, "min": 0.65, "max": 0.75, "count": 2}, "manipulation_score": {"mean": 0.5, "std": 0.282842712474619, "min": 0.3, "max": 0.7, "count": 2}, "justice_score": {"mean": 0.625, "std": 0.31819805153394637, "min": 0.4, "max": 0.85, "count": 2}, "resentment_score": {"mean": 0.425, "std": 0.24748737341529162, "min": 0.25, "max": 0.6, "count": 2}, "hope_score": {"mean": 0.7, "std": 0.0, "min": 0.7, "max": 0.7, "count": 2}, "fear_score": {"mean": 0.22499999999999998, "std": 0.10606601717798213, "min": 0.15, "max": 0.3, "count": 2}, "pragmatism_score": {"mean": 0.625, "std": 0.03535533905932741, "min": 0.6, "max": 0.65, "count": 2}, "fantasy_score": {"mean": 0.125, "std": 0.10606601717798214, "min": 0.05, "max": 0.2, "count": 2}, "dignity_salience": {"mean": 0.8500000000000001, "std": 0.07071067811865474, "min": 0.8, "max": 0.9, "count": 2}, "tribalism_salience": {"mean": 0.55, "std": 0.3535533905932738, "min": 0.3, "max": 0.8, "count": 2}, "truth_salience": {"mean": 0.7749999999999999, "std": 0.10606601717798214, "min": 0.7, "max": 0.85, "count": 2}, "manipulation_salience": {"mean": 0.575, "std": 0.24748737341529162, "min": 0.4, "max": 0.75, "count": 2}, "justice_salience": {"mean": 0.7, "std": 0.35355339059327373, "min": 0.45, "max": 0.95, "count": 2}, "resentment_salience": {"mean": 0.5249999999999999, "std": 0.24748737341529162, "min": 0.35, "max": 0.7, "count": 2}, "hope_salience": {"mean": 0.75, "std": 0.0, "min": 0.75, "max": 0.75, "count": 2}, "fear_salience": {"mean": 0.275, "std": 0.10606601717798211, "min": 0.2, "max": 0.35, "count": 2}, "pragmatism_salience": {"mean": 0.675, "std": 0.03535533905932733, "min": 0.65, "max": 0.7, "count": 2}, "fantasy_salience": {"mean": 0.175, "std": 0.10606601717798213, "min": 0.1, "max": 0.25, "count": 2}, "dignity_confidence": {"mean": 0.8, "std": 0.0, "min": 0.8, "max": 0.8, "count": 2}, "tribalism_confidence": {"mean": 0.725, "std": 0.03535533905932741, "min": 0.7, "max": 0.75, "count": 2}, "truth_confidence": {"mean": 0.725, "std": 0.03535533905932741, "min": 0.7, "max": 0.75, "count": 2}, "manipulation_confidence": {"mean": 0.675, "std": 0.03535533905932733, "min": 0.65, "max": 0.7, "count": 2}, "justice_confidence": {"mean": 0.7749999999999999, "std": 0.10606601717798214, "min": 0.7, "max": 0.85, "count": 2}, "resentment_confidence": {"mean": 0.6499999999999999, "std": 0.07071067811865474, "min": 0.6, "max": 0.7, "count": 2}, "hope_confidence": {"mean": 0.75, "std": 0.07071067811865482, "min": 0.7, "max": 0.8, "count": 2}, "fear_confidence": {"mean": 0.5, "std": 0.282842712474619, "min": 0.3, "max": 0.7, "count": 2}, "pragmatism_confidence": {"mean": 0.7, "std": 0.07071067811865474, "min": 0.65, "max": 0.75, "count": 2}, "fantasy_confidence": {"mean": 0.475, "std": 0.38890872965260115, "min": 0.2, "max": 0.75, "count": 2}}, "missing_metrics": []}, "validate_dimensional_scores": {"type": "descriptive_stats", "columns_analyzed": ["dignity_score", "tribalism_score", "truth_score", "manipulation_score", "justice_score", "resentment_score", "hope_score", "fear_score", "pragmatism_score", "fantasy_score"], "results": {"dignity_score": {"count": 2, "mean": 0.775, "std": 0.03535533905932741, "min": 0.75, "max": 0.8, "median": 0.775, "q25": 0.7625, "q75": 0.7875000000000001, "skewness": NaN, "kurtosis": NaN}, "tribalism_score": {"count": 2, "mean": 0.44999999999999996, "std": 0.35355339059327373, "min": 0.2, "max": 0.7, "median": 0.44999999999999996, "q25": 0.325, "q75": 0.575, "skewness": NaN, "kurtosis": NaN}, "truth_score": {"count": 2, "mean": 0.7, "std": 0.07071067811865474, "min": 0.65, "max": 0.75, "median": 0.7, "q25": 0.675, "q75": 0.725, "skewness": NaN, "kurtosis": NaN}, "manipulation_score": {"count": 2, "mean": 0.5, "std": 0.282842712474619, "min": 0.3, "max": 0.7, "median": 0.5, "q25": 0.39999999999999997, "q75": 0.6, "skewness": NaN, "kurtosis": NaN}, "justice_score": {"count": 2, "mean": 0.625, "std": 0.31819805153394637, "min": 0.4, "max": 0.85, "median": 0.625, "q25": 0.5125, "q75": 0.7375, "skewness": NaN, "kurtosis": NaN}, "resentment_score": {"count": 2, "mean": 0.425, "std": 0.24748737341529162, "min": 0.25, "max": 0.6, "median": 0.425, "q25": 0.3375, "q75": 0.5125, "skewness": NaN, "kurtosis": NaN}, "hope_score": {"count": 2, "mean": 0.7, "std": 0.0, "min": 0.7, "max": 0.7, "median": 0.7, "q25": 0.7, "q75": 0.7, "skewness": NaN, "kurtosis": NaN}, "fear_score": {"count": 2, "mean": 0.22499999999999998, "std": 0.10606601717798213, "min": 0.15, "max": 0.3, "median": 0.22499999999999998, "q25": 0.1875, "q75": 0.2625, "skewness": NaN, "kurtosis": NaN}, "pragmatism_score": {"count": 2, "mean": 0.625, "std": 0.03535533905932741, "min": 0.6, "max": 0.65, "median": 0.625, "q25": 0.6125, "q75": 0.6375, "skewness": NaN, "kurtosis": NaN}, "fantasy_score": {"count": 2, "mean": 0.125, "std": 0.10606601717798214, "min": 0.05, "max": 0.2, "median": 0.125, "q25": 0.08750000000000001, "q75": 0.1625, "skewness": NaN, "kurtosis": NaN}}}, "validate_salience_metadata": {"type": "descriptive_stats", "columns_analyzed": ["dignity_salience", "tribalism_salience", "truth_salience", "manipulation_salience", "justice_salience", "resentment_salience", "hope_salience", "fear_salience", "pragmatism_salience", "fantasy_salience"], "results": {"dignity_salience": {"count": 2, "mean": 0.8500000000000001, "std": 0.07071067811865474, "min": 0.8, "max": 0.9, "median": 0.8500000000000001, "q25": 0.8250000000000001, "q75": 0.875, "skewness": NaN, "kurtosis": NaN}, "tribalism_salience": {"count": 2, "mean": 0.55, "std": 0.3535533905932738, "min": 0.3, "max": 0.8, "median": 0.55, "q25": 0.425, "q75": 0.675, "skewness": NaN, "kurtosis": NaN}, "truth_salience": {"count": 2, "mean": 0.7749999999999999, "std": 0.10606601717798214, "min": 0.7, "max": 0.85, "median": 0.7749999999999999, "q25": 0.7374999999999999, "q75": 0.8125, "skewness": NaN, "kurtosis": NaN}, "manipulation_salience": {"count": 2, "mean": 0.575, "std": 0.24748737341529162, "min": 0.4, "max": 0.75, "median": 0.575, "q25": 0.48750000000000004, "q75": 0.6625, "skewness": NaN, "kurtosis": NaN}, "justice_salience": {"count": 2, "mean": 0.7, "std": 0.35355339059327373, "min": 0.45, "max": 0.95, "median": 0.7, "q25": 0.575, "q75": 0.825, "skewness": NaN, "kurtosis": NaN}, "resentment_salience": {"count": 2, "mean": 0.5249999999999999, "std": 0.24748737341529162, "min": 0.35, "max": 0.7, "median": 0.5249999999999999, "q25": 0.4375, "q75": 0.6124999999999999, "skewness": NaN, "kurtosis": NaN}, "hope_salience": {"count": 2, "mean": 0.75, "std": 0.0, "min": 0.75, "max": 0.75, "median": 0.75, "q25": 0.75, "q75": 0.75, "skewness": NaN, "kurtosis": NaN}, "fear_salience": {"count": 2, "mean": 0.275, "std": 0.10606601717798211, "min": 0.2, "max": 0.35, "median": 0.275, "q25": 0.2375, "q75": 0.3125, "skewness": NaN, "kurtosis": NaN}, "pragmatism_salience": {"count": 2, "mean": 0.675, "std": 0.03535533905932733, "min": 0.65, "max": 0.7, "median": 0.675, "q25": 0.6625, "q75": 0.6875, "skewness": NaN, "kurtosis": NaN}, "fantasy_salience": {"count": 2, "mean": 0.175, "std": 0.10606601717798213, "min": 0.1, "max": 0.25, "median": 0.175, "q25": 0.1375, "q75": 0.2125, "skewness": NaN, "kurtosis": NaN}}}, "validate_confidence_metadata": {"type": "descriptive_stats", "columns_analyzed": ["dignity_confidence", "tribalism_confidence", "truth_confidence", "manipulation_confidence", "justice_confidence", "resentment_confidence", "hope_confidence", "fear_confidence", "pragmatism_confidence", "fantasy_confidence"], "results": {"dignity_confidence": {"count": 2, "mean": 0.8, "std": 0.0, "min": 0.8, "max": 0.8, "median": 0.8, "q25": 0.8, "q75": 0.8, "skewness": NaN, "kurtosis": NaN}, "tribalism_confidence": {"count": 2, "mean": 0.725, "std": 0.03535533905932741, "min": 0.7, "max": 0.75, "median": 0.725, "q25": 0.7124999999999999, "q75": 0.7375, "skewness": NaN, "kurtosis": NaN}, "truth_confidence": {"count": 2, "mean": 0.725, "std": 0.03535533905932741, "min": 0.7, "max": 0.75, "median": 0.725, "q25": 0.7124999999999999, "q75": 0.7375, "skewness": NaN, "kurtosis": NaN}, "manipulation_confidence": {"count": 2, "mean": 0.675, "std": 0.03535533905932733, "min": 0.65, "max": 0.7, "median": 0.675, "q25": 0.6625, "q75": 0.6875, "skewness": NaN, "kurtosis": NaN}, "justice_confidence": {"count": 2, "mean": 0.7749999999999999, "std": 0.10606601717798214, "min": 0.7, "max": 0.85, "median": 0.7749999999999999, "q25": 0.7374999999999999, "q75": 0.8125, "skewness": NaN, "kurtosis": NaN}, "resentment_confidence": {"count": 2, "mean": 0.6499999999999999, "std": 0.07071067811865474, "min": 0.6, "max": 0.7, "median": 0.6499999999999999, "q25": 0.625, "q75": 0.6749999999999999, "skewness": NaN, "kurtosis": NaN}, "hope_confidence": {"count": 2, "mean": 0.75, "std": 0.07071067811865482, "min": 0.7, "max": 0.8, "median": 0.75, "q25": 0.725, "q75": 0.775, "skewness": NaN, "kurtosis": NaN}, "fear_confidence": {"count": 2, "mean": 0.5, "std": 0.282842712474619, "min": 0.3, "max": 0.7, "median": 0.5, "q25": 0.39999999999999997, "q75": 0.6, "skewness": NaN, "kurtosis": NaN}, "pragmatism_confidence": {"count": 2, "mean": 0.7, "std": 0.07071067811865474, "min": 0.65, "max": 0.75, "median": 0.7, "q25": 0.675, "q75": 0.725, "skewness": NaN, "kurtosis": NaN}, "fantasy_confidence": {"count": 2, "mean": 0.475, "std": 0.38890872965260115, "min": 0.2, "max": 0.75, "median": 0.475, "q25": 0.3375, "q75": 0.6125, "skewness": NaN, "kurtosis": NaN}}}, "validate_data_integrity_by_group": {"type": "descriptive_stats_grouped", "grouping_variable": "ideology", "groups": {"conservative": {"dignity_score": {"count": 1, "mean": 0.75, "std": NaN, "min": 0.75, "max": 0.75}, "tribalism_score": {"count": 1, "mean": 0.2, "std": NaN, "min": 0.2, "max": 0.2}, "justice_score": {"count": 1, "mean": 0.4, "std": NaN, "min": 0.4, "max": 0.4}, "resentment_score": {"count": 1, "mean": 0.25, "std": NaN, "min": 0.25, "max": 0.25}, "hope_score": {"count": 1, "mean": 0.7, "std": NaN, "min": 0.7, "max": 0.7}}, "progressive": {"dignity_score": {"count": 1, "mean": 0.8, "std": NaN, "min": 0.8, "max": 0.8}, "tribalism_score": {"count": 1, "mean": 0.7, "std": NaN, "min": 0.7, "max": 0.7}, "justice_score": {"count": 1, "mean": 0.85, "std": NaN, "min": 0.85, "max": 0.85}, "resentment_score": {"count": 1, "mean": 0.6, "std": NaN, "min": 0.6, "max": 0.6}, "hope_score": {"count": 1, "mean": 0.7, "std": NaN, "min": 0.7, "max": 0.7}}}}}, "errors": []}, "stage_2_derived_metrics": {"analysis_plan": {"stage": "derived_metrics_analysis", "experiment_summary": "This plan outlines the calculation of derived metrics based on the Civic Analysis Framework (CAF) v7.1 and subsequent statistical analysis. It includes the computation of five tension scores and an overall Civic Character Index. The plan also specifies validation of these new metrics, generation of descriptive statistics, and a correlation analysis to explore relationships between character dimensions. Statistical comparisons between ideological groups are not planned as the necessary grouping variables (e.g., 'ideology', 'speaker') are not present in the provided raw data columns.", "tasks": {"task_01_calculate_derived_metrics": {"tool": "calculate_derived_metrics", "parameters": {"metric_formulas": {"dignity_tribalism_tension": "(dignity_score + (1 - tribalism_score)) / 2", "truth_manipulation_tension": "(truth_score + (1 - manipulation_score)) / 2", "justice_resentment_tension": "(justice_score + (1 - resentment_score)) / 2", "hope_fear_tension": "(hope_score + (1 - fear_score)) / 2", "pragmatism_fantasy_tension": "(pragmatism_score + (1 - fantasy_score)) / 2", "civic_character_index": "(dignity_tribalism_tension + truth_manipulation_tension + justice_resentment_tension + hope_fear_tension + pragmatism_fantasy_tension) / 5"}, "input_columns": ["dignity_score", "tribalism_score", "truth_score", "manipulation_score", "justice_score", "resentment_score", "hope_score", "fear_score", "pragmatism_score", "fantasy_score"]}, "purpose": "To calculate the five core tension scores and the composite Civic Character Index as defined in the CAF v7.1 framework specification. These derived metrics are essential for higher-level analysis and hypothesis testing."}, "task_02_validate_calculated_metrics": {"tool": "validate_calculated_metrics", "parameters": {"validation_rules": [{"rule_name": "missing_data_check", "columns": ["dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "hope_fear_tension", "pragmatism_fantasy_tension", "civic_character_index"]}, {"rule_name": "range_check", "columns": ["dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "hope_fear_tension", "pragmatism_fantasy_tension", "civic_character_index"], "min_value": 0.0, "max_value": 1.0}], "quality_thresholds": {"missing_data_tolerance": 0.05}}, "purpose": "To ensure the newly calculated derived metrics are free of null values and fall within their expected theoretical range (0.0 to 1.0), confirming the integrity of the calculation step."}, "task_03_descriptive_statistics_all_metrics": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["dignity_score", "tribalism_score", "truth_score", "manipulation_score", "justice_score", "resentment_score", "hope_score", "fear_score", "pragmatism_score", "fantasy_score", "dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "hope_fear_tension", "pragmatism_fantasy_tension", "civic_character_index"]}, "purpose": "To generate descriptive statistics (mean, median, std dev, min, max) for all raw scores and derived metrics to understand their overall distribution and central tendencies across the entire dataset."}, "task_04_generate_character_correlation_matrix": {"tool": "generate_correlation_matrix", "parameters": {"dimensions": ["dignity_score", "tribalism_score", "truth_score", "manipulation_score", "justice_score", "resentment_score", "hope_score", "fear_score", "pragmatism_score", "fantasy_score"], "correlation_method": "pearson"}, "purpose": "To fulfill the 'character_correlation_matrix' validation requirement from the experiment configuration. This analysis will identify relationships and potential trade-offs between the core character dimensions."}, "task_05_summarize_metadata": {"tool": "create_summary_statistics", "parameters": {"metrics": ["dignity_salience", "tribalism_salience", "truth_salience", "manipulation_salience", "justice_salience", "resentment_salience", "hope_salience", "fear_salience", "pragmatism_salience", "fantasy_salience", "dignity_confidence", "tribalism_confidence", "truth_confidence", "manipulation_confidence", "justice_confidence", "resentment_confidence", "hope_confidence", "fear_confidence", "pragmatism_confidence", "fantasy_confidence", "extraction_time_seconds"], "summary_types": ["mean", "std", "min", "max"]}, "purpose": "To summarize the salience and confidence metadata scores, as well as the performance of the extraction gasket (extraction_time_seconds), providing data to assess the v7.1 architecture's performance (related to H3)."}}}, "results": {"task_01_calculate_derived_metrics": {"type": "derived_metrics_calculation", "success": true, "calculated_metrics": {"hope_fear_tension": [0.7, 0.7749999999999999], "dignity_tribalism_tension": [0.55, 0.775], "truth_manipulation_tension": [0.525, 0.675], "justice_resentment_tension": [0.625, 0.575], "pragmatism_fantasy_tension": [0.7250000000000001, 0.7749999999999999], "civic_character_index": [0.6250000000000001, 0.7150000000000001]}, "successful_calculations": ["hope_fear_tension", "dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "pragmatism_fantasy_tension", "civic_character_index"], "failed_calculations": [], "formulas_used": ["dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "hope_fear_tension", "pragmatism_fantasy_tension", "civic_character_index"], "input_columns": ["dignity_score", "tribalism_score", "truth_score", "manipulation_score", "justice_score", "resentment_score", "hope_score", "fear_score", "pragmatism_score", "fantasy_score"], "total_metrics": 6, "success_rate": 1.0}, "task_02_validate_calculated_metrics": {"type": "metric_validation", "validation_rules": ["{'rule_name': 'missing_data_check', 'columns': ['dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension', 'civic_character_index']}", "{'rule_name': 'range_check', 'columns': ['dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension', 'civic_character_index'], 'min_value': 0.0, 'max_value': 1.0}"], "results": {"unknown_rule": {"status": "not_found", "message": "Metric 'unknown_rule' not found in dataframe", "available_columns": ["aid", "document_type", "political_party", "year", "temporal_sequence", "speaker", "ideology", "character_profile", "event", "word_count", "source", "preparation_notes", "dignity_score", "tribalism_score", "dignity_salience", "tribalism_salience", "dignity_confidence", "tribalism_confidence", "truth_score", "manipulation_score", "truth_salience", "manipulation_salience", "truth_confidence", "manipulation_confidence", "justice_score", "resentment_score", "justice_salience", "resentment_salience", "justice_confidence", "resentment_confidence", "hope_score", "fear_score", "hope_salience", "fear_salience", "hope_confidence", "fear_confidence", "pragmatism_score", "fantasy_score", "pragmatism_salience", "fantasy_salience", "pragmatism_confidence", "fantasy_confidence", "gasket_version", "extraction_time_seconds", "hope_fear_tension", "dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "pragmatism_fantasy_tension", "civic_character_index"], "note": "This is a framework-agnostic validation - LLMs determine validation logic"}}, "quality_thresholds": {"missing_data_tolerance": 0.05}}, "task_03_descriptive_statistics_all_metrics": {"type": "descriptive_stats", "columns_analyzed": ["dignity_score", "tribalism_score", "truth_score", "manipulation_score", "justice_score", "resentment_score", "hope_score", "fear_score", "pragmatism_score", "fantasy_score", "dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "hope_fear_tension", "pragmatism_fantasy_tension", "civic_character_index"], "results": {"dignity_score": {"count": 2, "mean": 0.775, "std": 0.03535533905932741, "min": 0.75, "max": 0.8, "median": 0.775, "q25": 0.7625, "q75": 0.7875000000000001, "skewness": NaN, "kurtosis": NaN}, "tribalism_score": {"count": 2, "mean": 0.44999999999999996, "std": 0.35355339059327373, "min": 0.2, "max": 0.7, "median": 0.44999999999999996, "q25": 0.325, "q75": 0.575, "skewness": NaN, "kurtosis": NaN}, "truth_score": {"count": 2, "mean": 0.7, "std": 0.07071067811865474, "min": 0.65, "max": 0.75, "median": 0.7, "q25": 0.675, "q75": 0.725, "skewness": NaN, "kurtosis": NaN}, "manipulation_score": {"count": 2, "mean": 0.5, "std": 0.282842712474619, "min": 0.3, "max": 0.7, "median": 0.5, "q25": 0.39999999999999997, "q75": 0.6, "skewness": NaN, "kurtosis": NaN}, "justice_score": {"count": 2, "mean": 0.625, "std": 0.31819805153394637, "min": 0.4, "max": 0.85, "median": 0.625, "q25": 0.5125, "q75": 0.7375, "skewness": NaN, "kurtosis": NaN}, "resentment_score": {"count": 2, "mean": 0.425, "std": 0.24748737341529162, "min": 0.25, "max": 0.6, "median": 0.425, "q25": 0.3375, "q75": 0.5125, "skewness": NaN, "kurtosis": NaN}, "hope_score": {"count": 2, "mean": 0.7, "std": 0.0, "min": 0.7, "max": 0.7, "median": 0.7, "q25": 0.7, "q75": 0.7, "skewness": NaN, "kurtosis": NaN}, "fear_score": {"count": 2, "mean": 0.22499999999999998, "std": 0.10606601717798213, "min": 0.15, "max": 0.3, "median": 0.22499999999999998, "q25": 0.1875, "q75": 0.2625, "skewness": NaN, "kurtosis": NaN}, "pragmatism_score": {"count": 2, "mean": 0.625, "std": 0.03535533905932741, "min": 0.6, "max": 0.65, "median": 0.625, "q25": 0.6125, "q75": 0.6375, "skewness": NaN, "kurtosis": NaN}, "fantasy_score": {"count": 2, "mean": 0.125, "std": 0.10606601717798214, "min": 0.05, "max": 0.2, "median": 0.125, "q25": 0.08750000000000001, "q75": 0.1625, "skewness": NaN, "kurtosis": NaN}, "dignity_tribalism_tension": {"count": 2, "mean": 0.6625000000000001, "std": 0.15909902576697318, "min": 0.55, "max": 0.775, "median": 0.6625000000000001, "q25": 0.6062500000000001, "q75": 0.71875, "skewness": NaN, "kurtosis": NaN}, "truth_manipulation_tension": {"count": 2, "mean": 0.6000000000000001, "std": 0.10606601717798214, "min": 0.525, "max": 0.675, "median": 0.6000000000000001, "q25": 0.5625, "q75": 0.6375000000000001, "skewness": NaN, "kurtosis": NaN}, "justice_resentment_tension": {"count": 2, "mean": 0.6, "std": 0.03535533905932741, "min": 0.575, "max": 0.625, "median": 0.6, "q25": 0.5874999999999999, "q75": 0.6125, "skewness": NaN, "kurtosis": NaN}, "hope_fear_tension": {"count": 2, "mean": 0.7374999999999999, "std": 0.053033008588991036, "min": 0.7, "max": 0.7749999999999999, "median": 0.7374999999999999, "q25": 0.71875, "q75": 0.7562499999999999, "skewness": NaN, "kurtosis": NaN}, "pragmatism_fantasy_tension": {"count": 2, "mean": 0.75, "std": 0.03535533905932725, "min": 0.7250000000000001, "max": 0.7749999999999999, "median": 0.75, "q25": 0.7375, "q75": 0.7625, "skewness": NaN, "kurtosis": NaN}, "civic_character_index": {"count": 2, "mean": 0.6700000000000002, "std": 0.06363961030678926, "min": 0.6250000000000001, "max": 0.7150000000000001, "median": 0.6700000000000002, "q25": 0.6475000000000001, "q75": 0.6925000000000001, "skewness": NaN, "kurtosis": NaN}}}, "task_04_generate_character_correlation_matrix": {"type": "correlation_matrix", "dimensions": ["dignity_score", "tribalism_score", "truth_score", "manipulation_score", "justice_score", "resentment_score", "hope_score", "fear_score", "pragmatism_score", "fantasy_score"], "method": "pearson", "matrix": {"dignity_score": {"dignity_score": 1.0, "tribalism_score": 0.9999999999999999, "truth_score": 0.9999999999999994, "manipulation_score": 1.0, "justice_score": 1.0, "resentment_score": 1.0000000000000002, "hope_score": NaN, "fear_score": 0.9999999999999999, "pragmatism_score": 1.0, "fantasy_score": 0.9999999999999999}, "tribalism_score": {"dignity_score": 0.9999999999999999, "tribalism_score": 1.0, "truth_score": 0.9999999999999994, "manipulation_score": 1.0000000000000002, "justice_score": 1.0, "resentment_score": 1.0, "hope_score": NaN, "fear_score": 0.9999999999999998, "pragmatism_score": 1.0, "fantasy_score": 0.9999999999999998}, "truth_score": {"dignity_score": 0.9999999999999994, "tribalism_score": 0.9999999999999994, "truth_score": 1.0, "manipulation_score": 1.0000000000000007, "justice_score": 1.0000000000000004, "resentment_score": 1.0000000000000007, "hope_score": NaN, "fear_score": 1.0000000000000004, "pragmatism_score": 1.0000000000000007, "fantasy_score": 1.0000000000000004}, "manipulation_score": {"dignity_score": 1.0, "tribalism_score": 1.0000000000000002, "truth_score": 1.0000000000000007, "manipulation_score": 1.0, "justice_score": 1.0, "resentment_score": 1.0, "hope_score": NaN, "fear_score": 0.9999999999999998, "pragmatism_score": 1.0, "fantasy_score": 0.9999999999999998}, "justice_score": {"dignity_score": 1.0, "tribalism_score": 1.0, "truth_score": 1.0000000000000004, "manipulation_score": 1.0, "justice_score": 1.0, "resentment_score": 1.0, "hope_score": NaN, "fear_score": 0.9999999999999998, "pragmatism_score": 1.0, "fantasy_score": 1.0}, "resentment_score": {"dignity_score": 1.0000000000000002, "tribalism_score": 1.0, "truth_score": 1.0000000000000007, "manipulation_score": 1.0, "justice_score": 1.0, "resentment_score": 1.0, "hope_score": NaN, "fear_score": 0.9999999999999999, "pragmatism_score": 1.0000000000000002, "fantasy_score": 1.0}, "hope_score": {"dignity_score": NaN, "tribalism_score": NaN, "truth_score": NaN, "manipulation_score": NaN, "justice_score": NaN, "resentment_score": NaN, "hope_score": NaN, "fear_score": NaN, "pragmatism_score": NaN, "fantasy_score": NaN}, "fear_score": {"dignity_score": 0.9999999999999999, "tribalism_score": 0.9999999999999998, "truth_score": 1.0000000000000004, "manipulation_score": 0.9999999999999998, "justice_score": 0.9999999999999998, "resentment_score": 0.9999999999999999, "hope_score": NaN, "fear_score": 1.0, "pragmatism_score": 1.0000000000000002, "fantasy_score": 1.0}, "pragmatism_score": {"dignity_score": 1.0, "tribalism_score": 1.0, "truth_score": 1.0000000000000007, "manipulation_score": 1.0, "justice_score": 1.0, "resentment_score": 1.0000000000000002, "hope_score": NaN, "fear_score": 1.0000000000000002, "pragmatism_score": 1.0, "fantasy_score": 0.9999999999999999}, "fantasy_score": {"dignity_score": 0.9999999999999999, "tribalism_score": 0.9999999999999998, "truth_score": 1.0000000000000004, "manipulation_score": 0.9999999999999998, "justice_score": 1.0, "resentment_score": 1.0, "hope_score": NaN, "fear_score": 1.0, "pragmatism_score": 0.9999999999999999, "fantasy_score": 1.0}}, "missing_dimensions": []}, "task_05_summarize_metadata": {"type": "summary_statistics", "metrics": ["dignity_salience", "tribalism_salience", "truth_salience", "manipulation_salience", "justice_salience", "resentment_salience", "hope_salience", "fear_salience", "pragmatism_salience", "fantasy_salience", "dignity_confidence", "tribalism_confidence", "truth_confidence", "manipulation_confidence", "justice_confidence", "resentment_confidence", "hope_confidence", "fear_confidence", "pragmatism_confidence", "fantasy_confidence", "extraction_time_seconds"], "summary_types": ["mean", "std", "min", "max"], "results": {"dignity_salience": {"mean": 0.8500000000000001, "std": 0.07071067811865474, "min": 0.8, "max": 0.9}, "tribalism_salience": {"mean": 0.55, "std": 0.3535533905932738, "min": 0.3, "max": 0.8}, "truth_salience": {"mean": 0.7749999999999999, "std": 0.10606601717798214, "min": 0.7, "max": 0.85}, "manipulation_salience": {"mean": 0.575, "std": 0.24748737341529162, "min": 0.4, "max": 0.75}, "justice_salience": {"mean": 0.7, "std": 0.35355339059327373, "min": 0.45, "max": 0.95}, "resentment_salience": {"mean": 0.5249999999999999, "std": 0.24748737341529162, "min": 0.35, "max": 0.7}, "hope_salience": {"mean": 0.75, "std": 0.0, "min": 0.75, "max": 0.75}, "fear_salience": {"mean": 0.275, "std": 0.10606601717798211, "min": 0.2, "max": 0.35}, "pragmatism_salience": {"mean": 0.675, "std": 0.03535533905932733, "min": 0.65, "max": 0.7}, "fantasy_salience": {"mean": 0.175, "std": 0.10606601717798213, "min": 0.1, "max": 0.25}, "dignity_confidence": {"mean": 0.8, "std": 0.0, "min": 0.8, "max": 0.8}, "tribalism_confidence": {"mean": 0.725, "std": 0.03535533905932741, "min": 0.7, "max": 0.75}, "truth_confidence": {"mean": 0.725, "std": 0.03535533905932741, "min": 0.7, "max": 0.75}, "manipulation_confidence": {"mean": 0.675, "std": 0.03535533905932733, "min": 0.65, "max": 0.7}, "justice_confidence": {"mean": 0.7749999999999999, "std": 0.10606601717798214, "min": 0.7, "max": 0.85}, "resentment_confidence": {"mean": 0.6499999999999999, "std": 0.07071067811865474, "min": 0.6, "max": 0.7}, "hope_confidence": {"mean": 0.75, "std": 0.07071067811865482, "min": 0.7, "max": 0.8}, "fear_confidence": {"mean": 0.5, "std": 0.282842712474619, "min": 0.3, "max": 0.7}, "pragmatism_confidence": {"mean": 0.7, "std": 0.07071067811865474, "min": 0.65, "max": 0.75}, "fantasy_confidence": {"mean": 0.475, "std": 0.38890872965260115, "min": 0.2, "max": 0.75}, "extraction_time_seconds": {"mean": 1.3173335790634155, "std": 0.16041512011731376, "min": 1.2039029598236084, "max": 1.4307641983032227}}, "missing_metrics": []}}, "errors": []}, "combined_summary": "Two-stage execution: 5 raw data results + 5 derived metrics results"}