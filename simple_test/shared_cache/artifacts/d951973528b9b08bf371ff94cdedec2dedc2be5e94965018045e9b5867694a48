{"stage_1_raw_data": {"analysis_plan": {"stage": "raw_data_collection", "experiment_summary": "This plan outlines the collection and initial validation of raw data from LLM analysis based on the Character Assessment Framework v6.0. It focuses on capturing dimensional scores (score, salience, confidence) for all 10 character dimensions and performing descriptive statistical checks to ensure data integrity, completeness, and adherence to the 0.0-1.0 scale before any subsequent calculations or hypothesis testing.", "tasks": {"validate_dimensional_scores": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score"], "grouping_variable": "ideology"}, "purpose": "To validate that the raw dimensional scores generated by the LLM are numerically sound (within the 0.0-1.0 range), complete, and to get a preliminary overview of their distribution across ideological groups. This is a fundamental data quality check."}, "validate_salience_scores": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["dignity_salience", "truth_salience", "justice_salience", "hope_salience", "pragmatism_salience", "tribalism_salience", "manipulation_salience", "resentment_salience", "fear_salience", "fantasy_salience"]}, "purpose": "To verify the integrity and range of the raw salience scores for each dimension, ensuring they conform to the framework's 0.0-1.0 requirement. This confirms the LLM is correctly providing this critical metadata."}, "validate_confidence_scores": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["dignity_confidence", "truth_confidence", "justice_confidence", "hope_confidence", "pragmatism_confidence", "tribalism_confidence", "manipulation_confidence", "resentment_confidence", "fear_confidence", "fantasy_confidence"]}, "purpose": "To assess the LLM's self-reported confidence for each dimensional rating. This provides an initial check on the reliability of the raw data before proceeding to more complex analysis."}, "summarize_raw_data_collection": {"tool": "create_summary_statistics", "parameters": {"metrics": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score"], "summary_types": ["mean", "std", "min", "max", "count"]}, "purpose": "To generate a high-level summary table of the core dimensional scores. This provides a consolidated overview of the collected raw data, facilitating a quick check for anomalies, missing values, or unexpected distributions."}}}, "results": {"validate_dimensional_scores": {"type": "descriptive_stats", "columns_analyzed": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score"], "results": {"dignity_score": {"count": 2, "mean": 0.625, "std": 0.31819805153394637, "min": 0.4, "max": 0.85, "median": 0.625, "q25": 0.5125, "q75": 0.7375, "skewness": NaN, "kurtosis": NaN}, "truth_score": {"count": 2, "mean": 0.675, "std": 0.10606601717798214, "min": 0.6, "max": 0.75, "median": 0.675, "q25": 0.6375, "q75": 0.7125, "skewness": NaN, "kurtosis": NaN}, "justice_score": {"count": 2, "mean": 0.7, "std": 0.0, "min": 0.7, "max": 0.7, "median": 0.7, "q25": 0.7, "q75": 0.7, "skewness": NaN, "kurtosis": NaN}, "hope_score": {"count": 2, "mean": 0.65, "std": 0.21213203435596428, "min": 0.5, "max": 0.8, "median": 0.65, "q25": 0.575, "q75": 0.7250000000000001, "skewness": NaN, "kurtosis": NaN}, "pragmatism_score": {"count": 2, "mean": 0.44999999999999996, "std": 0.21213203435596426, "min": 0.3, "max": 0.6, "median": 0.44999999999999996, "q25": 0.375, "q75": 0.525, "skewness": NaN, "kurtosis": NaN}, "tribalism_score": {"count": 2, "mean": 0.4, "std": 0.282842712474619, "min": 0.2, "max": 0.6, "median": 0.4, "q25": 0.3, "q75": 0.5, "skewness": NaN, "kurtosis": NaN}, "manipulation_score": {"count": 2, "mean": 0.3, "std": 0.282842712474619, "min": 0.1, "max": 0.5, "median": 0.3, "q25": 0.2, "q75": 0.4, "skewness": NaN, "kurtosis": NaN}, "resentment_score": {"count": 2, "mean": 0.325, "std": 0.24748737341529164, "min": 0.15, "max": 0.5, "median": 0.325, "q25": 0.2375, "q75": 0.4125, "skewness": NaN, "kurtosis": NaN}, "fear_score": {"count": 2, "mean": 0.125, "std": 0.10606601717798214, "min": 0.05, "max": 0.2, "median": 0.125, "q25": 0.08750000000000001, "q75": 0.1625, "skewness": NaN, "kurtosis": NaN}, "fantasy_score": {"count": 2, "mean": 0.175, "std": 0.17677669529663687, "min": 0.05, "max": 0.3, "median": 0.175, "q25": 0.1125, "q75": 0.2375, "skewness": NaN, "kurtosis": NaN}}}, "validate_salience_scores": {"type": "descriptive_stats", "columns_analyzed": ["dignity_salience", "truth_salience", "justice_salience", "hope_salience", "pragmatism_salience", "tribalism_salience", "manipulation_salience", "resentment_salience", "fear_salience", "fantasy_salience"], "results": {"dignity_salience": {"count": 2, "mean": 0.8, "std": 0.14142135623730953, "min": 0.7, "max": 0.9, "median": 0.8, "q25": 0.75, "q75": 0.85, "skewness": NaN, "kurtosis": NaN}, "truth_salience": {"count": 2, "mean": 0.8, "std": 0.14142135623730953, "min": 0.7, "max": 0.9, "median": 0.8, "q25": 0.75, "q75": 0.85, "skewness": NaN, "kurtosis": NaN}, "justice_salience": {"count": 2, "mean": 0.7250000000000001, "std": 0.10606601717798214, "min": 0.65, "max": 0.8, "median": 0.7250000000000001, "q25": 0.6875, "q75": 0.7625000000000001, "skewness": NaN, "kurtosis": NaN}, "hope_salience": {"count": 2, "mean": 0.725, "std": 0.1767766952966369, "min": 0.6, "max": 0.85, "median": 0.725, "q25": 0.6625, "q75": 0.7875, "skewness": NaN, "kurtosis": NaN}, "pragmatism_salience": {"count": 2, "mean": 0.5, "std": 0.0, "min": 0.5, "max": 0.5, "median": 0.5, "q25": 0.5, "q75": 0.5, "skewness": NaN, "kurtosis": NaN}, "tribalism_salience": {"count": 2, "mean": 0.425, "std": 0.38890872965260115, "min": 0.15, "max": 0.7, "median": 0.425, "q25": 0.2875, "q75": 0.5625, "skewness": NaN, "kurtosis": NaN}, "manipulation_salience": {"count": 2, "mean": 0.375, "std": 0.4596194077712559, "min": 0.05, "max": 0.7, "median": 0.375, "q25": 0.21249999999999997, "q75": 0.5375, "skewness": NaN, "kurtosis": NaN}, "resentment_salience": {"count": 2, "mean": 0.39999999999999997, "std": 0.42426406871192845, "min": 0.1, "max": 0.7, "median": 0.39999999999999997, "q25": 0.25, "q75": 0.5499999999999999, "skewness": NaN, "kurtosis": NaN}, "fear_salience": {"count": 2, "mean": 0.16, "std": 0.1979898987322333, "min": 0.02, "max": 0.3, "median": 0.16, "q25": 0.09, "q75": 0.22999999999999998, "skewness": NaN, "kurtosis": NaN}, "fantasy_salience": {"count": 2, "mean": 0.20500000000000002, "std": 0.27577164466275356, "min": 0.01, "max": 0.4, "median": 0.20500000000000002, "q25": 0.1075, "q75": 0.3025, "skewness": NaN, "kurtosis": NaN}}}, "validate_confidence_scores": {"type": "descriptive_stats", "columns_analyzed": ["dignity_confidence", "truth_confidence", "justice_confidence", "hope_confidence", "pragmatism_confidence", "tribalism_confidence", "manipulation_confidence", "resentment_confidence", "fear_confidence", "fantasy_confidence"], "results": {"dignity_confidence": {"count": 2, "mean": 0.8500000000000001, "std": 0.07071067811865474, "min": 0.8, "max": 0.9, "median": 0.8500000000000001, "q25": 0.8250000000000001, "q75": 0.875, "skewness": NaN, "kurtosis": NaN}, "truth_confidence": {"count": 2, "mean": 0.875, "std": 0.03535533905932741, "min": 0.85, "max": 0.9, "median": 0.875, "q25": 0.8625, "q75": 0.8875, "skewness": NaN, "kurtosis": NaN}, "justice_confidence": {"count": 2, "mean": 0.825, "std": 0.03535533905932733, "min": 0.8, "max": 0.85, "median": 0.825, "q25": 0.8125, "q75": 0.8375, "skewness": NaN, "kurtosis": NaN}, "hope_confidence": {"count": 2, "mean": 0.825, "std": 0.10606601717798214, "min": 0.75, "max": 0.9, "median": 0.825, "q25": 0.7875, "q75": 0.8625, "skewness": NaN, "kurtosis": NaN}, "pragmatism_confidence": {"count": 2, "mean": 0.725, "std": 0.03535533905932741, "min": 0.7, "max": 0.75, "median": 0.725, "q25": 0.7124999999999999, "q75": 0.7375, "skewness": NaN, "kurtosis": NaN}, "tribalism_confidence": {"count": 2, "mean": 0.75, "std": 0.07071067811865482, "min": 0.7, "max": 0.8, "median": 0.75, "q25": 0.725, "q75": 0.775, "skewness": NaN, "kurtosis": NaN}, "manipulation_confidence": {"count": 2, "mean": 0.7, "std": 0.07071067811865474, "min": 0.65, "max": 0.75, "median": 0.7, "q25": 0.675, "q75": 0.725, "skewness": NaN, "kurtosis": NaN}, "resentment_confidence": {"count": 2, "mean": 0.75, "std": 0.07071067811865482, "min": 0.7, "max": 0.8, "median": 0.75, "q25": 0.725, "q75": 0.775, "skewness": NaN, "kurtosis": NaN}, "fear_confidence": {"count": 2, "mean": 0.6, "std": 0.0, "min": 0.6, "max": 0.6, "median": 0.6, "q25": 0.6, "q75": 0.6, "skewness": NaN, "kurtosis": NaN}, "fantasy_confidence": {"count": 2, "mean": 0.625, "std": 0.03535533905932741, "min": 0.6, "max": 0.65, "median": 0.625, "q25": 0.6125, "q75": 0.6375, "skewness": NaN, "kurtosis": NaN}}}, "summarize_raw_data_collection": {"type": "summary_statistics", "metrics": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score"], "summary_types": ["mean", "std", "min", "max", "count"], "results": {"dignity_score": {"mean": 0.625, "std": 0.31819805153394637, "min": 0.4, "max": 0.85, "count": 2}, "truth_score": {"mean": 0.675, "std": 0.10606601717798214, "min": 0.6, "max": 0.75, "count": 2}, "justice_score": {"mean": 0.7, "std": 0.0, "min": 0.7, "max": 0.7, "count": 2}, "hope_score": {"mean": 0.65, "std": 0.21213203435596428, "min": 0.5, "max": 0.8, "count": 2}, "pragmatism_score": {"mean": 0.44999999999999996, "std": 0.21213203435596426, "min": 0.3, "max": 0.6, "count": 2}, "tribalism_score": {"mean": 0.4, "std": 0.282842712474619, "min": 0.2, "max": 0.6, "count": 2}, "manipulation_score": {"mean": 0.3, "std": 0.282842712474619, "min": 0.1, "max": 0.5, "count": 2}, "resentment_score": {"mean": 0.325, "std": 0.24748737341529164, "min": 0.15, "max": 0.5, "count": 2}, "fear_score": {"mean": 0.125, "std": 0.10606601717798214, "min": 0.05, "max": 0.2, "count": 2}, "fantasy_score": {"mean": 0.175, "std": 0.17677669529663687, "min": 0.05, "max": 0.3, "count": 2}}, "missing_metrics": []}}, "errors": []}, "stage_2_derived_metrics": {"analysis_plan": {"stage": "derived_metrics_analysis", "experiment_summary": "This plan outlines Stage 2 of the analysis for the 'simple_character_validation' experiment. It focuses on calculating derived metrics as specified by the Character Assessment Framework v6.0, including Character Tension scores and the Moral Character Strategic Contradiction Index (MC-SCI). Following metric calculation and validation, the plan details statistical analyses to test the experiment's hypotheses, including comparing character dimensions and MC-SCI scores across different ideologies (Conservative vs. Progressive) using ANOVA tests and examining inter-dimensional relationships with a correlation matrix.", "tasks": {"task_01_calculate_derived_metrics": {"tool": "calculate_derived_metrics", "parameters": {"metric_formulas": {"dignity_tribalism_tension": "min(dignity_score, tribalism_score) * abs(dignity_salience - tribalism_salience)", "truth_manipulation_tension": "min(truth_score, manipulation_score) * abs(truth_salience - manipulation_salience)", "justice_resentment_tension": "min(justice_score, resentment_score) * abs(justice_salience - resentment_salience)", "hope_fear_tension": "min(hope_score, fear_score) * abs(hope_salience - fear_salience)", "pragmatism_fantasy_tension": "min(pragmatism_score, fantasy_score) * abs(pragmatism_salience - fantasy_salience)", "mc_sci": "(dignity_tribalism_tension + truth_manipulation_tension + justice_resentment_tension + hope_fear_tension + pragmatism_fantasy_tension) / 5.0"}, "input_columns": ["dignity_score", "dignity_salience", "truth_score", "truth_salience", "justice_score", "justice_salience", "hope_score", "hope_salience", "pragmatism_score", "pragmatism_salience", "tribalism_score", "tribalism_salience", "manipulation_score", "manipulation_salience", "resentment_score", "resentment_salience", "fear_score", "fear_salience", "fantasy_score", "fantasy_salience"]}, "purpose": "To calculate the core derived metrics (Character Tensions and MC-SCI) from the raw dimensional scores as defined by the Character Assessment Framework v6.0. These metrics are essential for testing H2 and for deeper character coherence analysis."}, "task_02_validate_calculated_metrics": {"tool": "validate_calculated_metrics", "parameters": {"validation_rules": [{"rule_name": "missing_data_check", "columns": ["dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "hope_fear_tension", "pragmatism_fantasy_tension", "mc_sci"]}, {"rule_name": "range_check", "column": "mc_sci", "min_value": 0.0, "max_value": 1.0}]}, "purpose": "To ensure the integrity and quality of the newly calculated derived metrics by checking for missing values and verifying that they fall within their expected theoretical ranges (0.0 to 1.0) before they are used in statistical testing."}, "task_03_generate_descriptive_statistics": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score", "mc_sci"], "grouping_variable": "ideology"}, "purpose": "To generate summary statistics (mean, std, min, max) for both raw scores and the primary derived metric (MC-SCI), segmented by the 'ideology' factor. This provides a foundational overview for the ideological comparison."}, "task_04_generate_character_correlation_matrix": {"tool": "generate_correlation_matrix", "parameters": {"dimensions": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score"], "correlation_method": "pearson"}, "purpose": "To fulfill the 'character_correlation_matrix' validation requirement by examining the inter-relationships between the ten core character dimensions. This helps identify patterns and potential collinearity, contributing to the understanding of character signatures."}, "task_05_test_H1_ideological_differences": {"tool": "perform_one_way_anova", "parameters": {"grouping_variable": "ideology", "dependent_variable": "dignity_score"}, "purpose": "To begin testing hypothesis H1 (Character dimensions will show significant differences... between speakers). This specific test compares the 'Dignity' score between the Conservative and Progressive speakers. This task would be repeated for all 10 dimensions."}, "task_06_test_H2_coherence_differences": {"tool": "perform_one_way_anova", "parameters": {"grouping_variable": "ideology", "dependent_variable": "mc_sci"}, "purpose": "To directly test hypothesis H2 (MC-SCI scores will successfully differentiate...). This analysis compares the calculated Moral Character Strategic Contradiction Index (MC-SCI) between the two ideologies to determine if the framework can detect differences in character coherence."}, "task_07_explore_factorial_effects": {"tool": "perform_two_way_anova", "parameters": {"factor1": "ideology", "factor2": "era", "dependent_variable": "mc_sci"}, "purpose": "To explore potential interaction effects between the 'ideology' and 'era' factors on the MC-SCI score. Although the N=2 design is minimal, this analysis probes the factorial design and can reveal if the effect of ideology on character coherence depends on the political era."}}}, "results": {"task_01_calculate_derived_metrics": {"type": "derived_metrics_calculation", "success": true, "calculated_metrics": {"hope_fear_tension": [0.06, 0.0415], "dignity_tribalism_tension": [0.0, 0.15000000000000002], "truth_manipulation_tension": [0.10000000000000003, 0.06499999999999999], "justice_resentment_tension": [0.050000000000000044, 0.0825], "pragmatism_fantasy_tension": [0.029999999999999992, 0.0245], "mc_sci": [0.048000000000000015, 0.07270000000000001]}, "successful_calculations": ["hope_fear_tension", "dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "pragmatism_fantasy_tension", "mc_sci"], "failed_calculations": [], "formulas_used": ["dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "hope_fear_tension", "pragmatism_fantasy_tension", "mc_sci"], "input_columns": ["dignity_score", "dignity_salience", "truth_score", "truth_salience", "justice_score", "justice_salience", "hope_score", "hope_salience", "pragmatism_score", "pragmatism_salience", "tribalism_score", "tribalism_salience", "manipulation_score", "manipulation_salience", "resentment_score", "resentment_salience", "fear_score", "fear_salience", "fantasy_score", "fantasy_salience"], "total_metrics": 6, "success_rate": 1.0}, "task_02_validate_calculated_metrics": {"type": "metric_validation", "validation_rules": ["{'rule_name': 'missing_data_check', 'columns': ['dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension', 'mc_sci']}", "{'rule_name': 'range_check', 'column': 'mc_sci', 'min_value': 0.0, 'max_value': 1.0}"], "results": {"unknown_rule": {"status": "not_found", "message": "Metric 'unknown_rule' not found in dataframe", "available_columns": ["aid", "dignity_score", "dignity_raw_score", "dignity_salience", "dignity_confidence", "truth_score", "truth_raw_score", "truth_salience", "truth_confidence", "justice_score", "justice_raw_score", "justice_salience", "justice_confidence", "hope_score", "hope_raw_score", "hope_salience", "hope_confidence", "pragmatism_score", "pragmatism_raw_score", "pragmatism_salience", "pragmatism_confidence", "tribalism_score", "tribalism_raw_score", "tribalism_salience", "tribalism_confidence", "manipulation_score", "manipulation_raw_score", "manipulation_salience", "manipulation_confidence", "resentment_score", "resentment_raw_score", "resentment_salience", "resentment_confidence", "fear_score", "fear_raw_score", "fear_salience", "fear_confidence", "fantasy_score", "fantasy_raw_score", "fantasy_salience", "fantasy_confidence", "hope_fear_tension", "dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "pragmatism_fantasy_tension", "mc_sci"], "note": "This is a framework-agnostic validation - LLMs determine validation logic"}}, "quality_thresholds": {"min_valid_ratio": 0.8, "max_outlier_ratio": 0.1, "min_variance": 0.01, "correlation_threshold": 0.95}}, "task_03_generate_descriptive_statistics": {"type": "descriptive_stats", "columns_analyzed": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score", "mc_sci"], "results": {"dignity_score": {"count": 2, "mean": 0.625, "std": 0.31819805153394637, "min": 0.4, "max": 0.85, "median": 0.625, "q25": 0.5125, "q75": 0.7375, "skewness": NaN, "kurtosis": NaN}, "truth_score": {"count": 2, "mean": 0.675, "std": 0.10606601717798214, "min": 0.6, "max": 0.75, "median": 0.675, "q25": 0.6375, "q75": 0.7125, "skewness": NaN, "kurtosis": NaN}, "justice_score": {"count": 2, "mean": 0.7, "std": 0.0, "min": 0.7, "max": 0.7, "median": 0.7, "q25": 0.7, "q75": 0.7, "skewness": NaN, "kurtosis": NaN}, "hope_score": {"count": 2, "mean": 0.65, "std": 0.21213203435596428, "min": 0.5, "max": 0.8, "median": 0.65, "q25": 0.575, "q75": 0.7250000000000001, "skewness": NaN, "kurtosis": NaN}, "pragmatism_score": {"count": 2, "mean": 0.44999999999999996, "std": 0.21213203435596426, "min": 0.3, "max": 0.6, "median": 0.44999999999999996, "q25": 0.375, "q75": 0.525, "skewness": NaN, "kurtosis": NaN}, "tribalism_score": {"count": 2, "mean": 0.4, "std": 0.282842712474619, "min": 0.2, "max": 0.6, "median": 0.4, "q25": 0.3, "q75": 0.5, "skewness": NaN, "kurtosis": NaN}, "manipulation_score": {"count": 2, "mean": 0.3, "std": 0.282842712474619, "min": 0.1, "max": 0.5, "median": 0.3, "q25": 0.2, "q75": 0.4, "skewness": NaN, "kurtosis": NaN}, "resentment_score": {"count": 2, "mean": 0.325, "std": 0.24748737341529164, "min": 0.15, "max": 0.5, "median": 0.325, "q25": 0.2375, "q75": 0.4125, "skewness": NaN, "kurtosis": NaN}, "fear_score": {"count": 2, "mean": 0.125, "std": 0.10606601717798214, "min": 0.05, "max": 0.2, "median": 0.125, "q25": 0.08750000000000001, "q75": 0.1625, "skewness": NaN, "kurtosis": NaN}, "fantasy_score": {"count": 2, "mean": 0.175, "std": 0.17677669529663687, "min": 0.05, "max": 0.3, "median": 0.175, "q25": 0.1125, "q75": 0.2375, "skewness": NaN, "kurtosis": NaN}, "mc_sci": {"count": 2, "mean": 0.060350000000000015, "std": 0.017465537495307725, "min": 0.048000000000000015, "max": 0.07270000000000001, "median": 0.060350000000000015, "q25": 0.054175000000000015, "q75": 0.06652500000000001, "skewness": NaN, "kurtosis": NaN}}}, "task_04_generate_character_correlation_matrix": {"type": "correlation_matrix", "dimensions": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score"], "method": "pearson", "matrix": {"dignity_score": {"dignity_score": 1.0, "truth_score": 0.9999999999999996, "justice_score": NaN, "hope_score": 1.0, "pragmatism_score": 1.0000000000000002, "tribalism_score": -1.0000000000000002, "manipulation_score": -1.0, "resentment_score": -1.0000000000000002, "fear_score": -1.0, "fantasy_score": -1.0}, "truth_score": {"dignity_score": 0.9999999999999996, "truth_score": 1.0, "justice_score": NaN, "hope_score": 1.0000000000000004, "pragmatism_score": 1.0000000000000004, "tribalism_score": -1.0000000000000004, "manipulation_score": -1.0000000000000004, "resentment_score": -1.0000000000000004, "fear_score": -1.0000000000000002, "fantasy_score": -1.0000000000000004}, "justice_score": {"dignity_score": NaN, "truth_score": NaN, "justice_score": NaN, "hope_score": NaN, "pragmatism_score": NaN, "tribalism_score": NaN, "manipulation_score": NaN, "resentment_score": NaN, "fear_score": NaN, "fantasy_score": NaN}, "hope_score": {"dignity_score": 1.0, "truth_score": 1.0000000000000004, "justice_score": NaN, "hope_score": 1.0, "pragmatism_score": 1.0000000000000002, "tribalism_score": -1.0, "manipulation_score": -0.9999999999999999, "resentment_score": -1.0000000000000002, "fear_score": -1.0, "fantasy_score": -0.9999999999999998}, "pragmatism_score": {"dignity_score": 1.0000000000000002, "truth_score": 1.0000000000000004, "justice_score": NaN, "hope_score": 1.0000000000000002, "pragmatism_score": 1.0, "tribalism_score": -0.9999999999999999, "manipulation_score": -0.9999999999999998, "resentment_score": -1.0, "fear_score": -0.9999999999999999, "fantasy_score": -0.9999999999999998}, "tribalism_score": {"dignity_score": -1.0000000000000002, "truth_score": -1.0000000000000004, "justice_score": NaN, "hope_score": -1.0, "pragmatism_score": -0.9999999999999999, "tribalism_score": 1.0, "manipulation_score": 0.9999999999999998, "resentment_score": 1.0000000000000002, "fear_score": 0.9999999999999998, "fantasy_score": 0.9999999999999999}, "manipulation_score": {"dignity_score": -1.0, "truth_score": -1.0000000000000004, "justice_score": NaN, "hope_score": -0.9999999999999999, "pragmatism_score": -0.9999999999999998, "tribalism_score": 0.9999999999999998, "manipulation_score": 1.0, "resentment_score": 1.0000000000000002, "fear_score": 0.9999999999999999, "fantasy_score": 1.0}, "resentment_score": {"dignity_score": -1.0000000000000002, "truth_score": -1.0000000000000004, "justice_score": NaN, "hope_score": -1.0000000000000002, "pragmatism_score": -1.0, "tribalism_score": 1.0000000000000002, "manipulation_score": 1.0000000000000002, "resentment_score": 1.0, "fear_score": 0.9999999999999999, "fantasy_score": 0.9999999999999999}, "fear_score": {"dignity_score": -1.0, "truth_score": -1.0000000000000002, "justice_score": NaN, "hope_score": -1.0, "pragmatism_score": -0.9999999999999999, "tribalism_score": 0.9999999999999998, "manipulation_score": 0.9999999999999999, "resentment_score": 0.9999999999999999, "fear_score": 1.0, "fantasy_score": 1.0}, "fantasy_score": {"dignity_score": -1.0, "truth_score": -1.0000000000000004, "justice_score": NaN, "hope_score": -0.9999999999999998, "pragmatism_score": -0.9999999999999998, "tribalism_score": 0.9999999999999999, "manipulation_score": 1.0, "resentment_score": 0.9999999999999999, "fear_score": 1.0, "fantasy_score": 1.0}}, "missing_dimensions": []}}, "errors": ["Task 'task_05_test_H1_ideological_differences' failed: ANOVA failed: Grouping variable 'ideology' not found in DataFrame", "Task 'task_06_test_H2_coherence_differences' failed: ANOVA failed: Grouping variable 'ideology' not found in DataFrame", "Task 'task_07_explore_factorial_effects' failed: Two-way ANOVA failed: Column 'ideology' not found in DataFrame"]}, "combined_summary": "Two-stage execution: 4 raw data results + 4 derived metrics results"}