{"stage_1_raw_data": {"analysis_plan": {"stage": "raw_data_collection", "experiment_summary": "This plan outlines the collection and initial validation of raw data for the 'simple_character_validation' experiment. It focuses on capturing the 10 dimensional scores, salience, and confidence values as specified by the Character Assessment Framework v6.0 for each of the 2 documents. The plan includes descriptive statistical checks to ensure data completeness and adherence to the 0.0-1.0 range, preparing the data for subsequent analysis.", "tasks": {"validate_dimensional_scores": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score"]}, "purpose": "To validate the completeness and range of the 10 core dimensional scores (0.0-1.0) collected from the LLM analysis. This checks for missing data and ensures scores adhere to the framework's constraints before any further processing."}, "validate_salience_scores": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["dignity_salience", "truth_salience", "justice_salience", "hope_salience", "pragmatism_salience", "tribalism_salience", "manipulation_salience", "resentment_salience", "fear_salience", "fantasy_salience"]}, "purpose": "To validate the completeness and range of the 10 salience scores (0.0-1.0). Salience is a key input for later tension calculations, so ensuring its quality is critical for Stage 2 analysis."}, "validate_confidence_scores": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["dignity_confidence", "truth_confidence", "justice_confidence", "hope_confidence", "pragmatism_confidence", "tribalism_confidence", "manipulation_confidence", "resentment_confidence", "fear_confidence", "fantasy_confidence"]}, "purpose": "To validate the completeness and range of the 10 confidence scores (0.0-1.0). This provides an initial check on the reliability of the LLM's assessments for each dimension."}, "generate_overall_raw_data_summary": {"tool": "create_summary_statistics", "parameters": {"metrics": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score", "dignity_salience", "truth_salience", "justice_salience", "hope_salience", "pragmatism_salience", "tribalism_salience", "manipulation_salience", "resentment_salience", "fear_salience", "fantasy_salience", "dignity_confidence", "truth_confidence", "justice_confidence", "hope_confidence", "pragmatism_confidence", "tribalism_confidence", "manipulation_confidence", "resentment_confidence", "fear_confidence", "fantasy_confidence"], "summary_types": ["mean", "std", "min", "max", "count"]}, "purpose": "To generate a comprehensive summary table of all 30 raw numerical data points (scores, salience, confidence) collected. This serves as a final quality assurance step to review the entire raw dataset's characteristics at a glance."}}}, "results": {"validate_dimensional_scores": {"type": "descriptive_stats", "columns_analyzed": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score"], "results": {"dignity_score": {"count": 2, "mean": 0.625, "std": 0.31819805153394637, "min": 0.4, "max": 0.85, "median": 0.625, "q25": 0.5125, "q75": 0.7375, "skewness": NaN, "kurtosis": NaN}, "truth_score": {"count": 2, "mean": 0.675, "std": 0.10606601717798214, "min": 0.6, "max": 0.75, "median": 0.675, "q25": 0.6375, "q75": 0.7125, "skewness": NaN, "kurtosis": NaN}, "justice_score": {"count": 2, "mean": 0.7, "std": 0.0, "min": 0.7, "max": 0.7, "median": 0.7, "q25": 0.7, "q75": 0.7, "skewness": NaN, "kurtosis": NaN}, "hope_score": {"count": 2, "mean": 0.65, "std": 0.21213203435596428, "min": 0.5, "max": 0.8, "median": 0.65, "q25": 0.575, "q75": 0.7250000000000001, "skewness": NaN, "kurtosis": NaN}, "pragmatism_score": {"count": 2, "mean": 0.44999999999999996, "std": 0.21213203435596426, "min": 0.3, "max": 0.6, "median": 0.44999999999999996, "q25": 0.375, "q75": 0.525, "skewness": NaN, "kurtosis": NaN}, "tribalism_score": {"count": 2, "mean": 0.4, "std": 0.282842712474619, "min": 0.2, "max": 0.6, "median": 0.4, "q25": 0.3, "q75": 0.5, "skewness": NaN, "kurtosis": NaN}, "manipulation_score": {"count": 2, "mean": 0.3, "std": 0.282842712474619, "min": 0.1, "max": 0.5, "median": 0.3, "q25": 0.2, "q75": 0.4, "skewness": NaN, "kurtosis": NaN}, "resentment_score": {"count": 2, "mean": 0.325, "std": 0.24748737341529164, "min": 0.15, "max": 0.5, "median": 0.325, "q25": 0.2375, "q75": 0.4125, "skewness": NaN, "kurtosis": NaN}, "fear_score": {"count": 2, "mean": 0.125, "std": 0.10606601717798214, "min": 0.05, "max": 0.2, "median": 0.125, "q25": 0.08750000000000001, "q75": 0.1625, "skewness": NaN, "kurtosis": NaN}, "fantasy_score": {"count": 2, "mean": 0.175, "std": 0.17677669529663687, "min": 0.05, "max": 0.3, "median": 0.175, "q25": 0.1125, "q75": 0.2375, "skewness": NaN, "kurtosis": NaN}}}, "validate_salience_scores": {"type": "descriptive_stats", "columns_analyzed": ["dignity_salience", "truth_salience", "justice_salience", "hope_salience", "pragmatism_salience", "tribalism_salience", "manipulation_salience", "resentment_salience", "fear_salience", "fantasy_salience"], "results": {"dignity_salience": {"count": 2, "mean": 0.8, "std": 0.14142135623730953, "min": 0.7, "max": 0.9, "median": 0.8, "q25": 0.75, "q75": 0.85, "skewness": NaN, "kurtosis": NaN}, "truth_salience": {"count": 2, "mean": 0.8, "std": 0.14142135623730953, "min": 0.7, "max": 0.9, "median": 0.8, "q25": 0.75, "q75": 0.85, "skewness": NaN, "kurtosis": NaN}, "justice_salience": {"count": 2, "mean": 0.7250000000000001, "std": 0.10606601717798214, "min": 0.65, "max": 0.8, "median": 0.7250000000000001, "q25": 0.6875, "q75": 0.7625000000000001, "skewness": NaN, "kurtosis": NaN}, "hope_salience": {"count": 2, "mean": 0.725, "std": 0.1767766952966369, "min": 0.6, "max": 0.85, "median": 0.725, "q25": 0.6625, "q75": 0.7875, "skewness": NaN, "kurtosis": NaN}, "pragmatism_salience": {"count": 2, "mean": 0.5, "std": 0.0, "min": 0.5, "max": 0.5, "median": 0.5, "q25": 0.5, "q75": 0.5, "skewness": NaN, "kurtosis": NaN}, "tribalism_salience": {"count": 2, "mean": 0.425, "std": 0.38890872965260115, "min": 0.15, "max": 0.7, "median": 0.425, "q25": 0.2875, "q75": 0.5625, "skewness": NaN, "kurtosis": NaN}, "manipulation_salience": {"count": 2, "mean": 0.375, "std": 0.4596194077712559, "min": 0.05, "max": 0.7, "median": 0.375, "q25": 0.21249999999999997, "q75": 0.5375, "skewness": NaN, "kurtosis": NaN}, "resentment_salience": {"count": 2, "mean": 0.39999999999999997, "std": 0.42426406871192845, "min": 0.1, "max": 0.7, "median": 0.39999999999999997, "q25": 0.25, "q75": 0.5499999999999999, "skewness": NaN, "kurtosis": NaN}, "fear_salience": {"count": 2, "mean": 0.16, "std": 0.1979898987322333, "min": 0.02, "max": 0.3, "median": 0.16, "q25": 0.09, "q75": 0.22999999999999998, "skewness": NaN, "kurtosis": NaN}, "fantasy_salience": {"count": 2, "mean": 0.20500000000000002, "std": 0.27577164466275356, "min": 0.01, "max": 0.4, "median": 0.20500000000000002, "q25": 0.1075, "q75": 0.3025, "skewness": NaN, "kurtosis": NaN}}}, "validate_confidence_scores": {"type": "descriptive_stats", "columns_analyzed": ["dignity_confidence", "truth_confidence", "justice_confidence", "hope_confidence", "pragmatism_confidence", "tribalism_confidence", "manipulation_confidence", "resentment_confidence", "fear_confidence", "fantasy_confidence"], "results": {"dignity_confidence": {"count": 2, "mean": 0.8500000000000001, "std": 0.07071067811865474, "min": 0.8, "max": 0.9, "median": 0.8500000000000001, "q25": 0.8250000000000001, "q75": 0.875, "skewness": NaN, "kurtosis": NaN}, "truth_confidence": {"count": 2, "mean": 0.875, "std": 0.03535533905932741, "min": 0.85, "max": 0.9, "median": 0.875, "q25": 0.8625, "q75": 0.8875, "skewness": NaN, "kurtosis": NaN}, "justice_confidence": {"count": 2, "mean": 0.825, "std": 0.03535533905932733, "min": 0.8, "max": 0.85, "median": 0.825, "q25": 0.8125, "q75": 0.8375, "skewness": NaN, "kurtosis": NaN}, "hope_confidence": {"count": 2, "mean": 0.825, "std": 0.10606601717798214, "min": 0.75, "max": 0.9, "median": 0.825, "q25": 0.7875, "q75": 0.8625, "skewness": NaN, "kurtosis": NaN}, "pragmatism_confidence": {"count": 2, "mean": 0.725, "std": 0.03535533905932741, "min": 0.7, "max": 0.75, "median": 0.725, "q25": 0.7124999999999999, "q75": 0.7375, "skewness": NaN, "kurtosis": NaN}, "tribalism_confidence": {"count": 2, "mean": 0.75, "std": 0.07071067811865482, "min": 0.7, "max": 0.8, "median": 0.75, "q25": 0.725, "q75": 0.775, "skewness": NaN, "kurtosis": NaN}, "manipulation_confidence": {"count": 2, "mean": 0.7, "std": 0.07071067811865474, "min": 0.65, "max": 0.75, "median": 0.7, "q25": 0.675, "q75": 0.725, "skewness": NaN, "kurtosis": NaN}, "resentment_confidence": {"count": 2, "mean": 0.75, "std": 0.07071067811865482, "min": 0.7, "max": 0.8, "median": 0.75, "q25": 0.725, "q75": 0.775, "skewness": NaN, "kurtosis": NaN}, "fear_confidence": {"count": 2, "mean": 0.6, "std": 0.0, "min": 0.6, "max": 0.6, "median": 0.6, "q25": 0.6, "q75": 0.6, "skewness": NaN, "kurtosis": NaN}, "fantasy_confidence": {"count": 2, "mean": 0.625, "std": 0.03535533905932741, "min": 0.6, "max": 0.65, "median": 0.625, "q25": 0.6125, "q75": 0.6375, "skewness": NaN, "kurtosis": NaN}}}, "generate_overall_raw_data_summary": {"type": "summary_statistics", "metrics": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score", "dignity_salience", "truth_salience", "justice_salience", "hope_salience", "pragmatism_salience", "tribalism_salience", "manipulation_salience", "resentment_salience", "fear_salience", "fantasy_salience", "dignity_confidence", "truth_confidence", "justice_confidence", "hope_confidence", "pragmatism_confidence", "tribalism_confidence", "manipulation_confidence", "resentment_confidence", "fear_confidence", "fantasy_confidence"], "summary_types": ["mean", "std", "min", "max", "count"], "results": {"dignity_score": {"mean": 0.625, "std": 0.31819805153394637, "min": 0.4, "max": 0.85, "count": 2}, "truth_score": {"mean": 0.675, "std": 0.10606601717798214, "min": 0.6, "max": 0.75, "count": 2}, "justice_score": {"mean": 0.7, "std": 0.0, "min": 0.7, "max": 0.7, "count": 2}, "hope_score": {"mean": 0.65, "std": 0.21213203435596428, "min": 0.5, "max": 0.8, "count": 2}, "pragmatism_score": {"mean": 0.44999999999999996, "std": 0.21213203435596426, "min": 0.3, "max": 0.6, "count": 2}, "tribalism_score": {"mean": 0.4, "std": 0.282842712474619, "min": 0.2, "max": 0.6, "count": 2}, "manipulation_score": {"mean": 0.3, "std": 0.282842712474619, "min": 0.1, "max": 0.5, "count": 2}, "resentment_score": {"mean": 0.325, "std": 0.24748737341529164, "min": 0.15, "max": 0.5, "count": 2}, "fear_score": {"mean": 0.125, "std": 0.10606601717798214, "min": 0.05, "max": 0.2, "count": 2}, "fantasy_score": {"mean": 0.175, "std": 0.17677669529663687, "min": 0.05, "max": 0.3, "count": 2}, "dignity_salience": {"mean": 0.8, "std": 0.14142135623730953, "min": 0.7, "max": 0.9, "count": 2}, "truth_salience": {"mean": 0.8, "std": 0.14142135623730953, "min": 0.7, "max": 0.9, "count": 2}, "justice_salience": {"mean": 0.7250000000000001, "std": 0.10606601717798214, "min": 0.65, "max": 0.8, "count": 2}, "hope_salience": {"mean": 0.725, "std": 0.1767766952966369, "min": 0.6, "max": 0.85, "count": 2}, "pragmatism_salience": {"mean": 0.5, "std": 0.0, "min": 0.5, "max": 0.5, "count": 2}, "tribalism_salience": {"mean": 0.425, "std": 0.38890872965260115, "min": 0.15, "max": 0.7, "count": 2}, "manipulation_salience": {"mean": 0.375, "std": 0.4596194077712559, "min": 0.05, "max": 0.7, "count": 2}, "resentment_salience": {"mean": 0.39999999999999997, "std": 0.42426406871192845, "min": 0.1, "max": 0.7, "count": 2}, "fear_salience": {"mean": 0.16, "std": 0.1979898987322333, "min": 0.02, "max": 0.3, "count": 2}, "fantasy_salience": {"mean": 0.20500000000000002, "std": 0.27577164466275356, "min": 0.01, "max": 0.4, "count": 2}, "dignity_confidence": {"mean": 0.8500000000000001, "std": 0.07071067811865474, "min": 0.8, "max": 0.9, "count": 2}, "truth_confidence": {"mean": 0.875, "std": 0.03535533905932741, "min": 0.85, "max": 0.9, "count": 2}, "justice_confidence": {"mean": 0.825, "std": 0.03535533905932733, "min": 0.8, "max": 0.85, "count": 2}, "hope_confidence": {"mean": 0.825, "std": 0.10606601717798214, "min": 0.75, "max": 0.9, "count": 2}, "pragmatism_confidence": {"mean": 0.725, "std": 0.03535533905932741, "min": 0.7, "max": 0.75, "count": 2}, "tribalism_confidence": {"mean": 0.75, "std": 0.07071067811865482, "min": 0.7, "max": 0.8, "count": 2}, "manipulation_confidence": {"mean": 0.7, "std": 0.07071067811865474, "min": 0.65, "max": 0.75, "count": 2}, "resentment_confidence": {"mean": 0.75, "std": 0.07071067811865482, "min": 0.7, "max": 0.8, "count": 2}, "fear_confidence": {"mean": 0.6, "std": 0.0, "min": 0.6, "max": 0.6, "count": 2}, "fantasy_confidence": {"mean": 0.625, "std": 0.03535533905932741, "min": 0.6, "max": 0.65, "count": 2}}, "missing_metrics": []}}, "errors": []}, "stage_2_derived_metrics": {"analysis_plan": {"stage": "derived_metrics_analysis", "experiment_summary": "This plan outlines the calculation of derived character metrics (Character Tensions, MC-SCI) from raw dimensional scores, followed by statistical analysis to test the experiment's hypotheses. The analysis will compare character profiles, assess metric reliability, and validate the synthesis pipeline's computational integrity using descriptive statistics and correlation analysis, adhering strictly to the available data columns and tools.", "tasks": {"task_1_calculate_derived_metrics": {"tool": "calculate_derived_metrics", "parameters": {"metric_formulas": {"dignity_tribalism_tension": "min(dignity_score, tribalism_score) * abs(dignity_salience - tribalism_salience)", "truth_manipulation_tension": "min(truth_score, manipulation_score) * abs(truth_salience - manipulation_salience)", "justice_resentment_tension": "min(justice_score, resentment_score) * abs(justice_salience - resentment_salience)", "hope_fear_tension": "min(hope_score, fear_score) * abs(hope_salience - fear_salience)", "pragmatism_fantasy_tension": "min(pragmatism_score, fantasy_score) * abs(pragmatism_salience - fantasy_salience)", "mc_sci": "(dignity_tribalism_tension + truth_manipulation_tension + justice_resentment_tension + hope_fear_tension + pragmatism_fantasy_tension) / 5.0"}, "input_columns": ["dignity_score", "dignity_salience", "truth_score", "truth_salience", "justice_score", "justice_salience", "hope_score", "hope_salience", "pragmatism_score", "pragmatism_salience", "tribalism_score", "tribalism_salience", "manipulation_score", "manipulation_salience", "resentment_score", "resentment_salience", "fear_score", "fear_salience", "fantasy_score", "fantasy_salience"]}, "purpose": "To calculate the core derived metrics (Character Tensions and MC-SCI) as specified by the Character Assessment Framework v6.0. These metrics are essential for testing H2 (Coherence)."}, "task_2_validate_calculated_metrics": {"tool": "validate_calculated_metrics", "parameters": {"validation_rules": [{"rule": "missing_data_check", "columns": ["dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "hope_fear_tension", "pragmatism_fantasy_tension", "mc_sci"]}, {"rule": "range_check", "columns": ["dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "hope_fear_tension", "pragmatism_fantasy_tension", "mc_sci"], "min": 0.0, "max": 1.0}], "quality_thresholds": {"missing_data_check": 0.0}}, "purpose": "To ensure the integrity and quality of the newly calculated derived metrics by checking for missing values and verifying that they fall within the expected [0.0, 1.0] range."}, "task_3_ideological_comparison_descriptives": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score", "mc_sci"]}, "purpose": "To generate descriptive statistics for comparing the two documents. With N=2, the min and max values will represent the scores for each speaker, directly addressing H1 (Ideological) and H2 (Coherence) by highlighting differences in character profiles and MC-SCI scores."}, "task_4_character_correlation_matrix": {"tool": "generate_correlation_matrix", "parameters": {"dimensions": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score"], "correlation_method": "pearson"}, "purpose": "To fulfill the 'character_correlation_matrix' requirement by analyzing the relationships between the ten core character dimensions across the corpus, providing insight into the framework's dimensional structure."}, "task_5_mc_sci_reliability_check": {"tool": "validate_calculated_metrics", "parameters": {"validation_rules": [{"rule": "consistency_check", "columns": ["mc_sci"]}]}, "purpose": "To perform a logical consistency check on the MC-SCI metric as a proxy for the 'mc_sci_reliability' requirement, given the available tools. This assesses the stability of the calculation."}, "task_6_synthesis_validation_summary": {"tool": "create_summary_statistics", "parameters": {"metrics": ["dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "hope_fear_tension", "pragmatism_fantasy_tension", "mc_sci"], "summary_types": ["mean", "std", "count"]}, "purpose": "To generate a final summary of all calculated metrics, confirming that the entire computational pipeline executed without errors. This serves as the primary validation for H3 (Architecture)."}}}, "results": {"task_1_calculate_derived_metrics": {"type": "derived_metrics_calculation", "success": true, "calculated_metrics": {"hope_fear_tension": [0.06, 0.0415], "dignity_tribalism_tension": [0.0, 0.15000000000000002], "truth_manipulation_tension": [0.10000000000000003, 0.06499999999999999], "justice_resentment_tension": [0.050000000000000044, 0.0825], "pragmatism_fantasy_tension": [0.029999999999999992, 0.0245], "mc_sci": [0.048000000000000015, 0.07270000000000001]}, "successful_calculations": ["hope_fear_tension", "dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "pragmatism_fantasy_tension", "mc_sci"], "failed_calculations": [], "formulas_used": ["dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "hope_fear_tension", "pragmatism_fantasy_tension", "mc_sci"], "input_columns": ["dignity_score", "dignity_salience", "truth_score", "truth_salience", "justice_score", "justice_salience", "hope_score", "hope_salience", "pragmatism_score", "pragmatism_salience", "tribalism_score", "tribalism_salience", "manipulation_score", "manipulation_salience", "resentment_score", "resentment_salience", "fear_score", "fear_salience", "fantasy_score", "fantasy_salience"], "total_metrics": 6, "success_rate": 1.0}, "task_2_validate_calculated_metrics": {"type": "metric_validation", "validation_rules": ["{'rule': 'missing_data_check', 'columns': ['dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension', 'mc_sci']}", "{'rule': 'range_check', 'columns': ['dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension', 'mc_sci'], 'min': 0.0, 'max': 1.0}"], "results": {"unknown_rule": {"status": "not_found", "message": "Metric 'unknown_rule' not found in dataframe", "available_columns": ["aid", "dignity_score", "dignity_raw_score", "dignity_salience", "dignity_confidence", "truth_score", "truth_raw_score", "truth_salience", "truth_confidence", "justice_score", "justice_raw_score", "justice_salience", "justice_confidence", "hope_score", "hope_raw_score", "hope_salience", "hope_confidence", "pragmatism_score", "pragmatism_raw_score", "pragmatism_salience", "pragmatism_confidence", "tribalism_score", "tribalism_raw_score", "tribalism_salience", "tribalism_confidence", "manipulation_score", "manipulation_raw_score", "manipulation_salience", "manipulation_confidence", "resentment_score", "resentment_raw_score", "resentment_salience", "resentment_confidence", "fear_score", "fear_raw_score", "fear_salience", "fear_confidence", "fantasy_score", "fantasy_raw_score", "fantasy_salience", "fantasy_confidence", "hope_fear_tension", "dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "pragmatism_fantasy_tension", "mc_sci"], "note": "This is a framework-agnostic validation - LLMs determine validation logic"}}, "quality_thresholds": {"missing_data_check": 0.0}}, "task_3_ideological_comparison_descriptives": {"type": "descriptive_stats", "columns_analyzed": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score", "mc_sci"], "results": {"dignity_score": {"count": 2, "mean": 0.625, "std": 0.31819805153394637, "min": 0.4, "max": 0.85, "median": 0.625, "q25": 0.5125, "q75": 0.7375, "skewness": NaN, "kurtosis": NaN}, "truth_score": {"count": 2, "mean": 0.675, "std": 0.10606601717798214, "min": 0.6, "max": 0.75, "median": 0.675, "q25": 0.6375, "q75": 0.7125, "skewness": NaN, "kurtosis": NaN}, "justice_score": {"count": 2, "mean": 0.7, "std": 0.0, "min": 0.7, "max": 0.7, "median": 0.7, "q25": 0.7, "q75": 0.7, "skewness": NaN, "kurtosis": NaN}, "hope_score": {"count": 2, "mean": 0.65, "std": 0.21213203435596428, "min": 0.5, "max": 0.8, "median": 0.65, "q25": 0.575, "q75": 0.7250000000000001, "skewness": NaN, "kurtosis": NaN}, "pragmatism_score": {"count": 2, "mean": 0.44999999999999996, "std": 0.21213203435596426, "min": 0.3, "max": 0.6, "median": 0.44999999999999996, "q25": 0.375, "q75": 0.525, "skewness": NaN, "kurtosis": NaN}, "tribalism_score": {"count": 2, "mean": 0.4, "std": 0.282842712474619, "min": 0.2, "max": 0.6, "median": 0.4, "q25": 0.3, "q75": 0.5, "skewness": NaN, "kurtosis": NaN}, "manipulation_score": {"count": 2, "mean": 0.3, "std": 0.282842712474619, "min": 0.1, "max": 0.5, "median": 0.3, "q25": 0.2, "q75": 0.4, "skewness": NaN, "kurtosis": NaN}, "resentment_score": {"count": 2, "mean": 0.325, "std": 0.24748737341529164, "min": 0.15, "max": 0.5, "median": 0.325, "q25": 0.2375, "q75": 0.4125, "skewness": NaN, "kurtosis": NaN}, "fear_score": {"count": 2, "mean": 0.125, "std": 0.10606601717798214, "min": 0.05, "max": 0.2, "median": 0.125, "q25": 0.08750000000000001, "q75": 0.1625, "skewness": NaN, "kurtosis": NaN}, "fantasy_score": {"count": 2, "mean": 0.175, "std": 0.17677669529663687, "min": 0.05, "max": 0.3, "median": 0.175, "q25": 0.1125, "q75": 0.2375, "skewness": NaN, "kurtosis": NaN}, "mc_sci": {"count": 2, "mean": 0.060350000000000015, "std": 0.017465537495307725, "min": 0.048000000000000015, "max": 0.07270000000000001, "median": 0.060350000000000015, "q25": 0.054175000000000015, "q75": 0.06652500000000001, "skewness": NaN, "kurtosis": NaN}}}, "task_4_character_correlation_matrix": {"type": "correlation_matrix", "dimensions": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score"], "method": "pearson", "matrix": {"dignity_score": {"dignity_score": 1.0, "truth_score": 0.9999999999999996, "justice_score": NaN, "hope_score": 1.0, "pragmatism_score": 1.0000000000000002, "tribalism_score": -1.0000000000000002, "manipulation_score": -1.0, "resentment_score": -1.0000000000000002, "fear_score": -1.0, "fantasy_score": -1.0}, "truth_score": {"dignity_score": 0.9999999999999996, "truth_score": 1.0, "justice_score": NaN, "hope_score": 1.0000000000000004, "pragmatism_score": 1.0000000000000004, "tribalism_score": -1.0000000000000004, "manipulation_score": -1.0000000000000004, "resentment_score": -1.0000000000000004, "fear_score": -1.0000000000000002, "fantasy_score": -1.0000000000000004}, "justice_score": {"dignity_score": NaN, "truth_score": NaN, "justice_score": NaN, "hope_score": NaN, "pragmatism_score": NaN, "tribalism_score": NaN, "manipulation_score": NaN, "resentment_score": NaN, "fear_score": NaN, "fantasy_score": NaN}, "hope_score": {"dignity_score": 1.0, "truth_score": 1.0000000000000004, "justice_score": NaN, "hope_score": 1.0, "pragmatism_score": 1.0000000000000002, "tribalism_score": -1.0, "manipulation_score": -0.9999999999999999, "resentment_score": -1.0000000000000002, "fear_score": -1.0, "fantasy_score": -0.9999999999999998}, "pragmatism_score": {"dignity_score": 1.0000000000000002, "truth_score": 1.0000000000000004, "justice_score": NaN, "hope_score": 1.0000000000000002, "pragmatism_score": 1.0, "tribalism_score": -0.9999999999999999, "manipulation_score": -0.9999999999999998, "resentment_score": -1.0, "fear_score": -0.9999999999999999, "fantasy_score": -0.9999999999999998}, "tribalism_score": {"dignity_score": -1.0000000000000002, "truth_score": -1.0000000000000004, "justice_score": NaN, "hope_score": -1.0, "pragmatism_score": -0.9999999999999999, "tribalism_score": 1.0, "manipulation_score": 0.9999999999999998, "resentment_score": 1.0000000000000002, "fear_score": 0.9999999999999998, "fantasy_score": 0.9999999999999999}, "manipulation_score": {"dignity_score": -1.0, "truth_score": -1.0000000000000004, "justice_score": NaN, "hope_score": -0.9999999999999999, "pragmatism_score": -0.9999999999999998, "tribalism_score": 0.9999999999999998, "manipulation_score": 1.0, "resentment_score": 1.0000000000000002, "fear_score": 0.9999999999999999, "fantasy_score": 1.0}, "resentment_score": {"dignity_score": -1.0000000000000002, "truth_score": -1.0000000000000004, "justice_score": NaN, "hope_score": -1.0000000000000002, "pragmatism_score": -1.0, "tribalism_score": 1.0000000000000002, "manipulation_score": 1.0000000000000002, "resentment_score": 1.0, "fear_score": 0.9999999999999999, "fantasy_score": 0.9999999999999999}, "fear_score": {"dignity_score": -1.0, "truth_score": -1.0000000000000002, "justice_score": NaN, "hope_score": -1.0, "pragmatism_score": -0.9999999999999999, "tribalism_score": 0.9999999999999998, "manipulation_score": 0.9999999999999999, "resentment_score": 0.9999999999999999, "fear_score": 1.0, "fantasy_score": 1.0}, "fantasy_score": {"dignity_score": -1.0, "truth_score": -1.0000000000000004, "justice_score": NaN, "hope_score": -0.9999999999999998, "pragmatism_score": -0.9999999999999998, "tribalism_score": 0.9999999999999999, "manipulation_score": 1.0, "resentment_score": 0.9999999999999999, "fear_score": 1.0, "fantasy_score": 1.0}}, "missing_dimensions": []}, "task_6_synthesis_validation_summary": {"type": "summary_statistics", "metrics": ["dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "hope_fear_tension", "pragmatism_fantasy_tension", "mc_sci"], "summary_types": ["mean", "std", "count"], "results": {"dignity_tribalism_tension": {"mean": 0.07500000000000001, "std": 0.10606601717798214, "count": 2}, "truth_manipulation_tension": {"mean": 0.08250000000000002, "std": 0.024748737341529194, "count": 2}, "justice_resentment_tension": {"mean": 0.06625000000000003, "std": 0.022980970388562765, "count": 2}, "hope_fear_tension": {"mean": 0.05075, "std": 0.013081475451951126, "count": 2}, "pragmatism_fantasy_tension": {"mean": 0.027249999999999996, "std": 0.003889087296526005, "count": 2}, "mc_sci": {"mean": 0.060350000000000015, "std": 0.017465537495307725, "count": 2}}, "missing_metrics": []}}, "errors": ["Task 'task_5_mc_sci_reliability_check' failed: validate_calculated_metrics() missing 1 required positional argument: 'quality_thresholds'"]}, "combined_summary": "Two-stage execution: 4 raw data results + 5 derived metrics results"}