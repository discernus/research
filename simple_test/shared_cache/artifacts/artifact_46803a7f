{"stage_1_raw_data": {"analysis_plan": {"stage": "raw_data_collection", "experiment_summary": "This plan outlines the raw data collection phase for the 'simple_character_validation_v7' experiment. The focus is on capturing and validating the raw dimensional scores, salience metadata, and confidence metadata generated by the LLM analysis for each document, according to the Civic Analysis Framework (CAF) v7.1. The plan includes initial data validation steps to ensure the completeness, range, and integrity of the collected raw data before any subsequent analysis.", "tasks": {"validate_data_completeness_and_range": {"tool": "create_summary_statistics", "parameters": {"metrics": ["dignity_score", "tribalism_score", "truth_score", "manipulation_score", "justice_score", "resentment_score", "hope_score", "fear_score", "pragmatism_score", "fantasy_score", "dignity_salience", "tribalism_salience", "truth_salience", "manipulation_salience", "justice_salience", "resentment_salience", "hope_salience", "fear_salience", "pragmatism_salience", "fantasy_salience", "dignity_confidence", "tribalism_confidence", "truth_confidence", "manipulation_confidence", "justice_confidence", "resentment_confidence", "hope_confidence", "fear_confidence", "pragmatism_confidence", "fantasy_confidence"], "summary_types": ["count", "min", "max"]}, "purpose": "To perform a comprehensive initial validation of all 30 raw data fields specified in the CAF v7.1 gasket schema. This task verifies that no data is missing ('count') and that all collected scores and metadata fall within the expected 0.0 to 1.0 range ('min', 'max'), ensuring data integrity at the point of collection."}, "descriptive_stats_for_scores": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["dignity_score", "tribalism_score", "truth_score", "manipulation_score", "justice_score", "resentment_score", "hope_score", "fear_score", "pragmatism_score", "fantasy_score"]}, "purpose": "To generate descriptive statistics for the 10 core dimensional scores. This provides a foundational overview of the raw data distribution, central tendency, and variance as collected from the LLM analysis, serving as a baseline quality check."}, "descriptive_stats_for_salience": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["dignity_salience", "tribalism_salience", "truth_salience", "manipulation_salience", "justice_salience", "resentment_salience", "hope_salience", "fear_salience", "pragmatism_salience", "fantasy_salience"]}, "purpose": "To generate descriptive statistics for the 10 salience metadata scores. This step is crucial for validating the collection of salience data, which is a key requirement of the v7.1 framework for later weighted analysis."}, "descriptive_stats_for_confidence": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["dignity_confidence", "tribalism_confidence", "truth_confidence", "manipulation_confidence", "justice_confidence", "resentment_confidence", "hope_confidence", "fear_confidence", "pragmatism_confidence", "fantasy_confidence"]}, "purpose": "To generate descriptive statistics for the 10 confidence metadata scores. This validates the collection of the model's self-reported confidence, a critical component for assessing the reliability of the raw LLM output."}, "grouped_data_integrity_check": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["dignity_score", "tribalism_score", "justice_score", "resentment_score"], "grouping_variable": "ideology"}, "purpose": "To verify that the raw analysis data has been correctly merged with the corpus metadata. By grouping key scores by the primary experimental variable ('ideology'), this task confirms the structural integrity of the dataset for future comparative analysis."}}}, "results": {"validate_data_completeness_and_range": {"type": "summary_statistics", "metrics": ["dignity_score", "tribalism_score", "truth_score", "manipulation_score", "justice_score", "resentment_score", "hope_score", "fear_score", "pragmatism_score", "fantasy_score", "dignity_salience", "tribalism_salience", "truth_salience", "manipulation_salience", "justice_salience", "resentment_salience", "hope_salience", "fear_salience", "pragmatism_salience", "fantasy_salience", "dignity_confidence", "tribalism_confidence", "truth_confidence", "manipulation_confidence", "justice_confidence", "resentment_confidence", "hope_confidence", "fear_confidence", "pragmatism_confidence", "fantasy_confidence"], "summary_types": ["count", "min", "max"], "results": {"dignity_score": {"min": 0.75, "max": 0.8, "count": 2}, "tribalism_score": {"min": 0.2, "max": 0.7, "count": 2}, "truth_score": {"min": 0.65, "max": 0.75, "count": 2}, "manipulation_score": {"min": 0.3, "max": 0.7, "count": 2}, "justice_score": {"min": 0.4, "max": 0.85, "count": 2}, "resentment_score": {"min": 0.25, "max": 0.6, "count": 2}, "hope_score": {"min": 0.7, "max": 0.7, "count": 2}, "fear_score": {"min": 0.15, "max": 0.3, "count": 2}, "pragmatism_score": {"min": 0.6, "max": 0.65, "count": 2}, "fantasy_score": {"min": 0.05, "max": 0.2, "count": 2}, "dignity_salience": {"min": 0.8, "max": 0.9, "count": 2}, "tribalism_salience": {"min": 0.3, "max": 0.8, "count": 2}, "truth_salience": {"min": 0.7, "max": 0.85, "count": 2}, "manipulation_salience": {"min": 0.4, "max": 0.75, "count": 2}, "justice_salience": {"min": 0.45, "max": 0.95, "count": 2}, "resentment_salience": {"min": 0.35, "max": 0.7, "count": 2}, "hope_salience": {"min": 0.75, "max": 0.75, "count": 2}, "fear_salience": {"min": 0.2, "max": 0.35, "count": 2}, "pragmatism_salience": {"min": 0.65, "max": 0.7, "count": 2}, "fantasy_salience": {"min": 0.1, "max": 0.25, "count": 2}, "dignity_confidence": {"min": 0.8, "max": 0.8, "count": 2}, "tribalism_confidence": {"min": 0.7, "max": 0.75, "count": 2}, "truth_confidence": {"min": 0.7, "max": 0.75, "count": 2}, "manipulation_confidence": {"min": 0.65, "max": 0.7, "count": 2}, "justice_confidence": {"min": 0.7, "max": 0.85, "count": 2}, "resentment_confidence": {"min": 0.6, "max": 0.7, "count": 2}, "hope_confidence": {"min": 0.7, "max": 0.8, "count": 2}, "fear_confidence": {"min": 0.3, "max": 0.7, "count": 2}, "pragmatism_confidence": {"min": 0.65, "max": 0.75, "count": 2}, "fantasy_confidence": {"min": 0.2, "max": 0.7, "count": 2}}, "missing_metrics": []}, "descriptive_stats_for_scores": {"type": "descriptive_stats", "columns_analyzed": ["dignity_score", "tribalism_score", "truth_score", "manipulation_score", "justice_score", "resentment_score", "hope_score", "fear_score", "pragmatism_score", "fantasy_score"], "results": {"dignity_score": {"count": 2, "mean": 0.775, "std": 0.03535533905932741, "min": 0.75, "max": 0.8, "median": 0.775, "q25": 0.7625, "q75": 0.7875000000000001, "skewness": NaN, "kurtosis": NaN}, "tribalism_score": {"count": 2, "mean": 0.44999999999999996, "std": 0.35355339059327373, "min": 0.2, "max": 0.7, "median": 0.44999999999999996, "q25": 0.325, "q75": 0.575, "skewness": NaN, "kurtosis": NaN}, "truth_score": {"count": 2, "mean": 0.7, "std": 0.07071067811865474, "min": 0.65, "max": 0.75, "median": 0.7, "q25": 0.675, "q75": 0.725, "skewness": NaN, "kurtosis": NaN}, "manipulation_score": {"count": 2, "mean": 0.5, "std": 0.282842712474619, "min": 0.3, "max": 0.7, "median": 0.5, "q25": 0.39999999999999997, "q75": 0.6, "skewness": NaN, "kurtosis": NaN}, "justice_score": {"count": 2, "mean": 0.625, "std": 0.31819805153394637, "min": 0.4, "max": 0.85, "median": 0.625, "q25": 0.5125, "q75": 0.7375, "skewness": NaN, "kurtosis": NaN}, "resentment_score": {"count": 2, "mean": 0.425, "std": 0.24748737341529162, "min": 0.25, "max": 0.6, "median": 0.425, "q25": 0.3375, "q75": 0.5125, "skewness": NaN, "kurtosis": NaN}, "hope_score": {"count": 2, "mean": 0.7, "std": 0.0, "min": 0.7, "max": 0.7, "median": 0.7, "q25": 0.7, "q75": 0.7, "skewness": NaN, "kurtosis": NaN}, "fear_score": {"count": 2, "mean": 0.22499999999999998, "std": 0.10606601717798213, "min": 0.15, "max": 0.3, "median": 0.22499999999999998, "q25": 0.1875, "q75": 0.2625, "skewness": NaN, "kurtosis": NaN}, "pragmatism_score": {"count": 2, "mean": 0.625, "std": 0.03535533905932741, "min": 0.6, "max": 0.65, "median": 0.625, "q25": 0.6125, "q75": 0.6375, "skewness": NaN, "kurtosis": NaN}, "fantasy_score": {"count": 2, "mean": 0.125, "std": 0.10606601717798214, "min": 0.05, "max": 0.2, "median": 0.125, "q25": 0.08750000000000001, "q75": 0.1625, "skewness": NaN, "kurtosis": NaN}}}, "descriptive_stats_for_salience": {"type": "descriptive_stats", "columns_analyzed": ["dignity_salience", "tribalism_salience", "truth_salience", "manipulation_salience", "justice_salience", "resentment_salience", "hope_salience", "fear_salience", "pragmatism_salience", "fantasy_salience"], "results": {"dignity_salience": {"count": 2, "mean": 0.8500000000000001, "std": 0.07071067811865474, "min": 0.8, "max": 0.9, "median": 0.8500000000000001, "q25": 0.8250000000000001, "q75": 0.875, "skewness": NaN, "kurtosis": NaN}, "tribalism_salience": {"count": 2, "mean": 0.55, "std": 0.3535533905932738, "min": 0.3, "max": 0.8, "median": 0.55, "q25": 0.425, "q75": 0.675, "skewness": NaN, "kurtosis": NaN}, "truth_salience": {"count": 2, "mean": 0.7749999999999999, "std": 0.10606601717798214, "min": 0.7, "max": 0.85, "median": 0.7749999999999999, "q25": 0.7374999999999999, "q75": 0.8125, "skewness": NaN, "kurtosis": NaN}, "manipulation_salience": {"count": 2, "mean": 0.575, "std": 0.24748737341529162, "min": 0.4, "max": 0.75, "median": 0.575, "q25": 0.48750000000000004, "q75": 0.6625, "skewness": NaN, "kurtosis": NaN}, "justice_salience": {"count": 2, "mean": 0.7, "std": 0.35355339059327373, "min": 0.45, "max": 0.95, "median": 0.7, "q25": 0.575, "q75": 0.825, "skewness": NaN, "kurtosis": NaN}, "resentment_salience": {"count": 2, "mean": 0.5249999999999999, "std": 0.24748737341529162, "min": 0.35, "max": 0.7, "median": 0.5249999999999999, "q25": 0.4375, "q75": 0.6124999999999999, "skewness": NaN, "kurtosis": NaN}, "hope_salience": {"count": 2, "mean": 0.75, "std": 0.0, "min": 0.75, "max": 0.75, "median": 0.75, "q25": 0.75, "q75": 0.75, "skewness": NaN, "kurtosis": NaN}, "fear_salience": {"count": 2, "mean": 0.275, "std": 0.10606601717798211, "min": 0.2, "max": 0.35, "median": 0.275, "q25": 0.2375, "q75": 0.3125, "skewness": NaN, "kurtosis": NaN}, "pragmatism_salience": {"count": 2, "mean": 0.675, "std": 0.03535533905932733, "min": 0.65, "max": 0.7, "median": 0.675, "q25": 0.6625, "q75": 0.6875, "skewness": NaN, "kurtosis": NaN}, "fantasy_salience": {"count": 2, "mean": 0.175, "std": 0.10606601717798213, "min": 0.1, "max": 0.25, "median": 0.175, "q25": 0.1375, "q75": 0.2125, "skewness": NaN, "kurtosis": NaN}}}, "descriptive_stats_for_confidence": {"type": "descriptive_stats", "columns_analyzed": ["dignity_confidence", "tribalism_confidence", "truth_confidence", "manipulation_confidence", "justice_confidence", "resentment_confidence", "hope_confidence", "fear_confidence", "pragmatism_confidence", "fantasy_confidence"], "results": {"dignity_confidence": {"count": 2, "mean": 0.8, "std": 0.0, "min": 0.8, "max": 0.8, "median": 0.8, "q25": 0.8, "q75": 0.8, "skewness": NaN, "kurtosis": NaN}, "tribalism_confidence": {"count": 2, "mean": 0.725, "std": 0.03535533905932741, "min": 0.7, "max": 0.75, "median": 0.725, "q25": 0.7124999999999999, "q75": 0.7375, "skewness": NaN, "kurtosis": NaN}, "truth_confidence": {"count": 2, "mean": 0.725, "std": 0.03535533905932741, "min": 0.7, "max": 0.75, "median": 0.725, "q25": 0.7124999999999999, "q75": 0.7375, "skewness": NaN, "kurtosis": NaN}, "manipulation_confidence": {"count": 2, "mean": 0.675, "std": 0.03535533905932733, "min": 0.65, "max": 0.7, "median": 0.675, "q25": 0.6625, "q75": 0.6875, "skewness": NaN, "kurtosis": NaN}, "justice_confidence": {"count": 2, "mean": 0.7749999999999999, "std": 0.10606601717798214, "min": 0.7, "max": 0.85, "median": 0.7749999999999999, "q25": 0.7374999999999999, "q75": 0.8125, "skewness": NaN, "kurtosis": NaN}, "resentment_confidence": {"count": 2, "mean": 0.6499999999999999, "std": 0.07071067811865474, "min": 0.6, "max": 0.7, "median": 0.6499999999999999, "q25": 0.625, "q75": 0.6749999999999999, "skewness": NaN, "kurtosis": NaN}, "hope_confidence": {"count": 2, "mean": 0.75, "std": 0.07071067811865482, "min": 0.7, "max": 0.8, "median": 0.75, "q25": 0.725, "q75": 0.775, "skewness": NaN, "kurtosis": NaN}, "fear_confidence": {"count": 2, "mean": 0.5, "std": 0.282842712474619, "min": 0.3, "max": 0.7, "median": 0.5, "q25": 0.39999999999999997, "q75": 0.6, "skewness": NaN, "kurtosis": NaN}, "pragmatism_confidence": {"count": 2, "mean": 0.7, "std": 0.07071067811865474, "min": 0.65, "max": 0.75, "median": 0.7, "q25": 0.675, "q75": 0.725, "skewness": NaN, "kurtosis": NaN}, "fantasy_confidence": {"count": 2, "mean": 0.44999999999999996, "std": 0.35355339059327373, "min": 0.2, "max": 0.7, "median": 0.44999999999999996, "q25": 0.325, "q75": 0.575, "skewness": NaN, "kurtosis": NaN}}}, "grouped_data_integrity_check": {"type": "descriptive_stats_grouped", "grouping_variable": "ideology", "groups": {"conservative": {"dignity_score": {"count": 1, "mean": 0.75, "std": NaN, "min": 0.75, "max": 0.75}, "tribalism_score": {"count": 1, "mean": 0.2, "std": NaN, "min": 0.2, "max": 0.2}, "justice_score": {"count": 1, "mean": 0.4, "std": NaN, "min": 0.4, "max": 0.4}, "resentment_score": {"count": 1, "mean": 0.25, "std": NaN, "min": 0.25, "max": 0.25}}, "progressive": {"dignity_score": {"count": 1, "mean": 0.8, "std": NaN, "min": 0.8, "max": 0.8}, "tribalism_score": {"count": 1, "mean": 0.7, "std": NaN, "min": 0.7, "max": 0.7}, "justice_score": {"count": 1, "mean": 0.85, "std": NaN, "min": 0.85, "max": 0.85}, "resentment_score": {"count": 1, "mean": 0.6, "std": NaN, "min": 0.6, "max": 0.6}}}}}, "errors": []}, "stage_2_derived_metrics": {"analysis_plan": {"stage": "derived_metrics_analysis", "experiment_summary": "This plan outlines the calculation of derived metrics and statistical analysis based on the CAF v7.1 framework. The primary steps include: 1) Calculating the five core tension axes and the composite Civic Character Index from the raw dimensional scores. 2) Validating the integrity of these new metrics. 3) Generating comprehensive descriptive statistics for all raw and derived metrics. 4) Creating a correlation matrix to analyze inter-dimensional relationships, fulfilling a key validation requirement. Direct statistical testing of hypotheses involving group comparisons (e.g., by 'ideology' or 'speaker') is not included, as the necessary grouping variables were not found in the available raw data columns. Analysis will focus on descriptive characterization and correlational patterns.", "tasks": {"task_01_calculate_derived_caf_metrics": {"tool": "calculate_derived_metrics", "parameters": {"metric_formulas": {"dignity_tribalism_tension": "(dignity_score + (1 - tribalism_score)) / 2", "truth_manipulation_tension": "(truth_score + (1 - manipulation_score)) / 2", "justice_resentment_tension": "(justice_score + (1 - resentment_score)) / 2", "hope_fear_tension": "(hope_score + (1 - fear_score)) / 2", "pragmatism_fantasy_tension": "(pragmatism_score + (1 - fantasy_score)) / 2", "civic_character_index": "(dignity_tribalism_tension + truth_manipulation_tension + justice_resentment_tension + hope_fear_tension + pragmatism_fantasy_tension) / 5"}, "input_columns": ["dignity_score", "tribalism_score", "truth_score", "manipulation_score", "justice_score", "resentment_score", "hope_score", "fear_score", "pragmatism_score", "fantasy_score"]}, "purpose": "To compute the five core tension axes and the composite Civic Character Index as defined in the CAF v7.1 framework's 'calculation_spec'. This is the foundational step for all subsequent analysis."}, "task_02_validate_calculated_metrics": {"tool": "validate_calculated_metrics", "parameters": {"validation_rules": [{"rule_name": "missing_data_check", "columns": ["dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "hope_fear_tension", "pragmatism_fantasy_tension", "civic_character_index"]}, {"rule_name": "range_check", "columns": ["dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "hope_fear_tension", "pragmatism_fantasy_tension", "civic_character_index"], "expected_range": {"min": 0.0, "max": 1.0}}], "quality_thresholds": {"max_missing_percentage": 0.0}}, "purpose": "To ensure the newly calculated derived metrics are free of null values and fall within the expected 0.0 to 1.0 range, confirming the integrity of the calculations from Task 1."}, "task_03_generate_descriptive_statistics": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["dignity_score", "tribalism_score", "truth_score", "manipulation_score", "justice_score", "resentment_score", "hope_score", "fear_score", "pragmatism_score", "fantasy_score", "dignity_salience", "tribalism_salience", "truth_salience", "manipulation_salience", "justice_salience", "resentment_salience", "hope_salience", "fear_salience", "pragmatism_salience", "fantasy_salience", "dignity_confidence", "tribalism_confidence", "truth_confidence", "manipulation_confidence", "justice_confidence", "resentment_confidence", "hope_confidence", "fear_confidence", "pragmatism_confidence", "fantasy_confidence", "dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "hope_fear_tension", "pragmatism_fantasy_tension", "civic_character_index"]}, "purpose": "To generate summary statistics (mean, std, min, max) for all raw scores, metadata scores, and derived metrics to provide a comprehensive overview of the dataset's characteristics."}, "task_04_generate_character_correlation_matrix": {"tool": "generate_correlation_matrix", "parameters": {"dimensions": ["dignity_score", "tribalism_score", "truth_score", "manipulation_score", "justice_score", "resentment_score", "hope_score", "fear_score", "pragmatism_score", "fantasy_score"], "correlation_method": "pearson"}, "purpose": "To fulfill the 'character_correlation_matrix' validation requirement by examining the inter-relationships between the 10 core character dimensions, identifying patterns of co-occurrence."}, "task_05_summarize_system_performance_metrics": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["extraction_time_seconds"]}, "purpose": "To provide descriptive statistics on system performance metadata, which supports the validation of the v7.1 gasket architecture's processing efficiency (related to Hypothesis H3)."}}}, "results": {"task_01_calculate_derived_caf_metrics": {"type": "derived_metrics_calculation", "success": true, "calculated_metrics": {"hope_fear_tension": [0.7, 0.7749999999999999], "dignity_tribalism_tension": [0.55, 0.775], "truth_manipulation_tension": [0.525, 0.675], "justice_resentment_tension": [0.625, 0.575], "pragmatism_fantasy_tension": [0.7250000000000001, 0.7749999999999999], "civic_character_index": [0.6250000000000001, 0.7150000000000001]}, "successful_calculations": ["hope_fear_tension", "dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "pragmatism_fantasy_tension", "civic_character_index"], "failed_calculations": [], "formulas_used": ["dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "hope_fear_tension", "pragmatism_fantasy_tension", "civic_character_index"], "input_columns": ["dignity_score", "tribalism_score", "truth_score", "manipulation_score", "justice_score", "resentment_score", "hope_score", "fear_score", "pragmatism_score", "fantasy_score"], "total_metrics": 6, "success_rate": 1.0}, "task_02_validate_calculated_metrics": {"type": "metric_validation", "validation_rules": ["{'rule_name': 'missing_data_check', 'columns': ['dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension', 'civic_character_index']}", "{'rule_name': 'range_check', 'columns': ['dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension', 'civic_character_index'], 'expected_range': {'min': 0.0, 'max': 1.0}}"], "results": {"unknown_rule": {"status": "not_found", "message": "Metric 'unknown_rule' not found in dataframe", "available_columns": ["aid", "document_type", "political_party", "year", "temporal_sequence", "speaker", "ideology", "character_profile", "event", "word_count", "source", "preparation_notes", "dignity_score", "tribalism_score", "dignity_salience", "tribalism_salience", "dignity_confidence", "tribalism_confidence", "truth_score", "manipulation_score", "truth_salience", "manipulation_salience", "truth_confidence", "manipulation_confidence", "justice_score", "resentment_score", "justice_salience", "resentment_salience", "justice_confidence", "resentment_confidence", "hope_score", "fear_score", "hope_salience", "fear_salience", "hope_confidence", "fear_confidence", "pragmatism_score", "fantasy_score", "pragmatism_salience", "fantasy_salience", "pragmatism_confidence", "fantasy_confidence", "gasket_version", "extraction_time_seconds", "hope_fear_tension", "dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "pragmatism_fantasy_tension", "civic_character_index"], "note": "This is a framework-agnostic validation - LLMs determine validation logic"}}, "quality_thresholds": {"max_missing_percentage": 0.0}}, "task_03_generate_descriptive_statistics": {"type": "descriptive_stats", "columns_analyzed": ["dignity_score", "tribalism_score", "truth_score", "manipulation_score", "justice_score", "resentment_score", "hope_score", "fear_score", "pragmatism_score", "fantasy_score", "dignity_salience", "tribalism_salience", "truth_salience", "manipulation_salience", "justice_salience", "resentment_salience", "hope_salience", "fear_salience", "pragmatism_salience", "fantasy_salience", "dignity_confidence", "tribalism_confidence", "truth_confidence", "manipulation_confidence", "justice_confidence", "resentment_confidence", "hope_confidence", "fear_confidence", "pragmatism_confidence", "fantasy_confidence", "dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "hope_fear_tension", "pragmatism_fantasy_tension", "civic_character_index"], "results": {"dignity_score": {"count": 2, "mean": 0.775, "std": 0.03535533905932741, "min": 0.75, "max": 0.8, "median": 0.775, "q25": 0.7625, "q75": 0.7875000000000001, "skewness": NaN, "kurtosis": NaN}, "tribalism_score": {"count": 2, "mean": 0.44999999999999996, "std": 0.35355339059327373, "min": 0.2, "max": 0.7, "median": 0.44999999999999996, "q25": 0.325, "q75": 0.575, "skewness": NaN, "kurtosis": NaN}, "truth_score": {"count": 2, "mean": 0.7, "std": 0.07071067811865474, "min": 0.65, "max": 0.75, "median": 0.7, "q25": 0.675, "q75": 0.725, "skewness": NaN, "kurtosis": NaN}, "manipulation_score": {"count": 2, "mean": 0.5, "std": 0.282842712474619, "min": 0.3, "max": 0.7, "median": 0.5, "q25": 0.39999999999999997, "q75": 0.6, "skewness": NaN, "kurtosis": NaN}, "justice_score": {"count": 2, "mean": 0.625, "std": 0.31819805153394637, "min": 0.4, "max": 0.85, "median": 0.625, "q25": 0.5125, "q75": 0.7375, "skewness": NaN, "kurtosis": NaN}, "resentment_score": {"count": 2, "mean": 0.425, "std": 0.24748737341529162, "min": 0.25, "max": 0.6, "median": 0.425, "q25": 0.3375, "q75": 0.5125, "skewness": NaN, "kurtosis": NaN}, "hope_score": {"count": 2, "mean": 0.7, "std": 0.0, "min": 0.7, "max": 0.7, "median": 0.7, "q25": 0.7, "q75": 0.7, "skewness": NaN, "kurtosis": NaN}, "fear_score": {"count": 2, "mean": 0.22499999999999998, "std": 0.10606601717798213, "min": 0.15, "max": 0.3, "median": 0.22499999999999998, "q25": 0.1875, "q75": 0.2625, "skewness": NaN, "kurtosis": NaN}, "pragmatism_score": {"count": 2, "mean": 0.625, "std": 0.03535533905932741, "min": 0.6, "max": 0.65, "median": 0.625, "q25": 0.6125, "q75": 0.6375, "skewness": NaN, "kurtosis": NaN}, "fantasy_score": {"count": 2, "mean": 0.125, "std": 0.10606601717798214, "min": 0.05, "max": 0.2, "median": 0.125, "q25": 0.08750000000000001, "q75": 0.1625, "skewness": NaN, "kurtosis": NaN}, "dignity_salience": {"count": 2, "mean": 0.8500000000000001, "std": 0.07071067811865474, "min": 0.8, "max": 0.9, "median": 0.8500000000000001, "q25": 0.8250000000000001, "q75": 0.875, "skewness": NaN, "kurtosis": NaN}, "tribalism_salience": {"count": 2, "mean": 0.55, "std": 0.3535533905932738, "min": 0.3, "max": 0.8, "median": 0.55, "q25": 0.425, "q75": 0.675, "skewness": NaN, "kurtosis": NaN}, "truth_salience": {"count": 2, "mean": 0.7749999999999999, "std": 0.10606601717798214, "min": 0.7, "max": 0.85, "median": 0.7749999999999999, "q25": 0.7374999999999999, "q75": 0.8125, "skewness": NaN, "kurtosis": NaN}, "manipulation_salience": {"count": 2, "mean": 0.575, "std": 0.24748737341529162, "min": 0.4, "max": 0.75, "median": 0.575, "q25": 0.48750000000000004, "q75": 0.6625, "skewness": NaN, "kurtosis": NaN}, "justice_salience": {"count": 2, "mean": 0.7, "std": 0.35355339059327373, "min": 0.45, "max": 0.95, "median": 0.7, "q25": 0.575, "q75": 0.825, "skewness": NaN, "kurtosis": NaN}, "resentment_salience": {"count": 2, "mean": 0.5249999999999999, "std": 0.24748737341529162, "min": 0.35, "max": 0.7, "median": 0.5249999999999999, "q25": 0.4375, "q75": 0.6124999999999999, "skewness": NaN, "kurtosis": NaN}, "hope_salience": {"count": 2, "mean": 0.75, "std": 0.0, "min": 0.75, "max": 0.75, "median": 0.75, "q25": 0.75, "q75": 0.75, "skewness": NaN, "kurtosis": NaN}, "fear_salience": {"count": 2, "mean": 0.275, "std": 0.10606601717798211, "min": 0.2, "max": 0.35, "median": 0.275, "q25": 0.2375, "q75": 0.3125, "skewness": NaN, "kurtosis": NaN}, "pragmatism_salience": {"count": 2, "mean": 0.675, "std": 0.03535533905932733, "min": 0.65, "max": 0.7, "median": 0.675, "q25": 0.6625, "q75": 0.6875, "skewness": NaN, "kurtosis": NaN}, "fantasy_salience": {"count": 2, "mean": 0.175, "std": 0.10606601717798213, "min": 0.1, "max": 0.25, "median": 0.175, "q25": 0.1375, "q75": 0.2125, "skewness": NaN, "kurtosis": NaN}, "dignity_confidence": {"count": 2, "mean": 0.8, "std": 0.0, "min": 0.8, "max": 0.8, "median": 0.8, "q25": 0.8, "q75": 0.8, "skewness": NaN, "kurtosis": NaN}, "tribalism_confidence": {"count": 2, "mean": 0.725, "std": 0.03535533905932741, "min": 0.7, "max": 0.75, "median": 0.725, "q25": 0.7124999999999999, "q75": 0.7375, "skewness": NaN, "kurtosis": NaN}, "truth_confidence": {"count": 2, "mean": 0.725, "std": 0.03535533905932741, "min": 0.7, "max": 0.75, "median": 0.725, "q25": 0.7124999999999999, "q75": 0.7375, "skewness": NaN, "kurtosis": NaN}, "manipulation_confidence": {"count": 2, "mean": 0.675, "std": 0.03535533905932733, "min": 0.65, "max": 0.7, "median": 0.675, "q25": 0.6625, "q75": 0.6875, "skewness": NaN, "kurtosis": NaN}, "justice_confidence": {"count": 2, "mean": 0.7749999999999999, "std": 0.10606601717798214, "min": 0.7, "max": 0.85, "median": 0.7749999999999999, "q25": 0.7374999999999999, "q75": 0.8125, "skewness": NaN, "kurtosis": NaN}, "resentment_confidence": {"count": 2, "mean": 0.6499999999999999, "std": 0.07071067811865474, "min": 0.6, "max": 0.7, "median": 0.6499999999999999, "q25": 0.625, "q75": 0.6749999999999999, "skewness": NaN, "kurtosis": NaN}, "hope_confidence": {"count": 2, "mean": 0.75, "std": 0.07071067811865482, "min": 0.7, "max": 0.8, "median": 0.75, "q25": 0.725, "q75": 0.775, "skewness": NaN, "kurtosis": NaN}, "fear_confidence": {"count": 2, "mean": 0.5, "std": 0.282842712474619, "min": 0.3, "max": 0.7, "median": 0.5, "q25": 0.39999999999999997, "q75": 0.6, "skewness": NaN, "kurtosis": NaN}, "pragmatism_confidence": {"count": 2, "mean": 0.7, "std": 0.07071067811865474, "min": 0.65, "max": 0.75, "median": 0.7, "q25": 0.675, "q75": 0.725, "skewness": NaN, "kurtosis": NaN}, "fantasy_confidence": {"count": 2, "mean": 0.44999999999999996, "std": 0.35355339059327373, "min": 0.2, "max": 0.7, "median": 0.44999999999999996, "q25": 0.325, "q75": 0.575, "skewness": NaN, "kurtosis": NaN}, "dignity_tribalism_tension": {"count": 2, "mean": 0.6625000000000001, "std": 0.15909902576697318, "min": 0.55, "max": 0.775, "median": 0.6625000000000001, "q25": 0.6062500000000001, "q75": 0.71875, "skewness": NaN, "kurtosis": NaN}, "truth_manipulation_tension": {"count": 2, "mean": 0.6000000000000001, "std": 0.10606601717798214, "min": 0.525, "max": 0.675, "median": 0.6000000000000001, "q25": 0.5625, "q75": 0.6375000000000001, "skewness": NaN, "kurtosis": NaN}, "justice_resentment_tension": {"count": 2, "mean": 0.6, "std": 0.03535533905932741, "min": 0.575, "max": 0.625, "median": 0.6, "q25": 0.5874999999999999, "q75": 0.6125, "skewness": NaN, "kurtosis": NaN}, "hope_fear_tension": {"count": 2, "mean": 0.7374999999999999, "std": 0.053033008588991036, "min": 0.7, "max": 0.7749999999999999, "median": 0.7374999999999999, "q25": 0.71875, "q75": 0.7562499999999999, "skewness": NaN, "kurtosis": NaN}, "pragmatism_fantasy_tension": {"count": 2, "mean": 0.75, "std": 0.03535533905932725, "min": 0.7250000000000001, "max": 0.7749999999999999, "median": 0.75, "q25": 0.7375, "q75": 0.7625, "skewness": NaN, "kurtosis": NaN}, "civic_character_index": {"count": 2, "mean": 0.6700000000000002, "std": 0.06363961030678926, "min": 0.6250000000000001, "max": 0.7150000000000001, "median": 0.6700000000000002, "q25": 0.6475000000000001, "q75": 0.6925000000000001, "skewness": NaN, "kurtosis": NaN}}}, "task_04_generate_character_correlation_matrix": {"type": "correlation_matrix", "dimensions": ["dignity_score", "tribalism_score", "truth_score", "manipulation_score", "justice_score", "resentment_score", "hope_score", "fear_score", "pragmatism_score", "fantasy_score"], "method": "pearson", "matrix": {"dignity_score": {"dignity_score": 1.0, "tribalism_score": 0.9999999999999999, "truth_score": 0.9999999999999994, "manipulation_score": 1.0, "justice_score": 1.0, "resentment_score": 1.0000000000000002, "hope_score": NaN, "fear_score": 0.9999999999999999, "pragmatism_score": 1.0, "fantasy_score": 0.9999999999999999}, "tribalism_score": {"dignity_score": 0.9999999999999999, "tribalism_score": 1.0, "truth_score": 0.9999999999999994, "manipulation_score": 1.0000000000000002, "justice_score": 1.0, "resentment_score": 1.0, "hope_score": NaN, "fear_score": 0.9999999999999998, "pragmatism_score": 1.0, "fantasy_score": 0.9999999999999998}, "truth_score": {"dignity_score": 0.9999999999999994, "tribalism_score": 0.9999999999999994, "truth_score": 1.0, "manipulation_score": 1.0000000000000007, "justice_score": 1.0000000000000004, "resentment_score": 1.0000000000000007, "hope_score": NaN, "fear_score": 1.0000000000000004, "pragmatism_score": 1.0000000000000007, "fantasy_score": 1.0000000000000004}, "manipulation_score": {"dignity_score": 1.0, "tribalism_score": 1.0000000000000002, "truth_score": 1.0000000000000007, "manipulation_score": 1.0, "justice_score": 1.0, "resentment_score": 1.0, "hope_score": NaN, "fear_score": 0.9999999999999998, "pragmatism_score": 1.0, "fantasy_score": 0.9999999999999998}, "justice_score": {"dignity_score": 1.0, "tribalism_score": 1.0, "truth_score": 1.0000000000000004, "manipulation_score": 1.0, "justice_score": 1.0, "resentment_score": 1.0, "hope_score": NaN, "fear_score": 0.9999999999999998, "pragmatism_score": 1.0, "fantasy_score": 1.0}, "resentment_score": {"dignity_score": 1.0000000000000002, "tribalism_score": 1.0, "truth_score": 1.0000000000000007, "manipulation_score": 1.0, "justice_score": 1.0, "resentment_score": 1.0, "hope_score": NaN, "fear_score": 0.9999999999999999, "pragmatism_score": 1.0000000000000002, "fantasy_score": 1.0}, "hope_score": {"dignity_score": NaN, "tribalism_score": NaN, "truth_score": NaN, "manipulation_score": NaN, "justice_score": NaN, "resentment_score": NaN, "hope_score": NaN, "fear_score": NaN, "pragmatism_score": NaN, "fantasy_score": NaN}, "fear_score": {"dignity_score": 0.9999999999999999, "tribalism_score": 0.9999999999999998, "truth_score": 1.0000000000000004, "manipulation_score": 0.9999999999999998, "justice_score": 0.9999999999999998, "resentment_score": 0.9999999999999999, "hope_score": NaN, "fear_score": 1.0, "pragmatism_score": 1.0000000000000002, "fantasy_score": 1.0}, "pragmatism_score": {"dignity_score": 1.0, "tribalism_score": 1.0, "truth_score": 1.0000000000000007, "manipulation_score": 1.0, "justice_score": 1.0, "resentment_score": 1.0000000000000002, "hope_score": NaN, "fear_score": 1.0000000000000002, "pragmatism_score": 1.0, "fantasy_score": 0.9999999999999999}, "fantasy_score": {"dignity_score": 0.9999999999999999, "tribalism_score": 0.9999999999999998, "truth_score": 1.0000000000000004, "manipulation_score": 0.9999999999999998, "justice_score": 1.0, "resentment_score": 1.0, "hope_score": NaN, "fear_score": 1.0, "pragmatism_score": 0.9999999999999999, "fantasy_score": 1.0}}, "missing_dimensions": []}, "task_05_summarize_system_performance_metrics": {"type": "descriptive_stats", "columns_analyzed": ["extraction_time_seconds"], "results": {"extraction_time_seconds": {"count": 2, "mean": 1.3078739643096924, "std": 0.06729941335261942, "min": 1.2602860927581787, "max": 1.355461835861206, "median": 1.3078739643096924, "q25": 1.2840800285339355, "q75": 1.3316679000854492, "skewness": NaN, "kurtosis": NaN}}}}, "errors": []}, "combined_summary": "Two-stage execution: 5 raw data results + 5 derived metrics results"}