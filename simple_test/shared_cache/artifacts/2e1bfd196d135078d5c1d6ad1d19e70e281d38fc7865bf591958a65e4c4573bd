{"stage_1_raw_data": {"analysis_plan": {"stage": "raw_data_collection", "experiment_summary": "This plan outlines the collection and initial validation of raw dimensional scores (score, salience, confidence) from the LLM analysis, as specified by the Character Assessment Framework v6.0. It focuses on ensuring data integrity and completeness before proceeding to statistical analysis.", "tasks": {"summarize_raw_dimensional_scores": {"tool": "create_summary_statistics", "parameters": {"metrics": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score"], "summary_types": ["mean", "std", "min", "max"]}, "purpose": "To perform an initial sanity check on the core character dimension scores, ensuring they fall within the expected 0.0-1.0 range and are populated correctly across all documents."}, "summarize_salience_and_confidence_scores": {"tool": "create_summary_statistics", "parameters": {"metrics": ["dignity_salience", "truth_salience", "justice_salience", "hope_salience", "pragmatism_salience", "tribalism_salience", "manipulation_salience", "resentment_salience", "fear_salience", "fantasy_salience", "dignity_confidence", "truth_confidence", "justice_confidence", "hope_confidence", "pragmatism_confidence", "tribalism_confidence", "manipulation_confidence", "resentment_confidence", "fear_confidence", "fantasy_confidence"], "summary_types": ["mean", "std", "min", "max"]}, "purpose": "To validate the raw salience and confidence scores, which are critical inputs for subsequent character tension calculations, ensuring their integrity and expected range."}, "generate_descriptive_stats_for_all_raw_scores": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score", "dignity_salience", "truth_salience", "justice_salience", "hope_salience", "pragmatism_salience", "tribalism_salience", "manipulation_salience", "resentment_salience", "fear_salience", "fantasy_salience"]}, "purpose": "To generate detailed descriptive statistics for all collected raw scores and salience values, providing a comprehensive overview of data distribution and identifying potential anomalies or biases in the LLM's raw output."}, "validate_evidence_collection_metadata": {"tool": "create_summary_statistics", "parameters": {"metrics": ["evidence_total_quotes", "evidence_average_confidence"], "summary_types": ["sum", "mean", "min", "max"]}, "purpose": "To numerically validate the completeness of the evidence collection process by summarizing key metadata fields (total quotes, average confidence) as specified in the framework's output contract."}}}, "results": {"summarize_raw_dimensional_scores": {"type": "summary_statistics", "metrics": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score"], "summary_types": ["mean", "std", "min", "max"], "results": {"dignity_score": {"mean": 0.625, "std": 0.31819805153394637, "min": 0.4, "max": 0.85}, "truth_score": {"mean": 0.675, "std": 0.10606601717798214, "min": 0.6, "max": 0.75}, "justice_score": {"mean": 0.7, "std": 0.0, "min": 0.7, "max": 0.7}, "hope_score": {"mean": 0.65, "std": 0.21213203435596428, "min": 0.5, "max": 0.8}, "pragmatism_score": {"mean": 0.44999999999999996, "std": 0.21213203435596426, "min": 0.3, "max": 0.6}, "tribalism_score": {"mean": 0.4, "std": 0.282842712474619, "min": 0.2, "max": 0.6}, "manipulation_score": {"mean": 0.3, "std": 0.282842712474619, "min": 0.1, "max": 0.5}, "resentment_score": {"mean": 0.325, "std": 0.24748737341529164, "min": 0.15, "max": 0.5}, "fear_score": {"mean": 0.125, "std": 0.10606601717798214, "min": 0.05, "max": 0.2}, "fantasy_score": {"mean": 0.175, "std": 0.17677669529663687, "min": 0.05, "max": 0.3}}, "missing_metrics": []}, "summarize_salience_and_confidence_scores": {"type": "summary_statistics", "metrics": ["dignity_salience", "truth_salience", "justice_salience", "hope_salience", "pragmatism_salience", "tribalism_salience", "manipulation_salience", "resentment_salience", "fear_salience", "fantasy_salience", "dignity_confidence", "truth_confidence", "justice_confidence", "hope_confidence", "pragmatism_confidence", "tribalism_confidence", "manipulation_confidence", "resentment_confidence", "fear_confidence", "fantasy_confidence"], "summary_types": ["mean", "std", "min", "max"], "results": {"dignity_salience": {"mean": 0.8, "std": 0.14142135623730953, "min": 0.7, "max": 0.9}, "truth_salience": {"mean": 0.8, "std": 0.14142135623730953, "min": 0.7, "max": 0.9}, "justice_salience": {"mean": 0.7250000000000001, "std": 0.10606601717798214, "min": 0.65, "max": 0.8}, "hope_salience": {"mean": 0.725, "std": 0.1767766952966369, "min": 0.6, "max": 0.85}, "pragmatism_salience": {"mean": 0.5, "std": 0.0, "min": 0.5, "max": 0.5}, "tribalism_salience": {"mean": 0.425, "std": 0.38890872965260115, "min": 0.15, "max": 0.7}, "manipulation_salience": {"mean": 0.375, "std": 0.4596194077712559, "min": 0.05, "max": 0.7}, "resentment_salience": {"mean": 0.39999999999999997, "std": 0.42426406871192845, "min": 0.1, "max": 0.7}, "fear_salience": {"mean": 0.16, "std": 0.1979898987322333, "min": 0.02, "max": 0.3}, "fantasy_salience": {"mean": 0.20500000000000002, "std": 0.27577164466275356, "min": 0.01, "max": 0.4}, "dignity_confidence": {"mean": 0.8500000000000001, "std": 0.07071067811865474, "min": 0.8, "max": 0.9}, "truth_confidence": {"mean": 0.875, "std": 0.03535533905932741, "min": 0.85, "max": 0.9}, "justice_confidence": {"mean": 0.825, "std": 0.03535533905932733, "min": 0.8, "max": 0.85}, "hope_confidence": {"mean": 0.825, "std": 0.10606601717798214, "min": 0.75, "max": 0.9}, "pragmatism_confidence": {"mean": 0.725, "std": 0.03535533905932741, "min": 0.7, "max": 0.75}, "tribalism_confidence": {"mean": 0.75, "std": 0.07071067811865482, "min": 0.7, "max": 0.8}, "manipulation_confidence": {"mean": 0.7, "std": 0.07071067811865474, "min": 0.65, "max": 0.75}, "resentment_confidence": {"mean": 0.75, "std": 0.07071067811865482, "min": 0.7, "max": 0.8}, "fear_confidence": {"mean": 0.6, "std": 0.0, "min": 0.6, "max": 0.6}, "fantasy_confidence": {"mean": 0.625, "std": 0.03535533905932741, "min": 0.6, "max": 0.65}}, "missing_metrics": []}, "generate_descriptive_stats_for_all_raw_scores": {"type": "descriptive_stats", "columns_analyzed": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score", "dignity_salience", "truth_salience", "justice_salience", "hope_salience", "pragmatism_salience", "tribalism_salience", "manipulation_salience", "resentment_salience", "fear_salience", "fantasy_salience"], "results": {"dignity_score": {"count": 2, "mean": 0.625, "std": 0.31819805153394637, "min": 0.4, "max": 0.85, "median": 0.625, "q25": 0.5125, "q75": 0.7375, "skewness": NaN, "kurtosis": NaN}, "truth_score": {"count": 2, "mean": 0.675, "std": 0.10606601717798214, "min": 0.6, "max": 0.75, "median": 0.675, "q25": 0.6375, "q75": 0.7125, "skewness": NaN, "kurtosis": NaN}, "justice_score": {"count": 2, "mean": 0.7, "std": 0.0, "min": 0.7, "max": 0.7, "median": 0.7, "q25": 0.7, "q75": 0.7, "skewness": NaN, "kurtosis": NaN}, "hope_score": {"count": 2, "mean": 0.65, "std": 0.21213203435596428, "min": 0.5, "max": 0.8, "median": 0.65, "q25": 0.575, "q75": 0.7250000000000001, "skewness": NaN, "kurtosis": NaN}, "pragmatism_score": {"count": 2, "mean": 0.44999999999999996, "std": 0.21213203435596426, "min": 0.3, "max": 0.6, "median": 0.44999999999999996, "q25": 0.375, "q75": 0.525, "skewness": NaN, "kurtosis": NaN}, "tribalism_score": {"count": 2, "mean": 0.4, "std": 0.282842712474619, "min": 0.2, "max": 0.6, "median": 0.4, "q25": 0.3, "q75": 0.5, "skewness": NaN, "kurtosis": NaN}, "manipulation_score": {"count": 2, "mean": 0.3, "std": 0.282842712474619, "min": 0.1, "max": 0.5, "median": 0.3, "q25": 0.2, "q75": 0.4, "skewness": NaN, "kurtosis": NaN}, "resentment_score": {"count": 2, "mean": 0.325, "std": 0.24748737341529164, "min": 0.15, "max": 0.5, "median": 0.325, "q25": 0.2375, "q75": 0.4125, "skewness": NaN, "kurtosis": NaN}, "fear_score": {"count": 2, "mean": 0.125, "std": 0.10606601717798214, "min": 0.05, "max": 0.2, "median": 0.125, "q25": 0.08750000000000001, "q75": 0.1625, "skewness": NaN, "kurtosis": NaN}, "fantasy_score": {"count": 2, "mean": 0.175, "std": 0.17677669529663687, "min": 0.05, "max": 0.3, "median": 0.175, "q25": 0.1125, "q75": 0.2375, "skewness": NaN, "kurtosis": NaN}, "dignity_salience": {"count": 2, "mean": 0.8, "std": 0.14142135623730953, "min": 0.7, "max": 0.9, "median": 0.8, "q25": 0.75, "q75": 0.85, "skewness": NaN, "kurtosis": NaN}, "truth_salience": {"count": 2, "mean": 0.8, "std": 0.14142135623730953, "min": 0.7, "max": 0.9, "median": 0.8, "q25": 0.75, "q75": 0.85, "skewness": NaN, "kurtosis": NaN}, "justice_salience": {"count": 2, "mean": 0.7250000000000001, "std": 0.10606601717798214, "min": 0.65, "max": 0.8, "median": 0.7250000000000001, "q25": 0.6875, "q75": 0.7625000000000001, "skewness": NaN, "kurtosis": NaN}, "hope_salience": {"count": 2, "mean": 0.725, "std": 0.1767766952966369, "min": 0.6, "max": 0.85, "median": 0.725, "q25": 0.6625, "q75": 0.7875, "skewness": NaN, "kurtosis": NaN}, "pragmatism_salience": {"count": 2, "mean": 0.5, "std": 0.0, "min": 0.5, "max": 0.5, "median": 0.5, "q25": 0.5, "q75": 0.5, "skewness": NaN, "kurtosis": NaN}, "tribalism_salience": {"count": 2, "mean": 0.425, "std": 0.38890872965260115, "min": 0.15, "max": 0.7, "median": 0.425, "q25": 0.2875, "q75": 0.5625, "skewness": NaN, "kurtosis": NaN}, "manipulation_salience": {"count": 2, "mean": 0.375, "std": 0.4596194077712559, "min": 0.05, "max": 0.7, "median": 0.375, "q25": 0.21249999999999997, "q75": 0.5375, "skewness": NaN, "kurtosis": NaN}, "resentment_salience": {"count": 2, "mean": 0.39999999999999997, "std": 0.42426406871192845, "min": 0.1, "max": 0.7, "median": 0.39999999999999997, "q25": 0.25, "q75": 0.5499999999999999, "skewness": NaN, "kurtosis": NaN}, "fear_salience": {"count": 2, "mean": 0.16, "std": 0.1979898987322333, "min": 0.02, "max": 0.3, "median": 0.16, "q25": 0.09, "q75": 0.22999999999999998, "skewness": NaN, "kurtosis": NaN}, "fantasy_salience": {"count": 2, "mean": 0.20500000000000002, "std": 0.27577164466275356, "min": 0.01, "max": 0.4, "median": 0.20500000000000002, "q25": 0.1075, "q75": 0.3025, "skewness": NaN, "kurtosis": NaN}}}}, "errors": ["Task 'validate_evidence_collection_metadata' failed: Summary statistics generation failed: No valid metrics found. Available columns: ['aid', 'dignity_score', 'dignity_raw_score', 'dignity_salience', 'dignity_confidence', 'truth_score', 'truth_raw_score', 'truth_salience', 'truth_confidence', 'justice_score', 'justice_raw_score', 'justice_salience', 'justice_confidence', 'hope_score', 'hope_raw_score', 'hope_salience', 'hope_confidence', 'pragmatism_score', 'pragmatism_raw_score', 'pragmatism_salience', 'pragmatism_confidence', 'tribalism_score', 'tribalism_raw_score', 'tribalism_salience', 'tribalism_confidence', 'manipulation_score', 'manipulation_raw_score', 'manipulation_salience', 'manipulation_confidence', 'resentment_score', 'resentment_raw_score', 'resentment_salience', 'resentment_confidence', 'fear_score', 'fear_raw_score', 'fear_salience', 'fear_confidence', 'fantasy_score', 'fantasy_raw_score', 'fantasy_salience', 'fantasy_confidence']"]}, "stage_2_derived_metrics": {"analysis_plan": {"stage": "derived_metrics_analysis", "experiment_summary": "This plan outlines the calculation of derived metrics from the Character Assessment Framework v6.0, including all five Character Tension scores and the Moral Character Strategic Contradiction Index (MC-SCI). Following calculation and validation, statistical analyses will be performed to compare character profiles, assess dimensional correlations, and evaluate the MC-SCI's ability to differentiate discourse styles, thereby testing the core research hypotheses.", "tasks": {"task_1_calculate_derived_metrics": {"tool": "calculate_derived_metrics", "parameters": {"metric_formulas": {"dignity_tribalism_tension": "np.minimum(dignity_score, tribalism_score) * abs(dignity_salience - tribalism_salience)", "truth_manipulation_tension": "np.minimum(truth_score, manipulation_score) * abs(truth_salience - manipulation_salience)", "justice_resentment_tension": "np.minimum(justice_score, resentment_score) * abs(justice_salience - resentment_salience)", "hope_fear_tension": "np.minimum(hope_score, fear_score) * abs(hope_salience - fear_salience)", "pragmatism_fantasy_tension": "np.minimum(pragmatism_score, fantasy_score) * abs(pragmatism_salience - fantasy_salience)", "mc_sci": "( (np.minimum(dignity_score, tribalism_score) * abs(dignity_salience - tribalism_salience)) + (np.minimum(truth_score, manipulation_score) * abs(truth_salience - manipulation_salience)) + (np.minimum(justice_score, resentment_score) * abs(justice_salience - resentment_salience)) + (np.minimum(hope_score, fear_score) * abs(hope_salience - fear_salience)) + (np.minimum(pragmatism_score, fantasy_score) * abs(pragmatism_salience - fantasy_salience)) ) / 5.0"}, "input_columns": ["dignity_score", "dignity_salience", "tribalism_score", "tribalism_salience", "truth_score", "truth_salience", "manipulation_score", "manipulation_salience", "justice_score", "justice_salience", "resentment_score", "resentment_salience", "hope_score", "hope_salience", "fear_score", "fear_salience", "pragmatism_score", "pragmatism_salience", "fantasy_score", "fantasy_salience"]}, "purpose": "To calculate all derived metrics as specified by the Character Assessment Framework v6.0, including character tensions and the primary MC-SCI index, which are essential for subsequent hypothesis testing."}, "task_2_validate_calculated_metrics": {"tool": "validate_calculated_metrics", "parameters": {"validation_rules": [{"rule_name": "missing_data_check", "columns": ["mc_sci", "dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "hope_fear_tension", "pragmatism_fantasy_tension"]}, {"rule_name": "range_check", "columns": ["mc_sci", "dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "hope_fear_tension", "pragmatism_fantasy_tension"], "min_value": 0.0, "max_value": 1.0}], "quality_thresholds": {"missing_data_check": 0.0}}, "purpose": "To ensure the integrity and reliability of the calculated derived metrics by checking for completeness and verifying that values fall within their expected theoretical ranges (0.0 to 1.0)."}, "task_3_ideological_comparison_analysis": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score", "mc_sci"]}, "purpose": "To generate descriptive statistics for each document (identified by 'aid') across all character dimensions and the MC-SCI. This enables a direct comparison of the character profiles to test H1 (Ideological) and H2 (Coherence) by examining the differences between the conservative and progressive speakers."}, "task_4_character_correlation_matrix": {"tool": "generate_correlation_matrix", "parameters": {"dimensions": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score"], "correlation_method": "pearson"}, "purpose": "To fulfill the 'character_correlation_matrix' requirement by analyzing the inter-relationships between the ten core character dimensions, revealing underlying structural patterns in the framework's application."}, "task_5_mc_sci_reliability_and_coherence_analysis": {"tool": "calculate_descriptive_stats", "parameters": {"columns": ["mc_sci"]}, "purpose": "To specifically analyze the MC-SCI scores for each document to test H2 (Coherence). This isolates the MC-SCI metric to determine if it successfully differentiates between the gracious institutional discourse (expected low MC-SCI) and passionate populist critique (expected higher MC-SCI)."}, "task_6_synthesis_validation_summary": {"tool": "create_summary_statistics", "parameters": {"metrics": ["mc_sci", "dignity_tribalism_tension", "truth_manipulation_tension"], "summary_types": ["mean", "std", "min", "max", "count"]}, "purpose": "To generate a final summary of key calculated metrics. The successful generation of this summary serves as the final validation step for H3 (Architecture), confirming that the v6.0 JSON-first synthesis pipeline successfully processed the analysis from raw data to final metrics without failure."}}}, "results": {"task_1_calculate_derived_metrics": {"type": "derived_metrics_calculation", "success": true, "calculated_metrics": {"hope_fear_tension": [0.06, 0.0415], "dignity_tribalism_tension": [0.0, 0.15000000000000002], "truth_manipulation_tension": [0.10000000000000003, 0.06499999999999999], "justice_resentment_tension": [0.050000000000000044, 0.0825], "pragmatism_fantasy_tension": [0.029999999999999992, 0.0245], "mc_sci": [0.048000000000000015, 0.07270000000000001]}, "successful_calculations": ["hope_fear_tension", "dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "pragmatism_fantasy_tension", "mc_sci"], "failed_calculations": [], "formulas_used": ["dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "hope_fear_tension", "pragmatism_fantasy_tension", "mc_sci"], "input_columns": ["dignity_score", "dignity_salience", "tribalism_score", "tribalism_salience", "truth_score", "truth_salience", "manipulation_score", "manipulation_salience", "justice_score", "justice_salience", "resentment_score", "resentment_salience", "hope_score", "hope_salience", "fear_score", "fear_salience", "pragmatism_score", "pragmatism_salience", "fantasy_score", "fantasy_salience"], "total_metrics": 6, "success_rate": 1.0}, "task_2_validate_calculated_metrics": {"type": "metric_validation", "validation_rules": ["{'rule_name': 'missing_data_check', 'columns': ['mc_sci', 'dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension']}", "{'rule_name': 'range_check', 'columns': ['mc_sci', 'dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension'], 'min_value': 0.0, 'max_value': 1.0}"], "results": {"unknown_rule": {"status": "not_found", "message": "Metric 'unknown_rule' not found in dataframe", "available_columns": ["aid", "dignity_score", "dignity_raw_score", "dignity_salience", "dignity_confidence", "truth_score", "truth_raw_score", "truth_salience", "truth_confidence", "justice_score", "justice_raw_score", "justice_salience", "justice_confidence", "hope_score", "hope_raw_score", "hope_salience", "hope_confidence", "pragmatism_score", "pragmatism_raw_score", "pragmatism_salience", "pragmatism_confidence", "tribalism_score", "tribalism_raw_score", "tribalism_salience", "tribalism_confidence", "manipulation_score", "manipulation_raw_score", "manipulation_salience", "manipulation_confidence", "resentment_score", "resentment_raw_score", "resentment_salience", "resentment_confidence", "fear_score", "fear_raw_score", "fear_salience", "fear_confidence", "fantasy_score", "fantasy_raw_score", "fantasy_salience", "fantasy_confidence", "hope_fear_tension", "dignity_tribalism_tension", "truth_manipulation_tension", "justice_resentment_tension", "pragmatism_fantasy_tension", "mc_sci"], "note": "This is a framework-agnostic validation - LLMs determine validation logic"}}, "quality_thresholds": {"missing_data_check": 0.0}}, "task_3_ideological_comparison_analysis": {"type": "descriptive_stats", "columns_analyzed": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score", "mc_sci"], "results": {"dignity_score": {"count": 2, "mean": 0.625, "std": 0.31819805153394637, "min": 0.4, "max": 0.85, "median": 0.625, "q25": 0.5125, "q75": 0.7375, "skewness": NaN, "kurtosis": NaN}, "truth_score": {"count": 2, "mean": 0.675, "std": 0.10606601717798214, "min": 0.6, "max": 0.75, "median": 0.675, "q25": 0.6375, "q75": 0.7125, "skewness": NaN, "kurtosis": NaN}, "justice_score": {"count": 2, "mean": 0.7, "std": 0.0, "min": 0.7, "max": 0.7, "median": 0.7, "q25": 0.7, "q75": 0.7, "skewness": NaN, "kurtosis": NaN}, "hope_score": {"count": 2, "mean": 0.65, "std": 0.21213203435596428, "min": 0.5, "max": 0.8, "median": 0.65, "q25": 0.575, "q75": 0.7250000000000001, "skewness": NaN, "kurtosis": NaN}, "pragmatism_score": {"count": 2, "mean": 0.44999999999999996, "std": 0.21213203435596426, "min": 0.3, "max": 0.6, "median": 0.44999999999999996, "q25": 0.375, "q75": 0.525, "skewness": NaN, "kurtosis": NaN}, "tribalism_score": {"count": 2, "mean": 0.4, "std": 0.282842712474619, "min": 0.2, "max": 0.6, "median": 0.4, "q25": 0.3, "q75": 0.5, "skewness": NaN, "kurtosis": NaN}, "manipulation_score": {"count": 2, "mean": 0.3, "std": 0.282842712474619, "min": 0.1, "max": 0.5, "median": 0.3, "q25": 0.2, "q75": 0.4, "skewness": NaN, "kurtosis": NaN}, "resentment_score": {"count": 2, "mean": 0.325, "std": 0.24748737341529164, "min": 0.15, "max": 0.5, "median": 0.325, "q25": 0.2375, "q75": 0.4125, "skewness": NaN, "kurtosis": NaN}, "fear_score": {"count": 2, "mean": 0.125, "std": 0.10606601717798214, "min": 0.05, "max": 0.2, "median": 0.125, "q25": 0.08750000000000001, "q75": 0.1625, "skewness": NaN, "kurtosis": NaN}, "fantasy_score": {"count": 2, "mean": 0.175, "std": 0.17677669529663687, "min": 0.05, "max": 0.3, "median": 0.175, "q25": 0.1125, "q75": 0.2375, "skewness": NaN, "kurtosis": NaN}, "mc_sci": {"count": 2, "mean": 0.060350000000000015, "std": 0.017465537495307725, "min": 0.048000000000000015, "max": 0.07270000000000001, "median": 0.060350000000000015, "q25": 0.054175000000000015, "q75": 0.06652500000000001, "skewness": NaN, "kurtosis": NaN}}}, "task_4_character_correlation_matrix": {"type": "correlation_matrix", "dimensions": ["dignity_score", "truth_score", "justice_score", "hope_score", "pragmatism_score", "tribalism_score", "manipulation_score", "resentment_score", "fear_score", "fantasy_score"], "method": "pearson", "matrix": {"dignity_score": {"dignity_score": 1.0, "truth_score": 0.9999999999999996, "justice_score": NaN, "hope_score": 1.0, "pragmatism_score": 1.0000000000000002, "tribalism_score": -1.0000000000000002, "manipulation_score": -1.0, "resentment_score": -1.0000000000000002, "fear_score": -1.0, "fantasy_score": -1.0}, "truth_score": {"dignity_score": 0.9999999999999996, "truth_score": 1.0, "justice_score": NaN, "hope_score": 1.0000000000000004, "pragmatism_score": 1.0000000000000004, "tribalism_score": -1.0000000000000004, "manipulation_score": -1.0000000000000004, "resentment_score": -1.0000000000000004, "fear_score": -1.0000000000000002, "fantasy_score": -1.0000000000000004}, "justice_score": {"dignity_score": NaN, "truth_score": NaN, "justice_score": NaN, "hope_score": NaN, "pragmatism_score": NaN, "tribalism_score": NaN, "manipulation_score": NaN, "resentment_score": NaN, "fear_score": NaN, "fantasy_score": NaN}, "hope_score": {"dignity_score": 1.0, "truth_score": 1.0000000000000004, "justice_score": NaN, "hope_score": 1.0, "pragmatism_score": 1.0000000000000002, "tribalism_score": -1.0, "manipulation_score": -0.9999999999999999, "resentment_score": -1.0000000000000002, "fear_score": -1.0, "fantasy_score": -0.9999999999999998}, "pragmatism_score": {"dignity_score": 1.0000000000000002, "truth_score": 1.0000000000000004, "justice_score": NaN, "hope_score": 1.0000000000000002, "pragmatism_score": 1.0, "tribalism_score": -0.9999999999999999, "manipulation_score": -0.9999999999999998, "resentment_score": -1.0, "fear_score": -0.9999999999999999, "fantasy_score": -0.9999999999999998}, "tribalism_score": {"dignity_score": -1.0000000000000002, "truth_score": -1.0000000000000004, "justice_score": NaN, "hope_score": -1.0, "pragmatism_score": -0.9999999999999999, "tribalism_score": 1.0, "manipulation_score": 0.9999999999999998, "resentment_score": 1.0000000000000002, "fear_score": 0.9999999999999998, "fantasy_score": 0.9999999999999999}, "manipulation_score": {"dignity_score": -1.0, "truth_score": -1.0000000000000004, "justice_score": NaN, "hope_score": -0.9999999999999999, "pragmatism_score": -0.9999999999999998, "tribalism_score": 0.9999999999999998, "manipulation_score": 1.0, "resentment_score": 1.0000000000000002, "fear_score": 0.9999999999999999, "fantasy_score": 1.0}, "resentment_score": {"dignity_score": -1.0000000000000002, "truth_score": -1.0000000000000004, "justice_score": NaN, "hope_score": -1.0000000000000002, "pragmatism_score": -1.0, "tribalism_score": 1.0000000000000002, "manipulation_score": 1.0000000000000002, "resentment_score": 1.0, "fear_score": 0.9999999999999999, "fantasy_score": 0.9999999999999999}, "fear_score": {"dignity_score": -1.0, "truth_score": -1.0000000000000002, "justice_score": NaN, "hope_score": -1.0, "pragmatism_score": -0.9999999999999999, "tribalism_score": 0.9999999999999998, "manipulation_score": 0.9999999999999999, "resentment_score": 0.9999999999999999, "fear_score": 1.0, "fantasy_score": 1.0}, "fantasy_score": {"dignity_score": -1.0, "truth_score": -1.0000000000000004, "justice_score": NaN, "hope_score": -0.9999999999999998, "pragmatism_score": -0.9999999999999998, "tribalism_score": 0.9999999999999999, "manipulation_score": 1.0, "resentment_score": 0.9999999999999999, "fear_score": 1.0, "fantasy_score": 1.0}}, "missing_dimensions": []}, "task_5_mc_sci_reliability_and_coherence_analysis": {"type": "descriptive_stats", "columns_analyzed": ["mc_sci"], "results": {"mc_sci": {"count": 2, "mean": 0.060350000000000015, "std": 0.017465537495307725, "min": 0.048000000000000015, "max": 0.07270000000000001, "median": 0.060350000000000015, "q25": 0.054175000000000015, "q75": 0.06652500000000001, "skewness": NaN, "kurtosis": NaN}}}, "task_6_synthesis_validation_summary": {"type": "summary_statistics", "metrics": ["mc_sci", "dignity_tribalism_tension", "truth_manipulation_tension"], "summary_types": ["mean", "std", "min", "max", "count"], "results": {"mc_sci": {"mean": 0.060350000000000015, "std": 0.017465537495307725, "min": 0.048000000000000015, "max": 0.07270000000000001, "count": 2}, "dignity_tribalism_tension": {"mean": 0.07500000000000001, "std": 0.10606601717798214, "min": 0.0, "max": 0.15000000000000002, "count": 2}, "truth_manipulation_tension": {"mean": 0.08250000000000002, "std": 0.024748737341529194, "min": 0.06499999999999999, "max": 0.10000000000000003, "count": 2}}, "missing_metrics": []}}, "errors": []}, "combined_summary": "Two-stage execution: 3 raw data results + 6 derived metrics results"}