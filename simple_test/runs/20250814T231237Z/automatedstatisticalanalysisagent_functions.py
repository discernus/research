"""
Automated Statistical Analysis Functions
========================================

Generated by AutomatedStatisticalAnalysisAgent for experiment: democratic_discourse_cohesion_study
Description: Comparative analysis of social cohesion patterns across institutional and populist democratic discourse styles
Generated: 2025-08-14T23:12:37.313830+00:00

This module contains automatically generated statistical analysis functions
for comprehensive data analysis including ANOVA, correlations, reliability,
and hypothesis testing as appropriate for the research questions.
"""

import pandas as pd
import numpy as np
import scipy.stats as stats
from typing import Dict, Any, Optional, List, Tuple
import warnings

# Suppress common statistical warnings for cleaner output
warnings.filterwarnings('ignore', category=RuntimeWarning)


def calculate_derived_metrics(data, **kwargs):
    """
    Calculates and adds derived social cohesion metrics to the DataFrame.

    Derived Metrics:
    - Identity Tension: Tribal Dominance - Individual Dignity
    - Emotional Balance: Hope - Fear
    - Success Climate: Compersion - Envy
    - Relational Climate: Amity - Enmity
    - Goal Orientation: Cohesive Goals - Fragmentative Goals
    - Overall Cohesion Index: (Avg of Positive Dimensions) - (Avg of Negative Dimensions)

    Positive Dimensions for OCI: Individual Dignity, Hope, Compersion, Amity, Cohesive Goals
    Negative Dimensions for OCI: Tribal Dominance, Fear, Envy, Enmity, Fragmentative Goals

    Args:
        data (pandas.DataFrame): DataFrame with core dimension scores.
                                 Expected columns: 'tribal_dominance_score',
                                 'individual_dignity_score', 'fear_score', 'hope_score',
                                 'envy_score', 'compersion_score', 'enmity_score',
                                 'amity_score', 'fragmentative_goals_score',
                                 'cohesive_goals_score'.
        **kwargs: Additional parameters (not used in this function, but for framework consistency).

    Returns:
        pandas.DataFrame: The original DataFrame with new derived metric columns,
                          or None if essential columns are missing or data is insufficient.
    """
    import pandas as pd
    import numpy as np

    if not isinstance(data, pd.DataFrame) or data.empty:
        return None

    # Define core dimension columns
    CORE_DIMENSION_COLUMNS = [
        'tribal_dominance_score', 'individual_dignity_score', 'fear_score',
        'hope_score', 'envy_score', 'compersion_score', 'enmity_score',
        'amity_score', 'fragmentative_goals_score', 'cohesive_goals_score'
    ]

    # Define dimensions for Overall Cohesion Index
    POSITIVE_DIMENSIONS_FOR_OCI = [
        'individual_dignity_score', 'hope_score', 'compersion_score',
        'amity_score', 'cohesive_goals_score'
    ]
    NEGATIVE_DIMENSIONS_FOR_OCI = [
        'tribal_dominance_score', 'fear_score', 'envy_score',
        'enmity_score', 'fragmentative_goals_score'
    ]

    # Check if all required columns exist
    missing_cols = [col for col in CORE_DIMENSION_COLUMNS if col not in data.columns]
    if missing_cols:
        print(f"Error: Missing required dimension columns: {', '.join(missing_cols)}")
        return None

    df_copy = data.copy()

    try:
        # Calculate individual derived metrics
        df_copy['identity_tension'] = df_copy['tribal_dominance_score'] - df_copy['individual_dignity_score']
        df_copy['emotional_balance'] = df_copy['hope_score'] - df_copy['fear_score']
        df_copy['success_climate'] = df_copy['compersion_score'] - df_copy['envy_score']
        df_copy['relational_climate'] = df_copy['amity_score'] - df_copy['enmity_score']
        df_copy['goal_orientation'] = df_copy['cohesive_goals_score'] - df_copy['fragmentative_goals_score']

        # Calculate Overall Cohesion Index
        # Ensure all OCI dimensions are numeric and handle NaNs for mean calculation
        positive_data = df_copy[POSITIVE_DIMENSIONS_FOR_OCI].apply(pd.to_numeric, errors='coerce')
        negative_data = df_copy[NEGATIVE_DIMENSIONS_FOR_OCI].apply(pd.to_numeric, errors='coerce')

        df_copy['avg_positive_dimensions'] = positive_data.mean(axis=1, skipna=True)
        df_copy['avg_negative_dimensions'] = negative_data.mean(axis=1, skipna=True)
        df_copy['overall_cohesion_index'] = df_copy['avg_positive_dimensions'] - df_copy['avg_negative_dimensions']

        # Drop intermediate average columns if not needed for final output
        df_copy = df_copy.drop(columns=['avg_positive_dimensions', 'avg_negative_dimensions'])

        return df_copy

    except Exception as e:
        print(f"An error occurred during derived metrics calculation: {e}")
        return None

def calculate_descriptive_statistics(data, **kwargs):
    """
    Calculate descriptive statistics for all numeric dimensions and derived metrics.

    Args:
        data (pandas.DataFrame): DataFrame with dimension scores and potentially derived metrics.
        **kwargs: Additional parameters (not used in this function, but for framework consistency).

    Returns:
        dict: Descriptive statistics (mean, std, count, min, max) for each relevant column,
              or None if insufficient data or an error occurs.
    """
    import pandas as pd
    import numpy as np

    try:
        if not isinstance(data, pd.DataFrame) or data.empty:
            return None

        # Ensure derived metrics are calculated if not already present
        if 'overall_cohesion_index' not in data.columns:
            data = calculate_derived_metrics(data)
            if data is None:
                return None # Failed to calculate derived metrics

        results = {}
        # Select columns that are likely to be scores or derived metrics
        relevant_columns = [col for col in data.columns if col.endswith('_score') or col in [
            'identity_tension', 'emotional_balance', 'success_climate',
            'relational_climate', 'goal_orientation', 'overall_cohesion_index'
        ]]

        for col in relevant_columns:
            # Ensure column is numeric, coerce non-numeric to NaN
            numeric_series = pd.to_numeric(data[col], errors='coerce').dropna()

            if numeric_series.empty:
                results[col] = {'mean': np.nan, 'std': np.nan, 'count': 0, 'min': np.nan, 'max': np.nan}
                continue

            results[col] = {
                'mean': float(numeric_series.mean()),
                'std': float(numeric_series.std()),
                'count': int(numeric_series.count()),
                'min': float(numeric_series.min()),
                'max': float(numeric_series.max())
            }

        return results

    except Exception as e:
        print(f"An error occurred during descriptive statistics calculation: {e}")
        return None

def calculate_correlation_matrix(data, **kwargs):
    """
    Calculates the Pearson correlation matrix for all relevant numeric dimensions and derived metrics.

    Args:
        data (pandas.DataFrame): DataFrame with dimension scores and potentially derived metrics.
        **kwargs:
            columns (list, optional): A list of column names to include in the correlation matrix.
                                      If None, all relevant dimension and derived metric columns are used.
            method (str, optional): The correlation method to use. Defaults to 'pearson'.
                                    Other options include 'kendall' or 'spearman'.

    Returns:
        dict: A dictionary where keys are column names and values are dictionaries
              of correlations with other columns, or None if insufficient data or an error occurs.
    """
    import pandas as pd
    import numpy as np

    try:
        if not isinstance(data, pd.DataFrame) or data.empty:
            return None

        # Ensure derived metrics are calculated if not already present
        if 'overall_cohesion_index' not in data.columns:
            data = calculate_derived_metrics(data)
            if data is None:
                return None # Failed to calculate derived metrics

        # Determine columns for correlation
        default_relevant_columns = [col for col in data.columns if col.endswith('_score') or col in [
            'identity_tension', 'emotional_balance', 'success_climate',
            'relational_climate', 'goal_orientation', 'overall_cohesion_index'
        ]]
        columns_to_correlate = kwargs.get('columns', default_relevant_columns)
        method = kwargs.get('method', 'pearson')

        # Filter data to only include specified columns and drop rows with any NaN in these columns
        df_filtered = data[columns_to_correlate].apply(pd.to_numeric, errors='coerce').dropna()

        if df_filtered.shape[0] < 2: # Need at least 2 rows for correlation
            print("Warning: Insufficient data points for correlation matrix calculation after dropping NaNs.")
            return None

        correlation_matrix = df_filtered.corr(method=method)

        # Convert to a dictionary for easier JSON serialization and framework consistency
        results = correlation_matrix.to_dict(orient='index')
        # Convert numpy types to native Python types for better serialization
        for col, correlations in results.items():
            for key, value in correlations.items():
                if isinstance(value, np.floating):
                    results[col][key] = float(value)
                elif isinstance(value, np.integer):
                    results[col][key] = int(value)
                elif pd.isna(value):
                    results[col][key] = None # Represent NaN as None

        return results

    except Exception as e:
        print(f"An error occurred during correlation matrix calculation: {e}")
        return None

def run_complete_statistical_analysis(data: pd.DataFrame, alpha: float = 0.05) -> Dict[str, Any]:
    """
    Run complete statistical analysis suite on the dataset.
    
    Args:
        data: pandas DataFrame with dimension scores
        alpha: Significance level for hypothesis tests (default: 0.05)
        
    Returns:
        Dictionary with all statistical analysis results
    """
    results = {
        'analysis_metadata': {
            'timestamp': pd.Timestamp.now().isoformat(),
            'sample_size': len(data),
            'alpha_level': alpha,
            'variables_analyzed': list(data.select_dtypes(include=[np.number]).columns)
        }
    }
    
    # Get all analysis functions from this module
    import inspect
    current_module = inspect.getmodule(inspect.currentframe())
    
    for name, obj in inspect.getmembers(current_module):
        if (inspect.isfunction(obj) and 
            name.startswith(('calculate_', 'perform_', 'test_')) and 
            name != 'run_complete_statistical_analysis'):
            try:
                # Pass alpha parameter to functions that might need it
                if 'alpha' in inspect.signature(obj).parameters:
                    results[name] = obj(data, alpha=alpha)
                else:
                    results[name] = obj(data)
            except Exception as e:
                results[name] = {'error': f'Analysis failed: {str(e)}'}
                
    return results


def generate_statistical_summary_report(analysis_results: Dict[str, Any]) -> str:
    """
    Generate a human-readable summary report from statistical analysis results.
    
    Args:
        analysis_results: Results from run_complete_statistical_analysis()
        
    Returns:
        String containing formatted statistical report
    """
    report_lines = []
    report_lines.append("STATISTICAL ANALYSIS SUMMARY REPORT")
    report_lines.append("=" * 50)
    
    metadata = analysis_results.get('analysis_metadata', {})
    report_lines.append(f"Analysis Timestamp: {metadata.get('timestamp', 'Unknown')}")
    report_lines.append(f"Sample Size: {metadata.get('sample_size', 'Unknown')}")
    report_lines.append(f"Alpha Level: {metadata.get('alpha_level', 'Unknown')}")
    report_lines.append(f"Variables: {len(metadata.get('variables_analyzed', []))}")
    report_lines.append("")
    
    # Summarize key findings
    for analysis_name, result in analysis_results.items():
        if analysis_name != 'analysis_metadata' and isinstance(result, dict):
            if 'error' not in result:
                report_lines.append(f"{analysis_name.replace('_', ' ').title()}:")
                
                # Extract key statistics based on analysis type
                if 'p_value' in result:
                    p_val = result['p_value']
                    significance = "significant" if p_val < metadata.get('alpha_level', 0.05) else "not significant"
                    report_lines.append(f"  - p-value: {p_val:.4f} ({significance})")
                
                if 'effect_size' in result:
                    report_lines.append(f"  - Effect size: {result['effect_size']:.4f}")
                
                if 'correlation_matrix' in result:
                    report_lines.append(f"  - Correlation matrix generated with {len(result['correlation_matrix'])} variables")
                
                if 'cronbach_alpha' in result:
                    alpha_val = result['cronbach_alpha']
                    reliability = "excellent" if alpha_val > 0.9 else "good" if alpha_val > 0.8 else "acceptable" if alpha_val > 0.7 else "questionable"
                    report_lines.append(f"  - Cronbach's Î±: {alpha_val:.3f} ({reliability})")
                
                report_lines.append("")
            else:
                report_lines.append(f"{analysis_name}: ERROR - {result['error']}")
                report_lines.append("")
    
    return "\n".join(report_lines)
