"""
Automated Derived Metrics Functions
===================================

Generated by AutomatedDerivedMetricsAgent for experiment: simple_test
Description: No description
Generated: 2025-08-18T22:57:20.685105+00:00

This module contains automatically generated calculation functions for derived metrics
as specified in the framework's natural language descriptions.
"""

import pandas as pd
import numpy as np
from typing import Optional, Dict, Any


def calculate_identity_tension(data, **kwargs):
    """
    Calculate identity_tension: Conflict between tribal dominance and individual dignity dimensions.

    Formula: abs(Tribal Dominance - Individual Dignity)

    Args:
        data (pd.Series): A pandas Series representing a single row of data from a DataFrame.
                          Must contain 'Tribal Dominance' and 'Individual Dignity' columns.
        **kwargs: Additional parameters (not used in this specific calculation).

    Returns:
        float: The calculated identity_tension score, ranging from 0.0 to 0.8.
        None: If required data ('Tribal Dominance', 'Individual Dignity') is missing,
              malformed, or contains NaN values.
    """
    import pandas as pd
    import numpy as np

    try:
        # Define required columns for the calculation
        required_columns = ['Tribal Dominance', 'Individual Dignity']

        # Check if all required columns are present in the input data
        for col in required_columns:
            if col not in data:
                return None

        # Extract scores from the data Series
        tribal_dominance = data['Tribal Dominance']
        individual_dignity = data['Individual Dignity']

        # Check if the extracted values are NaN (Not a Number)
        if pd.isna(tribal_dominance) or pd.isna(individual_dignity):
            return None

        # Ensure values are numeric. This check helps prevent TypeErrors later.
        if not (isinstance(tribal_dominance, (int, float)) and
                isinstance(individual_dignity, (int, float))):
            return None

        # Calculate the identity tension using the absolute difference
        identity_tension = np.abs(tribal_dominance - individual_dignity)

        # Return the result as a float
        return float(identity_tension)

    except Exception:
        # Catch any unexpected errors during processing and return None
        return None

def calculate_emotional_balance(data, **kwargs):
    """
    Calculate emotional_balance: Difference between hope and fear scores

    Args:
        data: pandas DataFrame (expected to be a single row/Series) with 'Hope' and 'Fear' scores.
        **kwargs: Additional parameters (not used in this calculation).

    Returns:
        float: Calculated emotional balance (Hope - Fear) or None if insufficient data.
    """
    import pandas as pd
    import numpy as np

    try:
        # Ensure 'data' is treated as a Series or has appropriate column access
        # If 'data' is a DataFrame containing a single row, access the first row
        if isinstance(data, pd.DataFrame):
            if data.empty:
                return None
            hope_score = data['Hope'].iloc[0] if 'Hope' in data.columns else np.nan
            fear_score = data['Fear'].iloc[0] if 'Fear' in data.columns else np.nan
        elif isinstance(data, pd.Series):
            hope_score = data.get('Hope', np.nan)
            fear_score = data.get('Fear', np.nan)
        else:
            # If data is not a Series or DataFrame, it's an unexpected format
            return None

        # Check for missing or non-numeric values
        if pd.isna(hope_score) or pd.isna(fear_score) or \
           not isinstance(hope_score, (int, float)) or \
           not isinstance(fear_score, (int, float)):
            return None

        emotional_balance = hope_score - fear_score
        return float(emotional_balance)
    except Exception:
        # Catch any other potential errors during access or calculation
        return None

def calculate_success_climate(data, **kwargs):
    """
    Calculate success_climate: Difference between compersion and envy scores.
    Formula: Compersion - Envy
    
    Args:
        data: pandas DataFrame or Series with dimension scores. Expected columns are 'Compersion' and 'Envy'.
        **kwargs: Additional parameters (not used in this calculation but included for framework compatibility).
        
    Returns:
        float: Calculated result or None if 'Compersion' or 'Envy' scores are missing or invalid.
    """
    import pandas as pd
    import numpy as np
    
    try:
        # Ensure data is treated as a Series for consistent access, especially if a single row DataFrame is passed.
        # If 'data' is already a Series (e.g., data.iloc[0]), this is fine.
        # If 'data' is a DataFrame with one row, we can convert it to a Series.
        if isinstance(data, pd.DataFrame) and not data.empty:
            data_row = data.iloc[0]
        elif isinstance(data, pd.Series):
            data_row = data
        else:
            return None # Invalid input data type/structure

        compersion = data_row.get('Compersion')
        envy = data_row.get('Envy')

        # Check for missing values (None or NaN)
        if compersion is None or pd.isna(compersion) or \
           envy is None or pd.isna(envy):
            return None
        
        # Ensure values are numeric before calculation
        if not isinstance(compersion, (int, float)) or \
           not isinstance(envy, (int, float)):
            return None

        result = compersion - envy
        return float(result) # Ensure the result is a float
    except Exception:
        # Catch any other potential errors during processing and return None
        return None

def calculate_relational_climate(data, **kwargs):
    """
    Calculate relational_climate: Difference between amity and enmity scores.
    Formula: Amity - Enmity
    
    Args:
        data: pandas DataFrame or Series containing 'Amity' and 'Enmity' scores.
              Expected to be a single row/Series for calculation.
        **kwargs: Additional parameters (not used in this calculation but part of framework signature).
        
    Returns:
        float: Calculated relational_climate score.
        None: If 'Amity' or 'Enmity' data is missing or cannot be converted to a float.
    """
    import pandas as pd
    import numpy as np
    
    try:
        # Access 'Amity' and 'Enmity' scores.
        # Data can be a Series (single row) or DataFrame.
        # Use .get() for robust access, or direct access if sure it's a Series.
        # Given it's often a single row/Series passed, direct Series access is common.
        
        # Check if data is a Series or a DataFrame (and take the first row if DataFrame)
        if isinstance(data, pd.DataFrame):
            if data.empty:
                return None
            # If it's a DataFrame, assume we're operating on its first row for a single calculation
            amity_val = data['Amity'].iloc[0]
            enmity_val = data['Enmity'].iloc[0]
        elif isinstance(data, pd.Series):
            amity_val = data['Amity']
            enmity_val = data['Enmity']
        else:
            # Unexpected data type
            return None

        # Handle missing data (NaN)
        if pd.isna(amity_val) or pd.isna(enmity_val):
            return None
            
        # Ensure values are numeric (float)
        amity_val = float(amity_val)
        enmity_val = float(enmity_val)
        
        # Calculate the relational_climate
        result = amity_val - enmity_val
        
        return result
        
    except KeyError:
        # One of the required columns ('Amity', 'Enmity') is missing
        return None
    except ValueError:
        # Data exists but cannot be converted to a float
        return None
    except Exception:
        # Catch any other unexpected errors
        return None

def calculate_goal_orientation(data, **kwargs):
    """
    Calculate goal_orientation: Difference between cohesive goals and fragmentative goals
    
    Formula: Cohesive Goals - Fragmentative Goals
    
    Args:
        data: pandas Series (representing a single row of data) or a pandas DataFrame
              (guaranteed to contain exactly one row) with dimension scores.
              Expected to contain 'Cohesive Goals' and 'Fragmentative Goals' columns.
        **kwargs: Additional parameters (not used in this calculation but required by signature).
        
    Returns:
        float: Calculated result (Cohesive Goals - Fragmentative Goals).
        None: If 'Cohesive Goals' or 'Fragmentative Goals' columns are missing in `data`,
              or if their values are non-numeric or NaN.
    """
    import pandas as pd
    import numpy as np # numpy import is often included for numerical ops, though pd.isna is used directly.
    
    required_columns = ['Cohesive Goals', 'Fragmentative Goals']
    
    try:
        # Check if required columns exist in the input data.
        # 'data' can be a Series or a single-row DataFrame.
        # Using 'in data' works for both Series (checking index) and DataFrame (checking columns).
        for col in required_columns:
            if col not in data:
                return None
        
        # Access the raw values from the data.
        # If 'data' is a Series, this will be a scalar.
        # If 'data' is a single-row DataFrame, this will be a Series of length 1.
        cohesive_goals_raw = data[required_columns[0]]
        fragmentative_goals_raw = data[required_columns[1]]

        # Convert Series of length 1 to scalar if necessary (when input 'data' was a DataFrame row)
        if isinstance(cohesive_goals_raw, pd.Series):
            if len(cohesive_goals_raw) == 1:
                cohesive_goals_val = cohesive_goals_raw.iloc[0]
            else:
                return None # Unexpected Series length for a "single row" input
        else:
            cohesive_goals_val = cohesive_goals_raw # Already a scalar (e.g., if input was a Series)

        if isinstance(fragmentative_goals_raw, pd.Series):
            if len(fragmentative_goals_raw) == 1:
                fragmentative_goals_val = fragmentative_goals_raw.iloc[0]
            else:
                return None
        else:
            fragmentative_goals_val = fragmentative_goals_raw

        # Convert extracted values to numeric, coercing any non-numeric or invalid values to NaN.
        cohesive_goals_float = pd.to_numeric(cohesive_goals_val, errors='coerce')
        fragmentative_goals_float = pd.to_numeric(fragmentative_goals_val, errors='coerce')

        # Check if either of the converted values are NaN (which includes original NaNs and coerced errors)
        if pd.isna(cohesive_goals_float) or pd.isna(fragmentative_goals_float):
            return None
            
        # Perform the calculation
        result = float(cohesive_goals_float - fragmentative_goals_float)
        
        return result
        
    except Exception:
        # Catch any unexpected errors during data access, type conversion, or calculation.
        return None

def calculate_overall_cohesion_index(data, **kwargs):
    """
    Calculate overall_cohesion_index: Comprehensive measure combining all dimensions.
    
    Formula:
    overall_cohesion_index = (Sum of [Dimension_Score * Dimension_Salience * Dimension_Confidence] for Cohesion-Promoting Dimensions) - (Sum of [Dimension_Score * Dimension_Salience * Dimension_Confidence] for Cohesion-Undermining Dimensions)
    
    Cohesion-Promoting Dimensions (P):
    - Individual Dignity
    - Hope
    - Compersion
    - Amity
    - Cohesive Goals
    - Compassion
    
    Cohesion-Undermining Dimensions (N):
    - Tribal Dominance
    - Fear
    - Envy
    - Enmity
    - Fragmentative Goals
    
    Args:
        data: pandas DataFrame (expected to be a single row)
        **kwargs: Additional parameters (not used in this calculation)
        
    Returns:
        float: Calculated overall cohesion index. Returns None if required data columns are missing
               or contain NaN values, or if the input 'data' is not a single-row pandas DataFrame.
    """
    
    # Imports are placed here as per template instructions
    import pandas as pd
    import numpy as np
    
    try:
        # Strict check: data must be a pandas DataFrame
        if not isinstance(data, pd.DataFrame):
            return None
        
        # Ensure it's a single-row DataFrame as expected for a single calculation
        if len(data) != 1:
            # If not a single row, the input is not as expected for a per-record calculation
            return None
        
        # Extract the single row as a Series for easier column access
        data_series = data.iloc[0]

        # Define all required base dimension names
        required_base_dimensions = [
            "Individual Dignity", "Hope", "Compersion", "Amity", "Cohesive Goals", "Compassion",
            "Tribal Dominance", "Fear", "Envy", "Enmity", "Fragmentative Goals"
        ]
        
        # Generate full list of required column names including salience and confidence
        required_cols = []
        for dim in required_base_dimensions:
            required_cols.extend([dim, f"{dim}_salience", f"{dim}_confidence"])

        # Check if all required columns exist in the input data_series
        if not all(col in data_series.index for col in required_cols):
            return None
        
        # Check for any NaN values within the required columns
        if data_series.loc[required_cols].isnull().any():
            return None

        # Define dimension groups for calculation
        positive_dimensions = [
            "Individual Dignity", "Hope", "Compersion", "Amity", "Cohesive Goals", "Compassion"
        ]
        negative_dimensions = [
            "Tribal Dominance", "Fear", "Envy", "Enmity", "Fragmentative Goals"
        ]

        total_positive_effect = 0.0
        for dim in positive_dimensions:
            score = data_series[dim]
            salience = data_series[f"{dim}_salience"]
            confidence = data_series[f"{dim}_confidence"]
            total_positive_effect += score * salience * confidence

        total_negative_effect = 0.0
        for dim in negative_dimensions:
            score = data_series[dim]
            salience = data_series[f"{dim}_salience"]
            confidence = data_series[f"{dim}_confidence"]
            total_negative_effect += score * salience * confidence

        overall_cohesion_index = total_positive_effect - total_negative_effect
        
        return float(overall_cohesion_index)
    except Exception:
        # Catch any other unexpected errors during computation and return None gracefully
        return None

def calculate_all_derived_metrics(data: pd.DataFrame) -> Dict[str, Optional[float]]:
    """
    Calculate all derived metrics for the given dataset.
    
    Args:
        data: pandas DataFrame with dimension scores
        
    Returns:
        Dictionary mapping metric names to calculated values
    """
    results = {}
    
    # Get all calculation functions from this module
    import inspect
    current_module = inspect.getmodule(inspect.currentframe())
    
    for name, obj in inspect.getmembers(current_module):
        if (inspect.isfunction(obj) and 
            name.startswith('calculate_') and 
            name not in ['calculate_all_derived_metrics', 'calculate_derived_metrics']):
            try:
                results[name.replace('calculate_', '')] = obj(data)
            except Exception as e:
                results[name.replace('calculate_', '')] = None
                
    return results


def calculate_derived_metrics(data: pd.DataFrame) -> pd.DataFrame:
    """
    Template-compatible wrapper function for derived metrics calculation.
    
    This function is called by the universal notebook template and returns
    the original data with additional derived metric columns.
    
    Args:
        data: pandas DataFrame with dimension scores
        
    Returns:
        DataFrame with original data plus derived metric columns
    """
    # Calculate all derived metrics
    derived_metrics = calculate_all_derived_metrics(data)
    
    # Create a copy of the original data
    result = data.copy()
    
    # Add derived metrics as new columns
    for metric_name, metric_value in derived_metrics.items():
        if metric_value is not None:
            # For scalar metrics, broadcast to all rows
            result[metric_name] = metric_value
        else:
            # For failed calculations, use NaN
            result[metric_name] = np.nan
    
    return result
