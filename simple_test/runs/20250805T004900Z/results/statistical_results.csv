test_name,test_type,statistic_name,statistic_value,p_value,effect_size,degrees_of_freedom,sample_size,dependent_variable,grouping_variable,significance_level,interpretation,notes
task_01_calculate_derived_metrics,derived_metrics_calculation,result_value,"{'type': 'derived_metrics_calculation', 'success': True, 'calculated_metrics': {'hope_fear_tension': [0.7, 0.7749999999999999], 'dignity_tribalism_tension': [0.55, 0.775], 'truth_manipulation_tension': [0.525, 0.675], 'justice_resentment_tension': [0.625, 0.575], 'pragmatism_fantasy_tension': [0.7250000000000001, 0.7749999999999999], 'civic_character_index': [0.6250000000000001, 0.7150000000000001]}, 'successful_calculations': ['hope_fear_tension', 'dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'pragmatism_fantasy_tension', 'civic_character_index'], 'failed_calculations': [], 'formulas_used': ['dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension', 'civic_character_index'], 'input_columns': ['dignity_score', 'tribalism_score', 'truth_score', 'manipulation_score', 'justice_score', 'resentment_score', 'hope_score', 'fear_score', 'pragmatism_score', 'fantasy_score'], 'total_metrics': 6, 'success_rate': 1.0}",,,,,,,,Generic derived_metrics_calculation result,
task_02_calculate_descriptive_statistics,descriptive_stats,result_value,"{'type': 'descriptive_stats', 'columns_analyzed': ['dignity_score', 'tribalism_score', 'truth_score', 'manipulation_score', 'justice_score', 'resentment_score', 'hope_score', 'fear_score', 'pragmatism_score', 'fantasy_score', 'dignity_salience', 'tribalism_salience', 'truth_salience', 'manipulation_salience', 'justice_salience', 'resentment_salience', 'hope_salience', 'fear_salience', 'pragmatism_salience', 'fantasy_salience', 'dignity_confidence', 'tribalism_confidence', 'truth_confidence', 'manipulation_confidence', 'justice_confidence', 'resentment_confidence', 'hope_confidence', 'fear_confidence', 'pragmatism_confidence', 'fantasy_confidence', 'dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension', 'civic_character_index'], 'results': {'dignity_score': {'count': 2, 'mean': 0.775, 'std': 0.03535533905932741, 'min': 0.75, 'max': 0.8, 'median': 0.775, 'q25': 0.7625, 'q75': 0.7875000000000001, 'skewness': nan, 'kurtosis': nan}, 'tribalism_score': {'count': 2, 'mean': 0.44999999999999996, 'std': 0.35355339059327373, 'min': 0.2, 'max': 0.7, 'median': 0.44999999999999996, 'q25': 0.325, 'q75': 0.575, 'skewness': nan, 'kurtosis': nan}, 'truth_score': {'count': 2, 'mean': 0.7, 'std': 0.07071067811865474, 'min': 0.65, 'max': 0.75, 'median': 0.7, 'q25': 0.675, 'q75': 0.725, 'skewness': nan, 'kurtosis': nan}, 'manipulation_score': {'count': 2, 'mean': 0.5, 'std': 0.282842712474619, 'min': 0.3, 'max': 0.7, 'median': 0.5, 'q25': 0.39999999999999997, 'q75': 0.6, 'skewness': nan, 'kurtosis': nan}, 'justice_score': {'count': 2, 'mean': 0.625, 'std': 0.31819805153394637, 'min': 0.4, 'max': 0.85, 'median': 0.625, 'q25': 0.5125, 'q75': 0.7375, 'skewness': nan, 'kurtosis': nan}, 'resentment_score': {'count': 2, 'mean': 0.425, 'std': 0.24748737341529162, 'min': 0.25, 'max': 0.6, 'median': 0.425, 'q25': 0.3375, 'q75': 0.5125, 'skewness': nan, 'kurtosis': nan}, 'hope_score': {'count': 2, 'mean': 0.7, 'std': 0.0, 'min': 0.7, 'max': 0.7, 'median': 0.7, 'q25': 0.7, 'q75': 0.7, 'skewness': nan, 'kurtosis': nan}, 'fear_score': {'count': 2, 'mean': 0.22499999999999998, 'std': 0.10606601717798213, 'min': 0.15, 'max': 0.3, 'median': 0.22499999999999998, 'q25': 0.1875, 'q75': 0.2625, 'skewness': nan, 'kurtosis': nan}, 'pragmatism_score': {'count': 2, 'mean': 0.625, 'std': 0.03535533905932741, 'min': 0.6, 'max': 0.65, 'median': 0.625, 'q25': 0.6125, 'q75': 0.6375, 'skewness': nan, 'kurtosis': nan}, 'fantasy_score': {'count': 2, 'mean': 0.125, 'std': 0.10606601717798214, 'min': 0.05, 'max': 0.2, 'median': 0.125, 'q25': 0.08750000000000001, 'q75': 0.1625, 'skewness': nan, 'kurtosis': nan}, 'dignity_salience': {'count': 2, 'mean': 0.8500000000000001, 'std': 0.07071067811865474, 'min': 0.8, 'max': 0.9, 'median': 0.8500000000000001, 'q25': 0.8250000000000001, 'q75': 0.875, 'skewness': nan, 'kurtosis': nan}, 'tribalism_salience': {'count': 2, 'mean': 0.55, 'std': 0.3535533905932738, 'min': 0.3, 'max': 0.8, 'median': 0.55, 'q25': 0.425, 'q75': 0.675, 'skewness': nan, 'kurtosis': nan}, 'truth_salience': {'count': 2, 'mean': 0.7749999999999999, 'std': 0.10606601717798214, 'min': 0.7, 'max': 0.85, 'median': 0.7749999999999999, 'q25': 0.7374999999999999, 'q75': 0.8125, 'skewness': nan, 'kurtosis': nan}, 'manipulation_salience': {'count': 2, 'mean': 0.575, 'std': 0.24748737341529162, 'min': 0.4, 'max': 0.75, 'median': 0.575, 'q25': 0.48750000000000004, 'q75': 0.6625, 'skewness': nan, 'kurtosis': nan}, 'justice_salience': {'count': 2, 'mean': 0.7, 'std': 0.35355339059327373, 'min': 0.45, 'max': 0.95, 'median': 0.7, 'q25': 0.575, 'q75': 0.825, 'skewness': nan, 'kurtosis': nan}, 'resentment_salience': {'count': 2, 'mean': 0.5249999999999999, 'std': 0.24748737341529162, 'min': 0.35, 'max': 0.7, 'median': 0.5249999999999999, 'q25': 0.4375, 'q75': 0.6124999999999999, 'skewness': nan, 'kurtosis': nan}, 'hope_salience': {'count': 2, 'mean': 0.75, 'std': 0.0, 'min': 0.75, 'max': 0.75, 'median': 0.75, 'q25': 0.75, 'q75': 0.75, 'skewness': nan, 'kurtosis': nan}, 'fear_salience': {'count': 2, 'mean': 0.275, 'std': 0.10606601717798211, 'min': 0.2, 'max': 0.35, 'median': 0.275, 'q25': 0.2375, 'q75': 0.3125, 'skewness': nan, 'kurtosis': nan}, 'pragmatism_salience': {'count': 2, 'mean': 0.675, 'std': 0.03535533905932733, 'min': 0.65, 'max': 0.7, 'median': 0.675, 'q25': 0.6625, 'q75': 0.6875, 'skewness': nan, 'kurtosis': nan}, 'fantasy_salience': {'count': 2, 'mean': 0.175, 'std': 0.10606601717798213, 'min': 0.1, 'max': 0.25, 'median': 0.175, 'q25': 0.1375, 'q75': 0.2125, 'skewness': nan, 'kurtosis': nan}, 'dignity_confidence': {'count': 2, 'mean': 0.8, 'std': 0.0, 'min': 0.8, 'max': 0.8, 'median': 0.8, 'q25': 0.8, 'q75': 0.8, 'skewness': nan, 'kurtosis': nan}, 'tribalism_confidence': {'count': 2, 'mean': 0.725, 'std': 0.03535533905932741, 'min': 0.7, 'max': 0.75, 'median': 0.725, 'q25': 0.7124999999999999, 'q75': 0.7375, 'skewness': nan, 'kurtosis': nan}, 'truth_confidence': {'count': 2, 'mean': 0.725, 'std': 0.03535533905932741, 'min': 0.7, 'max': 0.75, 'median': 0.725, 'q25': 0.7124999999999999, 'q75': 0.7375, 'skewness': nan, 'kurtosis': nan}, 'manipulation_confidence': {'count': 2, 'mean': 0.675, 'std': 0.03535533905932733, 'min': 0.65, 'max': 0.7, 'median': 0.675, 'q25': 0.6625, 'q75': 0.6875, 'skewness': nan, 'kurtosis': nan}, 'justice_confidence': {'count': 2, 'mean': 0.7749999999999999, 'std': 0.10606601717798214, 'min': 0.7, 'max': 0.85, 'median': 0.7749999999999999, 'q25': 0.7374999999999999, 'q75': 0.8125, 'skewness': nan, 'kurtosis': nan}, 'resentment_confidence': {'count': 2, 'mean': 0.6499999999999999, 'std': 0.07071067811865474, 'min': 0.6, 'max': 0.7, 'median': 0.6499999999999999, 'q25': 0.625, 'q75': 0.6749999999999999, 'skewness': nan, 'kurtosis': nan}, 'hope_confidence': {'count': 2, 'mean': 0.75, 'std': 0.07071067811865482, 'min': 0.7, 'max': 0.8, 'median': 0.75, 'q25': 0.725, 'q75': 0.775, 'skewness': nan, 'kurtosis': nan}, 'fear_confidence': {'count': 2, 'mean': 0.5, 'std': 0.282842712474619, 'min': 0.3, 'max': 0.7, 'median': 0.5, 'q25': 0.39999999999999997, 'q75': 0.6, 'skewness': nan, 'kurtosis': nan}, 'pragmatism_confidence': {'count': 2, 'mean': 0.7, 'std': 0.07071067811865474, 'min': 0.65, 'max': 0.75, 'median': 0.7, 'q25': 0.675, 'q75': 0.725, 'skewness': nan, 'kurtosis': nan}, 'fantasy_confidence': {'count': 2, 'mean': 0.475, 'std': 0.38890872965260115, 'min': 0.2, 'max': 0.75, 'median': 0.475, 'q25': 0.3375, 'q75': 0.6125, 'skewness': nan, 'kurtosis': nan}, 'dignity_tribalism_tension': {'count': 2, 'mean': 0.6625000000000001, 'std': 0.15909902576697318, 'min': 0.55, 'max': 0.775, 'median': 0.6625000000000001, 'q25': 0.6062500000000001, 'q75': 0.71875, 'skewness': nan, 'kurtosis': nan}, 'truth_manipulation_tension': {'count': 2, 'mean': 0.6000000000000001, 'std': 0.10606601717798214, 'min': 0.525, 'max': 0.675, 'median': 0.6000000000000001, 'q25': 0.5625, 'q75': 0.6375000000000001, 'skewness': nan, 'kurtosis': nan}, 'justice_resentment_tension': {'count': 2, 'mean': 0.6, 'std': 0.03535533905932741, 'min': 0.575, 'max': 0.625, 'median': 0.6, 'q25': 0.5874999999999999, 'q75': 0.6125, 'skewness': nan, 'kurtosis': nan}, 'hope_fear_tension': {'count': 2, 'mean': 0.7374999999999999, 'std': 0.053033008588991036, 'min': 0.7, 'max': 0.7749999999999999, 'median': 0.7374999999999999, 'q25': 0.71875, 'q75': 0.7562499999999999, 'skewness': nan, 'kurtosis': nan}, 'pragmatism_fantasy_tension': {'count': 2, 'mean': 0.75, 'std': 0.03535533905932725, 'min': 0.7250000000000001, 'max': 0.7749999999999999, 'median': 0.75, 'q25': 0.7375, 'q75': 0.7625, 'skewness': nan, 'kurtosis': nan}, 'civic_character_index': {'count': 2, 'mean': 0.6700000000000002, 'std': 0.06363961030678926, 'min': 0.6250000000000001, 'max': 0.7150000000000001, 'median': 0.6700000000000002, 'q25': 0.6475000000000001, 'q75': 0.6925000000000001, 'skewness': nan, 'kurtosis': nan}}}",,,,,,,,Generic descriptive_stats result,
task_04_validate_calculated_metrics,metric_validation,result_value,"{'type': 'metric_validation', 'validation_rules': [""{'rule_name': 'missing_data_check', 'columns': ['dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension', 'civic_character_index']}"", ""{'rule_name': 'range_check', 'columns': ['dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension', 'civic_character_index'], 'expected_range': {'min': 0.0, 'max': 1.0}}""], 'results': {'unknown_rule': {'status': 'not_found', 'message': ""Metric 'unknown_rule' not found in dataframe"", 'available_columns': ['aid', 'document_type', 'political_party', 'year', 'temporal_sequence', 'speaker', 'ideology', 'character_profile', 'event', 'word_count', 'source', 'preparation_notes', 'dignity_score', 'tribalism_score', 'dignity_salience', 'tribalism_salience', 'dignity_confidence', 'tribalism_confidence', 'truth_score', 'manipulation_score', 'truth_salience', 'manipulation_salience', 'truth_confidence', 'manipulation_confidence', 'justice_score', 'resentment_score', 'justice_salience', 'resentment_salience', 'justice_confidence', 'resentment_confidence', 'hope_score', 'fear_score', 'hope_salience', 'fear_salience', 'hope_confidence', 'fear_confidence', 'pragmatism_score', 'fantasy_score', 'pragmatism_salience', 'fantasy_salience', 'pragmatism_confidence', 'fantasy_confidence', 'gasket_version', 'extraction_time_seconds', 'hope_fear_tension', 'dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'pragmatism_fantasy_tension', 'civic_character_index'], 'note': 'This is a framework-agnostic validation - LLMs determine validation logic'}}, 'quality_thresholds': {'max_missing_percentage': 0.05}}",,,,,,,,Generic metric_validation result,
task_05_assess_analysis_reliability,summary_statistics,result_value,"{'type': 'summary_statistics', 'metrics': ['dignity_confidence', 'tribalism_confidence', 'truth_confidence', 'manipulation_confidence', 'justice_confidence', 'resentment_confidence', 'hope_confidence', 'fear_confidence', 'pragmatism_confidence', 'fantasy_confidence'], 'summary_types': ['mean', 'std', 'min', 'max'], 'results': {'dignity_confidence': {'mean': 0.8, 'std': 0.0, 'min': 0.8, 'max': 0.8}, 'tribalism_confidence': {'mean': 0.725, 'std': 0.03535533905932741, 'min': 0.7, 'max': 0.75}, 'truth_confidence': {'mean': 0.725, 'std': 0.03535533905932741, 'min': 0.7, 'max': 0.75}, 'manipulation_confidence': {'mean': 0.675, 'std': 0.03535533905932733, 'min': 0.65, 'max': 0.7}, 'justice_confidence': {'mean': 0.7749999999999999, 'std': 0.10606601717798214, 'min': 0.7, 'max': 0.85}, 'resentment_confidence': {'mean': 0.6499999999999999, 'std': 0.07071067811865474, 'min': 0.6, 'max': 0.7}, 'hope_confidence': {'mean': 0.75, 'std': 0.07071067811865482, 'min': 0.7, 'max': 0.8}, 'fear_confidence': {'mean': 0.5, 'std': 0.282842712474619, 'min': 0.3, 'max': 0.7}, 'pragmatism_confidence': {'mean': 0.7, 'std': 0.07071067811865474, 'min': 0.65, 'max': 0.75}, 'fantasy_confidence': {'mean': 0.475, 'std': 0.38890872965260115, 'min': 0.2, 'max': 0.75}}, 'missing_metrics': []}",,,,,,,,Generic summary_statistics result,
