test_name,test_type,statistic_name,statistic_value,p_value,effect_size,degrees_of_freedom,sample_size,dependent_variable,grouping_variable,significance_level,interpretation,notes
task_01_calculate_derived_metrics,derived_metrics_calculation,result_value,"{'type': 'derived_metrics_calculation', 'success': True, 'calculated_metrics': {'hope_fear_tension': [0.6499999999999999, 0.8], 'dignity_tribalism_tension': [0.55, 0.8], 'truth_manipulation_tension': [0.55, 0.75], 'justice_resentment_tension': [0.55, 0.65], 'pragmatism_fantasy_tension': [0.7, 0.7], 'virtue_index': [0.6599999999999999, 0.6], 'pathology_index': [0.45999999999999996, 0.12], 'civic_character_index': [0.6, 0.74], 'salience_weighted_civic_character_index': [0.5972972972972973, 0.7551724137931034]}, 'successful_calculations': ['hope_fear_tension', 'dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'pragmatism_fantasy_tension', 'virtue_index', 'pathology_index', 'civic_character_index', 'salience_weighted_civic_character_index'], 'failed_calculations': [], 'formulas_used': ['dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension', 'civic_character_index', 'salience_weighted_civic_character_index', 'virtue_index', 'pathology_index'], 'input_columns': ['dignity_score', 'tribalism_score', 'truth_score', 'manipulation_score', 'justice_score', 'resentment_score', 'hope_score', 'fear_score', 'pragmatism_score', 'fantasy_score', 'dignity_salience', 'truth_salience', 'justice_salience', 'hope_salience', 'pragmatism_salience'], 'total_metrics': 9, 'success_rate': 1.0}",,,,,,,,Generic derived_metrics_calculation result,
task_02_validate_calculated_metrics,metric_validation,result_value,"{'type': 'metric_validation', 'validation_rules': [""{'rule_name': 'missing_data_check', 'metrics': ['dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension', 'civic_character_index', 'salience_weighted_civic_character_index', 'virtue_index', 'pathology_index']}"", ""{'rule_name': 'range_check', 'metrics': ['dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension', 'civic_character_index', 'salience_weighted_civic_character_index', 'virtue_index', 'pathology_index'], 'min_value': 0.0, 'max_value': 1.0}""], 'results': {'unknown_rule': {'status': 'not_found', 'message': ""Metric 'unknown_rule' not found in dataframe"", 'available_columns': ['aid', 'document_type', 'political_party', 'year', 'temporal_sequence', 'speaker', 'ideology', 'character_profile', 'event', 'word_count', 'source', 'preparation_notes', 'dignity_score', 'tribalism_score', 'dignity_salience', 'tribalism_salience', 'dignity_confidence', 'tribalism_confidence', 'truth_score', 'manipulation_score', 'truth_salience', 'manipulation_salience', 'truth_confidence', 'manipulation_confidence', 'justice_score', 'resentment_score', 'justice_salience', 'resentment_salience', 'justice_confidence', 'resentment_confidence', 'hope_score', 'fear_score', 'hope_salience', 'fear_salience', 'hope_confidence', 'fear_confidence', 'pragmatism_score', 'fantasy_score', 'pragmatism_salience', 'fantasy_salience', 'pragmatism_confidence', 'fantasy_confidence', 'gasket_version', 'extraction_time_seconds', 'hope_fear_tension', 'dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'pragmatism_fantasy_tension', 'virtue_index', 'pathology_index', 'civic_character_index', 'salience_weighted_civic_character_index'], 'note': 'This is a framework-agnostic validation - LLMs determine validation logic'}}, 'quality_thresholds': {'min_valid_ratio': 0.8, 'max_outlier_ratio': 0.1, 'min_variance': 0.01, 'correlation_threshold': 0.95}}",,,,,,,,Generic metric_validation result,
task_03_descriptive_statistics_all_metrics,descriptive_stats,result_value,"{'type': 'descriptive_stats', 'columns_analyzed': ['dignity_score', 'tribalism_score', 'truth_score', 'manipulation_score', 'justice_score', 'resentment_score', 'hope_score', 'fear_score', 'pragmatism_score', 'fantasy_score', 'civic_character_index', 'salience_weighted_civic_character_index', 'virtue_index', 'pathology_index'], 'results': {'dignity_score': {'count': 2, 'mean': 0.75, 'std': 0.07071067811865482, 'min': 0.7, 'max': 0.8, 'median': 0.75, 'q25': 0.725, 'q75': 0.775, 'skewness': nan, 'kurtosis': nan}, 'tribalism_score': {'count': 2, 'mean': 0.4, 'std': 0.282842712474619, 'min': 0.2, 'max': 0.6, 'median': 0.4, 'q25': 0.3, 'q75': 0.5, 'skewness': nan, 'kurtosis': nan}, 'truth_score': {'count': 2, 'mean': 0.55, 'std': 0.07071067811865474, 'min': 0.5, 'max': 0.6, 'median': 0.55, 'q25': 0.525, 'q75': 0.575, 'skewness': nan, 'kurtosis': nan}, 'manipulation_score': {'count': 2, 'mean': 0.25, 'std': 0.21213203435596428, 'min': 0.1, 'max': 0.4, 'median': 0.25, 'q25': 0.17500000000000002, 'q75': 0.325, 'skewness': nan, 'kurtosis': nan}, 'justice_score': {'count': 2, 'mean': 0.6000000000000001, 'std': 0.282842712474619, 'min': 0.4, 'max': 0.8, 'median': 0.6000000000000001, 'q25': 0.5, 'q75': 0.7000000000000001, 'skewness': nan, 'kurtosis': nan}, 'resentment_score': {'count': 2, 'mean': 0.39999999999999997, 'std': 0.42426406871192845, 'min': 0.1, 'max': 0.7, 'median': 0.39999999999999997, 'q25': 0.25, 'q75': 0.5499999999999999, 'skewness': nan, 'kurtosis': nan}, 'hope_score': {'count': 2, 'mean': 0.6499999999999999, 'std': 0.07071067811865474, 'min': 0.6, 'max': 0.7, 'median': 0.6499999999999999, 'q25': 0.625, 'q75': 0.6749999999999999, 'skewness': nan, 'kurtosis': nan}, 'fear_score': {'count': 2, 'mean': 0.2, 'std': 0.1414213562373095, 'min': 0.1, 'max': 0.3, 'median': 0.2, 'q25': 0.15, 'q75': 0.25, 'skewness': nan, 'kurtosis': nan}, 'pragmatism_score': {'count': 2, 'mean': 0.6, 'std': 0.14142135623730948, 'min': 0.5, 'max': 0.7, 'median': 0.6, 'q25': 0.55, 'q75': 0.6499999999999999, 'skewness': nan, 'kurtosis': nan}, 'fantasy_score': {'count': 2, 'mean': 0.2, 'std': 0.1414213562373095, 'min': 0.1, 'max': 0.3, 'median': 0.2, 'q25': 0.15, 'q75': 0.25, 'skewness': nan, 'kurtosis': nan}, 'civic_character_index': {'count': 2, 'mean': 0.6699999999999999, 'std': 0.09899494936611666, 'min': 0.6, 'max': 0.74, 'median': 0.6699999999999999, 'q25': 0.635, 'q75': 0.705, 'skewness': nan, 'kurtosis': nan}, 'salience_weighted_civic_character_index': {'count': 2, 'mean': 0.6762348555452004, 'std': 0.11163456545480066, 'min': 0.5972972972972973, 'max': 0.7551724137931034, 'median': 0.6762348555452004, 'q25': 0.6367660764212488, 'q75': 0.7157036346691519, 'skewness': nan, 'kurtosis': nan}, 'virtue_index': {'count': 2, 'mean': 0.6299999999999999, 'std': 0.04242640687119281, 'min': 0.6, 'max': 0.6599999999999999, 'median': 0.6299999999999999, 'q25': 0.615, 'q75': 0.6449999999999999, 'skewness': nan, 'kurtosis': nan}, 'pathology_index': {'count': 2, 'mean': 0.29, 'std': 0.24041630560342614, 'min': 0.12, 'max': 0.45999999999999996, 'median': 0.29, 'q25': 0.205, 'q75': 0.375, 'skewness': nan, 'kurtosis': nan}}}",,,,,,,,Generic descriptive_stats result,
task_06_architecture_performance_summary,descriptive_stats,result_value,"{'type': 'descriptive_stats', 'columns_analyzed': ['extraction_time_seconds'], 'results': {'extraction_time_seconds': {'count': 2, 'mean': 1.6515809297561646, 'std': 0.6152945921525981, 'min': 1.2165019512176514, 'max': 2.0866599082946777, 'median': 1.6515809297561646, 'q25': 1.434041440486908, 'q75': 1.8691204190254211, 'skewness': nan, 'kurtosis': nan}}}",,,,,,,,Generic descriptive_stats result,
