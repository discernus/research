{
  "run_metadata": {
    "experiment_name": "simple_character_validation_v7",
    "run_timestamp": "20250805T215548Z",
    "framework_version": "../../frameworks/reference/core/caf_v7.3.md",
    "model_used": "vertex_ai/gemini-2.5-flash",
    "total_artifacts": 11,
    "organized_artifacts": 8
  },
  "directory_structure": {
    "data/": "CSV files for external statistical analysis",
    "artifacts/analysis_plans/": "What the LLM planned to analyze",
    "artifacts/analysis_results/": "Raw analysis outputs from LLM",
    "artifacts/statistical_results/": "Mathematical computations and metrics",
    "artifacts/evidence/": "Curated quotes and supporting data",
    "artifacts/reports/": "Final synthesis outputs and reports",
    "artifacts/inputs/": "Framework, corpus, and experiment configuration",
    "technical/": "System logs and model interaction records"
  },
  "pipeline_stages": {
    "inputs_and_system": {
      "artifacts": 4,
      "total_size_mb": 0.03970050811767578
    },
    "evidence_curation": {
      "artifacts": 1,
      "total_size_mb": 0.010164260864257812
    },
    "synthesis": {
      "artifacts": 2,
      "total_size_mb": 0.03078746795654297
    },
    "analysis": {
      "artifacts": 3,
      "total_size_mb": 0.022850990295410156
    },
    "statistical_computation": {
      "artifacts": 1,
      "total_size_mb": 0.030958175659179688
    }
  },
  "artifact_descriptions": {
    "curated_evidence_37551618.json": "Highest-confidence evidence supporting findings",
    "synthesis_report_2025-08-05_95e60ec0.md": "Synthesis report combining multiple analyses",
    "final_report_2025-08-05_a25a835d.md": "Final research report with findings and implications",
    "analysis_response_c6b47673.json": "Artifact of type analysis_json_v6",
    "analysis_plan_d1a59d13.md": "Analysis plan generated by LLM for systematic evaluation",
    "statistical_results_d6252491.json": "Statistical computations and significance tests",
    "raw_analysis_response_v6_e561cd55": "Raw analysis response from LLM with scores and reasoning",
    "raw_analysis_response_v6_fa05042f": "Raw analysis response from LLM with scores and reasoning"
  },
  "navigation_guide": {
    "primary_researcher": [
      "FINAL_REPORT.md",
      "data/scores.csv",
      "data/evidence.csv"
    ],
    "internal_reviewer": [
      "METHODOLOGY_SUMMARY.md",
      "STATISTICAL_SUMMARY.md"
    ],
    "replication_researcher": [
      "artifacts/",
      "technical/manifest.json",
      "README.md"
    ],
    "fraud_auditor": [
      "technical/manifest.json",
      "technical/logs/",
      "provenance.json"
    ],
    "llm_skeptic": [
      "technical/model_interactions/",
      "data/reliability_metrics.csv"
    ]
  }
}