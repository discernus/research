"""
Automated Derived Metrics Functions
===================================

Generated by AutomatedDerivedMetricsAgent for experiment: simple_test
Description: No description
Generated: 2025-08-16T02:39:08.392382+00:00

This module contains automatically generated calculation functions for derived metrics
as specified in the framework's natural language descriptions.
"""

import pandas as pd
import numpy as np
from typing import Optional, Dict, Any


def calculate_identity_tension(data, **kwargs):
    """
    Calculate identity_tension: Conflict between tribal dominance and individual dignity dimensions.

    Formula: identity_tension = abs(mean(Tribal Dominance) - mean(Individual Dignity))

    Args:
        data: pandas DataFrame with 'Tribal Dominance' and 'Individual Dignity' columns.
              Each column should contain scores (0.0-1.0).
        **kwargs: Additional parameters (currently not used).

    Returns:
        float: Calculated identity_tension score (0.0-1.0) or None if insufficient or invalid data.
    """
    import pandas as pd
    import numpy as np

    required_cols = ['Tribal Dominance', 'Individual Dignity']

    try:
        # Validate DataFrame input
        if not isinstance(data, pd.DataFrame) or data.empty:
            return None

        # Check for required columns
        for col in required_cols:
            if col not in data.columns:
                return None # Missing required column

        # Extract relevant columns and attempt to convert to numeric, coercing errors
        # This handles cases where values might be strings or mixed types, turning them into NaN
        td_scores = pd.to_numeric(data['Tribal Dominance'], errors='coerce')
        id_scores = pd.to_numeric(data['Individual Dignity'], errors='coerce')

        # Calculate means. pandas .mean() method automatically skips NaN values.
        # If all values in a series are NaN, the mean will also be NaN.
        mean_td = td_scores.mean()
        mean_id = id_scores.mean()

        # Check if the means are valid numbers (not NaN)
        if pd.isna(mean_td) or pd.isna(mean_id):
            return None # Cannot calculate if either dimension's mean is NaN

        # Calculate identity tension using the absolute difference of the means
        identity_tension_score = np.abs(mean_td - mean_id)

        # Ensure the score is explicitly within the 0.0-1.0 range,
        # although for this formula with 0-1 inputs, it should naturally be within.
        identity_tension_score = np.clip(identity_tension_score, 0.0, 1.0)

        return float(identity_tension_score)

    except Exception:
        # Catch any unexpected errors and return None as per requirement
        return None

def calculate_emotional_balance(data, **kwargs):
    """
    Calculate emotional_balance: Difference between hope and fear scores.

    Formula: (Mean of 'hope_score' column) - (Mean of 'fear_score' column)

    Args:
        data: pandas DataFrame expected to contain 'hope_score' and 'fear_score' columns.
              Each row can represent a data point, and the calculation will aggregate
              these scores by taking the mean of each column.
        **kwargs: Additional parameters (not used in this specific calculation).

    Returns:
        float: Calculated emotional balance score.
               Returns None if 'data' is not a pandas DataFrame, or if required columns
               ('hope_score', 'fear_score') are missing, or if scores cannot be
               converted to valid numeric types for calculation.
    """
    import pandas as pd
    import numpy as np

    try:
        # Ensure the input is a pandas DataFrame
        if not isinstance(data, pd.DataFrame):
            return None

        # Define the required columns for the calculation
        required_columns = ['hope_score', 'fear_score']

        # Check if all required columns exist in the DataFrame
        if not all(col in data.columns for col in required_columns):
            return None

        # Convert relevant columns to numeric, coercing any non-numeric values to NaN.
        # This handles mixed data types gracefully.
        hope_scores = pd.to_numeric(data['hope_score'], errors='coerce')
        fear_scores = pd.to_numeric(data['fear_score'], errors='coerce')

        # Calculate the mean of each score column, skipping NaN values.
        # If a column is entirely NaN or empty after coercion, its mean will be NaN.
        mean_hope = hope_scores.mean(skipna=True)
        mean_fear = fear_scores.mean(skipna=True)

        # If either mean is NaN (indicating no valid numeric data for that score),
        # return None as a valid calculation cannot be performed.
        if pd.isna(mean_hope) or pd.isna(mean_fear):
            return None

        # Calculate the emotional balance score as the difference
        emotional_balance_score = float(mean_hope - mean_fear)

        return emotional_balance_score

    except Exception:
        # Catch any unexpected errors during the process and return None
        return None

def calculate_success_climate(data, **kwargs):
    """
    Calculate success_climate: Difference between the mean compersion score and the mean envy score.

    Formula: success_climate = mean(compersion) - mean(enviy)

    Args:
        data (pandas.DataFrame): DataFrame containing 'compersion' and 'enviy' score columns.
                                 Scores are expected to be numeric (0.0-1.0).
        **kwargs: Additional parameters (not used in this function but included for framework compatibility).

    Returns:
        float: Calculated success_climate score (typically in range -1.0 to 1.0)
               or None if 'compersion' or 'enviy' columns are missing or contain no valid numeric data.
    """
    import pandas as pd
    import numpy as np
    
    try:
        # Check if required columns exist in the DataFrame
        required_columns = ['compersion', 'enviy']
        if not all(col in data.columns for col in required_columns):
            return None

        # Convert required columns to numeric, coercing non-numeric values to NaN.
        # This handles strings, None, etc., making them uncalculable but preventing errors.
        compersion_scores = pd.to_numeric(data['compersion'], errors='coerce')
        enviy_scores = pd.to_numeric(data['enviy'], errors='coerce')

        # Calculate the mean of valid (non-NaN) scores for each dimension.
        # pandas .mean() method automatically skips NaN values.
        mean_compersion = compersion_scores.mean()
        mean_enviy = enviy_scores.mean()

        # If either mean is NaN after conversion and calculation (meaning all values in the column
        # were non-numeric or NaN), then we don't have sufficient data.
        if pd.isna(mean_compersion) or pd.isna(mean_enviy):
            return None

        # Calculate the success_climate score
        success_climate = mean_compersion - mean_enviy

        return float(success_climate)

    except Exception:
        # Catch any unexpected errors (e.g., data is not a DataFrame) and return None.
        return None

def calculate_relational_climate(data, **kwargs):
    """
    Calculate relational_climate: Difference between amity and enmity scores.

    Formula: Mean(amity_scores) - Mean(enmity_scores)

    This metric quantifies the overall relational climate by
    subtracting the average enmity score from the average amity score
    across the dataset. A higher positive value indicates a more
    cohesive and amicable climate, while a negative value suggests a
    more conflict-ridden and antagonistic environment.

    Args:
        data: pandas DataFrame expected to contain at least two columns:
              'amity' and 'enmity'. Each column should contain numerical
              scores, typically within the range of 0.0 to 1.0, representing
              the degree of amity and enmity, respectively.
        **kwargs: Additional parameters. Not used in this specific calculation
                  but included for framework consistency.

    Returns:
        float: The calculated relational climate score, ranging from -1.0 to 1.0.
               Returns None if 'data' is not a pandas DataFrame, if required
               'amity' or 'enmity' columns are missing, or if there is
               insufficient valid numerical data for calculation after
               handling missing/non-numeric values.
    """
    import pandas as pd
    import numpy as np

    try:
        # Validate input is a pandas DataFrame
        if not isinstance(data, pd.DataFrame):
            return None

        required_columns = ['amity', 'enmity']

        # Check if all required columns exist
        for col in required_columns:
            if col not in data.columns:
                return None

        # Create a temporary copy of the relevant columns to avoid
        # SettingWithCopyWarning and perform in-place modifications safely.
        temp_data = data[required_columns].copy()

        # Coerce columns to numeric types. Any non-numeric values will be
        # converted to NaN (Not a Number).
        for col in required_columns:
            temp_data[col] = pd.to_numeric(temp_data[col], errors='coerce')

        # Drop rows where either 'amity' or 'enmity' score is NaN.
        # This ensures calculations are based only on complete and valid pairs.
        cleaned_data = temp_data.dropna(subset=required_columns)

        # If no valid data remains after cleaning, return None
        if cleaned_data.empty:
            return None

        # Calculate the mean of amity and enmity scores from the cleaned data
        mean_amity = cleaned_data['amity'].mean()
        mean_enmity = cleaned_data['enmity'].mean()

        # Calculate the relational climate score
        relational_climate_score = mean_amity - mean_enmity

        # Ensure the final result is a float type
        return float(relational_climate_score)

    except Exception:
        # Catch any unexpected errors during the process and return None
        return None

def calculate_goal_orientation(data, **kwargs):
    """
    Calculate goal_orientation: Difference between cohesive goals and fragmentative goals.

    Formula: Individual Dignity - Tribal Dominance
    Scores for dimensions (Individual Dignity, Tribal Dominance) are expected to be between 0.0 and 1.0.

    Args:
        data (pd.DataFrame): A pandas DataFrame containing dimension scores.
                             Expected to have 'individual_dignity' and 'tribal_dominance' columns.
                             If the DataFrame contains multiple rows, the mean of the respective
                             dimension column will be used for the calculation.
        **kwargs: Additional parameters (not used in this specific calculation but for API compatibility).

    Returns:
        float: The calculated goal_orientation score.
               Returns None if 'data' is not a DataFrame, if required columns are missing,
               if the DataFrame is empty, or if dimension scores are non-numeric/NaN.
    """
    import pandas as pd
    import numpy as np # Included as per template, though pd.isna is sufficient for NaN checks

    try:
        # Validate input is a pandas DataFrame
        if not isinstance(data, pd.DataFrame):
            return None

        # Define required columns for the calculation
        required_columns = ['individual_dignity', 'tribal_dominance']

        # Check if all required columns exist in the DataFrame
        if not all(col in data.columns for col in required_columns):
            return None

        # Check if the DataFrame is empty
        if data.empty:
            return None

        # Extract dimension scores. If the DataFrame contains multiple rows
        # (e.g., representing multiple analysis units or samples),
        # their mean is used to derive a single aggregate score for each dimension.
        individual_dignity_score = data['individual_dignity'].mean()
        tribal_dominance_score = data['tribal_dominance'].mean()

        # Check if the mean scores are NaN, which can happen if a column
        # was entirely composed of non-numeric values or NaNs.
        if pd.isna(individual_dignity_score) or pd.isna(tribal_dominance_score):
            return None

        # Perform the calculation as per the formula: Cohesive Goals - Fragmentative Goals
        # Based on the framework context, 'Individual Dignity' represents cohesive goals
        # and 'Tribal Dominance' represents fragmentative goals.
        goal_orientation_score = individual_dignity_score - tribal_dominance_score

        return goal_orientation_score

    except Exception:
        # Catch any unexpected errors that might occur during the process
        return None

def calculate_overall_cohesion_index(data, **kwargs):
    """
    Calculate overall_cohesion_index: Comprehensive measure combining all dimensions.
    
    The index is computed by first normalizing "Tribal Dominance" (a negative contributor to cohesion)
    and then averaging it with "Individual Dignity" (a positive contributor to cohesion) across all rows.
    A higher index value indicates greater cohesion.
    
    Formula:
    For each row: `row_cohesion_score = (data['Individual Dignity'] + (1.0 - data['Tribal Dominance'])) / 2.0`
    `overall_cohesion_index = Mean(row_cohesion_score across all valid rows)`
    
    Args:
        data (pd.DataFrame): Pandas DataFrame containing the dimension scores.
                             Must include 'Individual Dignity' and 'Tribal Dominance' columns,
                             with scores ranging from 0.0 to 1.0.
        **kwargs: Additional parameters (not used in this specific calculation but required by framework).
        
    Returns:
        float: Calculated overall cohesion index (0.0-1.0) or None if:
               - `data` is not a pandas DataFrame.
               - Required dimension columns ('Individual Dignity', 'Tribal Dominance') are missing.
               - All relevant data for the calculation (after `pd.to_numeric` conversion) is missing (NaNs).
    """
    import pandas as pd
    import numpy as np
    
    # 1. Handle non-DataFrame input gracefully
    if not isinstance(data, pd.DataFrame):
        return None

    # Define the required dimension columns
    POSITIVE_DIMENSION_COL = 'Individual Dignity'
    NEGATIVE_DIMENSION_COL = 'Tribal Dominance'
    
    required_cols = [POSITIVE_DIMENSION_COL, NEGATIVE_DIMENSION_COL]

    # 2. Check for missing required columns
    if not all(col in data.columns for col in required_cols):
        return None
    
    try:
        # Convert columns to numeric, coercing non-numeric values to NaN
        individual_dignity = pd.to_numeric(data[POSITIVE_DIMENSION_COL], errors='coerce')
        tribal_dominance = pd.to_numeric(data[NEGATIVE_DIMENSION_COL], errors='coerce')

        # 3. Transform the negative dimension (Tribal Dominance)
        # A higher Tribal Dominance score indicates less cohesion, so invert it (0.0 becomes 1.0, 1.0 becomes 0.0)
        # This aligns its contribution with Individual Dignity (where higher score means more cohesion).
        transformed_tribal_dominance = 1.0 - tribal_dominance

        # Calculate the per-row cohesion score
        # This calculation handles NaNs gracefully: if any component is NaN, the result for that row will be NaN.
        per_row_cohesion = (individual_dignity + transformed_tribal_dominance) / 2.0

        # Calculate the overall mean, ignoring any NaN values in per_row_cohesion.
        overall_index = per_row_cohesion.mean()

        # 4. Handle cases where the calculation results in NaN
        # This occurs if all values in 'per_row_cohesion' were NaN (e.g., all input data for required columns were NaN).
        if pd.isna(overall_index):
            return None
        
        # Ensure the final output is a standard float, not a numpy float type.
        return float(overall_index)
        
    except Exception:
        # Catch any other unexpected errors during the computation process
        return None

def calculate_all_derived_metrics(data: pd.DataFrame) -> Dict[str, Optional[float]]:
    """
    Calculate all derived metrics for the given dataset.
    
    Args:
        data: pandas DataFrame with dimension scores
        
    Returns:
        Dictionary mapping metric names to calculated values
    """
    results = {}
    
    # Get all calculation functions from this module
    import inspect
    current_module = inspect.getmodule(inspect.currentframe())
    
    for name, obj in inspect.getmembers(current_module):
        if (inspect.isfunction(obj) and 
            name.startswith('calculate_') and 
            name not in ['calculate_all_derived_metrics', 'calculate_derived_metrics']):
            try:
                results[name.replace('calculate_', '')] = obj(data)
            except Exception as e:
                results[name.replace('calculate_', '')] = None
                
    return results


def calculate_derived_metrics(data: pd.DataFrame) -> pd.DataFrame:
    """
    Template-compatible wrapper function for derived metrics calculation.
    
    This function is called by the universal notebook template and returns
    the original data with additional derived metric columns.
    
    Args:
        data: pandas DataFrame with dimension scores
        
    Returns:
        DataFrame with original data plus derived metric columns
    """
    # Calculate all derived metrics
    derived_metrics = calculate_all_derived_metrics(data)
    
    # Create a copy of the original data
    result = data.copy()
    
    # Add derived metrics as new columns
    for metric_name, metric_value in derived_metrics.items():
        if metric_value is not None:
            # For scalar metrics, broadcast to all rows
            result[metric_name] = metric_value
        else:
            # For failed calculations, use NaN
            result[metric_name] = np.nan
    
    return result
