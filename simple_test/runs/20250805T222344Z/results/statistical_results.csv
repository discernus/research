test_name,test_type,statistic_name,statistic_value,p_value,effect_size,degrees_of_freedom,sample_size,dependent_variable,grouping_variable,significance_level,interpretation,notes
calculate_tension_scores,derived_metrics_calculation,result_value,"{'type': 'derived_metrics_calculation', 'success': True, 'calculated_metrics': {'hope_fear_tension': [0.6499999999999999, 0.8], 'dignity_tribalism_tension': [0.55, 0.8], 'truth_manipulation_tension': [0.55, 0.75], 'justice_resentment_tension': [0.55, 0.65], 'pragmatism_fantasy_tension': [0.7, 0.7]}, 'successful_calculations': ['hope_fear_tension', 'dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'pragmatism_fantasy_tension'], 'failed_calculations': [], 'formulas_used': ['dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension'], 'input_columns': ['dignity_score', 'tribalism_score', 'truth_score', 'manipulation_score', 'justice_score', 'resentment_score', 'hope_score', 'fear_score', 'pragmatism_score', 'fantasy_score'], 'total_metrics': 5, 'success_rate': 1.0}",,,,,,,,Generic derived_metrics_calculation result,
calculate_composite_indices,derived_metrics_calculation,result_value,"{'type': 'derived_metrics_calculation', 'success': True, 'calculated_metrics': {'virtue_index': [0.6599999999999999, 0.6], 'pathology_index': [0.45999999999999996, 0.12], 'civic_character_index': [0.6, 0.74], 'salience_weighted_civic_character_index': [0.5972972972972973, 0.7551724137931034]}, 'successful_calculations': ['virtue_index', 'pathology_index', 'civic_character_index', 'salience_weighted_civic_character_index'], 'failed_calculations': [], 'formulas_used': ['civic_character_index', 'salience_weighted_civic_character_index', 'virtue_index', 'pathology_index'], 'input_columns': ['dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension', 'dignity_score', 'tribalism_score', 'truth_score', 'manipulation_score', 'justice_score', 'resentment_score', 'hope_score', 'fear_score', 'pragmatism_score', 'fantasy_score', 'dignity_salience', 'truth_salience', 'justice_salience', 'hope_salience', 'pragmatism_salience'], 'total_metrics': 4, 'success_rate': 1.0}",,,,,,,,Generic derived_metrics_calculation result,
validate_derived_metrics,metric_validation,result_value,"{'type': 'metric_validation', 'validation_rules': ['missing_data_check', 'range_check', 'consistency_check'], 'results': {'missing_data_check': {'status': 'completed', 'missing_data_by_column': {'aid': 0, 'document_type': 0, 'political_party': 0, 'year': 0, 'temporal_sequence': 0, 'speaker': 0, 'ideology': 0, 'character_profile': 0, 'event': 0, 'word_count': 0, 'source': 0, 'preparation_notes': 0, 'dignity_score': 0, 'tribalism_score': 0, 'dignity_salience': 0, 'tribalism_salience': 0, 'dignity_confidence': 0, 'tribalism_confidence': 0, 'truth_score': 0, 'manipulation_score': 0, 'truth_salience': 0, 'manipulation_salience': 0, 'truth_confidence': 0, 'manipulation_confidence': 0, 'justice_score': 0, 'resentment_score': 0, 'justice_salience': 0, 'resentment_salience': 0, 'justice_confidence': 0, 'resentment_confidence': 0, 'hope_score': 0, 'fear_score': 0, 'hope_salience': 0, 'fear_salience': 0, 'hope_confidence': 0, 'fear_confidence': 0, 'pragmatism_score': 0, 'fantasy_score': 0, 'pragmatism_salience': 0, 'fantasy_salience': 0, 'pragmatism_confidence': 0, 'fantasy_confidence': 0, 'gasket_version': 0, 'extraction_time_seconds': 0, 'hope_fear_tension': 0, 'dignity_tribalism_tension': 0, 'truth_manipulation_tension': 0, 'justice_resentment_tension': 0, 'pragmatism_fantasy_tension': 0, 'virtue_index': 0, 'pathology_index': 0, 'civic_character_index': 0, 'salience_weighted_civic_character_index': 0}, 'total_missing': 0}, 'range_check': {'status': 'completed', 'ranges': {'year': {'min': 2008.0, 'max': 2025.0, 'mean': 2016.5}, 'temporal_sequence': {'min': 1.0, 'max': 2.0, 'mean': 1.5}, 'word_count': {'min': 892.0, 'max': 1247.0, 'mean': 1069.5}, 'dignity_score': {'min': 0.7, 'max': 0.8, 'mean': 0.75}, 'tribalism_score': {'min': 0.2, 'max': 0.6, 'mean': 0.4}, 'dignity_salience': {'min': 0.7, 'max': 0.8, 'mean': 0.75}, 'tribalism_salience': {'min': 0.3, 'max': 0.7, 'mean': 0.5}, 'dignity_confidence': {'min': 0.9, 'max': 0.9, 'mean': 0.9}, 'tribalism_confidence': {'min': 0.7, 'max': 0.8, 'mean': 0.75}, 'truth_score': {'min': 0.5, 'max': 0.6, 'mean': 0.55}, 'manipulation_score': {'min': 0.1, 'max': 0.4, 'mean': 0.25}, 'truth_salience': {'min': 0.5, 'max': 0.6, 'mean': 0.55}, 'manipulation_salience': {'min': 0.2, 'max': 0.5, 'mean': 0.35}, 'truth_confidence': {'min': 0.7, 'max': 0.8, 'mean': 0.75}, 'manipulation_confidence': {'min': 0.6, 'max': 0.7, 'mean': 0.6499999999999999}, 'justice_score': {'min': 0.4, 'max': 0.8, 'mean': 0.6000000000000001}, 'resentment_score': {'min': 0.1, 'max': 0.7, 'mean': 0.39999999999999997}, 'justice_salience': {'min': 0.3, 'max': 0.9, 'mean': 0.6}, 'resentment_salience': {'min': 0.2, 'max': 0.8, 'mean': 0.5}, 'justice_confidence': {'min': 0.6, 'max': 0.95, 'mean': 0.7749999999999999}, 'resentment_confidence': {'min': 0.6, 'max': 0.85, 'mean': 0.725}, 'hope_score': {'min': 0.6, 'max': 0.7, 'mean': 0.6499999999999999}, 'fear_score': {'min': 0.1, 'max': 0.3, 'mean': 0.2}, 'hope_salience': {'min': 0.7, 'max': 0.8, 'mean': 0.75}, 'fear_salience': {'min': 0.1, 'max': 0.4, 'mean': 0.25}, 'hope_confidence': {'min': 0.8, 'max': 0.9, 'mean': 0.8500000000000001}, 'fear_confidence': {'min': 0.5, 'max': 0.6, 'mean': 0.55}, 'pragmatism_score': {'min': 0.5, 'max': 0.7, 'mean': 0.6}, 'fantasy_score': {'min': 0.1, 'max': 0.3, 'mean': 0.2}, 'pragmatism_salience': {'min': 0.6, 'max': 0.7, 'mean': 0.6499999999999999}, 'fantasy_salience': {'min': 0.1, 'max': 0.4, 'mean': 0.25}, 'pragmatism_confidence': {'min': 0.8, 'max': 0.8, 'mean': 0.8}, 'fantasy_confidence': {'min': 0.5, 'max': 0.6, 'mean': 0.55}, 'extraction_time_seconds': {'min': 1.2899959087371826, 'max': 2.155263900756836, 'mean': 1.7226299047470093}, 'hope_fear_tension': {'min': 0.6499999999999999, 'max': 0.8, 'mean': 0.725}, 'dignity_tribalism_tension': {'min': 0.55, 'max': 0.8, 'mean': 0.675}, 'truth_manipulation_tension': {'min': 0.55, 'max': 0.75, 'mean': 0.65}, 'justice_resentment_tension': {'min': 0.55, 'max': 0.65, 'mean': 0.6000000000000001}, 'pragmatism_fantasy_tension': {'min': 0.7, 'max': 0.7, 'mean': 0.7}, 'virtue_index': {'min': 0.6, 'max': 0.6599999999999999, 'mean': 0.6299999999999999}, 'pathology_index': {'min': 0.12, 'max': 0.45999999999999996, 'mean': 0.29}, 'civic_character_index': {'min': 0.6, 'max': 0.74, 'mean': 0.6699999999999999}, 'salience_weighted_civic_character_index': {'min': 0.5972972972972973, 'max': 0.7551724137931034, 'mean': 0.6762348555452004}}}, 'consistency_check': {'status': 'completed', 'notes': 'Basic consistency check completed'}}, 'quality_thresholds': {'missing_data_check': {'max_allowed_missing_percentage': 0.05}, 'range_check': {'min_value': 0.0, 'max_value': 1.0}, 'consistency_check': {'logic': 'Ensure calculated indices are logically derived from component scores.'}}}",,,,,,,,Generic metric_validation result,
describe_all_metrics,summary_statistics,result_value,"{'type': 'summary_statistics', 'metrics': ['dignity_score', 'tribalism_score', 'truth_score', 'manipulation_score', 'justice_score', 'resentment_score', 'hope_score', 'fear_score', 'pragmatism_score', 'fantasy_score', 'dignity_tribalism_tension', 'truth_manipulation_tension', 'justice_resentment_tension', 'hope_fear_tension', 'pragmatism_fantasy_tension', 'civic_character_index', 'salience_weighted_civic_character_index', 'virtue_index', 'pathology_index'], 'summary_types': ['mean', 'median', 'std', 'min', 'max'], 'results': {'dignity_score': {'mean': 0.75, 'std': 0.07071067811865482, 'min': 0.7, 'max': 0.8, 'median': 0.75}, 'tribalism_score': {'mean': 0.4, 'std': 0.282842712474619, 'min': 0.2, 'max': 0.6, 'median': 0.4}, 'truth_score': {'mean': 0.55, 'std': 0.07071067811865474, 'min': 0.5, 'max': 0.6, 'median': 0.55}, 'manipulation_score': {'mean': 0.25, 'std': 0.21213203435596428, 'min': 0.1, 'max': 0.4, 'median': 0.25}, 'justice_score': {'mean': 0.6000000000000001, 'std': 0.282842712474619, 'min': 0.4, 'max': 0.8, 'median': 0.6000000000000001}, 'resentment_score': {'mean': 0.39999999999999997, 'std': 0.42426406871192845, 'min': 0.1, 'max': 0.7, 'median': 0.39999999999999997}, 'hope_score': {'mean': 0.6499999999999999, 'std': 0.07071067811865474, 'min': 0.6, 'max': 0.7, 'median': 0.6499999999999999}, 'fear_score': {'mean': 0.2, 'std': 0.1414213562373095, 'min': 0.1, 'max': 0.3, 'median': 0.2}, 'pragmatism_score': {'mean': 0.6, 'std': 0.14142135623730948, 'min': 0.5, 'max': 0.7, 'median': 0.6}, 'fantasy_score': {'mean': 0.2, 'std': 0.1414213562373095, 'min': 0.1, 'max': 0.3, 'median': 0.2}, 'dignity_tribalism_tension': {'mean': 0.675, 'std': 0.1767766952966369, 'min': 0.55, 'max': 0.8, 'median': 0.675}, 'truth_manipulation_tension': {'mean': 0.65, 'std': 0.14142135623730948, 'min': 0.55, 'max': 0.75, 'median': 0.65}, 'justice_resentment_tension': {'mean': 0.6000000000000001, 'std': 0.07071067811865474, 'min': 0.55, 'max': 0.65, 'median': 0.6000000000000001}, 'hope_fear_tension': {'mean': 0.725, 'std': 0.10606601717798222, 'min': 0.6499999999999999, 'max': 0.8, 'median': 0.725}, 'pragmatism_fantasy_tension': {'mean': 0.7, 'std': 0.0, 'min': 0.7, 'max': 0.7, 'median': 0.7}, 'civic_character_index': {'mean': 0.6699999999999999, 'std': 0.09899494936611666, 'min': 0.6, 'max': 0.74, 'median': 0.6699999999999999}, 'salience_weighted_civic_character_index': {'mean': 0.6762348555452004, 'std': 0.11163456545480066, 'min': 0.5972972972972973, 'max': 0.7551724137931034, 'median': 0.6762348555452004}, 'virtue_index': {'mean': 0.6299999999999999, 'std': 0.04242640687119281, 'min': 0.6, 'max': 0.6599999999999999, 'median': 0.6299999999999999}, 'pathology_index': {'mean': 0.29, 'std': 0.24041630560342614, 'min': 0.12, 'max': 0.45999999999999996, 'median': 0.29}}, 'missing_metrics': []}",,,,,,,,Generic summary_statistics result,
anova_ideological_comparison_dignity,one_way_anova,F_statistic,nan,nan,,,,dignity_score,ideology,p >= 0.05,,
anova_ideological_comparison_tribalism,one_way_anova,F_statistic,nan,nan,,,,tribalism_score,ideology,p >= 0.05,,
anova_ideological_comparison_truth,one_way_anova,F_statistic,nan,nan,,,,truth_score,ideology,p >= 0.05,,
anova_ideological_comparison_manipulation,one_way_anova,F_statistic,nan,nan,,,,manipulation_score,ideology,p >= 0.05,,
anova_ideological_comparison_justice,one_way_anova,F_statistic,nan,nan,,,,justice_score,ideology,p >= 0.05,,
anova_ideological_comparison_resentment,one_way_anova,F_statistic,nan,nan,,,,resentment_score,ideology,p >= 0.05,,
anova_ideological_comparison_hope,one_way_anova,F_statistic,nan,nan,,,,hope_score,ideology,p >= 0.05,,
anova_ideological_comparison_fear,one_way_anova,F_statistic,nan,nan,,,,fear_score,ideology,p >= 0.05,,
anova_ideological_comparison_pragmatism,one_way_anova,F_statistic,nan,nan,,,,pragmatism_score,ideology,p >= 0.05,,
anova_ideological_comparison_fantasy,one_way_anova,F_statistic,nan,nan,,,,fantasy_score,ideology,p >= 0.05,,
anova_ideological_comparison_civic_index,one_way_anova,F_statistic,nan,nan,,,,civic_character_index,ideology,p >= 0.05,,
anova_ideological_comparison_virtue_index,one_way_anova,F_statistic,nan,nan,,,,virtue_index,ideology,p >= 0.05,,
anova_ideological_comparison_pathology_index,one_way_anova,F_statistic,nan,nan,,,,pathology_index,ideology,p >= 0.05,,
anova_character_profile_comparison_dignity,one_way_anova,F_statistic,nan,nan,,,,dignity_score,character_profile,p >= 0.05,,
anova_character_profile_comparison_tribalism,one_way_anova,F_statistic,nan,nan,,,,tribalism_score,character_profile,p >= 0.05,,
anova_character_profile_comparison_justice,one_way_anova,F_statistic,nan,nan,,,,justice_score,character_profile,p >= 0.05,,
anova_character_profile_comparison_resentment,one_way_anova,F_statistic,nan,nan,,,,resentment_score,character_profile,p >= 0.05,,
anova_character_profile_comparison_hope,one_way_anova,F_statistic,nan,nan,,,,hope_score,character_profile,p >= 0.05,,
anova_character_profile_comparison_fear,one_way_anova,F_statistic,nan,nan,,,,fear_score,character_profile,p >= 0.05,,
anova_character_profile_comparison_pragmatism,one_way_anova,F_statistic,nan,nan,,,,pragmatism_score,character_profile,p >= 0.05,,
anova_character_profile_comparison_fantasy,one_way_anova,F_statistic,nan,nan,,,,fantasy_score,character_profile,p >= 0.05,,
anova_character_profile_comparison_civic_index,one_way_anova,F_statistic,nan,nan,,,,civic_character_index,character_profile,p >= 0.05,,
anova_character_profile_comparison_virtue_index,one_way_anova,F_statistic,nan,nan,,,,virtue_index,character_profile,p >= 0.05,,
anova_character_profile_comparison_pathology_index,one_way_anova,F_statistic,nan,nan,,,,pathology_index,character_profile,p >= 0.05,,
validate_gasket_extraction_success,metric_validation,result_value,"{'type': 'metric_validation', 'validation_rules': ['missing_data_check'], 'results': {'missing_data_check': {'status': 'completed', 'missing_data_by_column': {'aid': 0, 'document_type': 0, 'political_party': 0, 'year': 0, 'temporal_sequence': 0, 'speaker': 0, 'ideology': 0, 'character_profile': 0, 'event': 0, 'word_count': 0, 'source': 0, 'preparation_notes': 0, 'dignity_score': 0, 'tribalism_score': 0, 'dignity_salience': 0, 'tribalism_salience': 0, 'dignity_confidence': 0, 'tribalism_confidence': 0, 'truth_score': 0, 'manipulation_score': 0, 'truth_salience': 0, 'manipulation_salience': 0, 'truth_confidence': 0, 'manipulation_confidence': 0, 'justice_score': 0, 'resentment_score': 0, 'justice_salience': 0, 'resentment_salience': 0, 'justice_confidence': 0, 'resentment_confidence': 0, 'hope_score': 0, 'fear_score': 0, 'hope_salience': 0, 'fear_salience': 0, 'hope_confidence': 0, 'fear_confidence': 0, 'pragmatism_score': 0, 'fantasy_score': 0, 'pragmatism_salience': 0, 'fantasy_salience': 0, 'pragmatism_confidence': 0, 'fantasy_confidence': 0, 'gasket_version': 0, 'extraction_time_seconds': 0, 'hope_fear_tension': 0, 'dignity_tribalism_tension': 0, 'truth_manipulation_tension': 0, 'justice_resentment_tension': 0, 'pragmatism_fantasy_tension': 0, 'virtue_index': 0, 'pathology_index': 0, 'civic_character_index': 0, 'salience_weighted_civic_character_index': 0}, 'total_missing': 0}}, 'quality_thresholds': {'missing_data_check': {'max_allowed_missing_percentage': 0.1}}}",,,,,,,,Generic metric_validation result,
