"""
Automated Derived Metrics Functions
===================================

Generated by AutomatedDerivedMetricsAgent for experiment: simple_test
Description: No description
Generated: 2025-08-18T23:10:10.570018+00:00

This module contains automatically generated calculation functions for derived metrics
as specified in the framework's natural language descriptions.
"""

import pandas as pd
import numpy as np
from typing import Optional, Dict, Any


def calculate_identity_tension(data, **kwargs):
    """
    Calculate identity_tension: Conflict between tribal dominance and individual dignity dimensions.

    This metric quantifies the degree of tension arising from the simultaneous
    presence of both tribal dominance and individual dignity dimensions within a discourse.
    It considers the base scores, their salience (prominence), and the confidence
    in their detection. A higher score indicates a stronger conflict or competing
    emphasis between these two dimensions.

    Formula:
    identity_tension = (tribal_dominance * tribal_dominance_salience * tribal_dominance_confidence) * \
                       (individual_dignity * individual_dignity_salience * individual_dignity_confidence)

    Args:
        data (pandas.Series or pandas.DataFrame): A pandas Series representing a single
            row of data, or a pandas DataFrame (expected to be a single row).
            It must contain the following columns:
            - 'tribal_dominance' (float)
            - 'tribal_dominance_salience' (float)
            - 'tribal_dominance_confidence' (float)
            - 'individual_dignity' (float)
            - 'individual_dignity_salience' (float)
            - 'individual_dignity_confidence' (float)
        **kwargs: Additional keyword arguments (not used in this calculation but
                  included for framework compatibility).

    Returns:
        float: The calculated identity_tension score, ranging from 0.0 to 1.0.
        None: If any required data columns are missing, are NaN, or if the input
              data format is not as expected.
    """
    import pandas as pd
    import numpy as np

    required_columns = [
        'tribal_dominance', 'tribal_dominance_salience', 'tribal_dominance_confidence',
        'individual_dignity', 'individual_dignity_salience', 'individual_dignity_confidence'
    ]

    # Ensure data is treated as a Series for consistent access, handling DataFrame input
    data_row = None
    if isinstance(data, pd.DataFrame):
        if data.empty:
            return None
        # If a DataFrame is passed, assume the calculation is for its first row
        data_row = data.iloc[0]
    elif isinstance(data, pd.Series):
        data_row = data
    else:
        # If data is neither a DataFrame nor a Series, it's an invalid input type
        return None

    try:
        # Extract values, handling missing columns or NaN values
        values = {}
        for col in required_columns:
            # .get() method for Series returns None if column not found
            val = data_row.get(col)
            if pd.isna(val) or val is None:
                # If any required value is missing (None) or NaN, we cannot compute
                return None
            values[col] = float(val) # Ensure type is float for calculation

        # Calculate the adjusted scores for each dimension
        adjusted_tribal_dominance = values['tribal_dominance'] * \
                                    values['tribal_dominance_salience'] * \
                                    values['tribal_dominance_confidence']

        adjusted_individual_dignity = values['individual_dignity'] * \
                                      values['individual_dignity_salience'] * \
                                      values['individual_dignity_confidence']

        # Calculate identity tension as the product of the two adjusted dimension scores
        identity_tension_score = adjusted_tribal_dominance * adjusted_individual_dignity

        # Return the result as a standard Python float
        return float(identity_tension_score)

    except Exception:
        # Catch any other exceptions (e.g., type conversion errors for non-numeric data)
        return None

def calculate_emotional_balance(data, **kwargs):
    """
    Calculate emotional_balance: Difference between hope and fear scores

    Formula: emotional_balance = hope - fear
    
    Args:
        data: pandas Series representing a single row of the DataFrame with dimension scores.
              Expected to contain 'hope' and 'fear' keys.
        **kwargs: Additional parameters (not used in this calculation).
        
    Returns:
        float: Calculated emotional balance score (hope - fear).
               Returns None if 'hope' or 'fear' scores are missing, not numeric, or NaN.
    """
    import pandas as pd
    import numpy as np # numpy is imported by default in the template, though not strictly needed here for pd.isna

    try:
        # Access the 'hope' and 'fear' scores from the data Series
        # Using .get() ensures that if a key is missing, it returns None,
        # which is then handled by pd.isna().
        hope_score = data.get('hope')
        fear_score = data.get('fear')
        
        # Check for missing values (None or NaN) or non-numeric types
        # pd.isna handles both None and np.nan
        if pd.isna(hope_score) or pd.isna(fear_score):
            return None
        
        # Explicitly check if the retrieved values are numeric (float or int)
        if not isinstance(hope_score, (int, float)) or not isinstance(fear_score, (int, float)):
            return None

        # Perform the calculation: Difference between hope and fear scores
        emotional_balance_score = hope_score - fear_score
        
        return float(emotional_balance_score)
        
    except Exception:
        # Catch any unexpected errors during processing (e.g., data type issues not caught above)
        return None

def calculate_success_climate(data, **kwargs):
    """
    Calculate success_climate: Difference between compassion and envy scores.
    
    Formula: `compassion - envy`
    
    Note: The framework's description used 'compersion', but based on the
    provided 'ACTUAL DATA STRUCTURE', 'compassion' is used as its equivalent.
    
    Args:
        data: A pandas Series or single-row DataFrame containing the 'compassion'
              and 'envy' scores.
        **kwargs: Additional parameters (not used in this calculation but part of the
                  framework's signature).
        
    Returns:
        float: The calculated `success_climate` score. Returns None if 'compassion'
               or 'envy' scores are missing, non-numeric, or NaN.
    """
    import pandas as pd
    import numpy as np # Included as per template, though pd.isna is used for robustness
    
    try:
        # Attempt to extract 'compassion' and 'envy' values.
        # If 'data' is a Series, data['column_name'] directly gives the scalar.
        # If 'data' is a single-row DataFrame, data['column_name'] gives a Series of length 1,
        # so .iloc[0] is used to extract the scalar value.
        
        # Accessing directly will raise KeyError if columns don't exist.
        compassion_series_or_scalar = data['compassion']
        envy_series_or_scalar = data['envy']

        # Convert to scalar if the extracted value is a pandas Series
        # (which happens if 'data' was a single-row DataFrame)
        if isinstance(compassion_series_or_scalar, pd.Series):
            if len(compassion_series_or_scalar) == 0:
                return None # Empty Series means no valid data
            compassion_score = compassion_series_or_scalar.iloc[0]
        else:
            compassion_score = compassion_series_or_scalar # Already a scalar
            
        if isinstance(envy_series_or_scalar, pd.Series):
            if len(envy_series_or_scalar) == 0:
                return None # Empty Series means no valid data
            envy_score = envy_series_or_scalar.iloc[0]
        else:
            envy_score = envy_series_or_scalar # Already a scalar

        # Check for NaN values or non-numeric types using pandas.isna and numeric type check
        # pd.isna handles None, np.nan, and pd.NA consistently.
        if pd.isna(compassion_score) or not pd.api.types.is_numeric_dtype(type(compassion_score)):
            return None
        if pd.isna(envy_score) or not pd.api.types.is_numeric_dtype(type(envy_score)):
            return None
            
        # Perform the calculation: compassion - envy
        result = float(compassion_score - envy_score)
        
        return result
        
    except KeyError:
        # One of the required columns ('compassion' or 'envy') was not found in 'data'.
        return None
    except TypeError:
        # This might occur if, despite checks, non-numeric data slipped through
        # or data structure was unexpected during subtraction.
        return None
    except Exception:
        # Catch any other unexpected errors during processing.
        return None

def calculate_relational_climate(data, **kwargs):
    """
    Calculate relational_climate: Difference between amity and enmity scores

    Formula: relational_climate = amity - enmity

    Args:
        data: pandas DataFrame with dimension scores (will be processed as a single row/Series).
        **kwargs: Additional parameters (not used in this calculation but
                  included for framework compatibility).

    Returns:
        float: The calculated relational_climate score.
        None: If 'amity' or 'enmity' scores are missing, non-numeric, or invalid.
    """
    import pandas as pd
    import numpy as np # numpy is imported as per template, though not directly used in this specific calculation

    try:
        # Access 'amity' and 'enmity' scores from the data object.
        # data.get() is used for robust access, returning None if the key doesn't exist.
        amity_score = data.get('amity')
        enmity_score = data.get('enmity')

        # Check if either of the required scores is None or NaN.
        # pd.isna() handles both Python's None and NumPy's np.nan.
        if pd.isna(amity_score) or pd.isna(enmity_score):
            return None

        # Perform the calculation: amity score minus enmity score.
        # Explicitly converting to float ensures the operation is numeric and
        # can help catch non-numeric types that were not caught by pd.isna if any.
        result = float(amity_score) - float(enmity_score)
        return result
    except Exception:
        # Catch any unforeseen errors during data access, type conversion, or calculation.
        return None

def calculate_goal_orientation(data, **kwargs):
    """
    Calculate goal_orientation: Difference between cohesive goals and fragmentative goals
    
    Formula: goal_orientation = cohesive_goals - fragmentative_goals
    
    Args:
        data: pandas Series (representing a single row) with dimension scores.
              Must contain 'cohesive_goals' and 'fragmentative_goals'.
        **kwargs: Additional parameters (not used in this calculation).
        
    Returns:
        float: Calculated result (cohesive_goals - fragmentative_goals) or None if insufficient data.
    """
    import pandas as pd
    import numpy as np # Imported as per skeleton, though not directly used for calculation beyond pd.isna handling

    try:
        # Access the required values from the data Series.
        # Using .get() provides robustness against missing keys, returning None if not found.
        cohesive_goals = data.get('cohesive_goals')
        fragmentative_goals = data.get('fragmentative_goals')

        # Check if either value is None or NaN.
        # pd.isna() handles both Python None and numpy.nan
        if pd.isna(cohesive_goals) or pd.isna(fragmentative_goals):
            return None
        
        # Ensure values are numeric before performing subtraction.
        # The problem description implies float, but this guard adds robustness.
        if not isinstance(cohesive_goals, (int, float)) or not isinstance(fragmentative_goals, (int, float)):
            return None

        # Perform the calculation
        result = float(cohesive_goals - fragmentative_goals)
        
        return result
        
    except Exception:
        # Catch any other unexpected errors during data access or calculation,
        # ensuring graceful failure as required.
        return None

def calculate_overall_cohesion_index(data, **kwargs):
    """
    Calculate overall_cohesion_index: Comprehensive measure combining all dimensions.

    Formula:
    1. For each dimension D (e.g., 'hope', 'fear'), calculate its weighted score:
       `weighted_D = D * D_salience * D_confidence`

    2. Identify positive and negative dimensions:
       `positive_dimensions_base = ['individual_dignity', 'hope', 'compassion', 'amity', 'cohesive_goals']`
       `negative_dimensions_base = ['tribal_dominance', 'fear', 'envy', 'enmity', 'fragmentative_goals']`

    3. Sum the weighted scores for each category:
       `sum_weighted_positive = sum(weighted_D for D in positive_dimensions_base)`
       `sum_weighted_negative = sum(weighted_D for D in negative_dimensions_base)`

    4. Calculate the Overall Cohesion Index:
       `overall_cohesion_index = (sum_weighted_positive - sum_weighted_negative) / (sum_weighted_positive + sum_weighted_negative)`
       The index ranges from -1 (purely fragmentative) to 1 (purely cohesive).

    Args:
        data (pd.Series or pd.DataFrame): A pandas Series representing a single row of scores,
                                         or a pandas DataFrame with a single row.
                                         Must contain all required dimension, salience, and confidence columns.
        **kwargs: Additional parameters (not used in this calculation).

    Returns:
        float: Calculated overall cohesion index, ranging from -1 to 1.
               Returns None if any required data is missing, NaN, or if the denominator for the
               final calculation is zero.
    """
    import pandas as pd
    import numpy as np
    
    try:
        # Ensure data is treated as a Series if it's a single-row DataFrame
        if isinstance(data, pd.DataFrame):
            if len(data) == 1:
                data = data.iloc[0]
            else:
                # If it's a multi-row DataFrame, return None as per single row/Series expectation.
                return None
        elif not isinstance(data, pd.Series):
            # If not a Series or DataFrame, it's invalid input
            return None

        positive_dims_base = ['individual_dignity', 'hope', 'compassion', 'amity', 'cohesive_goals']
        negative_dims_base = ['tribal_dominance', 'fear', 'envy', 'enmity', 'fragmentative_goals']

        all_dims_base = positive_dims_base + negative_dims_base
        
        required_cols = []
        for dim_base in all_dims_base:
            required_cols.append(dim_base)
            required_cols.append(f"{dim_base}_salience")
            required_cols.append(f"{dim_base}_confidence")
        
        # Check for presence of all required columns and for any NaN values within them
        for col in required_cols:
            if col not in data.index:
                return None  # Missing column
            if pd.isna(data[col]):
                return None  # NaN value in a required column
            
        sum_weighted_positive = 0.0
        for dim_base in positive_dims_base:
            value = data[dim_base]
            salience = data[f"{dim_base}_salience"]
            confidence = data[f"{dim_base}_confidence"]
            sum_weighted_positive += (value * salience * confidence)

        sum_weighted_negative = 0.0
        for dim_base in negative_dims_base:
            value = data[dim_base]
            salience = data[f"{dim_base}_salience"]
            confidence = data[f"{dim_base}_confidence"]
            sum_weighted_negative += (value * salience * confidence)
            
        denominator = sum_weighted_positive + sum_weighted_negative

        # Denominator should always be positive given the data ranges (all positive values for
        # base, salience, and confidence), but handle defensively against division by zero.
        if denominator == 0:
            return None
            
        overall_cohesion_index = (sum_weighted_positive - sum_weighted_negative) / denominator
        
        return overall_cohesion_index
        
    except Exception:
        # Catch any other unexpected errors, such as non-numeric data that wasn't caught by isna.
        return None

def calculate_all_derived_metrics(data: pd.DataFrame) -> Dict[str, Optional[float]]:
    """
    Calculate all derived metrics for the given dataset.
    
    Args:
        data: pandas DataFrame with dimension scores
        
    Returns:
        Dictionary mapping metric names to calculated values
    """
    results = {}
    
    # Get all calculation functions from this module
    import inspect
    current_module = inspect.getmodule(inspect.currentframe())
    
    for name, obj in inspect.getmembers(current_module):
        if (inspect.isfunction(obj) and 
            name.startswith('calculate_') and 
            name not in ['calculate_all_derived_metrics', 'calculate_derived_metrics']):
            try:
                results[name.replace('calculate_', '')] = obj(data)
            except Exception as e:
                results[name.replace('calculate_', '')] = None
                
    return results


def calculate_derived_metrics(data: pd.DataFrame) -> pd.DataFrame:
    """
    Template-compatible wrapper function for derived metrics calculation.
    
    This function is called by the universal notebook template and returns
    the original data with additional derived metric columns.
    
    Args:
        data: pandas DataFrame with dimension scores
        
    Returns:
        DataFrame with original data plus derived metric columns
    """
    # Calculate all derived metrics
    derived_metrics = calculate_all_derived_metrics(data)
    
    # Create a copy of the original data
    result = data.copy()
    
    # Add derived metrics as new columns
    for metric_name, metric_value in derived_metrics.items():
        if metric_value is not None:
            # For scalar metrics, broadcast to all rows
            result[metric_name] = metric_value
        else:
            # For failed calculations, use NaN
            result[metric_name] = np.nan
    
    return result
